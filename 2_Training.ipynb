{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** The default looks reasonable, although I have some doubts as to whether it makes sense to discard the data around the edge in this case. \n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sthenc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.58s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/414113] Tokenizing captions...\n",
      "[100000/414113] Tokenizing captions...\n",
      "[200000/414113] Tokenizing captions...\n",
      "[300000/414113] Tokenizing captions...\n",
      "[400000/414113] Tokenizing captions...\n",
      "loading annotations into memory...\n",
      "Done (t=0.62s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 897/414113 [00:00<00:46, 8966.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 414113/414113 [00:42<00:00, 9632.66it/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size=1\n",
    "#batch_size=10\n",
    "#batch_size = 64          # batch size, we have 10GB of GPU memory, let's use it\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = False    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size, max_batch_size=batch_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) + list(encoder.bn.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "#optimizer = torch.optim.SGD(params, lr=0.01)\n",
    "\n",
    "# this data is probably pretty sparse, and defaults are probably ok\n",
    "#http://ruder.io/optimizing-gradient-descent/\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Epoch [1/3], Step [100/414113], Loss: 4.3513, Perplexity: 77.57642\n",
      "Epoch [1/3], Step [200/414113], Loss: 4.3346, Perplexity: 76.29593\n",
      "Epoch [1/3], Step [300/414113], Loss: 6.6519, Perplexity: 774.22806\n",
      "Epoch [1/3], Step [400/414113], Loss: 3.2250, Perplexity: 25.15456\n",
      "Epoch [1/3], Step [500/414113], Loss: 3.4006, Perplexity: 29.981674\n",
      "Epoch [1/3], Step [600/414113], Loss: 4.5791, Perplexity: 97.424540\n",
      "Epoch [1/3], Step [700/414113], Loss: 2.3289, Perplexity: 10.26672\n",
      "Epoch [1/3], Step [800/414113], Loss: 4.1594, Perplexity: 64.03570\n",
      "Epoch [1/3], Step [900/414113], Loss: 3.1591, Perplexity: 23.549588\n",
      "Epoch [1/3], Step [1000/414113], Loss: 2.1412, Perplexity: 8.509665\n",
      "Epoch [1/3], Step [1100/414113], Loss: 4.1413, Perplexity: 62.883282\n",
      "Epoch [1/3], Step [1200/414113], Loss: 4.0120, Perplexity: 55.257608\n",
      "Epoch [1/3], Step [1300/414113], Loss: 3.8427, Perplexity: 46.64904\n",
      "Epoch [1/3], Step [1400/414113], Loss: 3.7261, Perplexity: 41.51733\n",
      "Epoch [1/3], Step [1500/414113], Loss: 4.6860, Perplexity: 108.4147\n",
      "Epoch [1/3], Step [1600/414113], Loss: 3.3633, Perplexity: 28.88551\n",
      "Epoch [1/3], Step [1700/414113], Loss: 4.0611, Perplexity: 58.03830\n",
      "Epoch [1/3], Step [1800/414113], Loss: 2.1831, Perplexity: 8.873843\n",
      "Epoch [1/3], Step [1900/414113], Loss: 5.1806, Perplexity: 177.7867\n",
      "Epoch [1/3], Step [2000/414113], Loss: 4.0124, Perplexity: 55.278634\n",
      "Epoch [1/3], Step [2100/414113], Loss: 2.5838, Perplexity: 13.24776\n",
      "Epoch [1/3], Step [2200/414113], Loss: 3.4522, Perplexity: 31.57111\n",
      "Epoch [1/3], Step [2300/414113], Loss: 2.2218, Perplexity: 9.2239465\n",
      "Epoch [1/3], Step [2400/414113], Loss: 2.4475, Perplexity: 11.55986\n",
      "Epoch [1/3], Step [2500/414113], Loss: 2.7012, Perplexity: 14.89835\n",
      "Epoch [1/3], Step [2600/414113], Loss: 2.9513, Perplexity: 19.13090\n",
      "Epoch [1/3], Step [2700/414113], Loss: 3.8774, Perplexity: 48.297371\n",
      "Epoch [1/3], Step [2800/414113], Loss: 2.7061, Perplexity: 14.97060\n",
      "Epoch [1/3], Step [2900/414113], Loss: 3.0487, Perplexity: 21.08840\n",
      "Epoch [1/3], Step [3000/414113], Loss: 3.7494, Perplexity: 42.49690\n",
      "Epoch [1/3], Step [3100/414113], Loss: 3.4554, Perplexity: 31.67087\n",
      "Epoch [1/3], Step [3200/414113], Loss: 2.7122, Perplexity: 15.061998\n",
      "Epoch [1/3], Step [3300/414113], Loss: 2.9899, Perplexity: 19.884206\n",
      "Epoch [1/3], Step [3400/414113], Loss: 2.5555, Perplexity: 12.87828\n",
      "Epoch [1/3], Step [3500/414113], Loss: 1.8390, Perplexity: 6.290345\n",
      "Epoch [1/3], Step [3600/414113], Loss: 2.4414, Perplexity: 11.48937\n",
      "Epoch [1/3], Step [3700/414113], Loss: 3.5192, Perplexity: 33.75738\n",
      "Epoch [1/3], Step [3800/414113], Loss: 5.3507, Perplexity: 210.7613\n",
      "Epoch [1/3], Step [3900/414113], Loss: 1.7509, Perplexity: 5.759634\n",
      "Epoch [1/3], Step [4000/414113], Loss: 3.8214, Perplexity: 45.668591\n",
      "Epoch [1/3], Step [4100/414113], Loss: 3.1142, Perplexity: 22.514369\n",
      "Epoch [1/3], Step [4200/414113], Loss: 4.6574, Perplexity: 105.3647\n",
      "Epoch [1/3], Step [4300/414113], Loss: 2.5810, Perplexity: 13.21034\n",
      "Epoch [1/3], Step [4400/414113], Loss: 3.8813, Perplexity: 48.48718\n",
      "Epoch [1/3], Step [4500/414113], Loss: 3.2324, Perplexity: 25.34033\n",
      "Epoch [1/3], Step [4600/414113], Loss: 3.6796, Perplexity: 39.63146\n",
      "Epoch [1/3], Step [4700/414113], Loss: 3.3990, Perplexity: 29.93566\n",
      "Epoch [1/3], Step [4800/414113], Loss: 3.3281, Perplexity: 27.884758\n",
      "Epoch [1/3], Step [4900/414113], Loss: 2.5596, Perplexity: 12.93102\n",
      "Epoch [1/3], Step [5000/414113], Loss: 5.0400, Perplexity: 154.4700\n",
      "Epoch [1/3], Step [5100/414113], Loss: 2.9215, Perplexity: 18.56930\n",
      "Epoch [1/3], Step [5200/414113], Loss: 2.0075, Perplexity: 7.4448109\n",
      "Epoch [1/3], Step [5300/414113], Loss: 3.1810, Perplexity: 24.07114\n",
      "Epoch [1/3], Step [5400/414113], Loss: 3.5701, Perplexity: 35.51865\n",
      "Epoch [1/3], Step [5500/414113], Loss: 4.2612, Perplexity: 70.894849\n",
      "Epoch [1/3], Step [5600/414113], Loss: 3.1880, Perplexity: 24.23882\n",
      "Epoch [1/3], Step [5700/414113], Loss: 3.0442, Perplexity: 20.99362\n",
      "Epoch [1/3], Step [5800/414113], Loss: 3.1948, Perplexity: 24.40502\n",
      "Epoch [1/3], Step [5900/414113], Loss: 3.8809, Perplexity: 48.46789\n",
      "Epoch [1/3], Step [6000/414113], Loss: 4.7455, Perplexity: 115.0635\n",
      "Epoch [1/3], Step [6100/414113], Loss: 5.4076, Perplexity: 223.0958\n",
      "Epoch [1/3], Step [6200/414113], Loss: 3.0376, Perplexity: 20.85573\n",
      "Epoch [1/3], Step [6300/414113], Loss: 3.4191, Perplexity: 30.54222\n",
      "Epoch [1/3], Step [6400/414113], Loss: 5.3435, Perplexity: 209.23674\n",
      "Epoch [1/3], Step [6500/414113], Loss: 3.2120, Perplexity: 24.82762\n",
      "Epoch [1/3], Step [6600/414113], Loss: 2.1826, Perplexity: 8.8693420\n",
      "Epoch [1/3], Step [6700/414113], Loss: 5.0757, Perplexity: 160.0817\n",
      "Epoch [1/3], Step [6800/414113], Loss: 3.7313, Perplexity: 41.73412\n",
      "Epoch [1/3], Step [6900/414113], Loss: 4.8594, Perplexity: 128.9479\n",
      "Epoch [1/3], Step [7000/414113], Loss: 2.6296, Perplexity: 13.868493\n",
      "Epoch [1/3], Step [7100/414113], Loss: 1.8130, Perplexity: 6.128611\n",
      "Epoch [1/3], Step [7200/414113], Loss: 3.0783, Perplexity: 21.72082\n",
      "Epoch [1/3], Step [7300/414113], Loss: 5.2727, Perplexity: 194.9362\n",
      "Epoch [1/3], Step [7400/414113], Loss: 4.7093, Perplexity: 110.9800\n",
      "Epoch [1/3], Step [7500/414113], Loss: 3.7629, Perplexity: 43.07219\n",
      "Epoch [1/3], Step [7600/414113], Loss: 3.0124, Perplexity: 20.33550\n",
      "Epoch [1/3], Step [7700/414113], Loss: 4.0494, Perplexity: 57.362274\n",
      "Epoch [1/3], Step [7800/414113], Loss: 2.9037, Perplexity: 18.242381\n",
      "Epoch [1/3], Step [7900/414113], Loss: 1.5240, Perplexity: 4.590677\n",
      "Epoch [1/3], Step [8000/414113], Loss: 2.4366, Perplexity: 11.434447\n",
      "Epoch [1/3], Step [8100/414113], Loss: 2.3588, Perplexity: 10.57852\n",
      "Epoch [1/3], Step [8200/414113], Loss: 3.9980, Perplexity: 54.48988\n",
      "Epoch [1/3], Step [8300/414113], Loss: 4.9733, Perplexity: 144.5094\n",
      "Epoch [1/3], Step [8400/414113], Loss: 4.0430, Perplexity: 56.99785\n",
      "Epoch [1/3], Step [8500/414113], Loss: 2.8769, Perplexity: 17.75942\n",
      "Epoch [1/3], Step [8600/414113], Loss: 3.1926, Perplexity: 24.35132\n",
      "Epoch [1/3], Step [8700/414113], Loss: 2.0421, Perplexity: 7.706753\n",
      "Epoch [1/3], Step [8800/414113], Loss: 3.6119, Perplexity: 37.03775\n",
      "Epoch [1/3], Step [8900/414113], Loss: 2.3665, Perplexity: 10.65960\n",
      "Epoch [1/3], Step [9000/414113], Loss: 3.9612, Perplexity: 52.522232\n",
      "Epoch [1/3], Step [9100/414113], Loss: 5.7403, Perplexity: 311.1532\n",
      "Epoch [1/3], Step [9200/414113], Loss: 2.4098, Perplexity: 11.131921\n",
      "Epoch [1/3], Step [9300/414113], Loss: 3.8472, Perplexity: 46.86205\n",
      "Epoch [1/3], Step [9400/414113], Loss: 3.1814, Perplexity: 24.081620\n",
      "Epoch [1/3], Step [9500/414113], Loss: 3.0104, Perplexity: 20.29456\n",
      "Epoch [1/3], Step [9600/414113], Loss: 4.5342, Perplexity: 93.14921\n",
      "Epoch [1/3], Step [9700/414113], Loss: 3.6983, Perplexity: 40.37682\n",
      "Epoch [1/3], Step [9800/414113], Loss: 1.6040, Perplexity: 4.972762\n",
      "Epoch [1/3], Step [9900/414113], Loss: 1.8870, Perplexity: 6.599490\n",
      "Epoch [1/3], Step [10000/414113], Loss: 4.4980, Perplexity: 89.8355\n",
      "Epoch [1/3], Step [10100/414113], Loss: 4.2517, Perplexity: 70.22774\n",
      "Epoch [1/3], Step [10200/414113], Loss: 3.7348, Perplexity: 41.881663\n",
      "Epoch [1/3], Step [10300/414113], Loss: 2.6790, Perplexity: 14.57123\n",
      "Epoch [1/3], Step [10400/414113], Loss: 5.3034, Perplexity: 201.02073\n",
      "Epoch [1/3], Step [10500/414113], Loss: 3.8143, Perplexity: 45.344834\n",
      "Epoch [1/3], Step [10600/414113], Loss: 5.2776, Perplexity: 195.8994\n",
      "Epoch [1/3], Step [10700/414113], Loss: 5.1614, Perplexity: 174.4005\n",
      "Epoch [1/3], Step [10800/414113], Loss: 6.4315, Perplexity: 621.1087\n",
      "Epoch [1/3], Step [10900/414113], Loss: 2.1016, Perplexity: 8.1796545\n",
      "Epoch [1/3], Step [11000/414113], Loss: 2.0239, Perplexity: 7.5674325\n",
      "Epoch [1/3], Step [11100/414113], Loss: 3.6104, Perplexity: 36.98165\n",
      "Epoch [1/3], Step [11200/414113], Loss: 1.5506, Perplexity: 4.714398\n",
      "Epoch [1/3], Step [11300/414113], Loss: 1.7162, Perplexity: 5.563312\n",
      "Epoch [1/3], Step [11400/414113], Loss: 4.4569, Perplexity: 86.222647\n",
      "Epoch [1/3], Step [11500/414113], Loss: 2.3643, Perplexity: 10.63649\n",
      "Epoch [1/3], Step [11600/414113], Loss: 5.9915, Perplexity: 400.0130\n",
      "Epoch [1/3], Step [11700/414113], Loss: 5.6304, Perplexity: 278.7826\n",
      "Epoch [1/3], Step [11800/414113], Loss: 2.3331, Perplexity: 10.309932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [11900/414113], Loss: 4.7725, Perplexity: 118.2184\n",
      "Epoch [1/3], Step [12000/414113], Loss: 2.8794, Perplexity: 17.80334\n",
      "Epoch [1/3], Step [12100/414113], Loss: 2.1564, Perplexity: 8.640272\n",
      "Epoch [1/3], Step [12200/414113], Loss: 4.8060, Perplexity: 122.2436\n",
      "Epoch [1/3], Step [12300/414113], Loss: 3.6914, Perplexity: 40.10197\n",
      "Epoch [1/3], Step [12400/414113], Loss: 1.7758, Perplexity: 5.9051643\n",
      "Epoch [1/3], Step [12500/414113], Loss: 2.3350, Perplexity: 10.32935\n",
      "Epoch [1/3], Step [12600/414113], Loss: 3.3156, Perplexity: 27.53829\n",
      "Epoch [1/3], Step [12700/414113], Loss: 1.9988, Perplexity: 7.3801384\n",
      "Epoch [1/3], Step [12800/414113], Loss: 4.6792, Perplexity: 107.6831\n",
      "Epoch [1/3], Step [12900/414113], Loss: 2.1044, Perplexity: 8.202141\n",
      "Epoch [1/3], Step [13000/414113], Loss: 3.2356, Perplexity: 25.42123\n",
      "Epoch [1/3], Step [13100/414113], Loss: 4.0272, Perplexity: 56.102916\n",
      "Epoch [1/3], Step [13200/414113], Loss: 4.4786, Perplexity: 88.108209\n",
      "Epoch [1/3], Step [13300/414113], Loss: 3.5159, Perplexity: 33.647414\n",
      "Epoch [1/3], Step [13400/414113], Loss: 3.0477, Perplexity: 21.06648\n",
      "Epoch [1/3], Step [13500/414113], Loss: 4.7412, Perplexity: 114.5715\n",
      "Epoch [1/3], Step [13600/414113], Loss: 4.4970, Perplexity: 89.744978\n",
      "Epoch [1/3], Step [13700/414113], Loss: 4.3679, Perplexity: 78.87824\n",
      "Epoch [1/3], Step [13800/414113], Loss: 5.2962, Perplexity: 199.5759\n",
      "Epoch [1/3], Step [13900/414113], Loss: 3.3553, Perplexity: 28.65394\n",
      "Epoch [1/3], Step [14000/414113], Loss: 4.2704, Perplexity: 71.55028\n",
      "Epoch [1/3], Step [14100/414113], Loss: 2.3838, Perplexity: 10.846124\n",
      "Epoch [1/3], Step [14200/414113], Loss: 2.7683, Perplexity: 15.93160\n",
      "Epoch [1/3], Step [14300/414113], Loss: 3.8349, Perplexity: 46.28703\n",
      "Epoch [1/3], Step [14400/414113], Loss: 3.1626, Perplexity: 23.63129\n",
      "Epoch [1/3], Step [14500/414113], Loss: 2.9226, Perplexity: 18.58901\n",
      "Epoch [1/3], Step [14600/414113], Loss: 1.4868, Perplexity: 4.422749\n",
      "Epoch [1/3], Step [14700/414113], Loss: 2.5749, Perplexity: 13.13050\n",
      "Epoch [1/3], Step [14800/414113], Loss: 2.2054, Perplexity: 9.073696\n",
      "Epoch [1/3], Step [14900/414113], Loss: 5.4709, Perplexity: 237.6653\n",
      "Epoch [1/3], Step [15000/414113], Loss: 5.5433, Perplexity: 255.5108\n",
      "Epoch [1/3], Step [15100/414113], Loss: 2.5354, Perplexity: 12.62109\n",
      "Epoch [1/3], Step [15200/414113], Loss: 3.6786, Perplexity: 39.59034\n",
      "Epoch [1/3], Step [15300/414113], Loss: 3.0898, Perplexity: 21.97259\n",
      "Epoch [1/3], Step [15400/414113], Loss: 2.2083, Perplexity: 9.100649\n",
      "Epoch [1/3], Step [15500/414113], Loss: 2.0915, Perplexity: 8.0967862\n",
      "Epoch [1/3], Step [15600/414113], Loss: 2.3223, Perplexity: 10.19953\n",
      "Epoch [1/3], Step [15700/414113], Loss: 1.8759, Perplexity: 6.5267560\n",
      "Epoch [1/3], Step [15800/414113], Loss: 4.9290, Perplexity: 138.2347\n",
      "Epoch [1/3], Step [15900/414113], Loss: 3.3919, Perplexity: 29.72225\n",
      "Epoch [1/3], Step [16000/414113], Loss: 4.4016, Perplexity: 81.577325\n",
      "Epoch [1/3], Step [16100/414113], Loss: 2.9667, Perplexity: 19.42768\n",
      "Epoch [1/3], Step [16200/414113], Loss: 2.2120, Perplexity: 9.133694\n",
      "Epoch [1/3], Step [16300/414113], Loss: 4.0959, Perplexity: 60.090702\n",
      "Epoch [1/3], Step [16400/414113], Loss: 3.1043, Perplexity: 22.29475\n",
      "Epoch [1/3], Step [16500/414113], Loss: 6.0150, Perplexity: 409.50598\n",
      "Epoch [1/3], Step [16600/414113], Loss: 1.5392, Perplexity: 4.6610204\n",
      "Epoch [1/3], Step [16700/414113], Loss: 4.1734, Perplexity: 64.93358\n",
      "Epoch [1/3], Step [16800/414113], Loss: 1.7106, Perplexity: 5.532486.6277\n",
      "Epoch [1/3], Step [16900/414113], Loss: 1.9510, Perplexity: 7.0359749\n",
      "Epoch [1/3], Step [17000/414113], Loss: 2.3737, Perplexity: 10.73738\n",
      "Epoch [1/3], Step [17100/414113], Loss: 2.8432, Perplexity: 17.16996\n",
      "Epoch [1/3], Step [17200/414113], Loss: 3.1388, Perplexity: 23.07565\n",
      "Epoch [1/3], Step [17300/414113], Loss: 2.9461, Perplexity: 19.03254\n",
      "Epoch [1/3], Step [17400/414113], Loss: 2.8953, Perplexity: 18.08860\n",
      "Epoch [1/3], Step [17500/414113], Loss: 4.0878, Perplexity: 59.61018\n",
      "Epoch [1/3], Step [17600/414113], Loss: 4.1204, Perplexity: 61.585162\n",
      "Epoch [1/3], Step [17700/414113], Loss: 3.9089, Perplexity: 49.84582\n",
      "Epoch [1/3], Step [17800/414113], Loss: 3.5799, Perplexity: 35.87128\n",
      "Epoch [1/3], Step [17900/414113], Loss: 4.5129, Perplexity: 91.190089\n",
      "Epoch [1/3], Step [18000/414113], Loss: 1.6348, Perplexity: 5.128416\n",
      "Epoch [1/3], Step [18100/414113], Loss: 2.5236, Perplexity: 12.47361\n",
      "Epoch [1/3], Step [18200/414113], Loss: 3.1739, Perplexity: 23.901177\n",
      "Epoch [1/3], Step [18300/414113], Loss: 5.3405, Perplexity: 208.6173\n",
      "Epoch [1/3], Step [18400/414113], Loss: 1.5776, Perplexity: 4.8433857\n",
      "Epoch [1/3], Step [18500/414113], Loss: 3.5979, Perplexity: 36.521516\n",
      "Epoch [1/3], Step [18600/414113], Loss: 2.4018, Perplexity: 11.042669\n",
      "Epoch [1/3], Step [18700/414113], Loss: 1.8681, Perplexity: 6.475967\n",
      "Epoch [1/3], Step [18800/414113], Loss: 2.2573, Perplexity: 9.557503\n",
      "Epoch [1/3], Step [18900/414113], Loss: 2.8346, Perplexity: 17.02333\n",
      "Epoch [1/3], Step [19000/414113], Loss: 2.6222, Perplexity: 13.765960\n",
      "Epoch [1/3], Step [19100/414113], Loss: 3.1486, Perplexity: 23.30363\n",
      "Epoch [1/3], Step [19200/414113], Loss: 2.9960, Perplexity: 20.00478\n",
      "Epoch [1/3], Step [19300/414113], Loss: 6.4993, Perplexity: 664.64707\n",
      "Epoch [1/3], Step [19400/414113], Loss: 2.4522, Perplexity: 11.61385\n",
      "Epoch [1/3], Step [19500/414113], Loss: 3.0740, Perplexity: 21.62817\n",
      "Epoch [1/3], Step [19600/414113], Loss: 2.7109, Perplexity: 15.04265\n",
      "Epoch [1/3], Step [19700/414113], Loss: 2.2634, Perplexity: 9.615950\n",
      "Epoch [1/3], Step [19800/414113], Loss: 2.6427, Perplexity: 14.05098\n",
      "Epoch [1/3], Step [19900/414113], Loss: 3.6824, Perplexity: 39.742976\n",
      "Epoch [1/3], Step [20000/414113], Loss: 4.2045, Perplexity: 66.98741\n",
      "Epoch [1/3], Step [20100/414113], Loss: 2.5664, Perplexity: 13.01842\n",
      "Epoch [1/3], Step [20200/414113], Loss: 3.3615, Perplexity: 28.831546\n",
      "Epoch [1/3], Step [20300/414113], Loss: 2.9533, Perplexity: 19.16939\n",
      "Epoch [1/3], Step [20400/414113], Loss: 1.9561, Perplexity: 7.071476\n",
      "Epoch [1/3], Step [20500/414113], Loss: 3.6509, Perplexity: 38.509053\n",
      "Epoch [1/3], Step [20600/414113], Loss: 3.6637, Perplexity: 39.00356\n",
      "Epoch [1/3], Step [20700/414113], Loss: 3.7200, Perplexity: 41.265679\n",
      "Epoch [1/3], Step [20800/414113], Loss: 1.9361, Perplexity: 6.931971\n",
      "Epoch [1/3], Step [20900/414113], Loss: 4.6173, Perplexity: 101.2154\n",
      "Epoch [1/3], Step [21000/414113], Loss: 2.9313, Perplexity: 18.751922\n",
      "Epoch [1/3], Step [21100/414113], Loss: 3.4145, Perplexity: 30.40219\n",
      "Epoch [1/3], Step [21200/414113], Loss: 3.1512, Perplexity: 23.364115\n",
      "Epoch [1/3], Step [21300/414113], Loss: 3.5743, Perplexity: 35.668491\n",
      "Epoch [1/3], Step [21400/414113], Loss: 2.0472, Perplexity: 7.746212\n",
      "Epoch [1/3], Step [21500/414113], Loss: 2.4711, Perplexity: 11.83569\n",
      "Epoch [1/3], Step [21600/414113], Loss: 2.5224, Perplexity: 12.45814\n",
      "Epoch [1/3], Step [21700/414113], Loss: 3.2131, Perplexity: 24.85496\n",
      "Epoch [1/3], Step [21800/414113], Loss: 1.2642, Perplexity: 3.540320\n",
      "Epoch [1/3], Step [21900/414113], Loss: 3.5810, Perplexity: 35.909970\n",
      "Epoch [1/3], Step [22000/414113], Loss: 3.0096, Perplexity: 20.279505\n",
      "Epoch [1/3], Step [22100/414113], Loss: 3.0121, Perplexity: 20.33009\n",
      "Epoch [1/3], Step [22200/414113], Loss: 5.3621, Perplexity: 213.1644\n",
      "Epoch [1/3], Step [22300/414113], Loss: 3.2052, Perplexity: 24.65976\n",
      "Epoch [1/3], Step [22400/414113], Loss: 1.2173, Perplexity: 3.378267\n",
      "Epoch [1/3], Step [22500/414113], Loss: 3.0491, Perplexity: 21.09734\n",
      "Epoch [1/3], Step [22600/414113], Loss: 3.9741, Perplexity: 53.20259\n",
      "Epoch [1/3], Step [22700/414113], Loss: 3.9598, Perplexity: 52.44537\n",
      "Epoch [1/3], Step [22800/414113], Loss: 2.1255, Perplexity: 8.377243\n",
      "Epoch [1/3], Step [22900/414113], Loss: 2.0949, Perplexity: 8.1249952\n",
      "Epoch [1/3], Step [23000/414113], Loss: 3.0196, Perplexity: 20.48357\n",
      "Epoch [1/3], Step [23100/414113], Loss: 3.1047, Perplexity: 22.30341\n",
      "Epoch [1/3], Step [23200/414113], Loss: 2.1105, Perplexity: 8.252467\n",
      "Epoch [1/3], Step [23300/414113], Loss: 1.8681, Perplexity: 6.4760009\n",
      "Epoch [1/3], Step [23400/414113], Loss: 2.7040, Perplexity: 14.93919\n",
      "Epoch [1/3], Step [23500/414113], Loss: 3.8711, Perplexity: 47.99646\n",
      "Epoch [1/3], Step [23600/414113], Loss: 3.8657, Perplexity: 47.736196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [23700/414113], Loss: 2.8627, Perplexity: 17.50943\n",
      "Epoch [1/3], Step [23800/414113], Loss: 4.8929, Perplexity: 133.3422\n",
      "Epoch [1/3], Step [23900/414113], Loss: 2.2793, Perplexity: 9.769876\n",
      "Epoch [1/3], Step [24000/414113], Loss: 2.2804, Perplexity: 9.780571\n",
      "Epoch [1/3], Step [24100/414113], Loss: 2.1963, Perplexity: 8.991702\n",
      "Epoch [1/3], Step [24200/414113], Loss: 1.4156, Perplexity: 4.118957\n",
      "Epoch [1/3], Step [24300/414113], Loss: 2.0429, Perplexity: 7.713102\n",
      "Epoch [1/3], Step [24400/414113], Loss: 4.6592, Perplexity: 105.5464\n",
      "Epoch [1/3], Step [24500/414113], Loss: 2.0119, Perplexity: 7.477531\n",
      "Epoch [1/3], Step [24600/414113], Loss: 3.5662, Perplexity: 35.38278\n",
      "Epoch [1/3], Step [24700/414113], Loss: 4.2369, Perplexity: 69.19644\n",
      "Epoch [1/3], Step [24800/414113], Loss: 2.2214, Perplexity: 9.219834\n",
      "Epoch [1/3], Step [24900/414113], Loss: 6.1331, Perplexity: 460.8695\n",
      "Epoch [1/3], Step [25000/414113], Loss: 2.6839, Perplexity: 14.641808\n",
      "Epoch [1/3], Step [25100/414113], Loss: 2.4573, Perplexity: 11.67351\n",
      "Epoch [1/3], Step [25200/414113], Loss: 0.7579, Perplexity: 2.133841\n",
      "Epoch [1/3], Step [25300/414113], Loss: 4.3361, Perplexity: 76.40591\n",
      "Epoch [1/3], Step [25400/414113], Loss: 4.5106, Perplexity: 90.97740\n",
      "Epoch [1/3], Step [25500/414113], Loss: 3.9446, Perplexity: 51.65356\n",
      "Epoch [1/3], Step [25600/414113], Loss: 2.3469, Perplexity: 10.45351\n",
      "Epoch [1/3], Step [25700/414113], Loss: 2.7885, Perplexity: 16.256357\n",
      "Epoch [1/3], Step [25800/414113], Loss: 2.6728, Perplexity: 14.48074\n",
      "Epoch [1/3], Step [25900/414113], Loss: 2.6479, Perplexity: 14.12391\n",
      "Epoch [1/3], Step [26000/414113], Loss: 2.0252, Perplexity: 7.577736\n",
      "Epoch [1/3], Step [26100/414113], Loss: 2.5315, Perplexity: 12.57176\n",
      "Epoch [1/3], Step [26200/414113], Loss: 3.2859, Perplexity: 26.73233\n",
      "Epoch [1/3], Step [26300/414113], Loss: 2.7253, Perplexity: 15.26142\n",
      "Epoch [1/3], Step [26400/414113], Loss: 2.6351, Perplexity: 13.94506\n",
      "Epoch [1/3], Step [26500/414113], Loss: 6.6223, Perplexity: 751.6814\n",
      "Epoch [1/3], Step [26600/414113], Loss: 2.8366, Perplexity: 17.05697\n",
      "Epoch [1/3], Step [26700/414113], Loss: 3.0479, Perplexity: 21.07036\n",
      "Epoch [1/3], Step [26800/414113], Loss: 6.8203, Perplexity: 916.2682\n",
      "Epoch [1/3], Step [26900/414113], Loss: 4.2003, Perplexity: 66.70321\n",
      "Epoch [1/3], Step [27000/414113], Loss: 3.1310, Perplexity: 22.89770\n",
      "Epoch [1/3], Step [27100/414113], Loss: 4.4622, Perplexity: 86.68161\n",
      "Epoch [1/3], Step [27200/414113], Loss: 3.1211, Perplexity: 22.67169\n",
      "Epoch [1/3], Step [27300/414113], Loss: 3.5866, Perplexity: 36.11007\n",
      "Epoch [1/3], Step [27400/414113], Loss: 3.3608, Perplexity: 28.81306\n",
      "Epoch [1/3], Step [27500/414113], Loss: 4.1790, Perplexity: 65.29898\n",
      "Epoch [1/3], Step [27600/414113], Loss: 3.7546, Perplexity: 42.71838\n",
      "Epoch [1/3], Step [27700/414113], Loss: 3.5454, Perplexity: 34.654937\n",
      "Epoch [1/3], Step [27800/414113], Loss: 3.8109, Perplexity: 45.19074\n",
      "Epoch [1/3], Step [27900/414113], Loss: 1.5776, Perplexity: 4.843422\n",
      "Epoch [1/3], Step [28000/414113], Loss: 2.8877, Perplexity: 17.95149\n",
      "Epoch [1/3], Step [28100/414113], Loss: 2.3376, Perplexity: 10.356626\n",
      "Epoch [1/3], Step [28200/414113], Loss: 3.1629, Perplexity: 23.639223\n",
      "Epoch [1/3], Step [28300/414113], Loss: 2.2945, Perplexity: 9.919926\n",
      "Epoch [1/3], Step [28400/414113], Loss: 2.7725, Perplexity: 15.998697\n",
      "Epoch [1/3], Step [28500/414113], Loss: 3.8413, Perplexity: 46.585315\n",
      "Epoch [1/3], Step [28600/414113], Loss: 2.0533, Perplexity: 7.793682\n",
      "Epoch [1/3], Step [28700/414113], Loss: 4.3253, Perplexity: 75.58541\n",
      "Epoch [1/3], Step [28800/414113], Loss: 1.5434, Perplexity: 4.680328\n",
      "Epoch [1/3], Step [28900/414113], Loss: 3.7888, Perplexity: 44.20234\n",
      "Epoch [1/3], Step [29000/414113], Loss: 4.6020, Perplexity: 99.68622\n",
      "Epoch [1/3], Step [29100/414113], Loss: 1.8514, Perplexity: 6.368978\n",
      "Epoch [1/3], Step [29200/414113], Loss: 4.3226, Perplexity: 75.385648\n",
      "Epoch [1/3], Step [29300/414113], Loss: 2.4872, Perplexity: 12.02743\n",
      "Epoch [1/3], Step [29400/414113], Loss: 3.2299, Perplexity: 25.27819\n",
      "Epoch [1/3], Step [29500/414113], Loss: 2.6957, Perplexity: 14.81644\n",
      "Epoch [1/3], Step [29600/414113], Loss: 2.3563, Perplexity: 10.55181\n",
      "Epoch [1/3], Step [29700/414113], Loss: 3.8205, Perplexity: 45.629058\n",
      "Epoch [1/3], Step [29800/414113], Loss: 3.1718, Perplexity: 23.851351\n",
      "Epoch [1/3], Step [29900/414113], Loss: 4.8874, Perplexity: 132.6050\n",
      "Epoch [1/3], Step [30000/414113], Loss: 2.1412, Perplexity: 8.509205\n",
      "Epoch [1/3], Step [30100/414113], Loss: 3.4524, Perplexity: 31.576415\n",
      "Epoch [1/3], Step [30200/414113], Loss: 4.5119, Perplexity: 91.098941\n",
      "Epoch [1/3], Step [30300/414113], Loss: 2.3689, Perplexity: 10.686167\n",
      "Epoch [1/3], Step [30400/414113], Loss: 2.1232, Perplexity: 8.357535\n",
      "Epoch [1/3], Step [30500/414113], Loss: 1.1912, Perplexity: 3.2909841\n",
      "Epoch [1/3], Step [30600/414113], Loss: 3.0662, Perplexity: 21.45972\n",
      "Epoch [1/3], Step [30700/414113], Loss: 3.0247, Perplexity: 20.58882\n",
      "Epoch [1/3], Step [30800/414113], Loss: 2.5779, Perplexity: 13.169651\n",
      "Epoch [1/3], Step [30900/414113], Loss: 4.0099, Perplexity: 55.13907\n",
      "Epoch [1/3], Step [31000/414113], Loss: 2.0018, Perplexity: 7.4023615\n",
      "Epoch [1/3], Step [31100/414113], Loss: 1.7460, Perplexity: 5.731713\n",
      "Epoch [1/3], Step [31200/414113], Loss: 5.6738, Perplexity: 291.1413\n",
      "Epoch [1/3], Step [31300/414113], Loss: 3.9589, Perplexity: 52.40183\n",
      "Epoch [1/3], Step [31400/414113], Loss: 4.6785, Perplexity: 107.6048\n",
      "Epoch [1/3], Step [31500/414113], Loss: 3.0772, Perplexity: 21.69787\n",
      "Epoch [1/3], Step [31600/414113], Loss: 3.9015, Perplexity: 49.47488\n",
      "Epoch [1/3], Step [31700/414113], Loss: 1.7107, Perplexity: 5.533087\n",
      "Epoch [1/3], Step [31800/414113], Loss: 4.7724, Perplexity: 118.1983\n",
      "Epoch [1/3], Step [31900/414113], Loss: 2.5419, Perplexity: 12.70448\n",
      "Epoch [1/3], Step [32000/414113], Loss: 1.9443, Perplexity: 6.989125\n",
      "Epoch [1/3], Step [32100/414113], Loss: 2.5658, Perplexity: 13.01171\n",
      "Epoch [1/3], Step [32200/414113], Loss: 3.5577, Perplexity: 35.08350\n",
      "Epoch [1/3], Step [32300/414113], Loss: 3.0131, Perplexity: 20.351003\n",
      "Epoch [1/3], Step [32400/414113], Loss: 1.6095, Perplexity: 5.000235\n",
      "Epoch [1/3], Step [32500/414113], Loss: 1.6372, Perplexity: 5.140738\n",
      "Epoch [1/3], Step [32600/414113], Loss: 2.8890, Perplexity: 17.97512\n",
      "Epoch [1/3], Step [32700/414113], Loss: 3.2465, Perplexity: 25.699058\n",
      "Epoch [1/3], Step [32800/414113], Loss: 3.0519, Perplexity: 21.15482\n",
      "Epoch [1/3], Step [32900/414113], Loss: 2.4532, Perplexity: 11.625473\n",
      "Epoch [1/3], Step [33000/414113], Loss: 3.3265, Perplexity: 27.840638\n",
      "Epoch [1/3], Step [33100/414113], Loss: 2.6191, Perplexity: 13.722812\n",
      "Epoch [1/3], Step [33200/414113], Loss: 1.8689, Perplexity: 6.4812624\n",
      "Epoch [1/3], Step [33300/414113], Loss: 2.8053, Perplexity: 16.53150\n",
      "Epoch [1/3], Step [33400/414113], Loss: 3.7700, Perplexity: 43.37894\n",
      "Epoch [1/3], Step [33500/414113], Loss: 3.5483, Perplexity: 34.75310\n",
      "Epoch [1/3], Step [33600/414113], Loss: 2.8721, Perplexity: 17.673895\n",
      "Epoch [1/3], Step [33700/414113], Loss: 4.3537, Perplexity: 77.763361\n",
      "Epoch [1/3], Step [33800/414113], Loss: 2.9861, Perplexity: 19.80841\n",
      "Epoch [1/3], Step [33900/414113], Loss: 4.4125, Perplexity: 82.47175\n",
      "Epoch [1/3], Step [34000/414113], Loss: 4.2078, Perplexity: 67.21010\n",
      "Epoch [1/3], Step [34100/414113], Loss: 2.3385, Perplexity: 10.36578\n",
      "Epoch [1/3], Step [34200/414113], Loss: 2.2881, Perplexity: 9.8565707\n",
      "Epoch [1/3], Step [34300/414113], Loss: 3.1971, Perplexity: 24.462278\n",
      "Epoch [1/3], Step [34400/414113], Loss: 3.2042, Perplexity: 24.63705\n",
      "Epoch [1/3], Step [34500/414113], Loss: 3.0762, Perplexity: 21.675078\n",
      "Epoch [1/3], Step [34600/414113], Loss: 1.7578, Perplexity: 5.799608\n",
      "Epoch [1/3], Step [34700/414113], Loss: 4.5188, Perplexity: 91.72912\n",
      "Epoch [1/3], Step [34800/414113], Loss: 2.0093, Perplexity: 7.4583964\n",
      "Epoch [1/3], Step [34900/414113], Loss: 2.1813, Perplexity: 8.8578139\n",
      "Epoch [1/3], Step [35000/414113], Loss: 2.8601, Perplexity: 17.46354\n",
      "Epoch [1/3], Step [35100/414113], Loss: 1.6675, Perplexity: 5.299028\n",
      "Epoch [1/3], Step [35200/414113], Loss: 1.4580, Perplexity: 4.297389\n",
      "Epoch [1/3], Step [35300/414113], Loss: 3.6921, Perplexity: 40.12936\n",
      "Epoch [1/3], Step [35400/414113], Loss: 3.3763, Perplexity: 29.2630128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [35500/414113], Loss: 4.0291, Perplexity: 56.21107\n",
      "Epoch [1/3], Step [35600/414113], Loss: 1.9061, Perplexity: 6.726612\n",
      "Epoch [1/3], Step [35700/414113], Loss: 4.1940, Perplexity: 66.28479\n",
      "Epoch [1/3], Step [35800/414113], Loss: 4.0062, Perplexity: 54.93849\n",
      "Epoch [1/3], Step [35900/414113], Loss: 2.0657, Perplexity: 7.890435\n",
      "Epoch [1/3], Step [36000/414113], Loss: 1.8206, Perplexity: 6.175817\n",
      "Epoch [1/3], Step [36100/414113], Loss: 4.6938, Perplexity: 109.2637\n",
      "Epoch [1/3], Step [36200/414113], Loss: 1.7664, Perplexity: 5.8498344\n",
      "Epoch [1/3], Step [36300/414113], Loss: 2.7890, Perplexity: 16.26480\n",
      "Epoch [1/3], Step [36400/414113], Loss: 3.7501, Perplexity: 42.525370\n",
      "Epoch [1/3], Step [36500/414113], Loss: 3.5265, Perplexity: 34.00347\n",
      "Epoch [1/3], Step [36600/414113], Loss: 2.1976, Perplexity: 9.003319\n",
      "Epoch [1/3], Step [36700/414113], Loss: 2.3423, Perplexity: 10.40505\n",
      "Epoch [1/3], Step [36800/414113], Loss: 3.8723, Perplexity: 48.05110\n",
      "Epoch [1/3], Step [36900/414113], Loss: 3.7631, Perplexity: 43.08297\n",
      "Epoch [1/3], Step [37000/414113], Loss: 2.7685, Perplexity: 15.934873\n",
      "Epoch [1/3], Step [37100/414113], Loss: 3.8912, Perplexity: 48.969272\n",
      "Epoch [1/3], Step [37200/414113], Loss: 2.7934, Perplexity: 16.335961\n",
      "Epoch [1/3], Step [37300/414113], Loss: 2.7741, Perplexity: 16.02437\n",
      "Epoch [1/3], Step [37400/414113], Loss: 1.5635, Perplexity: 4.775424\n",
      "Epoch [1/3], Step [37500/414113], Loss: 3.6866, Perplexity: 39.90929\n",
      "Epoch [1/3], Step [37600/414113], Loss: 3.6077, Perplexity: 36.881433\n",
      "Epoch [1/3], Step [37700/414113], Loss: 2.2840, Perplexity: 9.815923\n",
      "Epoch [1/3], Step [37800/414113], Loss: 2.8582, Perplexity: 17.43064\n",
      "Epoch [1/3], Step [37900/414113], Loss: 4.6830, Perplexity: 108.09002\n",
      "Epoch [1/3], Step [38000/414113], Loss: 2.3246, Perplexity: 10.222935\n",
      "Epoch [1/3], Step [38100/414113], Loss: 1.9083, Perplexity: 6.7417686\n",
      "Epoch [1/3], Step [38200/414113], Loss: 5.6501, Perplexity: 284.32511\n",
      "Epoch [1/3], Step [38300/414113], Loss: 4.7662, Perplexity: 117.4686\n",
      "Epoch [1/3], Step [38400/414113], Loss: 2.2533, Perplexity: 9.519397\n",
      "Epoch [1/3], Step [38500/414113], Loss: 3.7491, Perplexity: 42.48234\n",
      "Epoch [1/3], Step [38600/414113], Loss: 2.4560, Perplexity: 11.658040\n",
      "Epoch [1/3], Step [38700/414113], Loss: 1.2703, Perplexity: 3.562132\n",
      "Epoch [1/3], Step [38800/414113], Loss: 1.3427, Perplexity: 3.829504\n",
      "Epoch [1/3], Step [38900/414113], Loss: 2.8037, Perplexity: 16.50490\n",
      "Epoch [1/3], Step [39000/414113], Loss: 2.3705, Perplexity: 10.70236\n",
      "Epoch [1/3], Step [39100/414113], Loss: 2.2880, Perplexity: 9.854996\n",
      "Epoch [1/3], Step [39200/414113], Loss: 2.1628, Perplexity: 8.6957293\n",
      "Epoch [1/3], Step [39300/414113], Loss: 4.3628, Perplexity: 78.474432\n",
      "Epoch [1/3], Step [39400/414113], Loss: 1.9021, Perplexity: 6.699769\n",
      "Epoch [1/3], Step [39500/414113], Loss: 2.1659, Perplexity: 8.7227954\n",
      "Epoch [1/3], Step [39600/414113], Loss: 3.0704, Perplexity: 21.550054\n",
      "Epoch [1/3], Step [39700/414113], Loss: 2.8998, Perplexity: 18.169652\n",
      "Epoch [1/3], Step [39800/414113], Loss: 1.7556, Perplexity: 5.7867654\n",
      "Epoch [1/3], Step [39900/414113], Loss: 3.3426, Perplexity: 28.293078\n",
      "Epoch [1/3], Step [40000/414113], Loss: 3.1697, Perplexity: 23.79924\n",
      "Epoch [1/3], Step [40100/414113], Loss: 2.2291, Perplexity: 9.2911429\n",
      "Epoch [1/3], Step [40200/414113], Loss: 3.1933, Perplexity: 24.369027\n",
      "Epoch [1/3], Step [40300/414113], Loss: 2.4927, Perplexity: 12.09400\n",
      "Epoch [1/3], Step [40400/414113], Loss: 1.9901, Perplexity: 7.316511\n",
      "Epoch [1/3], Step [40500/414113], Loss: 2.8506, Perplexity: 17.29747\n",
      "Epoch [1/3], Step [40600/414113], Loss: 1.9051, Perplexity: 6.719870\n",
      "Epoch [1/3], Step [40700/414113], Loss: 2.8142, Perplexity: 16.67910\n",
      "Epoch [1/3], Step [40800/414113], Loss: 3.2952, Perplexity: 26.984172\n",
      "Epoch [1/3], Step [40900/414113], Loss: 4.7129, Perplexity: 111.3793\n",
      "Epoch [1/3], Step [41000/414113], Loss: 2.3977, Perplexity: 10.99776\n",
      "Epoch [1/3], Step [41100/414113], Loss: 3.2364, Perplexity: 25.44151\n",
      "Epoch [1/3], Step [41200/414113], Loss: 3.4306, Perplexity: 30.896791\n",
      "Epoch [1/3], Step [41300/414113], Loss: 2.8358, Perplexity: 17.04463\n",
      "Epoch [1/3], Step [41400/414113], Loss: 3.8908, Perplexity: 48.950843\n",
      "Epoch [1/3], Step [41500/414113], Loss: 3.2787, Perplexity: 26.542255\n",
      "Epoch [1/3], Step [41600/414113], Loss: 1.9857, Perplexity: 7.284353\n",
      "Epoch [1/3], Step [41700/414113], Loss: 2.8729, Perplexity: 17.689100\n",
      "Epoch [1/3], Step [41800/414113], Loss: 3.0853, Perplexity: 21.873953\n",
      "Epoch [1/3], Step [41900/414113], Loss: 2.9788, Perplexity: 19.66406\n",
      "Epoch [1/3], Step [42000/414113], Loss: 3.5671, Perplexity: 35.41538\n",
      "Epoch [1/3], Step [42100/414113], Loss: 4.3905, Perplexity: 80.67896\n",
      "Epoch [1/3], Step [42200/414113], Loss: 4.2143, Perplexity: 67.64435\n",
      "Epoch [1/3], Step [42300/414113], Loss: 3.0400, Perplexity: 20.905717\n",
      "Epoch [1/3], Step [42400/414113], Loss: 2.4163, Perplexity: 11.20442\n",
      "Epoch [1/3], Step [42500/414113], Loss: 3.4645, Perplexity: 31.960932\n",
      "Epoch [1/3], Step [42600/414113], Loss: 4.4461, Perplexity: 85.29653\n",
      "Epoch [1/3], Step [42700/414113], Loss: 1.8769, Perplexity: 6.532965\n",
      "Epoch [1/3], Step [42800/414113], Loss: 4.2250, Perplexity: 68.375564\n",
      "Epoch [1/3], Step [42900/414113], Loss: 2.5872, Perplexity: 13.29317\n",
      "Epoch [1/3], Step [43000/414113], Loss: 2.5439, Perplexity: 12.72988\n",
      "Epoch [1/3], Step [43100/414113], Loss: 3.2281, Perplexity: 25.23133\n",
      "Epoch [1/3], Step [43200/414113], Loss: 4.4430, Perplexity: 85.03046\n",
      "Epoch [1/3], Step [43300/414113], Loss: 3.5572, Perplexity: 35.06494\n",
      "Epoch [1/3], Step [43400/414113], Loss: 4.4396, Perplexity: 84.74104\n",
      "Epoch [1/3], Step [43500/414113], Loss: 1.6136, Perplexity: 5.021022\n",
      "Epoch [1/3], Step [43600/414113], Loss: 2.1379, Perplexity: 8.481552\n",
      "Epoch [1/3], Step [43700/414113], Loss: 1.4855, Perplexity: 4.4173450\n",
      "Epoch [1/3], Step [43800/414113], Loss: 3.0759, Perplexity: 21.66853\n",
      "Epoch [1/3], Step [43900/414113], Loss: 3.4232, Perplexity: 30.66882\n",
      "Epoch [1/3], Step [44000/414113], Loss: 4.0715, Perplexity: 58.64670\n",
      "Epoch [1/3], Step [44100/414113], Loss: 1.8131, Perplexity: 6.129196\n",
      "Epoch [1/3], Step [44200/414113], Loss: 4.0357, Perplexity: 56.58084\n",
      "Epoch [1/3], Step [44300/414113], Loss: 5.6993, Perplexity: 298.65858\n",
      "Epoch [1/3], Step [44400/414113], Loss: 4.4310, Perplexity: 84.014673\n",
      "Epoch [1/3], Step [44500/414113], Loss: 3.1127, Perplexity: 22.48224\n",
      "Epoch [1/3], Step [44600/414113], Loss: 3.4865, Perplexity: 32.67003\n",
      "Epoch [1/3], Step [44700/414113], Loss: 3.6297, Perplexity: 37.70141\n",
      "Epoch [1/3], Step [44800/414113], Loss: 2.4629, Perplexity: 11.73851\n",
      "Epoch [1/3], Step [44900/414113], Loss: 4.2757, Perplexity: 71.92776\n",
      "Epoch [1/3], Step [45000/414113], Loss: 2.8293, Perplexity: 16.934183\n",
      "Epoch [1/3], Step [45100/414113], Loss: 1.8106, Perplexity: 6.113894\n",
      "Epoch [1/3], Step [45200/414113], Loss: 2.2607, Perplexity: 9.589501\n",
      "Epoch [1/3], Step [45300/414113], Loss: 5.1990, Perplexity: 181.09296\n",
      "Epoch [1/3], Step [45400/414113], Loss: 3.0913, Perplexity: 22.00532\n",
      "Epoch [1/3], Step [45500/414113], Loss: 3.5018, Perplexity: 33.17500\n",
      "Epoch [1/3], Step [45600/414113], Loss: 1.8167, Perplexity: 6.151507\n",
      "Epoch [1/3], Step [45700/414113], Loss: 1.8801, Perplexity: 6.554458\n",
      "Epoch [1/3], Step [45800/414113], Loss: 5.4980, Perplexity: 244.2055\n",
      "Epoch [1/3], Step [45900/414113], Loss: 2.7671, Perplexity: 15.913277\n",
      "Epoch [1/3], Step [46000/414113], Loss: 1.9373, Perplexity: 6.940040\n",
      "Epoch [1/3], Step [46100/414113], Loss: 1.7589, Perplexity: 5.8062184\n",
      "Epoch [1/3], Step [46200/414113], Loss: 1.7179, Perplexity: 5.5728838\n",
      "Epoch [1/3], Step [46300/414113], Loss: 6.7159, Perplexity: 825.39523\n",
      "Epoch [1/3], Step [46400/414113], Loss: 4.5347, Perplexity: 93.19993\n",
      "Epoch [1/3], Step [46500/414113], Loss: 2.5848, Perplexity: 13.260394\n",
      "Epoch [1/3], Step [46600/414113], Loss: 2.6092, Perplexity: 13.58783\n",
      "Epoch [1/3], Step [46700/414113], Loss: 5.4445, Perplexity: 231.4922\n",
      "Epoch [1/3], Step [46800/414113], Loss: 3.7981, Perplexity: 44.616603\n",
      "Epoch [1/3], Step [46900/414113], Loss: 1.5328, Perplexity: 4.631237\n",
      "Epoch [1/3], Step [47000/414113], Loss: 5.2970, Perplexity: 199.73020\n",
      "Epoch [1/3], Step [47100/414113], Loss: 3.3665, Perplexity: 28.97713\n",
      "Epoch [1/3], Step [47200/414113], Loss: 6.1010, Perplexity: 446.3016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [47300/414113], Loss: 3.4210, Perplexity: 30.60120\n",
      "Epoch [1/3], Step [47400/414113], Loss: 2.1413, Perplexity: 8.510794\n",
      "Epoch [1/3], Step [47500/414113], Loss: 1.4539, Perplexity: 4.279961\n",
      "Epoch [1/3], Step [47600/414113], Loss: 2.0369, Perplexity: 7.6671051\n",
      "Epoch [1/3], Step [47700/414113], Loss: 3.4676, Perplexity: 32.059769\n",
      "Epoch [1/3], Step [47800/414113], Loss: 4.3956, Perplexity: 81.094573\n",
      "Epoch [1/3], Step [47900/414113], Loss: 3.0944, Perplexity: 22.07299\n",
      "Epoch [1/3], Step [48000/414113], Loss: 4.1755, Perplexity: 65.071406\n",
      "Epoch [1/3], Step [48100/414113], Loss: 4.0709, Perplexity: 58.60932\n",
      "Epoch [1/3], Step [48200/414113], Loss: 3.4318, Perplexity: 30.93191\n",
      "Epoch [1/3], Step [48300/414113], Loss: 2.5234, Perplexity: 12.470674\n",
      "Epoch [1/3], Step [48400/414113], Loss: 4.0181, Perplexity: 55.59287\n",
      "Epoch [1/3], Step [48500/414113], Loss: 2.6766, Perplexity: 14.53516\n",
      "Epoch [1/3], Step [48600/414113], Loss: 3.4671, Perplexity: 32.0427516\n",
      "Epoch [1/3], Step [48700/414113], Loss: 4.4724, Perplexity: 87.568446\n",
      "Epoch [1/3], Step [48800/414113], Loss: 3.0269, Perplexity: 20.633904\n",
      "Epoch [1/3], Step [48900/414113], Loss: 1.6152, Perplexity: 5.029045\n",
      "Epoch [1/3], Step [49000/414113], Loss: 1.6971, Perplexity: 5.458342\n",
      "Epoch [1/3], Step [49100/414113], Loss: 1.9961, Perplexity: 7.3604395\n",
      "Epoch [1/3], Step [49200/414113], Loss: 2.5893, Perplexity: 13.319914\n",
      "Epoch [1/3], Step [49300/414113], Loss: 3.1374, Perplexity: 23.04504\n",
      "Epoch [1/3], Step [49400/414113], Loss: 3.6274, Perplexity: 37.61426\n",
      "Epoch [1/3], Step [49500/414113], Loss: 2.7659, Perplexity: 15.89343\n",
      "Epoch [1/3], Step [49600/414113], Loss: 2.5569, Perplexity: 12.89606\n",
      "Epoch [1/3], Step [49700/414113], Loss: 2.7900, Perplexity: 16.28076\n",
      "Epoch [1/3], Step [49800/414113], Loss: 5.6730, Perplexity: 290.9171\n",
      "Epoch [1/3], Step [49900/414113], Loss: 2.6783, Perplexity: 14.56064\n",
      "Epoch [1/3], Step [50000/414113], Loss: 6.0097, Perplexity: 407.3806\n",
      "Epoch [1/3], Step [50100/414113], Loss: 6.6839, Perplexity: 799.39987\n",
      "Epoch [1/3], Step [50200/414113], Loss: 3.8247, Perplexity: 45.819038\n",
      "Epoch [1/3], Step [50300/414113], Loss: 5.7038, Perplexity: 300.0055\n",
      "Epoch [1/3], Step [50400/414113], Loss: 3.2856, Perplexity: 26.725775\n",
      "Epoch [1/3], Step [50500/414113], Loss: 2.8246, Perplexity: 16.85444\n",
      "Epoch [1/3], Step [50600/414113], Loss: 2.5625, Perplexity: 12.96797\n",
      "Epoch [1/3], Step [50700/414113], Loss: 3.0404, Perplexity: 20.91352\n",
      "Epoch [1/3], Step [50800/414113], Loss: 2.7281, Perplexity: 15.30447\n",
      "Epoch [1/3], Step [50900/414113], Loss: 2.2901, Perplexity: 9.876293\n",
      "Epoch [1/3], Step [51000/414113], Loss: 2.4171, Perplexity: 11.21368\n",
      "Epoch [1/3], Step [51100/414113], Loss: 2.2485, Perplexity: 9.4735795\n",
      "Epoch [1/3], Step [51200/414113], Loss: 2.7493, Perplexity: 15.631698\n",
      "Epoch [1/3], Step [51300/414113], Loss: 3.0201, Perplexity: 20.49263\n",
      "Epoch [1/3], Step [51400/414113], Loss: 3.1803, Perplexity: 24.05451\n",
      "Epoch [1/3], Step [51500/414113], Loss: 3.5627, Perplexity: 35.259274\n",
      "Epoch [1/3], Step [51600/414113], Loss: 1.8611, Perplexity: 6.431031\n",
      "Epoch [1/3], Step [51700/414113], Loss: 1.6661, Perplexity: 5.2916686\n",
      "Epoch [1/3], Step [51800/414113], Loss: 2.1773, Perplexity: 8.822401\n",
      "Epoch [1/3], Step [51900/414113], Loss: 1.3802, Perplexity: 3.975812\n",
      "Epoch [1/3], Step [52000/414113], Loss: 3.3852, Perplexity: 29.525298\n",
      "Epoch [1/3], Step [52100/414113], Loss: 2.6278, Perplexity: 13.843848\n",
      "Epoch [1/3], Step [52200/414113], Loss: 3.5709, Perplexity: 35.54947\n",
      "Epoch [1/3], Step [52300/414113], Loss: 2.9233, Perplexity: 18.60284\n",
      "Epoch [1/3], Step [52400/414113], Loss: 3.6833, Perplexity: 39.77908\n",
      "Epoch [1/3], Step [52500/414113], Loss: 2.6655, Perplexity: 14.37449\n",
      "Epoch [1/3], Step [52600/414113], Loss: 4.7758, Perplexity: 118.60281\n",
      "Epoch [1/3], Step [52700/414113], Loss: 2.9640, Perplexity: 19.37476\n",
      "Epoch [1/3], Step [52800/414113], Loss: 3.6734, Perplexity: 39.38601\n",
      "Epoch [1/3], Step [52900/414113], Loss: 6.3573, Perplexity: 576.7061\n",
      "Epoch [1/3], Step [53000/414113], Loss: 3.3883, Perplexity: 29.614224\n",
      "Epoch [1/3], Step [53100/414113], Loss: 3.3867, Perplexity: 29.56714\n",
      "Epoch [1/3], Step [53200/414113], Loss: 2.3553, Perplexity: 10.54144\n",
      "Epoch [1/3], Step [53300/414113], Loss: 2.3578, Perplexity: 10.56737\n",
      "Epoch [1/3], Step [53400/414113], Loss: 3.9239, Perplexity: 50.59636\n",
      "Epoch [1/3], Step [53500/414113], Loss: 1.4898, Perplexity: 4.4364836\n",
      "Epoch [1/3], Step [53600/414113], Loss: 1.7782, Perplexity: 5.919353\n",
      "Epoch [1/3], Step [53700/414113], Loss: 1.0915, Perplexity: 2.978610\n",
      "Epoch [1/3], Step [53800/414113], Loss: 3.3325, Perplexity: 28.007905\n",
      "Epoch [1/3], Step [53900/414113], Loss: 1.9828, Perplexity: 7.262979\n",
      "Epoch [1/3], Step [54000/414113], Loss: 3.2734, Perplexity: 26.40188\n",
      "Epoch [1/3], Step [54100/414113], Loss: 3.5775, Perplexity: 35.78236\n",
      "Epoch [1/3], Step [54200/414113], Loss: 2.8462, Perplexity: 17.222416\n",
      "Epoch [1/3], Step [54300/414113], Loss: 2.8983, Perplexity: 18.14250\n",
      "Epoch [1/3], Step [54400/414113], Loss: 2.0660, Perplexity: 7.893076\n",
      "Epoch [1/3], Step [54500/414113], Loss: 2.5427, Perplexity: 12.71344\n",
      "Epoch [1/3], Step [54600/414113], Loss: 2.9597, Perplexity: 19.29272\n",
      "Epoch [1/3], Step [54700/414113], Loss: 2.2947, Perplexity: 9.9213783\n",
      "Epoch [1/3], Step [54800/414113], Loss: 3.2588, Perplexity: 26.019321\n",
      "Epoch [1/3], Step [54900/414113], Loss: 2.1674, Perplexity: 8.7352197\n",
      "Epoch [1/3], Step [55000/414113], Loss: 1.4924, Perplexity: 4.4476285\n",
      "Epoch [1/3], Step [55100/414113], Loss: 2.3474, Perplexity: 10.45795\n",
      "Epoch [1/3], Step [55200/414113], Loss: 2.2423, Perplexity: 9.414924\n",
      "Epoch [1/3], Step [55300/414113], Loss: 2.3809, Perplexity: 10.81512\n",
      "Epoch [1/3], Step [55400/414113], Loss: 2.2250, Perplexity: 9.253243\n",
      "Epoch [1/3], Step [55500/414113], Loss: 2.2057, Perplexity: 9.07659565\n",
      "Epoch [1/3], Step [55600/414113], Loss: 3.4180, Perplexity: 30.508697\n",
      "Epoch [1/3], Step [55700/414113], Loss: 1.7105, Perplexity: 5.531900\n",
      "Epoch [1/3], Step [55800/414113], Loss: 2.3308, Perplexity: 10.28602\n",
      "Epoch [1/3], Step [55900/414113], Loss: 2.9092, Perplexity: 18.342464\n",
      "Epoch [1/3], Step [56000/414113], Loss: 4.7069, Perplexity: 110.7086\n",
      "Epoch [1/3], Step [56100/414113], Loss: 2.9379, Perplexity: 18.875695\n",
      "Epoch [1/3], Step [56200/414113], Loss: 4.0584, Perplexity: 57.88185\n",
      "Epoch [1/3], Step [56300/414113], Loss: 2.9809, Perplexity: 19.70639\n",
      "Epoch [1/3], Step [56400/414113], Loss: 3.6723, Perplexity: 39.341905\n",
      "Epoch [1/3], Step [56500/414113], Loss: 3.0882, Perplexity: 21.93794\n",
      "Epoch [1/3], Step [56600/414113], Loss: 1.7471, Perplexity: 5.737870\n",
      "Epoch [1/3], Step [56700/414113], Loss: 2.3808, Perplexity: 10.81331\n",
      "Epoch [1/3], Step [56800/414113], Loss: 2.3338, Perplexity: 10.31682\n",
      "Epoch [1/3], Step [56900/414113], Loss: 3.4057, Perplexity: 30.13482\n",
      "Epoch [1/3], Step [57000/414113], Loss: 2.7173, Perplexity: 15.13968\n",
      "Epoch [1/3], Step [57100/414113], Loss: 1.4497, Perplexity: 4.261964\n",
      "Epoch [1/3], Step [57200/414113], Loss: 2.5059, Perplexity: 12.25490\n",
      "Epoch [1/3], Step [57300/414113], Loss: 4.6587, Perplexity: 105.4950\n",
      "Epoch [1/3], Step [57400/414113], Loss: 3.7590, Perplexity: 42.90652\n",
      "Epoch [1/3], Step [57500/414113], Loss: 4.4437, Perplexity: 85.08805\n",
      "Epoch [1/3], Step [57600/414113], Loss: 3.7960, Perplexity: 44.52355\n",
      "Epoch [1/3], Step [57700/414113], Loss: 2.4542, Perplexity: 11.637781\n",
      "Epoch [1/3], Step [57800/414113], Loss: 2.0624, Perplexity: 7.864607\n",
      "Epoch [1/3], Step [57900/414113], Loss: 1.4816, Perplexity: 4.3998132\n",
      "Epoch [1/3], Step [58000/414113], Loss: 3.3144, Perplexity: 27.50663\n",
      "Epoch [1/3], Step [58100/414113], Loss: 2.7150, Perplexity: 15.10441\n",
      "Epoch [1/3], Step [58200/414113], Loss: 3.0424, Perplexity: 20.954870\n",
      "Epoch [1/3], Step [58300/414113], Loss: 3.1764, Perplexity: 23.96146\n",
      "Epoch [1/3], Step [58400/414113], Loss: 2.0096, Perplexity: 7.4607973\n",
      "Epoch [1/3], Step [58500/414113], Loss: 1.1680, Perplexity: 3.215522\n",
      "Epoch [1/3], Step [58600/414113], Loss: 3.6202, Perplexity: 37.34492\n",
      "Epoch [1/3], Step [58700/414113], Loss: 1.8873, Perplexity: 6.601538\n",
      "Epoch [1/3], Step [58800/414113], Loss: 3.3186, Perplexity: 27.621993\n",
      "Epoch [1/3], Step [58900/414113], Loss: 3.4777, Perplexity: 32.38626\n",
      "Epoch [1/3], Step [59000/414113], Loss: 3.4182, Perplexity: 30.51407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [59100/414113], Loss: 3.5524, Perplexity: 34.89733\n",
      "Epoch [1/3], Step [59200/414113], Loss: 6.2489, Perplexity: 517.42600\n",
      "Epoch [1/3], Step [59300/414113], Loss: 2.2676, Perplexity: 9.655916\n",
      "Epoch [1/3], Step [59400/414113], Loss: 2.2722, Perplexity: 9.700942\n",
      "Epoch [1/3], Step [59500/414113], Loss: 2.8195, Perplexity: 16.768289\n",
      "Epoch [1/3], Step [59600/414113], Loss: 2.1743, Perplexity: 8.7959051\n",
      "Epoch [1/3], Step [59700/414113], Loss: 4.1158, Perplexity: 61.29820\n",
      "Epoch [1/3], Step [59800/414113], Loss: 2.5413, Perplexity: 12.696016\n",
      "Epoch [1/3], Step [59900/414113], Loss: 1.8074, Perplexity: 6.0949450\n",
      "Epoch [1/3], Step [60000/414113], Loss: 4.2455, Perplexity: 69.79174\n",
      "Epoch [1/3], Step [60100/414113], Loss: 3.6085, Perplexity: 36.91082\n",
      "Epoch [1/3], Step [60200/414113], Loss: 2.8311, Perplexity: 16.96418\n",
      "Epoch [1/3], Step [60300/414113], Loss: 2.0496, Perplexity: 7.7647962\n",
      "Epoch [1/3], Step [60400/414113], Loss: 2.4180, Perplexity: 11.223278\n",
      "Epoch [1/3], Step [60500/414113], Loss: 1.6566, Perplexity: 5.241719\n",
      "Epoch [1/3], Step [60600/414113], Loss: 2.2393, Perplexity: 9.387211\n",
      "Epoch [1/3], Step [60700/414113], Loss: 2.5120, Perplexity: 12.329128\n",
      "Epoch [1/3], Step [60800/414113], Loss: 3.7917, Perplexity: 44.331107\n",
      "Epoch [1/3], Step [60900/414113], Loss: 6.3800, Perplexity: 589.95677\n",
      "Epoch [1/3], Step [61000/414113], Loss: 3.9636, Perplexity: 52.64739\n",
      "Epoch [1/3], Step [61100/414113], Loss: 2.9821, Perplexity: 19.73008\n",
      "Epoch [1/3], Step [61200/414113], Loss: 3.2791, Perplexity: 26.55308\n",
      "Epoch [1/3], Step [61300/414113], Loss: 2.9810, Perplexity: 19.70697\n",
      "Epoch [1/3], Step [61400/414113], Loss: 2.5513, Perplexity: 12.82404\n",
      "Epoch [1/3], Step [61500/414113], Loss: 3.7779, Perplexity: 43.724008\n",
      "Epoch [1/3], Step [61600/414113], Loss: 2.3244, Perplexity: 10.22039\n",
      "Epoch [1/3], Step [61700/414113], Loss: 1.7213, Perplexity: 5.5920537\n",
      "Epoch [1/3], Step [61800/414113], Loss: 3.8463, Perplexity: 46.818415\n",
      "Epoch [1/3], Step [61900/414113], Loss: 5.5189, Perplexity: 249.3585\n",
      "Epoch [1/3], Step [62000/414113], Loss: 3.3203, Perplexity: 27.66778\n",
      "Epoch [1/3], Step [62100/414113], Loss: 2.9781, Perplexity: 19.64985\n",
      "Epoch [1/3], Step [62200/414113], Loss: 3.0251, Perplexity: 20.59699\n",
      "Epoch [1/3], Step [62300/414113], Loss: 3.7294, Perplexity: 41.652203\n",
      "Epoch [1/3], Step [62400/414113], Loss: 2.0425, Perplexity: 7.710116\n",
      "Epoch [1/3], Step [62500/414113], Loss: 3.2557, Perplexity: 25.93714\n",
      "Epoch [1/3], Step [62600/414113], Loss: 3.6197, Perplexity: 37.32791\n",
      "Epoch [1/3], Step [62700/414113], Loss: 3.8360, Perplexity: 46.340610\n",
      "Epoch [1/3], Step [62800/414113], Loss: 2.0743, Perplexity: 7.9586864\n",
      "Epoch [1/3], Step [62900/414113], Loss: 1.8664, Perplexity: 6.465343\n",
      "Epoch [1/3], Step [63000/414113], Loss: 1.7263, Perplexity: 5.619970\n",
      "Epoch [1/3], Step [63100/414113], Loss: 2.6492, Perplexity: 14.142945\n",
      "Epoch [1/3], Step [63200/414113], Loss: 4.6687, Perplexity: 106.5601\n",
      "Epoch [1/3], Step [63300/414113], Loss: 2.6905, Perplexity: 14.73901\n",
      "Epoch [1/3], Step [63400/414113], Loss: 3.0358, Perplexity: 20.81830\n",
      "Epoch [1/3], Step [63500/414113], Loss: 3.3871, Perplexity: 29.58066\n",
      "Epoch [1/3], Step [63600/414113], Loss: 1.6098, Perplexity: 5.002049\n",
      "Epoch [1/3], Step [63700/414113], Loss: 2.4795, Perplexity: 11.93553\n",
      "Epoch [1/3], Step [63800/414113], Loss: 3.4657, Perplexity: 31.998331\n",
      "Epoch [1/3], Step [63900/414113], Loss: 4.0582, Perplexity: 57.870389\n",
      "Epoch [1/3], Step [64000/414113], Loss: 2.8352, Perplexity: 17.03319\n",
      "Epoch [1/3], Step [64100/414113], Loss: 2.3432, Perplexity: 10.41482\n",
      "Epoch [1/3], Step [64200/414113], Loss: 4.7116, Perplexity: 111.2257\n",
      "Epoch [1/3], Step [64300/414113], Loss: 2.5884, Perplexity: 13.30806\n",
      "Epoch [1/3], Step [64400/414113], Loss: 2.1276, Perplexity: 8.395022\n",
      "Epoch [1/3], Step [64500/414113], Loss: 1.6565, Perplexity: 5.241033\n",
      "Epoch [1/3], Step [64600/414113], Loss: 3.8485, Perplexity: 46.92051\n",
      "Epoch [1/3], Step [64700/414113], Loss: 0.9110, Perplexity: 2.486919\n",
      "Epoch [1/3], Step [64800/414113], Loss: 1.7994, Perplexity: 6.046174\n",
      "Epoch [1/3], Step [64900/414113], Loss: 3.4170, Perplexity: 30.476452\n",
      "Epoch [1/3], Step [65000/414113], Loss: 1.7919, Perplexity: 6.000939\n",
      "Epoch [1/3], Step [65100/414113], Loss: 1.7721, Perplexity: 5.8831387\n",
      "Epoch [1/3], Step [65200/414113], Loss: 2.9716, Perplexity: 19.52296\n",
      "Epoch [1/3], Step [65300/414113], Loss: 3.2370, Perplexity: 25.45784\n",
      "Epoch [1/3], Step [65400/414113], Loss: 2.5143, Perplexity: 12.35813\n",
      "Epoch [1/3], Step [65500/414113], Loss: 2.2414, Perplexity: 9.4065748\n",
      "Epoch [1/3], Step [65600/414113], Loss: 3.9550, Perplexity: 52.194585\n",
      "Epoch [1/3], Step [65700/414113], Loss: 4.1589, Perplexity: 63.998963\n",
      "Epoch [1/3], Step [65800/414113], Loss: 2.6569, Perplexity: 14.25258\n",
      "Epoch [1/3], Step [65900/414113], Loss: 3.4054, Perplexity: 30.12624\n",
      "Epoch [1/3], Step [66000/414113], Loss: 3.7962, Perplexity: 44.52948\n",
      "Epoch [1/3], Step [66100/414113], Loss: 4.2856, Perplexity: 72.64887\n",
      "Epoch [1/3], Step [66200/414113], Loss: 2.6182, Perplexity: 13.711160\n",
      "Epoch [1/3], Step [66300/414113], Loss: 2.0281, Perplexity: 7.5994794\n",
      "Epoch [1/3], Step [66400/414113], Loss: 1.7199, Perplexity: 5.583835\n",
      "Epoch [1/3], Step [66500/414113], Loss: 2.0585, Perplexity: 7.834005\n",
      "Epoch [1/3], Step [66600/414113], Loss: 3.0807, Perplexity: 21.773350\n",
      "Epoch [1/3], Step [66700/414113], Loss: 2.4654, Perplexity: 11.768677\n",
      "Epoch [1/3], Step [66800/414113], Loss: 3.2661, Perplexity: 26.21018\n",
      "Epoch [1/3], Step [66900/414113], Loss: 2.5821, Perplexity: 13.22448\n",
      "Epoch [1/3], Step [67000/414113], Loss: 1.7505, Perplexity: 5.757645\n",
      "Epoch [1/3], Step [67100/414113], Loss: 4.0466, Perplexity: 57.19992\n",
      "Epoch [1/3], Step [67200/414113], Loss: 2.3181, Perplexity: 10.15675\n",
      "Epoch [1/3], Step [67300/414113], Loss: 3.3975, Perplexity: 29.88961\n",
      "Epoch [1/3], Step [67400/414113], Loss: 4.1799, Perplexity: 65.357509\n",
      "Epoch [1/3], Step [67500/414113], Loss: 2.3544, Perplexity: 10.53158\n",
      "Epoch [1/3], Step [67600/414113], Loss: 3.5395, Perplexity: 34.44992\n",
      "Epoch [1/3], Step [67700/414113], Loss: 4.7957, Perplexity: 120.98661\n",
      "Epoch [1/3], Step [67800/414113], Loss: 3.6573, Perplexity: 38.75597\n",
      "Epoch [1/3], Step [67900/414113], Loss: 2.1400, Perplexity: 8.4997081\n",
      "Epoch [1/3], Step [68000/414113], Loss: 4.5784, Perplexity: 97.355811\n",
      "Epoch [1/3], Step [68100/414113], Loss: 1.5716, Perplexity: 4.814179\n",
      "Epoch [1/3], Step [68200/414113], Loss: 3.0995, Perplexity: 22.18682\n",
      "Epoch [1/3], Step [68300/414113], Loss: 3.6320, Perplexity: 37.789058\n",
      "Epoch [1/3], Step [68400/414113], Loss: 3.3934, Perplexity: 29.76729\n",
      "Epoch [1/3], Step [68500/414113], Loss: 1.8881, Perplexity: 6.607028\n",
      "Epoch [1/3], Step [68600/414113], Loss: 3.0739, Perplexity: 21.626867\n",
      "Epoch [1/3], Step [68700/414113], Loss: 4.1370, Perplexity: 62.615795\n",
      "Epoch [1/3], Step [68800/414113], Loss: 3.4239, Perplexity: 30.689910\n",
      "Epoch [1/3], Step [68900/414113], Loss: 2.3618, Perplexity: 10.60951\n",
      "Epoch [1/3], Step [69000/414113], Loss: 2.3193, Perplexity: 10.16868\n",
      "Epoch [1/3], Step [69100/414113], Loss: 2.6600, Perplexity: 14.29705\n",
      "Epoch [1/3], Step [69200/414113], Loss: 2.9122, Perplexity: 18.396889\n",
      "Epoch [1/3], Step [69300/414113], Loss: 3.7467, Perplexity: 42.381209\n",
      "Epoch [1/3], Step [69400/414113], Loss: 3.1625, Perplexity: 23.62892\n",
      "Epoch [1/3], Step [69500/414113], Loss: 4.4710, Perplexity: 87.44214\n",
      "Epoch [1/3], Step [69600/414113], Loss: 1.8807, Perplexity: 6.5582856\n",
      "Epoch [1/3], Step [69700/414113], Loss: 4.7890, Perplexity: 120.1792\n",
      "Epoch [1/3], Step [69800/414113], Loss: 2.6941, Perplexity: 14.79249\n",
      "Epoch [1/3], Step [69900/414113], Loss: 2.9235, Perplexity: 18.60618\n",
      "Epoch [1/3], Step [70000/414113], Loss: 1.6943, Perplexity: 5.443161\n",
      "Epoch [1/3], Step [70100/414113], Loss: 4.3797, Perplexity: 79.817610\n",
      "Epoch [1/3], Step [70200/414113], Loss: 2.6624, Perplexity: 14.33087\n",
      "Epoch [1/3], Step [70300/414113], Loss: 1.3207, Perplexity: 3.746194\n",
      "Epoch [1/3], Step [70400/414113], Loss: 5.3824, Perplexity: 217.5476\n",
      "Epoch [1/3], Step [70500/414113], Loss: 2.5570, Perplexity: 12.89650\n",
      "Epoch [1/3], Step [70600/414113], Loss: 1.4253, Perplexity: 4.159176\n",
      "Epoch [1/3], Step [70700/414113], Loss: 3.8483, Perplexity: 46.91389\n",
      "Epoch [1/3], Step [70800/414113], Loss: 3.8514, Perplexity: 47.05685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [70900/414113], Loss: 4.9213, Perplexity: 137.1852\n",
      "Epoch [1/3], Step [71000/414113], Loss: 3.6872, Perplexity: 39.932108\n",
      "Epoch [1/3], Step [71100/414113], Loss: 1.5305, Perplexity: 4.6203825\n",
      "Epoch [1/3], Step [71200/414113], Loss: 1.8396, Perplexity: 6.293940\n",
      "Epoch [1/3], Step [71300/414113], Loss: 2.0245, Perplexity: 7.572510\n",
      "Epoch [1/3], Step [71400/414113], Loss: 2.7993, Perplexity: 16.433120\n",
      "Epoch [1/3], Step [71500/414113], Loss: 1.6082, Perplexity: 4.993832\n",
      "Epoch [1/3], Step [71600/414113], Loss: 1.4385, Perplexity: 4.214565\n",
      "Epoch [1/3], Step [71700/414113], Loss: 3.4882, Perplexity: 32.72849\n",
      "Epoch [1/3], Step [71800/414113], Loss: 3.6613, Perplexity: 38.910610\n",
      "Epoch [1/3], Step [71900/414113], Loss: 2.0052, Perplexity: 7.4276959\n",
      "Epoch [1/3], Step [72000/414113], Loss: 3.8727, Perplexity: 48.07290\n",
      "Epoch [1/3], Step [72100/414113], Loss: 1.4376, Perplexity: 4.210703\n",
      "Epoch [1/3], Step [72200/414113], Loss: 1.7422, Perplexity: 5.709695\n",
      "Epoch [1/3], Step [72300/414113], Loss: 2.8495, Perplexity: 17.27900\n",
      "Epoch [1/3], Step [72400/414113], Loss: 4.8959, Perplexity: 133.73959\n",
      "Epoch [1/3], Step [72500/414113], Loss: 2.6309, Perplexity: 13.886975\n",
      "Epoch [1/3], Step [72600/414113], Loss: 2.8507, Perplexity: 17.29990\n",
      "Epoch [1/3], Step [72700/414113], Loss: 2.7577, Perplexity: 15.763607\n",
      "Epoch [1/3], Step [72800/414113], Loss: 2.7946, Perplexity: 16.35557\n",
      "Epoch [1/3], Step [72900/414113], Loss: 2.6657, Perplexity: 14.37804\n",
      "Epoch [1/3], Step [73000/414113], Loss: 3.3133, Perplexity: 27.47582\n",
      "Epoch [1/3], Step [73100/414113], Loss: 4.0220, Perplexity: 55.81113\n",
      "Epoch [1/3], Step [73200/414113], Loss: 1.8151, Perplexity: 6.141748\n",
      "Epoch [1/3], Step [73300/414113], Loss: 1.6695, Perplexity: 5.309721\n",
      "Epoch [1/3], Step [73400/414113], Loss: 3.9892, Perplexity: 54.01176\n",
      "Epoch [1/3], Step [73500/414113], Loss: 2.7988, Perplexity: 16.42478\n",
      "Epoch [1/3], Step [73600/414113], Loss: 1.8166, Perplexity: 6.150863\n",
      "Epoch [1/3], Step [73700/414113], Loss: 2.3172, Perplexity: 10.14722\n",
      "Epoch [1/3], Step [73800/414113], Loss: 2.9201, Perplexity: 18.54315\n",
      "Epoch [1/3], Step [73900/414113], Loss: 3.8407, Perplexity: 46.55928\n",
      "Epoch [1/3], Step [74000/414113], Loss: 3.2719, Perplexity: 26.36123\n",
      "Epoch [1/3], Step [74100/414113], Loss: 2.1601, Perplexity: 8.6720320\n",
      "Epoch [1/3], Step [74200/414113], Loss: 3.4276, Perplexity: 30.802229\n",
      "Epoch [1/3], Step [74300/414113], Loss: 1.9030, Perplexity: 6.706259\n",
      "Epoch [1/3], Step [74400/414113], Loss: 1.2316, Perplexity: 3.426755\n",
      "Epoch [1/3], Step [74500/414113], Loss: 2.3461, Perplexity: 10.445006\n",
      "Epoch [1/3], Step [74600/414113], Loss: 3.7788, Perplexity: 43.76524\n",
      "Epoch [1/3], Step [74700/414113], Loss: 2.7612, Perplexity: 15.81945\n",
      "Epoch [1/3], Step [74800/414113], Loss: 4.6486, Perplexity: 104.43683\n",
      "Epoch [1/3], Step [74900/414113], Loss: 4.1336, Perplexity: 62.39978\n",
      "Epoch [1/3], Step [75000/414113], Loss: 2.7232, Perplexity: 15.22960\n",
      "Epoch [1/3], Step [75100/414113], Loss: 2.3433, Perplexity: 10.41551\n",
      "Epoch [1/3], Step [75200/414113], Loss: 1.5608, Perplexity: 4.762425\n",
      "Epoch [1/3], Step [75300/414113], Loss: 1.6013, Perplexity: 4.959448\n",
      "Epoch [1/3], Step [75400/414113], Loss: 2.4185, Perplexity: 11.22912\n",
      "Epoch [1/3], Step [75500/414113], Loss: 2.5777, Perplexity: 13.166468\n",
      "Epoch [1/3], Step [75600/414113], Loss: 2.2920, Perplexity: 9.895179\n",
      "Epoch [1/3], Step [75700/414113], Loss: 5.8707, Perplexity: 354.4955\n",
      "Epoch [1/3], Step [75800/414113], Loss: 2.9956, Perplexity: 19.99778\n",
      "Epoch [1/3], Step [75900/414113], Loss: 1.6103, Perplexity: 5.004209\n",
      "Epoch [1/3], Step [76000/414113], Loss: 2.6108, Perplexity: 13.61036\n",
      "Epoch [1/3], Step [76100/414113], Loss: 4.3866, Perplexity: 80.362955\n",
      "Epoch [1/3], Step [76200/414113], Loss: 2.7761, Perplexity: 16.05636\n",
      "Epoch [1/3], Step [76300/414113], Loss: 5.7273, Perplexity: 307.1496\n",
      "Epoch [1/3], Step [76400/414113], Loss: 1.5758, Perplexity: 4.8346260\n",
      "Epoch [1/3], Step [76500/414113], Loss: 3.0773, Perplexity: 21.70078\n",
      "Epoch [1/3], Step [76600/414113], Loss: 2.9515, Perplexity: 19.13478\n",
      "Epoch [1/3], Step [76700/414113], Loss: 2.1624, Perplexity: 8.6921483\n",
      "Epoch [1/3], Step [76800/414113], Loss: 3.3771, Perplexity: 29.28701\n",
      "Epoch [1/3], Step [76900/414113], Loss: 1.6804, Perplexity: 5.3679474\n",
      "Epoch [1/3], Step [77000/414113], Loss: 2.9382, Perplexity: 18.88106\n",
      "Epoch [1/3], Step [77100/414113], Loss: 4.5989, Perplexity: 99.371619\n",
      "Epoch [1/3], Step [77200/414113], Loss: 3.9216, Perplexity: 50.48335\n",
      "Epoch [1/3], Step [77300/414113], Loss: 3.9345, Perplexity: 51.138264\n",
      "Epoch [1/3], Step [77400/414113], Loss: 3.2839, Perplexity: 26.67918\n",
      "Epoch [1/3], Step [77500/414113], Loss: 4.5085, Perplexity: 90.78449\n",
      "Epoch [1/3], Step [77600/414113], Loss: 2.5078, Perplexity: 12.27855\n",
      "Epoch [1/3], Step [77700/414113], Loss: 2.2727, Perplexity: 9.705950\n",
      "Epoch [1/3], Step [77800/414113], Loss: 2.7754, Perplexity: 16.04492\n",
      "Epoch [1/3], Step [77900/414113], Loss: 3.9839, Perplexity: 53.72567\n",
      "Epoch [1/3], Step [78000/414113], Loss: 3.9816, Perplexity: 53.604511\n",
      "Epoch [1/3], Step [78100/414113], Loss: 2.1916, Perplexity: 8.9494850\n",
      "Epoch [1/3], Step [78200/414113], Loss: 2.4475, Perplexity: 11.55974\n",
      "Epoch [1/3], Step [78300/414113], Loss: 2.9146, Perplexity: 18.44154\n",
      "Epoch [1/3], Step [78400/414113], Loss: 1.9190, Perplexity: 6.814254\n",
      "Epoch [1/3], Step [78500/414113], Loss: 1.6289, Perplexity: 5.098518\n",
      "Epoch [1/3], Step [78600/414113], Loss: 3.3176, Perplexity: 27.59407\n",
      "Epoch [1/3], Step [78700/414113], Loss: 4.0351, Perplexity: 56.548317\n",
      "Epoch [1/3], Step [78800/414113], Loss: 2.4405, Perplexity: 11.479250\n",
      "Epoch [1/3], Step [78900/414113], Loss: 3.0522, Perplexity: 21.16283\n",
      "Epoch [1/3], Step [79000/414113], Loss: 3.4151, Perplexity: 30.419731\n",
      "Epoch [1/3], Step [79100/414113], Loss: 1.7744, Perplexity: 5.8969042\n",
      "Epoch [1/3], Step [79200/414113], Loss: 2.1436, Perplexity: 8.5299815\n",
      "Epoch [1/3], Step [79300/414113], Loss: 4.5712, Perplexity: 96.65811\n",
      "Epoch [1/3], Step [79400/414113], Loss: 2.1670, Perplexity: 8.732274\n",
      "Epoch [1/3], Step [79500/414113], Loss: 2.5835, Perplexity: 13.24302\n",
      "Epoch [1/3], Step [79600/414113], Loss: 1.7905, Perplexity: 5.992522\n",
      "Epoch [1/3], Step [79700/414113], Loss: 2.5028, Perplexity: 12.216579\n",
      "Epoch [1/3], Step [79800/414113], Loss: 3.7086, Perplexity: 40.79643\n",
      "Epoch [1/3], Step [79900/414113], Loss: 2.2902, Perplexity: 9.876745\n",
      "Epoch [1/3], Step [80000/414113], Loss: 1.4801, Perplexity: 4.393440\n",
      "Epoch [1/3], Step [80100/414113], Loss: 1.6018, Perplexity: 4.9618995\n",
      "Epoch [1/3], Step [80200/414113], Loss: 2.0128, Perplexity: 7.484168\n",
      "Epoch [1/3], Step [80300/414113], Loss: 3.6825, Perplexity: 39.74713\n",
      "Epoch [1/3], Step [80400/414113], Loss: 2.1798, Perplexity: 8.844406\n",
      "Epoch [1/3], Step [80500/414113], Loss: 1.6023, Perplexity: 4.964356\n",
      "Epoch [1/3], Step [80600/414113], Loss: 4.4952, Perplexity: 89.589561\n",
      "Epoch [1/3], Step [80700/414113], Loss: 2.3605, Perplexity: 10.59631\n",
      "Epoch [1/3], Step [80800/414113], Loss: 1.4274, Perplexity: 4.1680256\n",
      "Epoch [1/3], Step [80900/414113], Loss: 2.4476, Perplexity: 11.56118\n",
      "Epoch [1/3], Step [81000/414113], Loss: 2.0429, Perplexity: 7.713226\n",
      "Epoch [1/3], Step [81100/414113], Loss: 5.3585, Perplexity: 212.4060\n",
      "Epoch [1/3], Step [81200/414113], Loss: 1.4910, Perplexity: 4.4414637\n",
      "Epoch [1/3], Step [81300/414113], Loss: 4.2048, Perplexity: 67.006821\n",
      "Epoch [1/3], Step [81400/414113], Loss: 4.7210, Perplexity: 112.28460\n",
      "Epoch [1/3], Step [81500/414113], Loss: 1.8574, Perplexity: 6.407098\n",
      "Epoch [1/3], Step [81600/414113], Loss: 3.1269, Perplexity: 22.80341\n",
      "Epoch [1/3], Step [81700/414113], Loss: 3.8218, Perplexity: 45.68549\n",
      "Epoch [1/3], Step [81800/414113], Loss: 4.1688, Perplexity: 64.63547\n",
      "Epoch [1/3], Step [81900/414113], Loss: 2.8636, Perplexity: 17.52444\n",
      "Epoch [1/3], Step [82000/414113], Loss: 4.3959, Perplexity: 81.12168\n",
      "Epoch [1/3], Step [82100/414113], Loss: 2.9404, Perplexity: 18.923571\n",
      "Epoch [1/3], Step [82200/414113], Loss: 4.5031, Perplexity: 90.298937\n",
      "Epoch [1/3], Step [82300/414113], Loss: 2.5861, Perplexity: 13.27857\n",
      "Epoch [1/3], Step [82400/414113], Loss: 2.7251, Perplexity: 15.258142\n",
      "Epoch [1/3], Step [82500/414113], Loss: 3.3067, Perplexity: 27.29578\n",
      "Epoch [1/3], Step [82600/414113], Loss: 2.5356, Perplexity: 12.62465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [82700/414113], Loss: 2.8689, Perplexity: 17.61797\n",
      "Epoch [1/3], Step [82800/414113], Loss: 2.2473, Perplexity: 9.461755\n",
      "Epoch [1/3], Step [82900/414113], Loss: 2.0868, Perplexity: 8.059239\n",
      "Epoch [1/3], Step [83000/414113], Loss: 2.5408, Perplexity: 12.69005\n",
      "Epoch [1/3], Step [83100/414113], Loss: 4.2713, Perplexity: 71.61115\n",
      "Epoch [1/3], Step [83200/414113], Loss: 2.7336, Perplexity: 15.38803\n",
      "Epoch [1/3], Step [83300/414113], Loss: 2.2391, Perplexity: 9.385165\n",
      "Epoch [1/3], Step [83400/414113], Loss: 4.8218, Perplexity: 124.1865\n",
      "Epoch [1/3], Step [83500/414113], Loss: 4.2453, Perplexity: 69.776647\n",
      "Epoch [1/3], Step [83600/414113], Loss: 4.9798, Perplexity: 145.4432\n",
      "Epoch [1/3], Step [83700/414113], Loss: 3.4961, Perplexity: 32.985698\n",
      "Epoch [1/3], Step [83800/414113], Loss: 1.8012, Perplexity: 6.056847\n",
      "Epoch [1/3], Step [83900/414113], Loss: 2.9198, Perplexity: 18.53706\n",
      "Epoch [1/3], Step [84000/414113], Loss: 4.6093, Perplexity: 100.4187\n",
      "Epoch [1/3], Step [84100/414113], Loss: 3.7517, Perplexity: 42.593824\n",
      "Epoch [1/3], Step [84200/414113], Loss: 4.4701, Perplexity: 87.36759\n",
      "Epoch [1/3], Step [84300/414113], Loss: 1.6911, Perplexity: 5.4252054\n",
      "Epoch [1/3], Step [84400/414113], Loss: 2.9187, Perplexity: 18.51664\n",
      "Epoch [1/3], Step [84500/414113], Loss: 4.5116, Perplexity: 91.065657\n",
      "Epoch [1/3], Step [84600/414113], Loss: 3.9979, Perplexity: 54.48313\n",
      "Epoch [1/3], Step [84700/414113], Loss: 4.4771, Perplexity: 87.98173\n",
      "Epoch [1/3], Step [84800/414113], Loss: 3.8255, Perplexity: 45.855770\n",
      "Epoch [1/3], Step [84900/414113], Loss: 1.0632, Perplexity: 2.895620\n",
      "Epoch [1/3], Step [85000/414113], Loss: 3.3235, Perplexity: 27.75798\n",
      "Epoch [1/3], Step [85100/414113], Loss: 3.8711, Perplexity: 47.99691\n",
      "Epoch [1/3], Step [85200/414113], Loss: 4.4194, Perplexity: 83.04940\n",
      "Epoch [1/3], Step [85300/414113], Loss: 1.3994, Perplexity: 4.052915\n",
      "Epoch [1/3], Step [85400/414113], Loss: 1.4400, Perplexity: 4.220920\n",
      "Epoch [1/3], Step [85500/414113], Loss: 4.1615, Perplexity: 64.167469\n",
      "Epoch [1/3], Step [85600/414113], Loss: 3.3972, Perplexity: 29.88043\n",
      "Epoch [1/3], Step [85700/414113], Loss: 1.9818, Perplexity: 7.2560310\n",
      "Epoch [1/3], Step [85800/414113], Loss: 3.1292, Perplexity: 22.85491\n",
      "Epoch [1/3], Step [85900/414113], Loss: 1.2780, Perplexity: 3.589545\n",
      "Epoch [1/3], Step [86000/414113], Loss: 4.0076, Perplexity: 55.013296\n",
      "Epoch [1/3], Step [86100/414113], Loss: 5.6343, Perplexity: 279.85054\n",
      "Epoch [1/3], Step [86200/414113], Loss: 2.1424, Perplexity: 8.519677\n",
      "Epoch [1/3], Step [86300/414113], Loss: 2.1060, Perplexity: 8.215477\n",
      "Epoch [1/3], Step [86400/414113], Loss: 2.1874, Perplexity: 8.9120258\n",
      "Epoch [1/3], Step [86500/414113], Loss: 2.5520, Perplexity: 12.83284\n",
      "Epoch [1/3], Step [86600/414113], Loss: 1.3707, Perplexity: 3.9380363\n",
      "Epoch [1/3], Step [86700/414113], Loss: 2.3766, Perplexity: 10.76836\n",
      "Epoch [1/3], Step [86800/414113], Loss: 4.0080, Perplexity: 55.03633\n",
      "Epoch [1/3], Step [86900/414113], Loss: 1.5908, Perplexity: 4.9079988\n",
      "Epoch [1/3], Step [87000/414113], Loss: 3.2105, Perplexity: 24.79196\n",
      "Epoch [1/3], Step [87100/414113], Loss: 1.8679, Perplexity: 6.474630\n",
      "Epoch [1/3], Step [87200/414113], Loss: 3.3804, Perplexity: 29.38326\n",
      "Epoch [1/3], Step [87300/414113], Loss: 3.6796, Perplexity: 39.629732\n",
      "Epoch [1/3], Step [87400/414113], Loss: 1.9933, Perplexity: 7.339674\n",
      "Epoch [1/3], Step [87500/414113], Loss: 2.7671, Perplexity: 15.91239\n",
      "Epoch [1/3], Step [87600/414113], Loss: 2.4871, Perplexity: 12.02596\n",
      "Epoch [1/3], Step [87700/414113], Loss: 3.4898, Perplexity: 32.778364\n",
      "Epoch [1/3], Step [87800/414113], Loss: 6.2721, Perplexity: 529.5712\n",
      "Epoch [1/3], Step [87900/414113], Loss: 2.8265, Perplexity: 16.886813\n",
      "Epoch [1/3], Step [88000/414113], Loss: 1.9969, Perplexity: 7.366497\n",
      "Epoch [1/3], Step [88100/414113], Loss: 2.8818, Perplexity: 17.845763\n",
      "Epoch [1/3], Step [88200/414113], Loss: 0.9659, Perplexity: 2.6272615\n",
      "Epoch [1/3], Step [88300/414113], Loss: 3.6620, Perplexity: 38.94017\n",
      "Epoch [1/3], Step [88400/414113], Loss: 3.3037, Perplexity: 27.21331\n",
      "Epoch [1/3], Step [88500/414113], Loss: 3.0040, Perplexity: 20.16534\n",
      "Epoch [1/3], Step [88600/414113], Loss: 5.0648, Perplexity: 158.3473\n",
      "Epoch [1/3], Step [88700/414113], Loss: 4.2413, Perplexity: 69.50161\n",
      "Epoch [1/3], Step [88800/414113], Loss: 3.4188, Perplexity: 30.53239\n",
      "Epoch [1/3], Step [88900/414113], Loss: 3.2791, Perplexity: 26.55174\n",
      "Epoch [1/3], Step [89000/414113], Loss: 2.8855, Perplexity: 17.91180\n",
      "Epoch [1/3], Step [89100/414113], Loss: 3.3141, Perplexity: 27.49653\n",
      "Epoch [1/3], Step [89200/414113], Loss: 1.9872, Perplexity: 7.2954252\n",
      "Epoch [1/3], Step [89300/414113], Loss: 1.9148, Perplexity: 6.7858231\n",
      "Epoch [1/3], Step [89400/414113], Loss: 2.6920, Perplexity: 14.76146\n",
      "Epoch [1/3], Step [89500/414113], Loss: 1.5486, Perplexity: 4.7048111\n",
      "Epoch [1/3], Step [89600/414113], Loss: 2.4477, Perplexity: 11.56199\n",
      "Epoch [1/3], Step [89700/414113], Loss: 2.1093, Perplexity: 8.2426552\n",
      "Epoch [1/3], Step [89800/414113], Loss: 2.6723, Perplexity: 14.473517\n",
      "Epoch [1/3], Step [89900/414113], Loss: 3.7485, Perplexity: 42.457564\n",
      "Epoch [1/3], Step [90000/414113], Loss: 1.9643, Perplexity: 7.129961\n",
      "Epoch [1/3], Step [90100/414113], Loss: 1.4734, Perplexity: 4.3639080\n",
      "Epoch [1/3], Step [90200/414113], Loss: 4.6467, Perplexity: 104.2446\n",
      "Epoch [1/3], Step [90300/414113], Loss: 4.7168, Perplexity: 111.8143\n",
      "Epoch [1/3], Step [90400/414113], Loss: 4.2325, Perplexity: 68.890700\n",
      "Epoch [1/3], Step [90500/414113], Loss: 3.4499, Perplexity: 31.49810\n",
      "Epoch [1/3], Step [90600/414113], Loss: 2.3765, Perplexity: 10.76717\n",
      "Epoch [1/3], Step [90700/414113], Loss: 2.9747, Perplexity: 19.58422\n",
      "Epoch [1/3], Step [90800/414113], Loss: 2.4445, Perplexity: 11.525358\n",
      "Epoch [1/3], Step [90900/414113], Loss: 2.0548, Perplexity: 7.804904\n",
      "Epoch [1/3], Step [91000/414113], Loss: 1.7842, Perplexity: 5.954613\n",
      "Epoch [1/3], Step [91100/414113], Loss: 3.1584, Perplexity: 23.533115\n",
      "Epoch [1/3], Step [91200/414113], Loss: 2.9602, Perplexity: 19.30155\n",
      "Epoch [1/3], Step [91300/414113], Loss: 2.9537, Perplexity: 19.176969\n",
      "Epoch [1/3], Step [91400/414113], Loss: 2.7730, Perplexity: 16.00691\n",
      "Epoch [1/3], Step [91500/414113], Loss: 3.7888, Perplexity: 44.203598\n",
      "Epoch [1/3], Step [91600/414113], Loss: 3.9516, Perplexity: 52.01632\n",
      "Epoch [1/3], Step [91700/414113], Loss: 2.3750, Perplexity: 10.751044\n",
      "Epoch [1/3], Step [91800/414113], Loss: 2.6324, Perplexity: 13.906522\n",
      "Epoch [1/3], Step [91900/414113], Loss: 3.0853, Perplexity: 21.87369\n",
      "Epoch [1/3], Step [92000/414113], Loss: 3.2285, Perplexity: 25.24066\n",
      "Epoch [1/3], Step [92100/414113], Loss: 4.1414, Perplexity: 62.89215\n",
      "Epoch [1/3], Step [92200/414113], Loss: 1.8391, Perplexity: 6.291291\n",
      "Epoch [1/3], Step [92300/414113], Loss: 2.1086, Perplexity: 8.236866\n",
      "Epoch [1/3], Step [92400/414113], Loss: 1.3120, Perplexity: 3.713712\n",
      "Epoch [1/3], Step [92500/414113], Loss: 4.4360, Perplexity: 84.43595\n",
      "Epoch [1/3], Step [92600/414113], Loss: 5.1005, Perplexity: 164.0997\n",
      "Epoch [1/3], Step [92700/414113], Loss: 1.9487, Perplexity: 7.0196715\n",
      "Epoch [1/3], Step [92800/414113], Loss: 1.9307, Perplexity: 6.8941575\n",
      "Epoch [1/3], Step [92900/414113], Loss: 2.6765, Perplexity: 14.53487\n",
      "Epoch [1/3], Step [93000/414113], Loss: 2.5059, Perplexity: 12.25491\n",
      "Epoch [1/3], Step [93100/414113], Loss: 1.2657, Perplexity: 3.545617\n",
      "Epoch [1/3], Step [93200/414113], Loss: 1.9400, Perplexity: 6.958827\n",
      "Epoch [1/3], Step [93300/414113], Loss: 2.6151, Perplexity: 13.668154\n",
      "Epoch [1/3], Step [93400/414113], Loss: 2.3430, Perplexity: 10.412285\n",
      "Epoch [1/3], Step [93500/414113], Loss: 2.4703, Perplexity: 11.826248\n",
      "Epoch [1/3], Step [93600/414113], Loss: 3.5539, Perplexity: 34.949104\n",
      "Epoch [1/3], Step [93700/414113], Loss: 2.7754, Perplexity: 16.04476\n",
      "Epoch [1/3], Step [93800/414113], Loss: 3.7367, Perplexity: 41.96028\n",
      "Epoch [1/3], Step [93900/414113], Loss: 2.0330, Perplexity: 7.636670\n",
      "Epoch [1/3], Step [94000/414113], Loss: 4.2789, Perplexity: 72.16378\n",
      "Epoch [1/3], Step [94100/414113], Loss: 2.0167, Perplexity: 7.513885\n",
      "Epoch [1/3], Step [94200/414113], Loss: 2.9213, Perplexity: 18.56605\n",
      "Epoch [1/3], Step [94300/414113], Loss: 2.6850, Perplexity: 14.65785\n",
      "Epoch [1/3], Step [94400/414113], Loss: 5.0782, Perplexity: 160.4826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [94500/414113], Loss: 1.6328, Perplexity: 5.117996\n",
      "Epoch [1/3], Step [94600/414113], Loss: 2.4140, Perplexity: 11.17890\n",
      "Epoch [1/3], Step [94700/414113], Loss: 3.3175, Perplexity: 27.59088\n",
      "Epoch [1/3], Step [94800/414113], Loss: 2.7518, Perplexity: 15.67104\n",
      "Epoch [1/3], Step [94900/414113], Loss: 3.3934, Perplexity: 29.767473\n",
      "Epoch [1/3], Step [95000/414113], Loss: 1.8889, Perplexity: 6.6124098\n",
      "Epoch [1/3], Step [95100/414113], Loss: 3.7102, Perplexity: 40.863181\n",
      "Epoch [1/3], Step [95200/414113], Loss: 1.2951, Perplexity: 3.6512289\n",
      "Epoch [1/3], Step [95300/414113], Loss: 3.2865, Perplexity: 26.748497\n",
      "Epoch [1/3], Step [95400/414113], Loss: 1.3533, Perplexity: 3.8702457\n",
      "Epoch [1/3], Step [95500/414113], Loss: 8.2971, Perplexity: 4012.1055\n",
      "Epoch [1/3], Step [95600/414113], Loss: 3.0476, Perplexity: 21.06435\n",
      "Epoch [1/3], Step [95700/414113], Loss: 2.1946, Perplexity: 8.976075\n",
      "Epoch [1/3], Step [95800/414113], Loss: 2.0417, Perplexity: 7.703924\n",
      "Epoch [1/3], Step [95900/414113], Loss: 1.8203, Perplexity: 6.173519\n",
      "Epoch [1/3], Step [96000/414113], Loss: 3.0524, Perplexity: 21.166988\n",
      "Epoch [1/3], Step [96100/414113], Loss: 1.7754, Perplexity: 5.9024641\n",
      "Epoch [1/3], Step [96200/414113], Loss: 3.4685, Perplexity: 32.08779\n",
      "Epoch [1/3], Step [96300/414113], Loss: 6.8792, Perplexity: 971.88334\n",
      "Epoch [1/3], Step [96400/414113], Loss: 2.6393, Perplexity: 14.003542\n",
      "Epoch [1/3], Step [96500/414113], Loss: 1.8975, Perplexity: 6.669284\n",
      "Epoch [1/3], Step [96600/414113], Loss: 2.0941, Perplexity: 8.1180025\n",
      "Epoch [1/3], Step [96700/414113], Loss: 2.1925, Perplexity: 8.957763\n",
      "Epoch [1/3], Step [96800/414113], Loss: 4.0741, Perplexity: 58.795707\n",
      "Epoch [1/3], Step [96900/414113], Loss: 3.4592, Perplexity: 31.79294\n",
      "Epoch [1/3], Step [97000/414113], Loss: 2.8198, Perplexity: 16.772940\n",
      "Epoch [1/3], Step [97100/414113], Loss: 2.5779, Perplexity: 13.170181\n",
      "Epoch [1/3], Step [97200/414113], Loss: 4.1275, Perplexity: 62.024848\n",
      "Epoch [1/3], Step [97300/414113], Loss: 2.1199, Perplexity: 8.3306942\n",
      "Epoch [1/3], Step [97400/414113], Loss: 1.9002, Perplexity: 6.6870528\n",
      "Epoch [1/3], Step [97500/414113], Loss: 1.7235, Perplexity: 5.604090\n",
      "Epoch [1/3], Step [97600/414113], Loss: 3.6510, Perplexity: 38.51250\n",
      "Epoch [1/3], Step [97700/414113], Loss: 4.2593, Perplexity: 70.760579\n",
      "Epoch [1/3], Step [97800/414113], Loss: 2.6551, Perplexity: 14.22575\n",
      "Epoch [1/3], Step [97900/414113], Loss: 2.6590, Perplexity: 14.281836\n",
      "Epoch [1/3], Step [98000/414113], Loss: 3.0252, Perplexity: 20.59853\n",
      "Epoch [1/3], Step [98100/414113], Loss: 2.4677, Perplexity: 11.79569\n",
      "Epoch [1/3], Step [98200/414113], Loss: 1.6869, Perplexity: 5.403095\n",
      "Epoch [1/3], Step [98300/414113], Loss: 3.1225, Perplexity: 22.70315\n",
      "Epoch [1/3], Step [98400/414113], Loss: 3.7785, Perplexity: 43.748511\n",
      "Epoch [1/3], Step [98500/414113], Loss: 3.4110, Perplexity: 30.29615\n",
      "Epoch [1/3], Step [98600/414113], Loss: 3.1396, Perplexity: 23.09500\n",
      "Epoch [1/3], Step [98700/414113], Loss: 2.4665, Perplexity: 11.780891\n",
      "Epoch [1/3], Step [98800/414113], Loss: 2.1793, Perplexity: 8.8398477\n",
      "Epoch [1/3], Step [98900/414113], Loss: 2.2263, Perplexity: 9.265886\n",
      "Epoch [1/3], Step [99000/414113], Loss: 1.7767, Perplexity: 5.9104849\n",
      "Epoch [1/3], Step [99100/414113], Loss: 3.7052, Perplexity: 40.65683\n",
      "Epoch [1/3], Step [99200/414113], Loss: 1.8281, Perplexity: 6.222015\n",
      "Epoch [1/3], Step [99300/414113], Loss: 1.1176, Perplexity: 3.0574457\n",
      "Epoch [1/3], Step [99400/414113], Loss: 5.4985, Perplexity: 244.3265\n",
      "Epoch [1/3], Step [99500/414113], Loss: 3.3814, Perplexity: 29.412456\n",
      "Epoch [1/3], Step [99600/414113], Loss: 2.2763, Perplexity: 9.740914\n",
      "Epoch [1/3], Step [99700/414113], Loss: 1.3840, Perplexity: 3.990915\n",
      "Epoch [1/3], Step [99800/414113], Loss: 3.2800, Perplexity: 26.576116\n",
      "Epoch [1/3], Step [99900/414113], Loss: 2.3061, Perplexity: 10.03502\n",
      "Epoch [1/3], Step [100000/414113], Loss: 4.2846, Perplexity: 72.5754\n",
      "Epoch [1/3], Step [100100/414113], Loss: 2.6511, Perplexity: 14.16915\n",
      "Epoch [1/3], Step [100200/414113], Loss: 3.4645, Perplexity: 31.960360\n",
      "Epoch [1/3], Step [100300/414113], Loss: 2.6100, Perplexity: 13.59870\n",
      "Epoch [1/3], Step [100400/414113], Loss: 2.3880, Perplexity: 10.89140\n",
      "Epoch [1/3], Step [100500/414113], Loss: 4.2059, Perplexity: 67.080222\n",
      "Epoch [1/3], Step [100600/414113], Loss: 3.6885, Perplexity: 39.98432\n",
      "Epoch [1/3], Step [100700/414113], Loss: 1.6588, Perplexity: 5.2530291\n",
      "Epoch [1/3], Step [100800/414113], Loss: 3.3045, Perplexity: 27.233679\n",
      "Epoch [1/3], Step [100900/414113], Loss: 1.9165, Perplexity: 6.797383\n",
      "Epoch [1/3], Step [101000/414113], Loss: 3.2939, Perplexity: 26.94753\n",
      "Epoch [1/3], Step [101100/414113], Loss: 2.1477, Perplexity: 8.5647913\n",
      "Epoch [1/3], Step [101200/414113], Loss: 2.3080, Perplexity: 10.054300\n",
      "Epoch [1/3], Step [101300/414113], Loss: 2.4226, Perplexity: 11.27492\n",
      "Epoch [1/3], Step [101400/414113], Loss: 3.8929, Perplexity: 49.05475\n",
      "Epoch [1/3], Step [101500/414113], Loss: 3.8854, Perplexity: 48.68505\n",
      "Epoch [1/3], Step [101600/414113], Loss: 2.4304, Perplexity: 11.36364\n",
      "Epoch [1/3], Step [101700/414113], Loss: 3.7677, Perplexity: 43.28035\n",
      "Epoch [1/3], Step [101800/414113], Loss: 1.3710, Perplexity: 3.939321\n",
      "Epoch [1/3], Step [101900/414113], Loss: 3.2599, Perplexity: 26.047023\n",
      "Epoch [1/3], Step [102000/414113], Loss: 2.2463, Perplexity: 9.4526601\n",
      "Epoch [1/3], Step [102100/414113], Loss: 3.8925, Perplexity: 49.03415\n",
      "Epoch [1/3], Step [102200/414113], Loss: 3.5585, Perplexity: 35.10989\n",
      "Epoch [1/3], Step [102300/414113], Loss: 2.3831, Perplexity: 10.83905\n",
      "Epoch [1/3], Step [102400/414113], Loss: 5.5549, Perplexity: 258.50007\n",
      "Epoch [1/3], Step [102500/414113], Loss: 2.4521, Perplexity: 11.61295\n",
      "Epoch [1/3], Step [102600/414113], Loss: 4.1836, Perplexity: 65.60217\n",
      "Epoch [1/3], Step [102700/414113], Loss: 1.3782, Perplexity: 3.9677415\n",
      "Epoch [1/3], Step [102800/414113], Loss: 4.2546, Perplexity: 70.430909\n",
      "Epoch [1/3], Step [102900/414113], Loss: 2.4338, Perplexity: 11.40251\n",
      "Epoch [1/3], Step [103000/414113], Loss: 1.6164, Perplexity: 5.0349377\n",
      "Epoch [1/3], Step [103100/414113], Loss: 6.9916, Perplexity: 1087.4834\n",
      "Epoch [1/3], Step [103200/414113], Loss: 2.3843, Perplexity: 10.85127\n",
      "Epoch [1/3], Step [103300/414113], Loss: 5.1103, Perplexity: 165.71707\n",
      "Epoch [1/3], Step [103400/414113], Loss: 2.6611, Perplexity: 14.31139\n",
      "Epoch [1/3], Step [103500/414113], Loss: 2.9550, Perplexity: 19.20160\n",
      "Epoch [1/3], Step [103600/414113], Loss: 3.9248, Perplexity: 50.644244\n",
      "Epoch [1/3], Step [103700/414113], Loss: 2.9533, Perplexity: 19.168523\n",
      "Epoch [1/3], Step [103800/414113], Loss: 3.4482, Perplexity: 31.44221\n",
      "Epoch [1/3], Step [103900/414113], Loss: 1.6591, Perplexity: 5.254473\n",
      "Epoch [1/3], Step [104000/414113], Loss: 2.5428, Perplexity: 12.715502\n",
      "Epoch [1/3], Step [104100/414113], Loss: 2.1357, Perplexity: 8.463065\n",
      "Epoch [1/3], Step [104200/414113], Loss: 3.0746, Perplexity: 21.64159\n",
      "Epoch [1/3], Step [104300/414113], Loss: 3.4259, Perplexity: 30.75079\n",
      "Epoch [1/3], Step [104400/414113], Loss: 3.9685, Perplexity: 52.90285\n",
      "Epoch [1/3], Step [104500/414113], Loss: 1.8581, Perplexity: 6.4112475\n",
      "Epoch [1/3], Step [104600/414113], Loss: 2.8124, Perplexity: 16.64906\n",
      "Epoch [1/3], Step [104700/414113], Loss: 1.6755, Perplexity: 5.341286\n",
      "Epoch [1/3], Step [104800/414113], Loss: 4.4387, Perplexity: 84.66872\n",
      "Epoch [1/3], Step [104900/414113], Loss: 3.4895, Perplexity: 32.77080\n",
      "Epoch [1/3], Step [105000/414113], Loss: 5.9772, Perplexity: 394.3247\n",
      "Epoch [1/3], Step [105100/414113], Loss: 2.2009, Perplexity: 9.0333882\n",
      "Epoch [1/3], Step [105200/414113], Loss: 1.5357, Perplexity: 4.644430\n",
      "Epoch [1/3], Step [105300/414113], Loss: 1.4617, Perplexity: 4.313390\n",
      "Epoch [1/3], Step [105400/414113], Loss: 2.0763, Perplexity: 7.975261\n",
      "Epoch [1/3], Step [105500/414113], Loss: 2.0191, Perplexity: 7.531818\n",
      "Epoch [1/3], Step [105600/414113], Loss: 3.8629, Perplexity: 47.60286\n",
      "Epoch [1/3], Step [105700/414113], Loss: 4.3252, Perplexity: 75.58367\n",
      "Epoch [1/3], Step [105800/414113], Loss: 2.0728, Perplexity: 7.947032\n",
      "Epoch [1/3], Step [105900/414113], Loss: 4.7572, Perplexity: 116.42199\n",
      "Epoch [1/3], Step [106000/414113], Loss: 1.9314, Perplexity: 6.899203\n",
      "Epoch [1/3], Step [106100/414113], Loss: 2.9972, Perplexity: 20.029570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [106200/414113], Loss: 1.6475, Perplexity: 5.1939140\n",
      "Epoch [1/3], Step [106300/414113], Loss: 2.1328, Perplexity: 8.438392\n",
      "Epoch [1/3], Step [106400/414113], Loss: 1.4889, Perplexity: 4.4321151\n",
      "Epoch [1/3], Step [106500/414113], Loss: 2.5816, Perplexity: 13.21777\n",
      "Epoch [1/3], Step [106600/414113], Loss: 2.7832, Perplexity: 16.17136\n",
      "Epoch [1/3], Step [106700/414113], Loss: 2.3637, Perplexity: 10.630482\n",
      "Epoch [1/3], Step [106800/414113], Loss: 2.4219, Perplexity: 11.266993.9089\n",
      "Epoch [1/3], Step [106900/414113], Loss: 2.2074, Perplexity: 9.092236\n",
      "Epoch [1/3], Step [107000/414113], Loss: 2.3883, Perplexity: 10.89454\n",
      "Epoch [1/3], Step [107100/414113], Loss: 2.3199, Perplexity: 10.17468\n",
      "Epoch [1/3], Step [107200/414113], Loss: 3.6558, Perplexity: 38.69760\n",
      "Epoch [1/3], Step [107300/414113], Loss: 1.4219, Perplexity: 4.144811\n",
      "Epoch [1/3], Step [107400/414113], Loss: 5.6916, Perplexity: 296.3619\n",
      "Epoch [1/3], Step [107500/414113], Loss: 5.7083, Perplexity: 301.3571\n",
      "Epoch [1/3], Step [107600/414113], Loss: 2.7040, Perplexity: 14.939668\n",
      "Epoch [1/3], Step [107700/414113], Loss: 2.3892, Perplexity: 10.90515\n",
      "Epoch [1/3], Step [107800/414113], Loss: 1.8334, Perplexity: 6.254944\n",
      "Epoch [1/3], Step [107900/414113], Loss: 3.8556, Perplexity: 47.25922\n",
      "Epoch [1/3], Step [108000/414113], Loss: 6.1627, Perplexity: 474.7127\n",
      "Epoch [1/3], Step [108100/414113], Loss: 2.6773, Perplexity: 14.545344\n",
      "Epoch [1/3], Step [108200/414113], Loss: 5.2803, Perplexity: 196.42730\n",
      "Epoch [1/3], Step [108300/414113], Loss: 3.9011, Perplexity: 49.45551\n",
      "Epoch [1/3], Step [108400/414113], Loss: 2.7299, Perplexity: 15.33129\n",
      "Epoch [1/3], Step [108500/414113], Loss: 3.0856, Perplexity: 21.87984\n",
      "Epoch [1/3], Step [108600/414113], Loss: 2.9523, Perplexity: 19.14972\n",
      "Epoch [1/3], Step [108700/414113], Loss: 2.9031, Perplexity: 18.23002\n",
      "Epoch [1/3], Step [108800/414113], Loss: 1.3112, Perplexity: 3.710606\n",
      "Epoch [1/3], Step [108900/414113], Loss: 5.1016, Perplexity: 164.2785\n",
      "Epoch [1/3], Step [109000/414113], Loss: 2.2845, Perplexity: 9.820814\n",
      "Epoch [1/3], Step [109100/414113], Loss: 2.6214, Perplexity: 13.75483\n",
      "Epoch [1/3], Step [109200/414113], Loss: 3.0547, Perplexity: 21.215819\n",
      "Epoch [1/3], Step [109300/414113], Loss: 3.9613, Perplexity: 52.52534\n",
      "Epoch [1/3], Step [109400/414113], Loss: 2.3202, Perplexity: 10.17733\n",
      "Epoch [1/3], Step [109500/414113], Loss: 3.6615, Perplexity: 38.920159\n",
      "Epoch [1/3], Step [109600/414113], Loss: 2.6625, Perplexity: 14.33184\n",
      "Epoch [1/3], Step [109700/414113], Loss: 2.3666, Perplexity: 10.661412\n",
      "Epoch [1/3], Step [109800/414113], Loss: 5.2817, Perplexity: 196.70981\n",
      "Epoch [1/3], Step [109900/414113], Loss: 2.4425, Perplexity: 11.50187\n",
      "Epoch [1/3], Step [110000/414113], Loss: 3.5965, Perplexity: 36.468817\n",
      "Epoch [1/3], Step [110100/414113], Loss: 3.4397, Perplexity: 31.177818\n",
      "Epoch [1/3], Step [110200/414113], Loss: 1.5702, Perplexity: 4.8078183\n",
      "Epoch [1/3], Step [110300/414113], Loss: 1.2945, Perplexity: 3.649198\n",
      "Epoch [1/3], Step [110400/414113], Loss: 2.9775, Perplexity: 19.63837\n",
      "Epoch [1/3], Step [110500/414113], Loss: 2.3212, Perplexity: 10.187979\n",
      "Epoch [1/3], Step [110600/414113], Loss: 2.1783, Perplexity: 8.831766\n",
      "Epoch [1/3], Step [110700/414113], Loss: 1.8450, Perplexity: 6.3279950\n",
      "Epoch [1/3], Step [110800/414113], Loss: 6.3299, Perplexity: 561.1164\n",
      "Epoch [1/3], Step [110900/414113], Loss: 2.5822, Perplexity: 13.22613\n",
      "Epoch [1/3], Step [111000/414113], Loss: 4.7858, Perplexity: 119.7967\n",
      "Epoch [1/3], Step [111100/414113], Loss: 1.4786, Perplexity: 4.3870361\n",
      "Epoch [1/3], Step [111200/414113], Loss: 3.4329, Perplexity: 30.96677\n",
      "Epoch [1/3], Step [111300/414113], Loss: 1.4253, Perplexity: 4.1591769\n",
      "Epoch [1/3], Step [111400/414113], Loss: 2.9457, Perplexity: 19.02360\n",
      "Epoch [1/3], Step [111500/414113], Loss: 4.7687, Perplexity: 117.7693\n",
      "Epoch [1/3], Step [111600/414113], Loss: 6.1517, Perplexity: 469.5357\n",
      "Epoch [1/3], Step [111700/414113], Loss: 1.9105, Perplexity: 6.756401\n",
      "Epoch [1/3], Step [111800/414113], Loss: 2.9306, Perplexity: 18.73874\n",
      "Epoch [1/3], Step [111900/414113], Loss: 2.2692, Perplexity: 9.672151\n",
      "Epoch [1/3], Step [112000/414113], Loss: 3.0185, Perplexity: 20.461479\n",
      "Epoch [1/3], Step [112100/414113], Loss: 1.8770, Perplexity: 6.533641\n",
      "Epoch [1/3], Step [112200/414113], Loss: 2.8203, Perplexity: 16.781450\n",
      "Epoch [1/3], Step [112300/414113], Loss: 2.0991, Perplexity: 8.1586457\n",
      "Epoch [1/3], Step [112400/414113], Loss: 3.4014, Perplexity: 30.00760\n",
      "Epoch [1/3], Step [112500/414113], Loss: 3.0547, Perplexity: 21.21556\n",
      "Epoch [1/3], Step [112600/414113], Loss: 1.2356, Perplexity: 3.440311\n",
      "Epoch [1/3], Step [112700/414113], Loss: 2.2433, Perplexity: 9.4246469\n",
      "Epoch [1/3], Step [112800/414113], Loss: 2.9766, Perplexity: 19.621557\n",
      "Epoch [1/3], Step [112900/414113], Loss: 3.5194, Perplexity: 33.76464\n",
      "Epoch [1/3], Step [113000/414113], Loss: 4.1866, Perplexity: 65.797213\n",
      "Epoch [1/3], Step [113100/414113], Loss: 4.4403, Perplexity: 84.80273\n",
      "Epoch [1/3], Step [113200/414113], Loss: 3.1517, Perplexity: 23.37599\n",
      "Epoch [1/3], Step [113300/414113], Loss: 1.8017, Perplexity: 6.0599486\n",
      "Epoch [1/3], Step [113400/414113], Loss: 2.3607, Perplexity: 10.59866\n",
      "Epoch [1/3], Step [113500/414113], Loss: 4.9523, Perplexity: 141.50569\n",
      "Epoch [1/3], Step [113600/414113], Loss: 1.5336, Perplexity: 4.634949\n",
      "Epoch [1/3], Step [113700/414113], Loss: 3.2750, Perplexity: 26.44426\n",
      "Epoch [1/3], Step [113800/414113], Loss: 3.2918, Perplexity: 26.89085\n",
      "Epoch [1/3], Step [113900/414113], Loss: 1.4391, Perplexity: 4.2170388\n",
      "Epoch [1/3], Step [114000/414113], Loss: 2.8103, Perplexity: 16.61414\n",
      "Epoch [1/3], Step [114100/414113], Loss: 3.7531, Perplexity: 42.654648\n",
      "Epoch [1/3], Step [114200/414113], Loss: 6.5700, Perplexity: 713.3948\n",
      "Epoch [1/3], Step [114300/414113], Loss: 2.2521, Perplexity: 9.507926\n",
      "Epoch [1/3], Step [114400/414113], Loss: 2.8320, Perplexity: 16.98006\n",
      "Epoch [1/3], Step [114500/414113], Loss: 2.2545, Perplexity: 9.530937\n",
      "Epoch [1/3], Step [114600/414113], Loss: 1.4252, Perplexity: 4.158841\n",
      "Epoch [1/3], Step [114700/414113], Loss: 5.1205, Perplexity: 167.42352\n",
      "Epoch [1/3], Step [114800/414113], Loss: 4.1887, Perplexity: 65.93839\n",
      "Epoch [1/3], Step [114900/414113], Loss: 1.6282, Perplexity: 5.0949013\n",
      "Epoch [1/3], Step [115000/414113], Loss: 2.0806, Perplexity: 8.009544\n",
      "Epoch [1/3], Step [115100/414113], Loss: 2.3620, Perplexity: 10.611994\n",
      "Epoch [1/3], Step [115200/414113], Loss: 3.2754, Perplexity: 26.45309\n",
      "Epoch [1/3], Step [115300/414113], Loss: 3.0735, Perplexity: 21.61843\n",
      "Epoch [1/3], Step [115400/414113], Loss: 2.6879, Perplexity: 14.701545\n",
      "Epoch [1/3], Step [115500/414113], Loss: 4.5701, Perplexity: 96.55848\n",
      "Epoch [1/3], Step [115600/414113], Loss: 2.7764, Perplexity: 16.060976\n",
      "Epoch [1/3], Step [115700/414113], Loss: 2.9956, Perplexity: 19.99700\n",
      "Epoch [1/3], Step [115800/414113], Loss: 3.7696, Perplexity: 43.362739\n",
      "Epoch [1/3], Step [115900/414113], Loss: 1.2856, Perplexity: 3.616907\n",
      "Epoch [1/3], Step [116000/414113], Loss: 4.1773, Perplexity: 65.18666\n",
      "Epoch [1/3], Step [116100/414113], Loss: 2.7215, Perplexity: 15.20369\n",
      "Epoch [1/3], Step [116200/414113], Loss: 2.4891, Perplexity: 12.04998\n",
      "Epoch [1/3], Step [116300/414113], Loss: 2.8495, Perplexity: 17.279393\n",
      "Epoch [1/3], Step [116400/414113], Loss: 3.6164, Perplexity: 37.203780\n",
      "Epoch [1/3], Step [116500/414113], Loss: 1.4678, Perplexity: 4.3396550\n",
      "Epoch [1/3], Step [116600/414113], Loss: 2.7762, Perplexity: 16.05733\n",
      "Epoch [1/3], Step [116700/414113], Loss: 4.3784, Perplexity: 79.71349\n",
      "Epoch [1/3], Step [116800/414113], Loss: 2.3036, Perplexity: 10.00998\n",
      "Epoch [1/3], Step [116900/414113], Loss: 1.5103, Perplexity: 4.528142\n",
      "Epoch [1/3], Step [117000/414113], Loss: 2.1891, Perplexity: 8.926836\n",
      "Epoch [1/3], Step [117100/414113], Loss: 2.4123, Perplexity: 11.15918\n",
      "Epoch [1/3], Step [117200/414113], Loss: 3.8252, Perplexity: 45.840734\n",
      "Epoch [1/3], Step [117300/414113], Loss: 3.2028, Perplexity: 24.60027\n",
      "Epoch [1/3], Step [117400/414113], Loss: 1.1431, Perplexity: 3.136445217\n",
      "Epoch [1/3], Step [117500/414113], Loss: 5.6773, Perplexity: 292.17152\n",
      "Epoch [1/3], Step [117600/414113], Loss: 1.6784, Perplexity: 5.357289\n",
      "Epoch [1/3], Step [117700/414113], Loss: 1.5359, Perplexity: 4.645374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [117800/414113], Loss: 3.1270, Perplexity: 22.80598\n",
      "Epoch [1/3], Step [117900/414113], Loss: 2.3770, Perplexity: 10.772456\n",
      "Epoch [1/3], Step [118000/414113], Loss: 2.4327, Perplexity: 11.389720\n",
      "Epoch [1/3], Step [118100/414113], Loss: 1.9021, Perplexity: 6.700228\n",
      "Epoch [1/3], Step [118200/414113], Loss: 1.8109, Perplexity: 6.115954\n",
      "Epoch [1/3], Step [118300/414113], Loss: 1.8888, Perplexity: 6.611308\n",
      "Epoch [1/3], Step [118400/414113], Loss: 3.2973, Perplexity: 27.038530\n",
      "Epoch [1/3], Step [118500/414113], Loss: 3.0337, Perplexity: 20.77489\n",
      "Epoch [1/3], Step [118600/414113], Loss: 1.6267, Perplexity: 5.086876\n",
      "Epoch [1/3], Step [118700/414113], Loss: 3.0125, Perplexity: 20.33853\n",
      "Epoch [1/3], Step [118800/414113], Loss: 3.4157, Perplexity: 30.43950\n",
      "Epoch [1/3], Step [118900/414113], Loss: 1.6901, Perplexity: 5.419948\n",
      "Epoch [1/3], Step [119000/414113], Loss: 4.4839, Perplexity: 88.58012\n",
      "Epoch [1/3], Step [119100/414113], Loss: 2.1574, Perplexity: 8.6487622\n",
      "Epoch [1/3], Step [119200/414113], Loss: 3.3753, Perplexity: 29.23409\n",
      "Epoch [1/3], Step [119300/414113], Loss: 2.9519, Perplexity: 19.141999\n",
      "Epoch [1/3], Step [119400/414113], Loss: 2.4610, Perplexity: 11.71633\n",
      "Epoch [1/3], Step [119500/414113], Loss: 1.5165, Perplexity: 4.556052\n",
      "Epoch [1/3], Step [119600/414113], Loss: 3.8302, Perplexity: 46.06957575\n",
      "Epoch [1/3], Step [119700/414113], Loss: 2.7503, Perplexity: 15.64678\n",
      "Epoch [1/3], Step [119800/414113], Loss: 4.2460, Perplexity: 69.82848\n",
      "Epoch [1/3], Step [119900/414113], Loss: 2.4677, Perplexity: 11.795634\n",
      "Epoch [1/3], Step [120000/414113], Loss: 4.4233, Perplexity: 83.372597\n",
      "Epoch [1/3], Step [120100/414113], Loss: 2.4506, Perplexity: 11.59537\n",
      "Epoch [1/3], Step [120200/414113], Loss: 2.5256, Perplexity: 12.49871\n",
      "Epoch [1/3], Step [120300/414113], Loss: 2.7832, Perplexity: 16.17071\n",
      "Epoch [1/3], Step [120400/414113], Loss: 3.5388, Perplexity: 34.42631\n",
      "Epoch [1/3], Step [120500/414113], Loss: 1.0422, Perplexity: 2.8355302\n",
      "Epoch [1/3], Step [120600/414113], Loss: 3.1595, Perplexity: 23.559444\n",
      "Epoch [1/3], Step [120700/414113], Loss: 1.7331, Perplexity: 5.658042\n",
      "Epoch [1/3], Step [120800/414113], Loss: 2.3369, Perplexity: 10.349411\n",
      "Epoch [1/3], Step [120900/414113], Loss: 1.0898, Perplexity: 2.973825\n",
      "Epoch [1/3], Step [121000/414113], Loss: 4.2052, Perplexity: 67.030703\n",
      "Epoch [1/3], Step [121100/414113], Loss: 2.6750, Perplexity: 14.512588\n",
      "Epoch [1/3], Step [121200/414113], Loss: 4.7505, Perplexity: 115.6434\n",
      "Epoch [1/3], Step [121300/414113], Loss: 2.3506, Perplexity: 10.492176\n",
      "Epoch [1/3], Step [121400/414113], Loss: 2.3288, Perplexity: 10.265587\n",
      "Epoch [1/3], Step [121500/414113], Loss: 3.7044, Perplexity: 40.62392\n",
      "Epoch [1/3], Step [121600/414113], Loss: 4.2196, Perplexity: 68.00690\n",
      "Epoch [1/3], Step [121700/414113], Loss: 2.7437, Perplexity: 15.54447\n",
      "Epoch [1/3], Step [121800/414113], Loss: 1.7299, Perplexity: 5.640138\n",
      "Epoch [1/3], Step [121900/414113], Loss: 3.6755, Perplexity: 39.46841\n",
      "Epoch [1/3], Step [122000/414113], Loss: 4.3900, Perplexity: 80.63696\n",
      "Epoch [1/3], Step [122100/414113], Loss: 6.7858, Perplexity: 885.1732\n",
      "Epoch [1/3], Step [122200/414113], Loss: 2.1843, Perplexity: 8.8847663\n",
      "Epoch [1/3], Step [122300/414113], Loss: 5.6021, Perplexity: 270.9923\n",
      "Epoch [1/3], Step [122400/414113], Loss: 2.0152, Perplexity: 7.501993\n",
      "Epoch [1/3], Step [122500/414113], Loss: 2.5603, Perplexity: 12.93932\n",
      "Epoch [1/3], Step [122600/414113], Loss: 3.8274, Perplexity: 45.941528\n",
      "Epoch [1/3], Step [122700/414113], Loss: 1.6436, Perplexity: 5.1738762\n",
      "Epoch [1/3], Step [122800/414113], Loss: 1.4350, Perplexity: 4.199504\n",
      "Epoch [1/3], Step [122900/414113], Loss: 2.0920, Perplexity: 8.101363\n",
      "Epoch [1/3], Step [123000/414113], Loss: 4.4649, Perplexity: 86.91182\n",
      "Epoch [1/3], Step [123100/414113], Loss: 2.5759, Perplexity: 13.143525\n",
      "Epoch [1/3], Step [123200/414113], Loss: 2.8450, Perplexity: 17.20159\n",
      "Epoch [1/3], Step [123300/414113], Loss: 4.4710, Perplexity: 87.441954\n",
      "Epoch [1/3], Step [123400/414113], Loss: 5.2174, Perplexity: 184.44690\n",
      "Epoch [1/3], Step [123500/414113], Loss: 2.3169, Perplexity: 10.14406\n",
      "Epoch [1/3], Step [123600/414113], Loss: 2.5760, Perplexity: 13.14463\n",
      "Epoch [1/3], Step [123700/414113], Loss: 2.0443, Perplexity: 7.723711\n",
      "Epoch [1/3], Step [123800/414113], Loss: 2.7288, Perplexity: 15.314663\n",
      "Epoch [1/3], Step [123900/414113], Loss: 2.1786, Perplexity: 8.834089\n",
      "Epoch [1/3], Step [124000/414113], Loss: 3.1014, Perplexity: 22.22994\n",
      "Epoch [1/3], Step [124100/414113], Loss: 2.5847, Perplexity: 13.259469\n",
      "Epoch [1/3], Step [124200/414113], Loss: 2.6838, Perplexity: 14.640747\n",
      "Epoch [1/3], Step [124300/414113], Loss: 4.7843, Perplexity: 119.61769\n",
      "Epoch [1/3], Step [124400/414113], Loss: 3.8202, Perplexity: 45.61398\n",
      "Epoch [1/3], Step [124500/414113], Loss: 1.2707, Perplexity: 3.563520\n",
      "Epoch [1/3], Step [124600/414113], Loss: 3.3715, Perplexity: 29.12343\n",
      "Epoch [1/3], Step [124700/414113], Loss: 2.1686, Perplexity: 8.746413423\n",
      "Epoch [1/3], Step [124800/414113], Loss: 2.9362, Perplexity: 18.843433\n",
      "Epoch [1/3], Step [124900/414113], Loss: 2.4465, Perplexity: 11.54781\n",
      "Epoch [1/3], Step [125000/414113], Loss: 4.8481, Perplexity: 127.50130\n",
      "Epoch [1/3], Step [125100/414113], Loss: 2.2891, Perplexity: 9.865811972\n",
      "Epoch [1/3], Step [125200/414113], Loss: 2.7731, Perplexity: 16.008195\n",
      "Epoch [1/3], Step [125300/414113], Loss: 1.6834, Perplexity: 5.383924\n",
      "Epoch [1/3], Step [125400/414113], Loss: 2.6398, Perplexity: 14.011054\n",
      "Epoch [1/3], Step [125500/414113], Loss: 3.9426, Perplexity: 51.55082\n",
      "Epoch [1/3], Step [125600/414113], Loss: 2.8721, Perplexity: 17.674579\n",
      "Epoch [1/3], Step [125700/414113], Loss: 2.3290, Perplexity: 10.26775\n",
      "Epoch [1/3], Step [125800/414113], Loss: 1.7218, Perplexity: 5.594572\n",
      "Epoch [1/3], Step [125900/414113], Loss: 3.7444, Perplexity: 42.28263\n",
      "Epoch [1/3], Step [126000/414113], Loss: 4.6999, Perplexity: 109.93108\n",
      "Epoch [1/3], Step [126100/414113], Loss: 1.8258, Perplexity: 6.207694\n",
      "Epoch [1/3], Step [126200/414113], Loss: 1.6268, Perplexity: 5.087648\n",
      "Epoch [1/3], Step [126300/414113], Loss: 4.6543, Perplexity: 105.0381\n",
      "Epoch [1/3], Step [126400/414113], Loss: 1.7792, Perplexity: 5.925032\n",
      "Epoch [1/3], Step [126500/414113], Loss: 1.0587, Perplexity: 2.8826162\n",
      "Epoch [1/3], Step [126600/414113], Loss: 2.5877, Perplexity: 13.299294\n",
      "Epoch [1/3], Step [126700/414113], Loss: 4.8325, Perplexity: 125.5299\n",
      "Epoch [1/3], Step [126800/414113], Loss: 2.0913, Perplexity: 8.095805\n",
      "Epoch [1/3], Step [126900/414113], Loss: 2.4532, Perplexity: 11.62549\n",
      "Epoch [1/3], Step [127000/414113], Loss: 1.1175, Perplexity: 3.0571535\n",
      "Epoch [1/3], Step [127100/414113], Loss: 1.7788, Perplexity: 5.9227330\n",
      "Epoch [1/3], Step [127200/414113], Loss: 3.5584, Perplexity: 35.108579\n",
      "Epoch [1/3], Step [127300/414113], Loss: 1.8519, Perplexity: 6.371892\n",
      "Epoch [1/3], Step [127400/414113], Loss: 0.9331, Perplexity: 2.542315\n",
      "Epoch [1/3], Step [127500/414113], Loss: 4.8340, Perplexity: 125.7101\n",
      "Epoch [1/3], Step [127600/414113], Loss: 2.1057, Perplexity: 8.2132100\n",
      "Epoch [1/3], Step [127700/414113], Loss: 3.5390, Perplexity: 34.433424\n",
      "Epoch [1/3], Step [127800/414113], Loss: 2.1098, Perplexity: 8.246290\n",
      "Epoch [1/3], Step [127900/414113], Loss: 2.5832, Perplexity: 13.24006\n",
      "Epoch [1/3], Step [128000/414113], Loss: 2.5032, Perplexity: 12.221783\n",
      "Epoch [1/3], Step [128100/414113], Loss: 2.4774, Perplexity: 11.91060\n",
      "Epoch [1/3], Step [128200/414113], Loss: 3.3991, Perplexity: 29.93835\n",
      "Epoch [1/3], Step [128300/414113], Loss: 4.6378, Perplexity: 103.3167\n",
      "Epoch [1/3], Step [128400/414113], Loss: 5.4786, Perplexity: 239.5203\n",
      "Epoch [1/3], Step [128500/414113], Loss: 1.9417, Perplexity: 6.970867\n",
      "Epoch [1/3], Step [128600/414113], Loss: 5.4036, Perplexity: 222.20909\n",
      "Epoch [1/3], Step [128700/414113], Loss: 1.4165, Perplexity: 4.122609\n",
      "Epoch [1/3], Step [128800/414113], Loss: 4.9180, Perplexity: 136.7305\n",
      "Epoch [1/3], Step [128900/414113], Loss: 2.9635, Perplexity: 19.364706\n",
      "Epoch [1/3], Step [129000/414113], Loss: 2.7849, Perplexity: 16.19767\n",
      "Epoch [1/3], Step [129100/414113], Loss: 5.4784, Perplexity: 239.46939\n",
      "Epoch [1/3], Step [129200/414113], Loss: 3.8231, Perplexity: 45.744334\n",
      "Epoch [1/3], Step [129300/414113], Loss: 8.8944, Perplexity: 7291.3604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [129400/414113], Loss: 3.0069, Perplexity: 20.223936\n",
      "Epoch [1/3], Step [129500/414113], Loss: 2.1838, Perplexity: 8.880159\n",
      "Epoch [1/3], Step [129600/414113], Loss: 1.8290, Perplexity: 6.227579\n",
      "Epoch [1/3], Step [129700/414113], Loss: 1.7540, Perplexity: 5.777981\n",
      "Epoch [1/3], Step [129800/414113], Loss: 3.7596, Perplexity: 42.932761\n",
      "Epoch [1/3], Step [129900/414113], Loss: 2.9007, Perplexity: 18.18761\n",
      "Epoch [1/3], Step [130000/414113], Loss: 2.2730, Perplexity: 9.7085801\n",
      "Epoch [1/3], Step [130100/414113], Loss: 2.6846, Perplexity: 14.65317\n",
      "Epoch [1/3], Step [130200/414113], Loss: 2.3065, Perplexity: 10.03913\n",
      "Epoch [1/3], Step [130300/414113], Loss: 4.4640, Perplexity: 86.8376347\n",
      "Epoch [1/3], Step [130400/414113], Loss: 4.7326, Perplexity: 113.59179\n",
      "Epoch [1/3], Step [130500/414113], Loss: 3.6258, Perplexity: 37.554466\n",
      "Epoch [1/3], Step [130600/414113], Loss: 2.8553, Perplexity: 17.37891\n",
      "Epoch [1/3], Step [130700/414113], Loss: 3.0235, Perplexity: 20.562710\n",
      "Epoch [1/3], Step [130800/414113], Loss: 3.2387, Perplexity: 25.500773\n",
      "Epoch [1/3], Step [130900/414113], Loss: 3.8709, Perplexity: 47.985002\n",
      "Epoch [1/3], Step [131000/414113], Loss: 1.0563, Perplexity: 2.875698\n",
      "Epoch [1/3], Step [131100/414113], Loss: 4.2664, Perplexity: 71.265795\n",
      "Epoch [1/3], Step [131200/414113], Loss: 1.6882, Perplexity: 5.4096622\n",
      "Epoch [1/3], Step [131300/414113], Loss: 1.0695, Perplexity: 2.914064\n",
      "Epoch [1/3], Step [131400/414113], Loss: 2.3907, Perplexity: 10.92081\n",
      "Epoch [1/3], Step [131500/414113], Loss: 2.2282, Perplexity: 9.2835179\n",
      "Epoch [1/3], Step [131600/414113], Loss: 5.7131, Perplexity: 302.81554\n",
      "Epoch [1/3], Step [131700/414113], Loss: 2.5121, Perplexity: 12.330272\n",
      "Epoch [1/3], Step [131800/414113], Loss: 3.0623, Perplexity: 21.37728\n",
      "Epoch [1/3], Step [131900/414113], Loss: 2.7492, Perplexity: 15.630209\n",
      "Epoch [1/3], Step [132000/414113], Loss: 3.4697, Perplexity: 32.12811\n",
      "Epoch [1/3], Step [132100/414113], Loss: 2.2544, Perplexity: 9.5300881\n",
      "Epoch [1/3], Step [132200/414113], Loss: 8.6446, Perplexity: 5679.2592\n",
      "Epoch [1/3], Step [132300/414113], Loss: 3.6673, Perplexity: 39.14548\n",
      "Epoch [1/3], Step [132400/414113], Loss: 3.0105, Perplexity: 20.29855\n",
      "Epoch [1/3], Step [132500/414113], Loss: 2.4903, Perplexity: 12.06541\n",
      "Epoch [1/3], Step [132600/414113], Loss: 2.3233, Perplexity: 10.20915\n",
      "Epoch [1/3], Step [132700/414113], Loss: 2.0190, Perplexity: 7.530752\n",
      "Epoch [1/3], Step [132800/414113], Loss: 2.7614, Perplexity: 15.822899\n",
      "Epoch [1/3], Step [132900/414113], Loss: 1.6409, Perplexity: 5.1599400\n",
      "Epoch [1/3], Step [133000/414113], Loss: 3.3997, Perplexity: 29.95639\n",
      "Epoch [1/3], Step [133100/414113], Loss: 1.5206, Perplexity: 4.575088\n",
      "Epoch [1/3], Step [133200/414113], Loss: 4.6858, Perplexity: 108.39522\n",
      "Epoch [1/3], Step [133300/414113], Loss: 2.1262, Perplexity: 8.383146\n",
      "Epoch [1/3], Step [133400/414113], Loss: 2.6834, Perplexity: 14.63514\n",
      "Epoch [1/3], Step [133500/414113], Loss: 2.2769, Perplexity: 9.7464691\n",
      "Epoch [1/3], Step [133600/414113], Loss: 1.7904, Perplexity: 5.992007\n",
      "Epoch [1/3], Step [133700/414113], Loss: 3.6946, Perplexity: 40.229117\n",
      "Epoch [1/3], Step [133800/414113], Loss: 5.1769, Perplexity: 177.12786\n",
      "Epoch [1/3], Step [133900/414113], Loss: 2.2821, Perplexity: 9.7976362\n",
      "Epoch [1/3], Step [134000/414113], Loss: 2.5548, Perplexity: 12.86884\n",
      "Epoch [1/3], Step [134100/414113], Loss: 2.4127, Perplexity: 11.16382\n",
      "Epoch [1/3], Step [134200/414113], Loss: 5.7373, Perplexity: 310.2261\n",
      "Epoch [1/3], Step [134300/414113], Loss: 2.0256, Perplexity: 7.580446\n",
      "Epoch [1/3], Step [134400/414113], Loss: 2.5268, Perplexity: 12.513190\n",
      "Epoch [1/3], Step [134500/414113], Loss: 2.4417, Perplexity: 11.49266\n",
      "Epoch [1/3], Step [134600/414113], Loss: 3.6023, Perplexity: 36.68164\n",
      "Epoch [1/3], Step [134700/414113], Loss: 2.2774, Perplexity: 9.751494\n",
      "Epoch [1/3], Step [134800/414113], Loss: 2.3969, Perplexity: 10.988976\n",
      "Epoch [1/3], Step [134900/414113], Loss: 1.0938, Perplexity: 2.9855035\n",
      "Epoch [1/3], Step [135000/414113], Loss: 3.7182, Perplexity: 41.190577\n",
      "Epoch [1/3], Step [135100/414113], Loss: 1.2334, Perplexity: 3.432992\n",
      "Epoch [1/3], Step [135200/414113], Loss: 4.6782, Perplexity: 107.5810\n",
      "Epoch [1/3], Step [135300/414113], Loss: 3.6469, Perplexity: 38.357591\n",
      "Epoch [1/3], Step [135400/414113], Loss: 2.5204, Perplexity: 12.433256\n",
      "Epoch [1/3], Step [135500/414113], Loss: 2.5285, Perplexity: 12.534254\n",
      "Epoch [1/3], Step [135600/414113], Loss: 2.2298, Perplexity: 9.298197\n",
      "Epoch [1/3], Step [135700/414113], Loss: 2.7914, Perplexity: 16.30406\n",
      "Epoch [1/3], Step [135800/414113], Loss: 3.2514, Perplexity: 25.826713\n",
      "Epoch [1/3], Step [135900/414113], Loss: 3.8868, Perplexity: 48.753994\n",
      "Epoch [1/3], Step [136000/414113], Loss: 3.0313, Perplexity: 20.7250648\n",
      "Epoch [1/3], Step [136100/414113], Loss: 1.5656, Perplexity: 4.78579066\n",
      "Epoch [1/3], Step [136200/414113], Loss: 4.8134, Perplexity: 123.1437\n",
      "Epoch [1/3], Step [136300/414113], Loss: 2.2282, Perplexity: 9.283101\n",
      "Epoch [1/3], Step [136400/414113], Loss: 3.3312, Perplexity: 27.972178\n",
      "Epoch [1/3], Step [136500/414113], Loss: 3.0414, Perplexity: 20.93530\n",
      "Epoch [1/3], Step [136600/414113], Loss: 2.3370, Perplexity: 10.35038\n",
      "Epoch [1/3], Step [136700/414113], Loss: 2.6667, Perplexity: 14.392032\n",
      "Epoch [1/3], Step [136800/414113], Loss: 1.8868, Perplexity: 6.598297\n",
      "Epoch [1/3], Step [136900/414113], Loss: 3.0421, Perplexity: 20.94938\n",
      "Epoch [1/3], Step [137000/414113], Loss: 3.2395, Perplexity: 25.52083\n",
      "Epoch [1/3], Step [137100/414113], Loss: 1.4761, Perplexity: 4.3759747\n",
      "Epoch [1/3], Step [137200/414113], Loss: 2.5671, Perplexity: 13.02793\n",
      "Epoch [1/3], Step [137300/414113], Loss: 2.1879, Perplexity: 8.916763\n",
      "Epoch [1/3], Step [137400/414113], Loss: 3.2418, Perplexity: 25.57989\n",
      "Epoch [1/3], Step [137500/414113], Loss: 2.2296, Perplexity: 9.2964958\n",
      "Epoch [1/3], Step [137600/414113], Loss: 6.2145, Perplexity: 499.9426\n",
      "Epoch [1/3], Step [137700/414113], Loss: 2.3620, Perplexity: 10.612213\n",
      "Epoch [1/3], Step [137800/414113], Loss: 2.9530, Perplexity: 19.162603\n",
      "Epoch [1/3], Step [137900/414113], Loss: 3.4427, Perplexity: 31.2713722\n",
      "Epoch [1/3], Step [138000/414113], Loss: 5.0100, Perplexity: 149.90156\n",
      "Epoch [1/3], Step [138100/414113], Loss: 3.2200, Perplexity: 25.027611\n",
      "Epoch [1/3], Step [138200/414113], Loss: 2.2178, Perplexity: 9.187239\n",
      "Epoch [1/3], Step [138300/414113], Loss: 3.2921, Perplexity: 26.899851\n",
      "Epoch [1/3], Step [138400/414113], Loss: 2.0843, Perplexity: 8.038757\n",
      "Epoch [1/3], Step [138500/414113], Loss: 1.8927, Perplexity: 6.637339\n",
      "Epoch [1/3], Step [138600/414113], Loss: 3.7202, Perplexity: 41.27106\n",
      "Epoch [1/3], Step [138700/414113], Loss: 4.3218, Perplexity: 75.3254945\n",
      "Epoch [1/3], Step [138800/414113], Loss: 1.7745, Perplexity: 5.8975941\n",
      "Epoch [1/3], Step [138900/414113], Loss: 2.4184, Perplexity: 11.228162\n",
      "Epoch [1/3], Step [139000/414113], Loss: 6.2544, Perplexity: 520.2945\n",
      "Epoch [1/3], Step [139100/414113], Loss: 1.7718, Perplexity: 5.881684\n",
      "Epoch [1/3], Step [139200/414113], Loss: 4.7952, Perplexity: 120.93379\n",
      "Epoch [1/3], Step [139300/414113], Loss: 2.9105, Perplexity: 18.36639\n",
      "Epoch [1/3], Step [139400/414113], Loss: 1.8161, Perplexity: 6.147946\n",
      "Epoch [1/3], Step [139500/414113], Loss: 2.1350, Perplexity: 8.456703\n",
      "Epoch [1/3], Step [139600/414113], Loss: 2.6679, Perplexity: 14.409713\n",
      "Epoch [1/3], Step [139700/414113], Loss: 1.5898, Perplexity: 4.9029917\n",
      "Epoch [1/3], Step [139800/414113], Loss: 3.1899, Perplexity: 24.286453\n",
      "Epoch [1/3], Step [139900/414113], Loss: 1.2123, Perplexity: 3.3613517\n",
      "Epoch [1/3], Step [140000/414113], Loss: 2.0808, Perplexity: 8.0108143\n",
      "Epoch [1/3], Step [140100/414113], Loss: 3.2274, Perplexity: 25.21326\n",
      "Epoch [1/3], Step [140200/414113], Loss: 2.7848, Perplexity: 16.197180\n",
      "Epoch [1/3], Step [140300/414113], Loss: 1.2406, Perplexity: 3.4577611\n",
      "Epoch [1/3], Step [140400/414113], Loss: 4.1820, Perplexity: 65.49900\n",
      "Epoch [1/3], Step [140500/414113], Loss: 2.2703, Perplexity: 9.682337\n",
      "Epoch [1/3], Step [140600/414113], Loss: 1.9965, Perplexity: 7.3631358\n",
      "Epoch [1/3], Step [140700/414113], Loss: 2.5732, Perplexity: 13.108073\n",
      "Epoch [1/3], Step [140800/414113], Loss: 1.0913, Perplexity: 2.978264\n",
      "Epoch [1/3], Step [140900/414113], Loss: 4.2496, Perplexity: 70.076305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [141000/414113], Loss: 3.0671, Perplexity: 21.47892\n",
      "Epoch [1/3], Step [141100/414113], Loss: 1.5733, Perplexity: 4.822617\n",
      "Epoch [1/3], Step [141200/414113], Loss: 1.6644, Perplexity: 5.282711\n",
      "Epoch [1/3], Step [141300/414113], Loss: 2.3871, Perplexity: 10.88174\n",
      "Epoch [1/3], Step [141400/414113], Loss: 2.2861, Perplexity: 9.836190\n",
      "Epoch [1/3], Step [141500/414113], Loss: 1.7895, Perplexity: 5.986503\n",
      "Epoch [1/3], Step [141600/414113], Loss: 5.1866, Perplexity: 178.8552\n",
      "Epoch [1/3], Step [141700/414113], Loss: 3.6977, Perplexity: 40.3539427\n",
      "Epoch [1/3], Step [141800/414113], Loss: 1.5323, Perplexity: 4.6287129\n",
      "Epoch [1/3], Step [141900/414113], Loss: 3.8178, Perplexity: 45.504878\n",
      "Epoch [1/3], Step [142000/414113], Loss: 2.7869, Perplexity: 16.230920\n",
      "Epoch [1/3], Step [142100/414113], Loss: 2.1364, Perplexity: 8.4690627\n",
      "Epoch [1/3], Step [142200/414113], Loss: 2.5051, Perplexity: 12.244796\n",
      "Epoch [1/3], Step [142300/414113], Loss: 4.5009, Perplexity: 90.09797\n",
      "Epoch [1/3], Step [142400/414113], Loss: 2.5633, Perplexity: 12.97813\n",
      "Epoch [1/3], Step [142500/414113], Loss: 3.2942, Perplexity: 26.95567\n",
      "Epoch [1/3], Step [142600/414113], Loss: 2.0489, Perplexity: 7.759566\n",
      "Epoch [1/3], Step [142700/414113], Loss: 3.2329, Perplexity: 25.353220\n",
      "Epoch [1/3], Step [142800/414113], Loss: 2.3147, Perplexity: 10.122094\n",
      "Epoch [1/3], Step [142900/414113], Loss: 2.4538, Perplexity: 11.63210\n",
      "Epoch [1/3], Step [143000/414113], Loss: 2.1234, Perplexity: 8.3597024\n",
      "Epoch [1/3], Step [143100/414113], Loss: 2.2522, Perplexity: 9.508992\n",
      "Epoch [1/3], Step [143200/414113], Loss: 3.4780, Perplexity: 32.393771\n",
      "Epoch [1/3], Step [143300/414113], Loss: 3.0974, Perplexity: 22.14100\n",
      "Epoch [1/3], Step [143400/414113], Loss: 2.2587, Perplexity: 9.5705687\n",
      "Epoch [1/3], Step [143500/414113], Loss: 2.3468, Perplexity: 10.45164\n",
      "Epoch [1/3], Step [143600/414113], Loss: 1.6310, Perplexity: 5.109136\n",
      "Epoch [1/3], Step [143700/414113], Loss: 4.1160, Perplexity: 61.310622\n",
      "Epoch [1/3], Step [143800/414113], Loss: 2.3991, Perplexity: 11.01278\n",
      "Epoch [1/3], Step [143900/414113], Loss: 2.0512, Perplexity: 7.7771053\n",
      "Epoch [1/3], Step [144000/414113], Loss: 2.0221, Perplexity: 7.554510\n",
      "Epoch [1/3], Step [144100/414113], Loss: 1.6828, Perplexity: 5.3805812\n",
      "Epoch [1/3], Step [144200/414113], Loss: 4.4512, Perplexity: 85.72684\n",
      "Epoch [1/3], Step [144300/414113], Loss: 2.6356, Perplexity: 13.951934\n",
      "Epoch [1/3], Step [144400/414113], Loss: 3.1920, Perplexity: 24.33591\n",
      "Epoch [1/3], Step [144500/414113], Loss: 2.8236, Perplexity: 16.837445\n",
      "Epoch [1/3], Step [144600/414113], Loss: 1.7591, Perplexity: 5.807150\n",
      "Epoch [1/3], Step [144700/414113], Loss: 3.8937, Perplexity: 49.09175\n",
      "Epoch [1/3], Step [144800/414113], Loss: 5.8953, Perplexity: 363.3376\n",
      "Epoch [1/3], Step [144900/414113], Loss: 2.3459, Perplexity: 10.443054\n",
      "Epoch [1/3], Step [145000/414113], Loss: 4.8369, Perplexity: 126.0798\n",
      "Epoch [1/3], Step [145100/414113], Loss: 1.3487, Perplexity: 3.852405\n",
      "Epoch [1/3], Step [145200/414113], Loss: 3.9133, Perplexity: 50.06615\n",
      "Epoch [1/3], Step [145300/414113], Loss: 2.5590, Perplexity: 12.922874\n",
      "Epoch [1/3], Step [145400/414113], Loss: 3.5023, Perplexity: 33.190157\n",
      "Epoch [1/3], Step [145500/414113], Loss: 1.6479, Perplexity: 5.1960443\n",
      "Epoch [1/3], Step [145600/414113], Loss: 4.2446, Perplexity: 69.727462\n",
      "Epoch [1/3], Step [145700/414113], Loss: 2.8632, Perplexity: 17.517328\n",
      "Epoch [1/3], Step [145800/414113], Loss: 1.7756, Perplexity: 5.9038774\n",
      "Epoch [1/3], Step [145900/414113], Loss: 5.4525, Perplexity: 233.344327\n",
      "Epoch [1/3], Step [146000/414113], Loss: 1.4753, Perplexity: 4.372274\n",
      "Epoch [1/3], Step [146100/414113], Loss: 3.7658, Perplexity: 43.198439\n",
      "Epoch [1/3], Step [146200/414113], Loss: 2.7167, Perplexity: 15.130215\n",
      "Epoch [1/3], Step [146300/414113], Loss: 1.0298, Perplexity: 2.8006072\n",
      "Epoch [1/3], Step [146400/414113], Loss: 1.8107, Perplexity: 6.114670\n",
      "Epoch [1/3], Step [146500/414113], Loss: 2.5938, Perplexity: 13.38024\n",
      "Epoch [1/3], Step [146600/414113], Loss: 2.8820, Perplexity: 17.85085\n",
      "Epoch [1/3], Step [146700/414113], Loss: 3.5892, Perplexity: 36.2058541\n",
      "Epoch [1/3], Step [146800/414113], Loss: 2.7728, Perplexity: 16.00338\n",
      "Epoch [1/3], Step [146900/414113], Loss: 2.0614, Perplexity: 7.856668\n",
      "Epoch [1/3], Step [147000/414113], Loss: 3.4619, Perplexity: 31.876530\n",
      "Epoch [1/3], Step [147100/414113], Loss: 2.5762, Perplexity: 13.14734\n",
      "Epoch [1/3], Step [147200/414113], Loss: 4.0831, Perplexity: 59.33029\n",
      "Epoch [1/3], Step [147300/414113], Loss: 2.6771, Perplexity: 14.543125\n",
      "Epoch [1/3], Step [147400/414113], Loss: 1.9220, Perplexity: 6.8346883\n",
      "Epoch [1/3], Step [147500/414113], Loss: 2.8423, Perplexity: 17.154445\n",
      "Epoch [1/3], Step [147600/414113], Loss: 5.4087, Perplexity: 223.3496\n",
      "Epoch [1/3], Step [147700/414113], Loss: 2.3958, Perplexity: 10.97670\n",
      "Epoch [1/3], Step [147800/414113], Loss: 4.2655, Perplexity: 71.20384\n",
      "Epoch [1/3], Step [147900/414113], Loss: 2.0614, Perplexity: 7.857181\n",
      "Epoch [1/3], Step [148000/414113], Loss: 1.9236, Perplexity: 6.8458540\n",
      "Epoch [1/3], Step [148100/414113], Loss: 2.7184, Perplexity: 15.15590\n",
      "Epoch [1/3], Step [148200/414113], Loss: 3.3432, Perplexity: 28.310832\n",
      "Epoch [1/3], Step [148300/414113], Loss: 1.6293, Perplexity: 5.1003738\n",
      "Epoch [1/3], Step [148400/414113], Loss: 1.7737, Perplexity: 5.892429\n",
      "Epoch [1/3], Step [148500/414113], Loss: 4.5516, Perplexity: 94.78284\n",
      "Epoch [1/3], Step [148600/414113], Loss: 2.2657, Perplexity: 9.6379883\n",
      "Epoch [1/3], Step [148700/414113], Loss: 2.1225, Perplexity: 8.3519979\n",
      "Epoch [1/3], Step [148800/414113], Loss: 3.5125, Perplexity: 33.53061\n",
      "Epoch [1/3], Step [148900/414113], Loss: 3.4217, Perplexity: 30.62183\n",
      "Epoch [1/3], Step [149000/414113], Loss: 3.3126, Perplexity: 27.457389\n",
      "Epoch [1/3], Step [149100/414113], Loss: 1.9008, Perplexity: 6.691584\n",
      "Epoch [1/3], Step [149200/414113], Loss: 2.3326, Perplexity: 10.304886\n",
      "Epoch [1/3], Step [149300/414113], Loss: 2.0748, Perplexity: 7.962817\n",
      "Epoch [1/3], Step [149400/414113], Loss: 3.8704, Perplexity: 47.963198\n",
      "Epoch [1/3], Step [149500/414113], Loss: 2.6323, Perplexity: 13.905276\n",
      "Epoch [1/3], Step [149600/414113], Loss: 1.7112, Perplexity: 5.5356004\n",
      "Epoch [1/3], Step [149700/414113], Loss: 2.8018, Perplexity: 16.475142\n",
      "Epoch [1/3], Step [149800/414113], Loss: 7.1096, Perplexity: 1223.6849\n",
      "Epoch [1/3], Step [149900/414113], Loss: 2.4427, Perplexity: 11.50423\n",
      "Epoch [1/3], Step [150000/414113], Loss: 5.7317, Perplexity: 308.48526\n",
      "Epoch [1/3], Step [150100/414113], Loss: 5.3198, Perplexity: 204.3529\n",
      "Epoch [1/3], Step [150200/414113], Loss: 3.7068, Perplexity: 40.72251\n",
      "Epoch [1/3], Step [150300/414113], Loss: 2.7301, Perplexity: 15.334266\n",
      "Epoch [1/3], Step [150400/414113], Loss: 4.4661, Perplexity: 87.01656\n",
      "Epoch [1/3], Step [150500/414113], Loss: 2.2209, Perplexity: 9.2159160\n",
      "Epoch [1/3], Step [150600/414113], Loss: 1.7509, Perplexity: 5.7598387\n",
      "Epoch [1/3], Step [150700/414113], Loss: 2.4249, Perplexity: 11.300954\n",
      "Epoch [1/3], Step [150800/414113], Loss: 1.2652, Perplexity: 3.54382406\n",
      "Epoch [1/3], Step [150900/414113], Loss: 2.1913, Perplexity: 8.946569\n",
      "Epoch [1/3], Step [151000/414113], Loss: 3.3771, Perplexity: 29.285322\n",
      "Epoch [1/3], Step [151100/414113], Loss: 3.3816, Perplexity: 29.41696\n",
      "Epoch [1/3], Step [151200/414113], Loss: 2.4763, Perplexity: 11.896625\n",
      "Epoch [1/3], Step [151300/414113], Loss: 1.9404, Perplexity: 6.961960\n",
      "Epoch [1/3], Step [151400/414113], Loss: 2.0015, Perplexity: 7.400146\n",
      "Epoch [1/3], Step [151500/414113], Loss: 4.0855, Perplexity: 59.470523\n",
      "Epoch [1/3], Step [151600/414113], Loss: 1.3303, Perplexity: 3.7822748\n",
      "Epoch [1/3], Step [151700/414113], Loss: 1.7944, Perplexity: 6.0157317\n",
      "Epoch [1/3], Step [151800/414113], Loss: 4.3765, Perplexity: 79.559066\n",
      "Epoch [1/3], Step [151900/414113], Loss: 3.6832, Perplexity: 39.771777\n",
      "Epoch [1/3], Step [152000/414113], Loss: 1.5196, Perplexity: 4.570426\n",
      "Epoch [1/3], Step [152100/414113], Loss: 3.6411, Perplexity: 38.135582\n",
      "Epoch [1/3], Step [152200/414113], Loss: 3.4196, Perplexity: 30.55736\n",
      "Epoch [1/3], Step [152300/414113], Loss: 2.8211, Perplexity: 16.795606\n",
      "Epoch [1/3], Step [152400/414113], Loss: 4.5051, Perplexity: 90.48047\n",
      "Epoch [1/3], Step [152500/414113], Loss: 2.4590, Perplexity: 11.693605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [152600/414113], Loss: 3.0862, Perplexity: 21.89281\n",
      "Epoch [1/3], Step [152700/414113], Loss: 2.2177, Perplexity: 9.1858757\n",
      "Epoch [1/3], Step [152800/414113], Loss: 3.7118, Perplexity: 40.926424\n",
      "Epoch [1/3], Step [152900/414113], Loss: 3.1622, Perplexity: 23.622797\n",
      "Epoch [1/3], Step [153000/414113], Loss: 2.1111, Perplexity: 8.257291\n",
      "Epoch [1/3], Step [153100/414113], Loss: 1.9084, Perplexity: 6.7421178\n",
      "Epoch [1/3], Step [153200/414113], Loss: 3.1469, Perplexity: 23.26393\n",
      "Epoch [1/3], Step [153300/414113], Loss: 4.0160, Perplexity: 55.478819\n",
      "Epoch [1/3], Step [153400/414113], Loss: 2.0169, Perplexity: 7.515174\n",
      "Epoch [1/3], Step [153500/414113], Loss: 3.0709, Perplexity: 21.56223\n",
      "Epoch [1/3], Step [153600/414113], Loss: 2.5036, Perplexity: 12.22656\n",
      "Epoch [1/3], Step [153700/414113], Loss: 2.3807, Perplexity: 10.81221\n",
      "Epoch [1/3], Step [153800/414113], Loss: 2.6294, Perplexity: 13.866032\n",
      "Epoch [1/3], Step [153900/414113], Loss: 3.0964, Perplexity: 22.117839\n",
      "Epoch [1/3], Step [154000/414113], Loss: 1.3659, Perplexity: 3.919374\n",
      "Epoch [1/3], Step [154100/414113], Loss: 2.3895, Perplexity: 10.908088\n",
      "Epoch [1/3], Step [154200/414113], Loss: 1.3966, Perplexity: 4.041589\n",
      "Epoch [1/3], Step [154300/414113], Loss: 4.4671, Perplexity: 87.10399\n",
      "Epoch [1/3], Step [154400/414113], Loss: 2.1441, Perplexity: 8.5346762\n",
      "Epoch [1/3], Step [154500/414113], Loss: 5.1072, Perplexity: 165.20028\n",
      "Epoch [1/3], Step [154600/414113], Loss: 4.5575, Perplexity: 95.347266\n",
      "Epoch [1/3], Step [154700/414113], Loss: 1.9949, Perplexity: 7.3518499\n",
      "Epoch [1/3], Step [154800/414113], Loss: 1.3151, Perplexity: 3.725133\n",
      "Epoch [1/3], Step [154900/414113], Loss: 2.7754, Perplexity: 16.045639\n",
      "Epoch [1/3], Step [155000/414113], Loss: 2.8444, Perplexity: 17.19116\n",
      "Epoch [1/3], Step [155100/414113], Loss: 3.8966, Perplexity: 49.235450\n",
      "Epoch [1/3], Step [155200/414113], Loss: 4.4015, Perplexity: 81.570385\n",
      "Epoch [1/3], Step [155300/414113], Loss: 3.6918, Perplexity: 40.11695\n",
      "Epoch [1/3], Step [155400/414113], Loss: 1.7999, Perplexity: 6.049164\n",
      "Epoch [1/3], Step [155500/414113], Loss: 3.4158, Perplexity: 30.44225\n",
      "Epoch [1/3], Step [155600/414113], Loss: 4.0286, Perplexity: 56.180234\n",
      "Epoch [1/3], Step [155700/414113], Loss: 2.2197, Perplexity: 9.2045868\n",
      "Epoch [1/3], Step [155800/414113], Loss: 1.6396, Perplexity: 5.1531934\n",
      "Epoch [1/3], Step [155900/414113], Loss: 2.0020, Perplexity: 7.404059\n",
      "Epoch [1/3], Step [156000/414113], Loss: 1.9861, Perplexity: 7.287496\n",
      "Epoch [1/3], Step [156100/414113], Loss: 1.8928, Perplexity: 6.6379678\n",
      "Epoch [1/3], Step [156200/414113], Loss: 3.7292, Perplexity: 41.644986\n",
      "Epoch [1/3], Step [156300/414113], Loss: 1.6250, Perplexity: 5.078600\n",
      "Epoch [1/3], Step [156400/414113], Loss: 4.7636, Perplexity: 117.1654\n",
      "Epoch [1/3], Step [156500/414113], Loss: 1.8147, Perplexity: 6.1391639\n",
      "Epoch [1/3], Step [156600/414113], Loss: 1.5255, Perplexity: 4.5976625\n",
      "Epoch [1/3], Step [156700/414113], Loss: 3.7489, Perplexity: 42.474206\n",
      "Epoch [1/3], Step [156800/414113], Loss: 0.9184, Perplexity: 2.5053797\n",
      "Epoch [1/3], Step [156900/414113], Loss: 2.3338, Perplexity: 10.31757\n",
      "Epoch [1/3], Step [157000/414113], Loss: 1.8548, Perplexity: 6.390631\n",
      "Epoch [1/3], Step [157100/414113], Loss: 3.4857, Perplexity: 32.643691\n",
      "Epoch [1/3], Step [157200/414113], Loss: 1.9978, Perplexity: 7.372628\n",
      "Epoch [1/3], Step [157300/414113], Loss: 2.7022, Perplexity: 14.91284\n",
      "Epoch [1/3], Step [157400/414113], Loss: 1.7949, Perplexity: 6.019039\n",
      "Epoch [1/3], Step [157500/414113], Loss: 2.9675, Perplexity: 19.44282\n",
      "Epoch [1/3], Step [157600/414113], Loss: 2.0347, Perplexity: 7.6502744\n",
      "Epoch [1/3], Step [157700/414113], Loss: 2.5992, Perplexity: 13.4529798\n",
      "Epoch [1/3], Step [157800/414113], Loss: 5.5377, Perplexity: 254.0915\n",
      "Epoch [1/3], Step [157900/414113], Loss: 2.7709, Perplexity: 15.97322\n",
      "Epoch [1/3], Step [158000/414113], Loss: 3.0194, Perplexity: 20.480059\n",
      "Epoch [1/3], Step [158100/414113], Loss: 3.8014, Perplexity: 44.765548\n",
      "Epoch [1/3], Step [158200/414113], Loss: 5.2605, Perplexity: 192.57457\n",
      "Epoch [1/3], Step [158300/414113], Loss: 2.1306, Perplexity: 8.419736\n",
      "Epoch [1/3], Step [158400/414113], Loss: 2.7078, Perplexity: 14.99620\n",
      "Epoch [1/3], Step [158500/414113], Loss: 2.1906, Perplexity: 8.9404190\n",
      "Epoch [1/3], Step [158600/414113], Loss: 2.2683, Perplexity: 9.6627685\n",
      "Epoch [1/3], Step [158700/414113], Loss: 2.1873, Perplexity: 8.911062\n",
      "Epoch [1/3], Step [158800/414113], Loss: 2.2823, Perplexity: 9.799251\n",
      "Epoch [1/3], Step [158900/414113], Loss: 3.1269, Perplexity: 22.80381\n",
      "Epoch [1/3], Step [159000/414113], Loss: 4.4169, Perplexity: 82.84080\n",
      "Epoch [1/3], Step [159100/414113], Loss: 5.5321, Perplexity: 252.68211\n",
      "Epoch [1/3], Step [159200/414113], Loss: 3.8386, Perplexity: 46.462677\n",
      "Epoch [1/3], Step [159300/414113], Loss: 3.6190, Perplexity: 37.299598\n",
      "Epoch [1/3], Step [159400/414113], Loss: 2.2359, Perplexity: 9.3552330\n",
      "Epoch [1/3], Step [159500/414113], Loss: 2.3895, Perplexity: 10.90846\n",
      "Epoch [1/3], Step [159600/414113], Loss: 2.5486, Perplexity: 12.789519\n",
      "Epoch [1/3], Step [159700/414113], Loss: 2.5207, Perplexity: 12.437860\n",
      "Epoch [1/3], Step [159800/414113], Loss: 2.2427, Perplexity: 9.418377\n",
      "Epoch [1/3], Step [159900/414113], Loss: 3.0283, Perplexity: 20.6623058\n",
      "Epoch [1/3], Step [160000/414113], Loss: 1.5973, Perplexity: 4.9396927\n",
      "Epoch [1/3], Step [160100/414113], Loss: 4.4170, Perplexity: 82.85058\n",
      "Epoch [1/3], Step [160200/414113], Loss: 2.9608, Perplexity: 19.31411\n",
      "Epoch [1/3], Step [160300/414113], Loss: 2.3707, Perplexity: 10.704842\n",
      "Epoch [1/3], Step [160400/414113], Loss: 5.4925, Perplexity: 242.87547\n",
      "Epoch [1/3], Step [160500/414113], Loss: 2.2755, Perplexity: 9.733272\n",
      "Epoch [1/3], Step [160600/414113], Loss: 2.4588, Perplexity: 11.690709\n",
      "Epoch [1/3], Step [160700/414113], Loss: 3.5245, Perplexity: 33.93628\n",
      "Epoch [1/3], Step [160800/414113], Loss: 3.7754, Perplexity: 43.614349\n",
      "Epoch [1/3], Step [160900/414113], Loss: 3.0207, Perplexity: 20.5062891\n",
      "Epoch [1/3], Step [161000/414113], Loss: 2.3210, Perplexity: 10.18617\n",
      "Epoch [1/3], Step [161100/414113], Loss: 1.9063, Perplexity: 6.728017\n",
      "Epoch [1/3], Step [161200/414113], Loss: 1.5112, Perplexity: 4.532290\n",
      "Epoch [1/3], Step [161300/414113], Loss: 3.0700, Perplexity: 21.542555\n",
      "Epoch [1/3], Step [161400/414113], Loss: 4.6292, Perplexity: 102.4299\n",
      "Epoch [1/3], Step [161500/414113], Loss: 4.3986, Perplexity: 81.33370\n",
      "Epoch [1/3], Step [161600/414113], Loss: 2.5499, Perplexity: 12.80552\n",
      "Epoch [1/3], Step [161700/414113], Loss: 1.9928, Perplexity: 7.336045\n",
      "Epoch [1/3], Step [161800/414113], Loss: 4.8669, Perplexity: 129.9232\n",
      "Epoch [1/3], Step [161900/414113], Loss: 2.0686, Perplexity: 7.913510\n",
      "Epoch [1/3], Step [162000/414113], Loss: 2.5194, Perplexity: 12.421853\n",
      "Epoch [1/3], Step [162100/414113], Loss: 2.2361, Perplexity: 9.357183\n",
      "Epoch [1/3], Step [162200/414113], Loss: 2.8044, Perplexity: 16.51783\n",
      "Epoch [1/3], Step [162300/414113], Loss: 1.9189, Perplexity: 6.813455\n",
      "Epoch [1/3], Step [162400/414113], Loss: 4.3583, Perplexity: 78.126017\n",
      "Epoch [1/3], Step [162500/414113], Loss: 3.3463, Perplexity: 28.39836\n",
      "Epoch [1/3], Step [162600/414113], Loss: 3.3531, Perplexity: 28.592007\n",
      "Epoch [1/3], Step [162700/414113], Loss: 3.7464, Perplexity: 42.368373\n",
      "Epoch [1/3], Step [162800/414113], Loss: 4.5918, Perplexity: 98.670219\n",
      "Epoch [1/3], Step [162900/414113], Loss: 1.4166, Perplexity: 4.1231433\n",
      "Epoch [1/3], Step [163000/414113], Loss: 2.5139, Perplexity: 12.35306\n",
      "Epoch [1/3], Step [163100/414113], Loss: 2.5930, Perplexity: 13.37003\n",
      "Epoch [1/3], Step [163200/414113], Loss: 3.2838, Perplexity: 26.67802\n",
      "Epoch [1/3], Step [163300/414113], Loss: 2.6386, Perplexity: 13.99315\n",
      "Epoch [1/3], Step [163400/414113], Loss: 1.4202, Perplexity: 4.1378543\n",
      "Epoch [1/3], Step [163500/414113], Loss: 2.6047, Perplexity: 13.52705\n",
      "Epoch [1/3], Step [163600/414113], Loss: 3.2490, Perplexity: 25.76440\n",
      "Epoch [1/3], Step [163700/414113], Loss: 5.0386, Perplexity: 154.2496\n",
      "Epoch [1/3], Step [163800/414113], Loss: 2.9323, Perplexity: 18.771046\n",
      "Epoch [1/3], Step [163900/414113], Loss: 3.6187, Perplexity: 37.289320\n",
      "Epoch [1/3], Step [164000/414113], Loss: 2.5075, Perplexity: 12.27481\n",
      "Epoch [1/3], Step [164100/414113], Loss: 1.7426, Perplexity: 5.7119789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [164200/414113], Loss: 2.9242, Perplexity: 18.61944\n",
      "Epoch [1/3], Step [164300/414113], Loss: 2.3491, Perplexity: 10.47654\n",
      "Epoch [1/3], Step [164400/414113], Loss: 2.2151, Perplexity: 9.1619035\n",
      "Epoch [1/3], Step [164500/414113], Loss: 3.4346, Perplexity: 31.01815\n",
      "Epoch [1/3], Step [164600/414113], Loss: 6.4917, Perplexity: 659.66755\n",
      "Epoch [1/3], Step [164700/414113], Loss: 1.5628, Perplexity: 4.772453\n",
      "Epoch [1/3], Step [164800/414113], Loss: 2.6765, Perplexity: 14.534188\n",
      "Epoch [1/3], Step [164900/414113], Loss: 2.7541, Perplexity: 15.706694\n",
      "Epoch [1/3], Step [165000/414113], Loss: 2.0211, Perplexity: 7.546314\n",
      "Epoch [1/3], Step [165100/414113], Loss: 2.7976, Perplexity: 16.405437\n",
      "Epoch [1/3], Step [165200/414113], Loss: 2.7696, Perplexity: 15.95225\n",
      "Epoch [1/3], Step [165300/414113], Loss: 2.0540, Perplexity: 7.7991563\n",
      "Epoch [1/3], Step [165400/414113], Loss: 2.2581, Perplexity: 9.565481\n",
      "Epoch [1/3], Step [165500/414113], Loss: 3.4082, Perplexity: 30.212295\n",
      "Epoch [1/3], Step [165600/414113], Loss: 1.8981, Perplexity: 6.673348\n",
      "Epoch [1/3], Step [165700/414113], Loss: 3.2443, Perplexity: 25.644758\n",
      "Epoch [1/3], Step [165800/414113], Loss: 1.2016, Perplexity: 3.325420\n",
      "Epoch [1/3], Step [165900/414113], Loss: 3.2187, Perplexity: 24.995183\n",
      "Epoch [1/3], Step [166000/414113], Loss: 5.2654, Perplexity: 193.52067\n",
      "Epoch [1/3], Step [166100/414113], Loss: 3.2314, Perplexity: 25.315771\n",
      "Epoch [1/3], Step [166200/414113], Loss: 1.8058, Perplexity: 6.084941\n",
      "Epoch [1/3], Step [166300/414113], Loss: 5.4355, Perplexity: 229.4058\n",
      "Epoch [1/3], Step [166400/414113], Loss: 1.3169, Perplexity: 3.731884\n",
      "Epoch [1/3], Step [166500/414113], Loss: 3.3109, Perplexity: 27.40944\n",
      "Epoch [1/3], Step [166600/414113], Loss: 4.3239, Perplexity: 75.48013\n",
      "Epoch [1/3], Step [166700/414113], Loss: 4.1272, Perplexity: 62.00448\n",
      "Epoch [1/3], Step [166800/414113], Loss: 2.6283, Perplexity: 13.85010\n",
      "Epoch [1/3], Step [166900/414113], Loss: 3.7827, Perplexity: 43.932763\n",
      "Epoch [1/3], Step [167000/414113], Loss: 2.2077, Perplexity: 9.094405\n",
      "Epoch [1/3], Step [167100/414113], Loss: 3.7879, Perplexity: 44.165462\n",
      "Epoch [1/3], Step [167200/414113], Loss: 5.3217, Perplexity: 204.7335\n",
      "Epoch [1/3], Step [167300/414113], Loss: 1.1623, Perplexity: 3.1973816\n",
      "Epoch [1/3], Step [167400/414113], Loss: 3.3682, Perplexity: 29.0261020\n",
      "Epoch [1/3], Step [167500/414113], Loss: 2.6211, Perplexity: 13.751028\n",
      "Epoch [1/3], Step [167600/414113], Loss: 4.8490, Perplexity: 127.6112\n",
      "Epoch [1/3], Step [167700/414113], Loss: 2.3058, Perplexity: 10.032471\n",
      "Epoch [1/3], Step [167800/414113], Loss: 6.1771, Perplexity: 481.5920\n",
      "Epoch [1/3], Step [167900/414113], Loss: 4.2888, Perplexity: 72.878137\n",
      "Epoch [1/3], Step [168000/414113], Loss: 1.0643, Perplexity: 2.8989766\n",
      "Epoch [1/3], Step [168100/414113], Loss: 2.5366, Perplexity: 12.63638\n",
      "Epoch [1/3], Step [168200/414113], Loss: 3.0902, Perplexity: 21.98068\n",
      "Epoch [1/3], Step [168300/414113], Loss: 1.5223, Perplexity: 4.582932\n",
      "Epoch [1/3], Step [168400/414113], Loss: 2.2066, Perplexity: 9.084869\n",
      "Epoch [1/3], Step [168500/414113], Loss: 2.0801, Perplexity: 8.005545\n",
      "Epoch [1/3], Step [168600/414113], Loss: 2.4577, Perplexity: 11.67770\n",
      "Epoch [1/3], Step [168700/414113], Loss: 3.5354, Perplexity: 34.30781\n",
      "Epoch [1/3], Step [168800/414113], Loss: 5.9965, Perplexity: 402.00418\n",
      "Epoch [1/3], Step [168900/414113], Loss: 2.4510, Perplexity: 11.599679\n",
      "Epoch [1/3], Step [169000/414113], Loss: 2.4037, Perplexity: 11.06453\n",
      "Epoch [1/3], Step [169100/414113], Loss: 3.1509, Perplexity: 23.35606\n",
      "Epoch [1/3], Step [169200/414113], Loss: 1.8131, Perplexity: 6.1291852\n",
      "Epoch [1/3], Step [169300/414113], Loss: 1.8436, Perplexity: 6.319508\n",
      "Epoch [1/3], Step [169400/414113], Loss: 4.0289, Perplexity: 56.19836\n",
      "Epoch [1/3], Step [169500/414113], Loss: 3.5149, Perplexity: 33.612078\n",
      "Epoch [1/3], Step [169600/414113], Loss: 2.1761, Perplexity: 8.8121743\n",
      "Epoch [1/3], Step [169700/414113], Loss: 2.4545, Perplexity: 11.64108\n",
      "Epoch [1/3], Step [169800/414113], Loss: 4.1457, Perplexity: 63.162580\n",
      "Epoch [1/3], Step [169900/414113], Loss: 2.6074, Perplexity: 13.56434\n",
      "Epoch [1/3], Step [170000/414113], Loss: 2.5352, Perplexity: 12.619528\n",
      "Epoch [1/3], Step [170100/414113], Loss: 4.1509, Perplexity: 63.49060\n",
      "Epoch [1/3], Step [170200/414113], Loss: 2.7308, Perplexity: 15.345310\n",
      "Epoch [1/3], Step [170300/414113], Loss: 1.1307, Perplexity: 3.0979605\n",
      "Epoch [1/3], Step [170400/414113], Loss: 4.2590, Perplexity: 70.737720\n",
      "Epoch [1/3], Step [170500/414113], Loss: 4.9800, Perplexity: 145.47220\n",
      "Epoch [1/3], Step [170600/414113], Loss: 2.7107, Perplexity: 15.039361\n",
      "Epoch [1/3], Step [170700/414113], Loss: 1.4022, Perplexity: 4.0641318\n",
      "Epoch [1/3], Step [170800/414113], Loss: 5.7745, Perplexity: 321.9846\n",
      "Epoch [1/3], Step [170900/414113], Loss: 2.3431, Perplexity: 10.41357\n",
      "Epoch [1/3], Step [171000/414113], Loss: 3.9211, Perplexity: 50.457211\n",
      "Epoch [1/3], Step [171100/414113], Loss: 2.3107, Perplexity: 10.081552\n",
      "Epoch [1/3], Step [171200/414113], Loss: 1.7572, Perplexity: 5.796228\n",
      "Epoch [1/3], Step [171300/414113], Loss: 2.6271, Perplexity: 13.833810\n",
      "Epoch [1/3], Step [171400/414113], Loss: 4.0408, Perplexity: 56.874237\n",
      "Epoch [1/3], Step [171500/414113], Loss: 1.9592, Perplexity: 7.0939166\n",
      "Epoch [1/3], Step [171600/414113], Loss: 3.8304, Perplexity: 46.08096\n",
      "Epoch [1/3], Step [171700/414113], Loss: 4.1982, Perplexity: 66.565562\n",
      "Epoch [1/3], Step [171800/414113], Loss: 3.3994, Perplexity: 29.946246\n",
      "Epoch [1/3], Step [171900/414113], Loss: 1.7882, Perplexity: 5.978793\n",
      "Epoch [1/3], Step [172000/414113], Loss: 1.9636, Perplexity: 7.1248223\n",
      "Epoch [1/3], Step [172100/414113], Loss: 3.1113, Perplexity: 22.449996\n",
      "Epoch [1/3], Step [172200/414113], Loss: 3.2942, Perplexity: 26.95652\n",
      "Epoch [1/3], Step [172300/414113], Loss: 4.0859, Perplexity: 59.49325\n",
      "Epoch [1/3], Step [172400/414113], Loss: 4.0284, Perplexity: 56.171104\n",
      "Epoch [1/3], Step [172500/414113], Loss: 1.6101, Perplexity: 5.003293\n",
      "Epoch [1/3], Step [172600/414113], Loss: 4.8338, Perplexity: 125.6914\n",
      "Epoch [1/3], Step [172700/414113], Loss: 2.9049, Perplexity: 18.263979\n",
      "Epoch [1/3], Step [172800/414113], Loss: 2.1181, Perplexity: 8.3151714\n",
      "Epoch [1/3], Step [172900/414113], Loss: 1.4081, Perplexity: 4.0880883\n",
      "Epoch [1/3], Step [173000/414113], Loss: 2.9638, Perplexity: 19.37080\n",
      "Epoch [1/3], Step [173100/414113], Loss: 2.0107, Perplexity: 7.4684909\n",
      "Epoch [1/3], Step [173200/414113], Loss: 3.2099, Perplexity: 24.77617\n",
      "Epoch [1/3], Step [173300/414113], Loss: 2.2516, Perplexity: 9.503086\n",
      "Epoch [1/3], Step [173400/414113], Loss: 3.4232, Perplexity: 30.66766\n",
      "Epoch [1/3], Step [173500/414113], Loss: 4.4608, Perplexity: 86.553545\n",
      "Epoch [1/3], Step [173600/414113], Loss: 4.1862, Perplexity: 65.77393\n",
      "Epoch [1/3], Step [173700/414113], Loss: 3.3327, Perplexity: 28.01480819\n",
      "Epoch [1/3], Step [173800/414113], Loss: 2.2034, Perplexity: 9.0561437\n",
      "Epoch [1/3], Step [173900/414113], Loss: 3.9414, Perplexity: 51.493051\n",
      "Epoch [1/3], Step [174000/414113], Loss: 2.5102, Perplexity: 12.307818\n",
      "Epoch [1/3], Step [174100/414113], Loss: 2.7008, Perplexity: 14.891409\n",
      "Epoch [1/3], Step [174200/414113], Loss: 2.4069, Perplexity: 11.09949\n",
      "Epoch [1/3], Step [174300/414113], Loss: 3.8978, Perplexity: 49.2919610\n",
      "Epoch [1/3], Step [174400/414113], Loss: 2.4666, Perplexity: 11.781985\n",
      "Epoch [1/3], Step [174500/414113], Loss: 3.2857, Perplexity: 26.728384\n",
      "Epoch [1/3], Step [174600/414113], Loss: 5.1029, Perplexity: 164.49692\n",
      "Epoch [1/3], Step [174700/414113], Loss: 5.4312, Perplexity: 228.4142\n",
      "Epoch [1/3], Step [174800/414113], Loss: 2.8214, Perplexity: 16.80050\n",
      "Epoch [1/3], Step [174900/414113], Loss: 2.2714, Perplexity: 9.6929889\n",
      "Epoch [1/3], Step [175000/414113], Loss: 2.2656, Perplexity: 9.6370180\n",
      "Epoch [1/3], Step [175100/414113], Loss: 3.3279, Perplexity: 27.87882\n",
      "Epoch [1/3], Step [175200/414113], Loss: 2.6985, Perplexity: 14.85745\n",
      "Epoch [1/3], Step [175300/414113], Loss: 1.9939, Perplexity: 7.3443331\n",
      "Epoch [1/3], Step [175400/414113], Loss: 3.6308, Perplexity: 37.742481\n",
      "Epoch [1/3], Step [175500/414113], Loss: 4.6943, Perplexity: 109.3215\n",
      "Epoch [1/3], Step [175600/414113], Loss: 3.0490, Perplexity: 21.094668\n",
      "Epoch [1/3], Step [175700/414113], Loss: 2.9860, Perplexity: 19.807121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [175800/414113], Loss: 4.8674, Perplexity: 129.98446\n",
      "Epoch [1/3], Step [175900/414113], Loss: 3.5313, Perplexity: 34.169719\n",
      "Epoch [1/3], Step [176000/414113], Loss: 3.8779, Perplexity: 48.323316\n",
      "Epoch [1/3], Step [176100/414113], Loss: 2.7630, Perplexity: 15.847968\n",
      "Epoch [1/3], Step [176200/414113], Loss: 3.9205, Perplexity: 50.42742\n",
      "Epoch [1/3], Step [176300/414113], Loss: 3.7621, Perplexity: 43.03968\n",
      "Epoch [1/3], Step [176400/414113], Loss: 2.6250, Perplexity: 13.80471\n",
      "Epoch [1/3], Step [176500/414113], Loss: 5.0852, Perplexity: 161.6172\n",
      "Epoch [1/3], Step [176600/414113], Loss: 2.4759, Perplexity: 11.892676\n",
      "Epoch [1/3], Step [176700/414113], Loss: 3.5951, Perplexity: 36.420939\n",
      "Epoch [1/3], Step [176800/414113], Loss: 3.7737, Perplexity: 43.54066\n",
      "Epoch [1/3], Step [176900/414113], Loss: 1.7831, Perplexity: 5.9485278\n",
      "Epoch [1/3], Step [177000/414113], Loss: 2.2782, Perplexity: 9.759536\n",
      "Epoch [1/3], Step [177100/414113], Loss: 5.8448, Perplexity: 345.4390\n",
      "Epoch [1/3], Step [177200/414113], Loss: 3.6679, Perplexity: 39.16849\n",
      "Epoch [1/3], Step [177300/414113], Loss: 2.2637, Perplexity: 9.618584\n",
      "Epoch [1/3], Step [177400/414113], Loss: 1.6227, Perplexity: 5.066515\n",
      "Epoch [1/3], Step [177500/414113], Loss: 1.8439, Perplexity: 6.320951\n",
      "Epoch [1/3], Step [177600/414113], Loss: 2.2212, Perplexity: 9.2185824\n",
      "Epoch [1/3], Step [177700/414113], Loss: 4.1488, Perplexity: 63.360387\n",
      "Epoch [1/3], Step [177800/414113], Loss: 2.1935, Perplexity: 8.9665751\n",
      "Epoch [1/3], Step [177900/414113], Loss: 3.8019, Perplexity: 44.78757\n",
      "Epoch [1/3], Step [178000/414113], Loss: 4.8464, Perplexity: 127.28680\n",
      "Epoch [1/3], Step [178100/414113], Loss: 1.6700, Perplexity: 5.3122394\n",
      "Epoch [1/3], Step [178200/414113], Loss: 3.4119, Perplexity: 30.321805\n",
      "Epoch [1/3], Step [178300/414113], Loss: 3.5033, Perplexity: 33.22493\n",
      "Epoch [1/3], Step [178400/414113], Loss: 5.1536, Perplexity: 173.05514\n",
      "Epoch [1/3], Step [178500/414113], Loss: 3.8481, Perplexity: 46.901850\n",
      "Epoch [1/3], Step [178600/414113], Loss: 1.9178, Perplexity: 6.806041\n",
      "Epoch [1/3], Step [178700/414113], Loss: 1.6810, Perplexity: 5.3710874\n",
      "Epoch [1/3], Step [178800/414113], Loss: 2.7109, Perplexity: 15.04213\n",
      "Epoch [1/3], Step [178900/414113], Loss: 3.9765, Perplexity: 53.328749\n",
      "Epoch [1/3], Step [179000/414113], Loss: 2.1613, Perplexity: 8.6828544\n",
      "Epoch [1/3], Step [179100/414113], Loss: 2.3611, Perplexity: 10.60221\n",
      "Epoch [1/3], Step [179200/414113], Loss: 3.2149, Perplexity: 24.901275\n",
      "Epoch [1/3], Step [179300/414113], Loss: 1.3070, Perplexity: 3.695178\n",
      "Epoch [1/3], Step [179400/414113], Loss: 6.7850, Perplexity: 884.4361.4066\n",
      "Epoch [1/3], Step [179500/414113], Loss: 2.7193, Perplexity: 15.169870\n",
      "Epoch [1/3], Step [179600/414113], Loss: 1.2189, Perplexity: 3.3833292\n",
      "Epoch [1/3], Step [179700/414113], Loss: 2.7359, Perplexity: 15.423362\n",
      "Epoch [1/3], Step [179800/414113], Loss: 2.4500, Perplexity: 11.588293\n",
      "Epoch [1/3], Step [179900/414113], Loss: 2.4888, Perplexity: 12.046771\n",
      "Epoch [1/3], Step [180000/414113], Loss: 3.2181, Perplexity: 24.980199\n",
      "Epoch [1/3], Step [180100/414113], Loss: 4.1492, Perplexity: 63.381428\n",
      "Epoch [1/3], Step [180200/414113], Loss: 4.0288, Perplexity: 56.19110\n",
      "Epoch [1/3], Step [180300/414113], Loss: 1.8796, Perplexity: 6.5507857\n",
      "Epoch [1/3], Step [180400/414113], Loss: 4.4339, Perplexity: 84.262214\n",
      "Epoch [1/3], Step [180500/414113], Loss: 3.1065, Perplexity: 22.34309\n",
      "Epoch [1/3], Step [180600/414113], Loss: 3.6904, Perplexity: 40.06200\n",
      "Epoch [1/3], Step [180700/414113], Loss: 2.4503, Perplexity: 11.59189\n",
      "Epoch [1/3], Step [180800/414113], Loss: 1.8362, Perplexity: 6.272401\n",
      "Epoch [1/3], Step [180900/414113], Loss: 0.7734, Perplexity: 2.167183\n",
      "Epoch [1/3], Step [181000/414113], Loss: 2.8144, Perplexity: 16.68278\n",
      "Epoch [1/3], Step [181100/414113], Loss: 5.0898, Perplexity: 162.3629\n",
      "Epoch [1/3], Step [181200/414113], Loss: 2.2864, Perplexity: 9.8394156\n",
      "Epoch [1/3], Step [181300/414113], Loss: 2.7798, Perplexity: 16.11608179\n",
      "Epoch [1/3], Step [181400/414113], Loss: 3.0646, Perplexity: 21.425863\n",
      "Epoch [1/3], Step [181500/414113], Loss: 2.6647, Perplexity: 14.363011\n",
      "Epoch [1/3], Step [181600/414113], Loss: 2.8189, Perplexity: 16.759030\n",
      "Epoch [1/3], Step [181700/414113], Loss: 3.8915, Perplexity: 48.9858780\n",
      "Epoch [1/3], Step [181800/414113], Loss: 2.9877, Perplexity: 19.84021\n",
      "Epoch [1/3], Step [181900/414113], Loss: 3.3143, Perplexity: 27.504002\n",
      "Epoch [1/3], Step [182000/414113], Loss: 2.1318, Perplexity: 8.429881\n",
      "Epoch [1/3], Step [182100/414113], Loss: 1.9590, Perplexity: 7.092474\n",
      "Epoch [1/3], Step [182200/414113], Loss: 4.7435, Perplexity: 114.8380\n",
      "Epoch [1/3], Step [182300/414113], Loss: 3.2730, Perplexity: 26.39005\n",
      "Epoch [1/3], Step [182400/414113], Loss: 1.8424, Perplexity: 6.311577\n",
      "Epoch [1/3], Step [182500/414113], Loss: 2.4135, Perplexity: 11.17293\n",
      "Epoch [1/3], Step [182600/414113], Loss: 3.2060, Perplexity: 24.67977\n",
      "Epoch [1/3], Step [182700/414113], Loss: 5.4694, Perplexity: 237.32585\n",
      "Epoch [1/3], Step [182800/414113], Loss: 1.7016, Perplexity: 5.4829483\n",
      "Epoch [1/3], Step [182900/414113], Loss: 3.5355, Perplexity: 34.311445\n",
      "Epoch [1/3], Step [183000/414113], Loss: 2.5090, Perplexity: 12.29312\n",
      "Epoch [1/3], Step [183100/414113], Loss: 1.7828, Perplexity: 5.946626\n",
      "Epoch [1/3], Step [183200/414113], Loss: 1.6858, Perplexity: 5.3970472\n",
      "Epoch [1/3], Step [183300/414113], Loss: 1.7751, Perplexity: 5.9011198\n",
      "Epoch [1/3], Step [183400/414113], Loss: 3.7062, Perplexity: 40.700082\n",
      "Epoch [1/3], Step [183500/414113], Loss: 3.8826, Perplexity: 48.55149\n",
      "Epoch [1/3], Step [183600/414113], Loss: 2.5914, Perplexity: 13.348381\n",
      "Epoch [1/3], Step [183700/414113], Loss: 5.5137, Perplexity: 248.06036\n",
      "Epoch [1/3], Step [183800/414113], Loss: 2.0015, Perplexity: 7.400545\n",
      "Epoch [1/3], Step [183900/414113], Loss: 2.5811, Perplexity: 13.21178\n",
      "Epoch [1/3], Step [184000/414113], Loss: 2.1795, Perplexity: 8.842097\n",
      "Epoch [1/3], Step [184100/414113], Loss: 2.4179, Perplexity: 11.222560\n",
      "Epoch [1/3], Step [184200/414113], Loss: 2.1340, Perplexity: 8.448661\n",
      "Epoch [1/3], Step [184300/414113], Loss: 4.8869, Perplexity: 132.53673\n",
      "Epoch [1/3], Step [184400/414113], Loss: 2.7877, Perplexity: 16.24366\n",
      "Epoch [1/3], Step [184500/414113], Loss: 3.3634, Perplexity: 28.887887\n",
      "Epoch [1/3], Step [184600/414113], Loss: 2.1944, Perplexity: 8.9743524\n",
      "Epoch [1/3], Step [184700/414113], Loss: 2.8180, Perplexity: 16.7429667\n",
      "Epoch [1/3], Step [184800/414113], Loss: 3.0226, Perplexity: 20.54438\n",
      "Epoch [1/3], Step [184900/414113], Loss: 2.9430, Perplexity: 18.97287\n",
      "Epoch [1/3], Step [185000/414113], Loss: 3.3212, Perplexity: 27.692705\n",
      "Epoch [1/3], Step [185100/414113], Loss: 0.9162, Perplexity: 2.4998235\n",
      "Epoch [1/3], Step [185200/414113], Loss: 1.4563, Perplexity: 4.2903337\n",
      "Epoch [1/3], Step [185300/414113], Loss: 6.4305, Perplexity: 620.46522\n",
      "Epoch [1/3], Step [185400/414113], Loss: 3.3374, Perplexity: 28.144697\n",
      "Epoch [1/3], Step [185500/414113], Loss: 2.0999, Perplexity: 8.1653039\n",
      "Epoch [1/3], Step [185600/414113], Loss: 4.8209, Perplexity: 124.07949\n",
      "Epoch [1/3], Step [185700/414113], Loss: 3.1949, Perplexity: 24.40739\n",
      "Epoch [1/3], Step [185800/414113], Loss: 1.6444, Perplexity: 5.177749\n",
      "Epoch [1/3], Step [185900/414113], Loss: 3.0100, Perplexity: 20.28784\n",
      "Epoch [1/3], Step [186000/414113], Loss: 3.1488, Perplexity: 23.3071972\n",
      "Epoch [1/3], Step [186100/414113], Loss: 2.8949, Perplexity: 18.081387\n",
      "Epoch [1/3], Step [186200/414113], Loss: 2.4544, Perplexity: 11.639733\n",
      "Epoch [1/3], Step [186300/414113], Loss: 1.7247, Perplexity: 5.611116541\n",
      "Epoch [1/3], Step [186400/414113], Loss: 5.4979, Perplexity: 244.16935\n",
      "Epoch [1/3], Step [186500/414113], Loss: 2.1383, Perplexity: 8.484779\n",
      "Epoch [1/3], Step [186600/414113], Loss: 1.7336, Perplexity: 5.660771\n",
      "Epoch [1/3], Step [186700/414113], Loss: 3.1405, Perplexity: 23.11473\n",
      "Epoch [1/3], Step [186800/414113], Loss: 2.8999, Perplexity: 18.17167\n",
      "Epoch [1/3], Step [186900/414113], Loss: 5.7621, Perplexity: 318.00283\n",
      "Epoch [1/3], Step [187000/414113], Loss: 1.2986, Perplexity: 3.664235\n",
      "Epoch [1/3], Step [187100/414113], Loss: 4.5443, Perplexity: 94.096491\n",
      "Epoch [1/3], Step [187200/414113], Loss: 0.8581, Perplexity: 2.358786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [187300/414113], Loss: 3.6595, Perplexity: 38.84376\n",
      "Epoch [1/3], Step [187400/414113], Loss: 5.7828, Perplexity: 324.6691\n",
      "Epoch [1/3], Step [187500/414113], Loss: 1.2105, Perplexity: 3.3553138\n",
      "Epoch [1/3], Step [187600/414113], Loss: 5.5035, Perplexity: 245.55516\n",
      "Epoch [1/3], Step [187700/414113], Loss: 2.0209, Perplexity: 7.545222\n",
      "Epoch [1/3], Step [187800/414113], Loss: 1.7136, Perplexity: 5.548887\n",
      "Epoch [1/3], Step [187900/414113], Loss: 3.4745, Perplexity: 32.28246\n",
      "Epoch [1/3], Step [188000/414113], Loss: 2.3106, Perplexity: 10.080907\n",
      "Epoch [1/3], Step [188100/414113], Loss: 2.6372, Perplexity: 13.97420\n",
      "Epoch [1/3], Step [188200/414113], Loss: 2.3168, Perplexity: 10.142707\n",
      "Epoch [1/3], Step [188300/414113], Loss: 2.7789, Perplexity: 16.101911\n",
      "Epoch [1/3], Step [188400/414113], Loss: 4.1260, Perplexity: 61.928981\n",
      "Epoch [1/3], Step [188500/414113], Loss: 6.2185, Perplexity: 501.93454\n",
      "Epoch [1/3], Step [188600/414113], Loss: 2.5672, Perplexity: 13.029310\n",
      "Epoch [1/3], Step [188700/414113], Loss: 2.2594, Perplexity: 9.5774066\n",
      "Epoch [1/3], Step [188800/414113], Loss: 3.0248, Perplexity: 20.5894775\n",
      "Epoch [1/3], Step [188900/414113], Loss: 3.5484, Perplexity: 34.759304\n",
      "Epoch [1/3], Step [189000/414113], Loss: 3.1489, Perplexity: 23.311346\n",
      "Epoch [1/3], Step [189100/414113], Loss: 3.1498, Perplexity: 23.331925\n",
      "Epoch [1/3], Step [189200/414113], Loss: 1.3404, Perplexity: 3.8206044\n",
      "Epoch [1/3], Step [189300/414113], Loss: 3.3051, Perplexity: 27.251518\n",
      "Epoch [1/3], Step [189400/414113], Loss: 5.2426, Perplexity: 189.16070\n",
      "Epoch [1/3], Step [189500/414113], Loss: 3.1065, Perplexity: 22.342644\n",
      "Epoch [1/3], Step [189600/414113], Loss: 5.5243, Perplexity: 250.72198\n",
      "Epoch [1/3], Step [189700/414113], Loss: 2.6778, Perplexity: 14.55273\n",
      "Epoch [1/3], Step [189800/414113], Loss: 3.5561, Perplexity: 35.02545\n",
      "Epoch [1/3], Step [189900/414113], Loss: 4.2068, Perplexity: 67.138780\n",
      "Epoch [1/3], Step [190000/414113], Loss: 2.0378, Perplexity: 7.6735624\n",
      "Epoch [1/3], Step [190100/414113], Loss: 6.2833, Perplexity: 535.5525\n",
      "Epoch [1/3], Step [190200/414113], Loss: 3.0610, Perplexity: 21.348963\n",
      "Epoch [1/3], Step [190300/414113], Loss: 2.0969, Perplexity: 8.1409478\n",
      "Epoch [1/3], Step [190400/414113], Loss: 3.1040, Perplexity: 22.28780\n",
      "Epoch [1/3], Step [190500/414113], Loss: 2.3932, Perplexity: 10.94898\n",
      "Epoch [1/3], Step [190600/414113], Loss: 2.9082, Perplexity: 18.32450\n",
      "Epoch [1/3], Step [190700/414113], Loss: 1.7566, Perplexity: 5.792489\n",
      "Epoch [1/3], Step [190800/414113], Loss: 2.9672, Perplexity: 19.437517\n",
      "Epoch [1/3], Step [190900/414113], Loss: 1.0864, Perplexity: 2.963659\n",
      "Epoch [1/3], Step [191000/414113], Loss: 2.1087, Perplexity: 8.237304\n",
      "Epoch [1/3], Step [191100/414113], Loss: 2.9513, Perplexity: 19.12995\n",
      "Epoch [1/3], Step [191200/414113], Loss: 1.0707, Perplexity: 2.917383\n",
      "Epoch [1/3], Step [191300/414113], Loss: 3.2178, Perplexity: 24.97381\n",
      "Epoch [1/3], Step [191400/414113], Loss: 2.1020, Perplexity: 8.182665\n",
      "Epoch [1/3], Step [191500/414113], Loss: 4.3093, Perplexity: 74.388164\n",
      "Epoch [1/3], Step [191600/414113], Loss: 3.1469, Perplexity: 23.263693\n",
      "Epoch [1/3], Step [191700/414113], Loss: 2.0116, Perplexity: 7.4751060\n",
      "Epoch [1/3], Step [191800/414113], Loss: 1.7472, Perplexity: 5.738816\n",
      "Epoch [1/3], Step [191900/414113], Loss: 4.5349, Perplexity: 93.21245\n",
      "Epoch [1/3], Step [192000/414113], Loss: 1.8551, Perplexity: 6.392213\n",
      "Epoch [1/3], Step [192100/414113], Loss: 1.7635, Perplexity: 5.832696\n",
      "Epoch [1/3], Step [192200/414113], Loss: 3.4332, Perplexity: 30.974333\n",
      "Epoch [1/3], Step [192300/414113], Loss: 2.1735, Perplexity: 8.788751\n",
      "Epoch [1/3], Step [192400/414113], Loss: 2.9685, Perplexity: 19.46233\n",
      "Epoch [1/3], Step [192500/414113], Loss: 3.3256, Perplexity: 27.816286\n",
      "Epoch [1/3], Step [192600/414113], Loss: 2.3473, Perplexity: 10.45726\n",
      "Epoch [1/3], Step [192700/414113], Loss: 3.5638, Perplexity: 35.29842\n",
      "Epoch [1/3], Step [192800/414113], Loss: 1.4821, Perplexity: 4.402134\n",
      "Epoch [1/3], Step [192900/414113], Loss: 3.7648, Perplexity: 43.1536354\n",
      "Epoch [1/3], Step [193000/414113], Loss: 2.2300, Perplexity: 9.2996488\n",
      "Epoch [1/3], Step [193100/414113], Loss: 3.5483, Perplexity: 34.753097\n",
      "Epoch [1/3], Step [193200/414113], Loss: 4.1447, Perplexity: 63.098775\n",
      "Epoch [1/3], Step [193300/414113], Loss: 1.5004, Perplexity: 4.483525\n",
      "Epoch [1/3], Step [193400/414113], Loss: 4.1245, Perplexity: 61.836278\n",
      "Epoch [1/3], Step [193500/414113], Loss: 3.5702, Perplexity: 35.52383\n",
      "Epoch [1/3], Step [193600/414113], Loss: 3.4175, Perplexity: 30.49401\n",
      "Epoch [1/3], Step [193700/414113], Loss: 3.7567, Perplexity: 42.808543\n",
      "Epoch [1/3], Step [193800/414113], Loss: 3.1316, Perplexity: 22.91153\n",
      "Epoch [1/3], Step [193900/414113], Loss: 2.6543, Perplexity: 14.214800\n",
      "Epoch [1/3], Step [194000/414113], Loss: 3.2450, Perplexity: 25.662357\n",
      "Epoch [1/3], Step [194100/414113], Loss: 1.5984, Perplexity: 4.9453410\n",
      "Epoch [1/3], Step [194200/414113], Loss: 3.3501, Perplexity: 28.506688\n",
      "Epoch [1/3], Step [194300/414113], Loss: 6.7869, Perplexity: 886.12006\n",
      "Epoch [1/3], Step [194400/414113], Loss: 0.9977, Perplexity: 2.7120342\n",
      "Epoch [1/3], Step [194500/414113], Loss: 3.9149, Perplexity: 50.14450\n",
      "Epoch [1/3], Step [194600/414113], Loss: 2.0837, Perplexity: 8.033869\n",
      "Epoch [1/3], Step [194700/414113], Loss: 2.2331, Perplexity: 9.3284120\n",
      "Epoch [1/3], Step [194800/414113], Loss: 3.3168, Perplexity: 27.57333\n",
      "Epoch [1/3], Step [194900/414113], Loss: 2.2367, Perplexity: 9.3627054\n",
      "Epoch [1/3], Step [195000/414113], Loss: 2.1896, Perplexity: 8.9315103\n",
      "Epoch [1/3], Step [195100/414113], Loss: 3.4102, Perplexity: 30.27118\n",
      "Epoch [1/3], Step [195200/414113], Loss: 5.6337, Perplexity: 279.69629\n",
      "Epoch [1/3], Step [195300/414113], Loss: 1.5208, Perplexity: 4.5761016\n",
      "Epoch [1/3], Step [195400/414113], Loss: 4.1638, Perplexity: 64.317384\n",
      "Epoch [1/3], Step [195500/414113], Loss: 1.2915, Perplexity: 3.6381826\n",
      "Epoch [1/3], Step [195600/414113], Loss: 3.5224, Perplexity: 33.86602\n",
      "Epoch [1/3], Step [195700/414113], Loss: 1.5405, Perplexity: 4.6671637\n",
      "Epoch [1/3], Step [195800/414113], Loss: 3.4216, Perplexity: 30.6169177\n",
      "Epoch [1/3], Step [195900/414113], Loss: 3.2557, Perplexity: 25.93655\n",
      "Epoch [1/3], Step [196000/414113], Loss: 2.1471, Perplexity: 8.5603701\n",
      "Epoch [1/3], Step [196100/414113], Loss: 2.3011, Perplexity: 9.9848529\n",
      "Epoch [1/3], Step [196200/414113], Loss: 3.9356, Perplexity: 51.192414\n",
      "Epoch [1/3], Step [196300/414113], Loss: 1.6509, Perplexity: 5.2115917\n",
      "Epoch [1/3], Step [196400/414113], Loss: 2.7043, Perplexity: 14.943622\n",
      "Epoch [1/3], Step [196500/414113], Loss: 2.2780, Perplexity: 9.757354\n",
      "Epoch [1/3], Step [196600/414113], Loss: 2.4446, Perplexity: 11.525772\n",
      "Epoch [1/3], Step [196700/414113], Loss: 1.3502, Perplexity: 3.858346\n",
      "Epoch [1/3], Step [196800/414113], Loss: 3.1740, Perplexity: 23.903200\n",
      "Epoch [1/3], Step [196900/414113], Loss: 2.7253, Perplexity: 15.26107\n",
      "Epoch [1/3], Step [197000/414113], Loss: 2.2660, Perplexity: 9.641172\n",
      "Epoch [1/3], Step [197100/414113], Loss: 3.8630, Perplexity: 47.609337\n",
      "Epoch [1/3], Step [197200/414113], Loss: 2.6361, Perplexity: 13.95918\n",
      "Epoch [1/3], Step [197300/414113], Loss: 4.0735, Perplexity: 58.761755\n",
      "Epoch [1/3], Step [197400/414113], Loss: 1.5851, Perplexity: 4.879868\n",
      "Epoch [1/3], Step [197500/414113], Loss: 3.1508, Perplexity: 23.354369\n",
      "Epoch [1/3], Step [197600/414113], Loss: 2.3125, Perplexity: 10.099383\n",
      "Epoch [1/3], Step [197700/414113], Loss: 5.1140, Perplexity: 166.33406\n",
      "Epoch [1/3], Step [197800/414113], Loss: 3.1807, Perplexity: 24.063445\n",
      "Epoch [1/3], Step [197900/414113], Loss: 1.3042, Perplexity: 3.6847366\n",
      "Epoch [1/3], Step [198000/414113], Loss: 1.7859, Perplexity: 5.965089\n",
      "Epoch [1/3], Step [198100/414113], Loss: 4.6784, Perplexity: 107.6000\n",
      "Epoch [1/3], Step [198200/414113], Loss: 3.3910, Perplexity: 29.69668\n",
      "Epoch [1/3], Step [198300/414113], Loss: 4.4809, Perplexity: 88.316576\n",
      "Epoch [1/3], Step [198400/414113], Loss: 2.3288, Perplexity: 10.26522\n",
      "Epoch [1/3], Step [198500/414113], Loss: 1.8202, Perplexity: 6.173022\n",
      "Epoch [1/3], Step [198600/414113], Loss: 5.0560, Perplexity: 156.9649\n",
      "Epoch [1/3], Step [198700/414113], Loss: 1.9478, Perplexity: 7.0133580\n",
      "Epoch [1/3], Step [198800/414113], Loss: 1.3907, Perplexity: 4.017737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [198900/414113], Loss: 1.6778, Perplexity: 5.3535719\n",
      "Epoch [1/3], Step [199000/414113], Loss: 1.2161, Perplexity: 3.373924\n",
      "Epoch [1/3], Step [199100/414113], Loss: 3.3777, Perplexity: 29.302603\n",
      "Epoch [1/3], Step [199200/414113], Loss: 1.6119, Perplexity: 5.012375\n",
      "Epoch [1/3], Step [199300/414113], Loss: 3.3170, Perplexity: 27.57835\n",
      "Epoch [1/3], Step [199400/414113], Loss: 1.7417, Perplexity: 5.7071990\n",
      "Epoch [1/3], Step [199500/414113], Loss: 3.6367, Perplexity: 37.966927\n",
      "Epoch [1/3], Step [199600/414113], Loss: 3.2231, Perplexity: 25.10631\n",
      "Epoch [1/3], Step [199700/414113], Loss: 0.9540, Perplexity: 2.5960268\n",
      "Epoch [1/3], Step [199800/414113], Loss: 4.1443, Perplexity: 63.075593\n",
      "Epoch [1/3], Step [199900/414113], Loss: 1.8062, Perplexity: 6.0872053\n",
      "Epoch [1/3], Step [200000/414113], Loss: 3.0787, Perplexity: 21.730057\n",
      "Epoch [1/3], Step [200100/414113], Loss: 3.1759, Perplexity: 23.948392\n",
      "Epoch [1/3], Step [200200/414113], Loss: 2.9586, Perplexity: 19.27123\n",
      "Epoch [1/3], Step [200300/414113], Loss: 1.0770, Perplexity: 2.9358734\n",
      "Epoch [1/3], Step [200400/414113], Loss: 2.3114, Perplexity: 10.089015\n",
      "Epoch [1/3], Step [200500/414113], Loss: 1.6924, Perplexity: 5.432453\n",
      "Epoch [1/3], Step [200600/414113], Loss: 1.8615, Perplexity: 6.4334589\n",
      "Epoch [1/3], Step [200700/414113], Loss: 1.3785, Perplexity: 3.968943\n",
      "Epoch [1/3], Step [200800/414113], Loss: 4.1581, Perplexity: 63.951856409\n",
      "Epoch [1/3], Step [200900/414113], Loss: 2.0779, Perplexity: 7.988060\n",
      "Epoch [1/3], Step [201000/414113], Loss: 2.0945, Perplexity: 8.121376\n",
      "Epoch [1/3], Step [201100/414113], Loss: 1.2380, Perplexity: 3.448685\n",
      "Epoch [1/3], Step [201200/414113], Loss: 2.7295, Perplexity: 15.325839\n",
      "Epoch [1/3], Step [201300/414113], Loss: 2.2085, Perplexity: 9.1020525\n",
      "Epoch [1/3], Step [201400/414113], Loss: 3.1734, Perplexity: 23.887803\n",
      "Epoch [1/3], Step [201500/414113], Loss: 3.4945, Perplexity: 32.93518\n",
      "Epoch [1/3], Step [201600/414113], Loss: 2.4974, Perplexity: 12.15073\n",
      "Epoch [1/3], Step [201700/414113], Loss: 4.8583, Perplexity: 128.80882\n",
      "Epoch [1/3], Step [201800/414113], Loss: 1.6215, Perplexity: 5.06096920\n",
      "Epoch [1/3], Step [201900/414113], Loss: 2.4939, Perplexity: 12.108528\n",
      "Epoch [1/3], Step [202000/414113], Loss: 2.7668, Perplexity: 15.907788\n",
      "Epoch [1/3], Step [202100/414113], Loss: 6.0227, Perplexity: 412.67369\n",
      "Epoch [1/3], Step [202200/414113], Loss: 2.7403, Perplexity: 15.49092\n",
      "Epoch [1/3], Step [202300/414113], Loss: 2.8376, Perplexity: 17.07499\n",
      "Epoch [1/3], Step [202400/414113], Loss: 1.9337, Perplexity: 6.9152210\n",
      "Epoch [1/3], Step [202500/414113], Loss: 1.8627, Perplexity: 6.4412208\n",
      "Epoch [1/3], Step [202600/414113], Loss: 1.8014, Perplexity: 6.0580944\n",
      "Epoch [1/3], Step [202700/414113], Loss: 1.5171, Perplexity: 4.5588154\n",
      "Epoch [1/3], Step [202800/414113], Loss: 2.9656, Perplexity: 19.406814\n",
      "Epoch [1/3], Step [202900/414113], Loss: 4.3182, Perplexity: 75.05443\n",
      "Epoch [1/3], Step [203000/414113], Loss: 1.4226, Perplexity: 4.1477284\n",
      "Epoch [1/3], Step [203100/414113], Loss: 3.5532, Perplexity: 34.92634\n",
      "Epoch [1/3], Step [203200/414113], Loss: 1.9981, Perplexity: 7.3753309\n",
      "Epoch [1/3], Step [203300/414113], Loss: 4.3690, Perplexity: 78.966134\n",
      "Epoch [1/3], Step [203400/414113], Loss: 5.6390, Perplexity: 281.17832\n",
      "Epoch [1/3], Step [203500/414113], Loss: 2.9610, Perplexity: 19.317536\n",
      "Epoch [1/3], Step [203600/414113], Loss: 2.7895, Perplexity: 16.27238\n",
      "Epoch [1/3], Step [203700/414113], Loss: 2.2985, Perplexity: 9.95939857\n",
      "Epoch [1/3], Step [203800/414113], Loss: 1.8942, Perplexity: 6.647289\n",
      "Epoch [1/3], Step [203900/414113], Loss: 1.7261, Perplexity: 5.6189970\n",
      "Epoch [1/3], Step [204000/414113], Loss: 2.0377, Perplexity: 7.6727992\n",
      "Epoch [1/3], Step [204100/414113], Loss: 2.0515, Perplexity: 7.779269\n",
      "Epoch [1/3], Step [204200/414113], Loss: 2.9627, Perplexity: 19.34933744\n",
      "Epoch [1/3], Step [204300/414113], Loss: 2.0123, Perplexity: 7.4804500\n",
      "Epoch [1/3], Step [204400/414113], Loss: 2.2821, Perplexity: 9.797069\n",
      "Epoch [1/3], Step [204500/414113], Loss: 2.2010, Perplexity: 9.0343525\n",
      "Epoch [1/3], Step [204600/414113], Loss: 1.6426, Perplexity: 5.1685284\n",
      "Epoch [1/3], Step [204700/414113], Loss: 2.7164, Perplexity: 15.12627\n",
      "Epoch [1/3], Step [204800/414113], Loss: 3.2400, Perplexity: 25.5338386\n",
      "Epoch [1/3], Step [204900/414113], Loss: 3.9958, Perplexity: 54.370393\n",
      "Epoch [1/3], Step [205000/414113], Loss: 5.8546, Perplexity: 348.83980\n",
      "Epoch [1/3], Step [205100/414113], Loss: 5.0031, Perplexity: 148.87080\n",
      "Epoch [1/3], Step [205200/414113], Loss: 2.2534, Perplexity: 9.5198458\n",
      "Epoch [1/3], Step [205300/414113], Loss: 3.3575, Perplexity: 28.71775\n",
      "Epoch [1/3], Step [205400/414113], Loss: 1.2986, Perplexity: 3.664030\n",
      "Epoch [1/3], Step [205500/414113], Loss: 5.4223, Perplexity: 226.4102\n",
      "Epoch [1/3], Step [205600/414113], Loss: 2.3531, Perplexity: 10.51815\n",
      "Epoch [1/3], Step [205700/414113], Loss: 4.6130, Perplexity: 100.78800\n",
      "Epoch [1/3], Step [205800/414113], Loss: 2.9227, Perplexity: 18.5919793\n",
      "Epoch [1/3], Step [205900/414113], Loss: 1.9509, Perplexity: 7.0348074\n",
      "Epoch [1/3], Step [206000/414113], Loss: 3.1415, Perplexity: 23.13828\n",
      "Epoch [1/3], Step [206100/414113], Loss: 1.6539, Perplexity: 5.227336\n",
      "Epoch [1/3], Step [206200/414113], Loss: 2.8346, Perplexity: 17.02353\n",
      "Epoch [1/3], Step [206300/414113], Loss: 2.6364, Perplexity: 13.963258\n",
      "Epoch [1/3], Step [206400/414113], Loss: 1.9369, Perplexity: 6.9372263\n",
      "Epoch [1/3], Step [206500/414113], Loss: 1.4051, Perplexity: 4.076151\n",
      "Epoch [1/3], Step [206600/414113], Loss: 3.6125, Perplexity: 37.059165\n",
      "Epoch [1/3], Step [206700/414113], Loss: 3.1814, Perplexity: 24.079992\n",
      "Epoch [1/3], Step [206800/414113], Loss: 3.0238, Perplexity: 20.56892\n",
      "Epoch [1/3], Step [206900/414113], Loss: 1.8566, Perplexity: 6.402088\n",
      "Epoch [1/3], Step [207000/414113], Loss: 2.8804, Perplexity: 17.821204\n",
      "Epoch [1/3], Step [207100/414113], Loss: 3.0889, Perplexity: 21.95311\n",
      "Epoch [1/3], Step [207200/414113], Loss: 2.7301, Perplexity: 15.334299\n",
      "Epoch [1/3], Step [207300/414113], Loss: 3.6303, Perplexity: 37.72608\n",
      "Epoch [1/3], Step [207400/414113], Loss: 4.6203, Perplexity: 101.52413\n",
      "Epoch [1/3], Step [207500/414113], Loss: 3.4504, Perplexity: 31.51336\n",
      "Epoch [1/3], Step [207600/414113], Loss: 5.5813, Perplexity: 265.4126\n",
      "Epoch [1/3], Step [207700/414113], Loss: 3.5325, Perplexity: 34.20969\n",
      "Epoch [1/3], Step [207800/414113], Loss: 4.3624, Perplexity: 78.44527\n",
      "Epoch [1/3], Step [207900/414113], Loss: 2.1438, Perplexity: 8.53199370\n",
      "Epoch [1/3], Step [208000/414113], Loss: 2.8971, Perplexity: 18.121717\n",
      "Epoch [1/3], Step [208100/414113], Loss: 4.5456, Perplexity: 94.22140\n",
      "Epoch [1/3], Step [208200/414113], Loss: 2.8119, Perplexity: 16.641880\n",
      "Epoch [1/3], Step [208300/414113], Loss: 2.6111, Perplexity: 13.613488\n",
      "Epoch [1/3], Step [208400/414113], Loss: 2.6913, Perplexity: 14.750101\n",
      "Epoch [1/3], Step [208500/414113], Loss: 4.2893, Perplexity: 72.914770\n",
      "Epoch [1/3], Step [208600/414113], Loss: 2.7594, Perplexity: 15.7902157\n",
      "Epoch [1/3], Step [208700/414113], Loss: 3.1111, Perplexity: 22.445078\n",
      "Epoch [1/3], Step [208800/414113], Loss: 2.2848, Perplexity: 9.823621\n",
      "Epoch [1/3], Step [208900/414113], Loss: 1.7052, Perplexity: 5.5026739\n",
      "Epoch [1/3], Step [209000/414113], Loss: 4.0368, Perplexity: 56.642725\n",
      "Epoch [1/3], Step [209100/414113], Loss: 3.7392, Perplexity: 42.065544\n",
      "Epoch [1/3], Step [209200/414113], Loss: 3.8299, Perplexity: 46.059325\n",
      "Epoch [1/3], Step [209300/414113], Loss: 4.0431, Perplexity: 57.00401\n",
      "Epoch [1/3], Step [209400/414113], Loss: 1.9170, Perplexity: 6.800243\n",
      "Epoch [1/3], Step [209500/414113], Loss: 1.4964, Perplexity: 4.465557\n",
      "Epoch [1/3], Step [209600/414113], Loss: 1.3117, Perplexity: 3.71237211\n",
      "Epoch [1/3], Step [209700/414113], Loss: 3.9418, Perplexity: 51.51359\n",
      "Epoch [1/3], Step [209800/414113], Loss: 1.6474, Perplexity: 5.19369890\n",
      "Epoch [1/3], Step [209900/414113], Loss: 3.0588, Perplexity: 21.30163\n",
      "Epoch [1/3], Step [210000/414113], Loss: 2.4023, Perplexity: 11.048449\n",
      "Epoch [1/3], Step [210100/414113], Loss: 4.2861, Perplexity: 72.68074\n",
      "Epoch [1/3], Step [210200/414113], Loss: 4.1483, Perplexity: 63.32482\n",
      "Epoch [1/3], Step [210300/414113], Loss: 2.5998, Perplexity: 13.461654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [210400/414113], Loss: 3.2023, Perplexity: 24.588140\n",
      "Epoch [1/3], Step [210500/414113], Loss: 2.0669, Perplexity: 7.900350\n",
      "Epoch [1/3], Step [210600/414113], Loss: 2.6420, Perplexity: 14.040757\n",
      "Epoch [1/3], Step [210700/414113], Loss: 4.7643, Perplexity: 117.25401\n",
      "Epoch [1/3], Step [210800/414113], Loss: 1.8995, Perplexity: 6.6828722\n",
      "Epoch [1/3], Step [210900/414113], Loss: 1.3983, Perplexity: 4.0483720\n",
      "Epoch [1/3], Step [211000/414113], Loss: 3.5059, Perplexity: 33.31164\n",
      "Epoch [1/3], Step [211100/414113], Loss: 1.5401, Perplexity: 4.665033\n",
      "Epoch [1/3], Step [211200/414113], Loss: 3.3983, Perplexity: 29.913137\n",
      "Epoch [1/3], Step [211300/414113], Loss: 2.8015, Perplexity: 16.468999\n",
      "Epoch [1/3], Step [211400/414113], Loss: 2.4170, Perplexity: 11.21160\n",
      "Epoch [1/3], Step [211500/414113], Loss: 3.6599, Perplexity: 38.855975\n",
      "Epoch [1/3], Step [211600/414113], Loss: 2.8961, Perplexity: 18.102804\n",
      "Epoch [1/3], Step [211700/414113], Loss: 2.5304, Perplexity: 12.55867\n",
      "Epoch [1/3], Step [211800/414113], Loss: 1.9286, Perplexity: 6.879639\n",
      "Epoch [1/3], Step [211900/414113], Loss: 2.8640, Perplexity: 17.531536\n",
      "Epoch [1/3], Step [212000/414113], Loss: 3.6907, Perplexity: 40.07224\n",
      "Epoch [1/3], Step [212100/414113], Loss: 2.7816, Perplexity: 16.14567\n",
      "Epoch [1/3], Step [212200/414113], Loss: 1.3918, Perplexity: 4.0219923\n",
      "Epoch [1/3], Step [212300/414113], Loss: 2.0557, Perplexity: 7.812196\n",
      "Epoch [1/3], Step [212400/414113], Loss: 1.8793, Perplexity: 6.5487626\n",
      "Epoch [1/3], Step [212500/414113], Loss: 2.9818, Perplexity: 19.72402\n",
      "Epoch [1/3], Step [212600/414113], Loss: 2.8769, Perplexity: 17.759262\n",
      "Epoch [1/3], Step [212700/414113], Loss: 2.5557, Perplexity: 12.880263\n",
      "Epoch [1/3], Step [212800/414113], Loss: 2.9884, Perplexity: 19.85326\n",
      "Epoch [1/3], Step [212900/414113], Loss: 3.9562, Perplexity: 52.259030\n",
      "Epoch [1/3], Step [213000/414113], Loss: 5.8059, Perplexity: 332.2529\n",
      "Epoch [1/3], Step [213100/414113], Loss: 2.7533, Perplexity: 15.693903\n",
      "Epoch [1/3], Step [213200/414113], Loss: 2.8817, Perplexity: 17.844118\n",
      "Epoch [1/3], Step [213300/414113], Loss: 2.1251, Perplexity: 8.373862\n",
      "Epoch [1/3], Step [213400/414113], Loss: 3.9699, Perplexity: 52.981973\n",
      "Epoch [1/3], Step [213500/414113], Loss: 1.7433, Perplexity: 5.716409\n",
      "Epoch [1/3], Step [213600/414113], Loss: 1.6399, Perplexity: 5.1545743\n",
      "Epoch [1/3], Step [213700/414113], Loss: 6.8526, Perplexity: 946.3383\n",
      "Epoch [1/3], Step [213800/414113], Loss: 3.7828, Perplexity: 43.936898\n",
      "Epoch [1/3], Step [213900/414113], Loss: 2.2970, Perplexity: 9.9443106\n",
      "Epoch [1/3], Step [214000/414113], Loss: 1.9745, Perplexity: 7.2027194\n",
      "Epoch [1/3], Step [214100/414113], Loss: 3.9879, Perplexity: 53.93992\n",
      "Epoch [1/3], Step [214200/414113], Loss: 1.6036, Perplexity: 4.971038\n",
      "Epoch [1/3], Step [214300/414113], Loss: 1.3159, Perplexity: 3.7280696\n",
      "Epoch [1/3], Step [214400/414113], Loss: 3.8469, Perplexity: 46.84848\n",
      "Epoch [1/3], Step [214500/414113], Loss: 2.5173, Perplexity: 12.394579\n",
      "Epoch [1/3], Step [214600/414113], Loss: 1.7765, Perplexity: 5.9089551\n",
      "Epoch [1/3], Step [214700/414113], Loss: 2.1396, Perplexity: 8.495945\n",
      "Epoch [1/3], Step [214800/414113], Loss: 2.7115, Perplexity: 15.051329\n",
      "Epoch [1/3], Step [214900/414113], Loss: 2.2597, Perplexity: 9.580494\n",
      "Epoch [1/3], Step [215000/414113], Loss: 5.2610, Perplexity: 192.67096\n",
      "Epoch [1/3], Step [215100/414113], Loss: 1.5093, Perplexity: 4.5234544\n",
      "Epoch [1/3], Step [215200/414113], Loss: 4.3407, Perplexity: 76.76353\n",
      "Epoch [1/3], Step [215300/414113], Loss: 2.3524, Perplexity: 10.510505\n",
      "Epoch [1/3], Step [215400/414113], Loss: 5.0158, Perplexity: 150.77928\n",
      "Epoch [1/3], Step [215500/414113], Loss: 5.6708, Perplexity: 290.27273\n",
      "Epoch [1/3], Step [215600/414113], Loss: 2.9160, Perplexity: 18.46799\n",
      "Epoch [1/3], Step [215700/414113], Loss: 3.2273, Perplexity: 25.210450\n",
      "Epoch [1/3], Step [215800/414113], Loss: 2.4821, Perplexity: 11.96633\n",
      "Epoch [1/3], Step [215900/414113], Loss: 3.1777, Perplexity: 23.99211\n",
      "Epoch [1/3], Step [216000/414113], Loss: 2.6294, Perplexity: 13.865757\n",
      "Epoch [1/3], Step [216100/414113], Loss: 3.9012, Perplexity: 49.461687\n",
      "Epoch [1/3], Step [216200/414113], Loss: 4.6267, Perplexity: 102.17438\n",
      "Epoch [1/3], Step [216300/414113], Loss: 2.4453, Perplexity: 11.53404\n",
      "Epoch [1/3], Step [216400/414113], Loss: 2.3031, Perplexity: 10.004860\n",
      "Epoch [1/3], Step [216500/414113], Loss: 3.3748, Perplexity: 29.219363\n",
      "Epoch [1/3], Step [216600/414113], Loss: 3.1847, Perplexity: 24.161252\n",
      "Epoch [1/3], Step [216700/414113], Loss: 3.4437, Perplexity: 31.303865\n",
      "Epoch [1/3], Step [216800/414113], Loss: 3.5358, Perplexity: 34.323088\n",
      "Epoch [1/3], Step [216900/414113], Loss: 1.1007, Perplexity: 3.006215\n",
      "Epoch [1/3], Step [217000/414113], Loss: 1.7310, Perplexity: 5.6464248\n",
      "Epoch [1/3], Step [217100/414113], Loss: 2.4242, Perplexity: 11.29362\n",
      "Epoch [1/3], Step [217200/414113], Loss: 2.7104, Perplexity: 15.035881\n",
      "Epoch [1/3], Step [217300/414113], Loss: 3.0314, Perplexity: 20.725666\n",
      "Epoch [1/3], Step [217400/414113], Loss: 4.0959, Perplexity: 60.09485\n",
      "Epoch [1/3], Step [217500/414113], Loss: 0.9598, Perplexity: 2.6112810\n",
      "Epoch [1/3], Step [217600/414113], Loss: 2.6307, Perplexity: 13.88395\n",
      "Epoch [1/3], Step [217700/414113], Loss: 1.5672, Perplexity: 4.7933134\n",
      "Epoch [1/3], Step [217800/414113], Loss: 5.2688, Perplexity: 194.1856\n",
      "Epoch [1/3], Step [217900/414113], Loss: 2.0559, Perplexity: 7.8136444\n",
      "Epoch [1/3], Step [218000/414113], Loss: 3.5622, Perplexity: 35.23979\n",
      "Epoch [1/3], Step [218100/414113], Loss: 2.8933, Perplexity: 18.05242\n",
      "Epoch [1/3], Step [218200/414113], Loss: 2.4478, Perplexity: 11.56242\n",
      "Epoch [1/3], Step [218300/414113], Loss: 2.4945, Perplexity: 12.116310\n",
      "Epoch [1/3], Step [218400/414113], Loss: 3.6289, Perplexity: 37.671865\n",
      "Epoch [1/3], Step [218500/414113], Loss: 1.9324, Perplexity: 6.905848\n",
      "Epoch [1/3], Step [218600/414113], Loss: 2.2294, Perplexity: 9.294355\n",
      "Epoch [1/3], Step [218700/414113], Loss: 3.1058, Perplexity: 22.32770\n",
      "Epoch [1/3], Step [218800/414113], Loss: 4.3416, Perplexity: 76.83120\n",
      "Epoch [1/3], Step [218900/414113], Loss: 2.0891, Perplexity: 8.0780289\n",
      "Epoch [1/3], Step [219000/414113], Loss: 2.1148, Perplexity: 8.2880682\n",
      "Epoch [1/3], Step [219100/414113], Loss: 2.3766, Perplexity: 10.768660\n",
      "Epoch [1/3], Step [219200/414113], Loss: 3.5278, Perplexity: 34.048427\n",
      "Epoch [1/3], Step [219300/414113], Loss: 2.6209, Perplexity: 13.747891\n",
      "Epoch [1/3], Step [219400/414113], Loss: 4.1110, Perplexity: 61.007728\n",
      "Epoch [1/3], Step [219500/414113], Loss: 2.0479, Perplexity: 7.7518095\n",
      "Epoch [1/3], Step [219600/414113], Loss: 1.1941, Perplexity: 3.300581\n",
      "Epoch [1/3], Step [219700/414113], Loss: 1.0754, Perplexity: 2.931361\n",
      "Epoch [1/3], Step [219800/414113], Loss: 5.0137, Perplexity: 150.458862\n",
      "Epoch [1/3], Step [219900/414113], Loss: 1.6054, Perplexity: 4.979751\n",
      "Epoch [1/3], Step [220000/414113], Loss: 4.1143, Perplexity: 61.208176\n",
      "Epoch [1/3], Step [220100/414113], Loss: 2.1910, Perplexity: 8.944266\n",
      "Epoch [1/3], Step [220200/414113], Loss: 3.1753, Perplexity: 23.93472\n",
      "Epoch [1/3], Step [220300/414113], Loss: 4.5312, Perplexity: 92.871396\n",
      "Epoch [1/3], Step [220400/414113], Loss: 1.8964, Perplexity: 6.662196\n",
      "Epoch [1/3], Step [220500/414113], Loss: 2.4827, Perplexity: 11.973621\n",
      "Epoch [1/3], Step [220600/414113], Loss: 2.4536, Perplexity: 11.63078\n",
      "Epoch [1/3], Step [220700/414113], Loss: 2.4395, Perplexity: 11.467007\n",
      "Epoch [1/3], Step [220800/414113], Loss: 6.3591, Perplexity: 577.70633\n",
      "Epoch [1/3], Step [220900/414113], Loss: 4.7318, Perplexity: 113.49482\n",
      "Epoch [1/3], Step [221000/414113], Loss: 2.5916, Perplexity: 13.350875\n",
      "Epoch [1/3], Step [221100/414113], Loss: 3.3683, Perplexity: 29.02961\n",
      "Epoch [1/3], Step [221200/414113], Loss: 4.4609, Perplexity: 86.561943\n",
      "Epoch [1/3], Step [221300/414113], Loss: 1.8408, Perplexity: 6.3016288\n",
      "Epoch [1/3], Step [221400/414113], Loss: 4.0515, Perplexity: 57.485653\n",
      "Epoch [1/3], Step [221500/414113], Loss: 1.4832, Perplexity: 4.4069518\n",
      "Epoch [1/3], Step [221600/414113], Loss: 2.9697, Perplexity: 19.486731\n",
      "Epoch [1/3], Step [221700/414113], Loss: 4.1093, Perplexity: 60.903590\n",
      "Epoch [1/3], Step [221800/414113], Loss: 1.8123, Perplexity: 6.124481\n",
      "Epoch [1/3], Step [221900/414113], Loss: 3.0002, Perplexity: 20.089941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [222000/414113], Loss: 3.9707, Perplexity: 53.02023\n",
      "Epoch [1/3], Step [222100/414113], Loss: 1.8538, Perplexity: 6.3839940\n",
      "Epoch [1/3], Step [222200/414113], Loss: 1.7234, Perplexity: 5.603699\n",
      "Epoch [1/3], Step [222300/414113], Loss: 2.0905, Perplexity: 8.08904045\n",
      "Epoch [1/3], Step [222400/414113], Loss: 2.8504, Perplexity: 17.294356\n",
      "Epoch [1/3], Step [222500/414113], Loss: 1.1166, Perplexity: 3.054437\n",
      "Epoch [1/3], Step [222600/414113], Loss: 4.2893, Perplexity: 72.91228\n",
      "Epoch [1/3], Step [222700/414113], Loss: 3.2053, Perplexity: 24.663526\n",
      "Epoch [1/3], Step [222800/414113], Loss: 2.4235, Perplexity: 11.285841\n",
      "Epoch [1/3], Step [222900/414113], Loss: 1.6350, Perplexity: 5.1294437\n",
      "Epoch [1/3], Step [223000/414113], Loss: 2.0598, Perplexity: 7.8441241\n",
      "Epoch [1/3], Step [223100/414113], Loss: 1.4603, Perplexity: 4.307043\n",
      "Epoch [1/3], Step [223200/414113], Loss: 2.3575, Perplexity: 10.564095\n",
      "Epoch [1/3], Step [223300/414113], Loss: 2.7835, Perplexity: 16.17639\n",
      "Epoch [1/3], Step [223400/414113], Loss: 1.8450, Perplexity: 6.3279138\n",
      "Epoch [1/3], Step [223500/414113], Loss: 1.8823, Perplexity: 6.5684569\n",
      "Epoch [1/3], Step [223600/414113], Loss: 2.6266, Perplexity: 13.826069\n",
      "Epoch [1/3], Step [223700/414113], Loss: 1.5144, Perplexity: 4.546817\n",
      "Epoch [1/3], Step [223800/414113], Loss: 2.9445, Perplexity: 19.001671\n",
      "Epoch [1/3], Step [223900/414113], Loss: 2.1086, Perplexity: 8.236972\n",
      "Epoch [1/3], Step [224000/414113], Loss: 3.9760, Perplexity: 53.3035700\n",
      "Epoch [1/3], Step [224100/414113], Loss: 6.4643, Perplexity: 641.831908\n",
      "Epoch [1/3], Step [224200/414113], Loss: 3.0676, Perplexity: 21.49085\n",
      "Epoch [1/3], Step [224300/414113], Loss: 6.5560, Perplexity: 703.420932\n",
      "Epoch [1/3], Step [224400/414113], Loss: 2.5726, Perplexity: 13.099967\n",
      "Epoch [1/3], Step [224500/414113], Loss: 2.2218, Perplexity: 9.2242943\n",
      "Epoch [1/3], Step [224600/414113], Loss: 1.8375, Perplexity: 6.2809859\n",
      "Epoch [1/3], Step [224700/414113], Loss: 1.7349, Perplexity: 5.6682987\n",
      "Epoch [1/3], Step [224800/414113], Loss: 2.1841, Perplexity: 8.8831318\n",
      "Epoch [1/3], Step [224900/414113], Loss: 1.5031, Perplexity: 4.4956757\n",
      "Epoch [1/3], Step [225000/414113], Loss: 3.1303, Perplexity: 22.88084\n",
      "Epoch [1/3], Step [225100/414113], Loss: 2.8577, Perplexity: 17.421925\n",
      "Epoch [1/3], Step [225200/414113], Loss: 3.1009, Perplexity: 22.21873\n",
      "Epoch [1/3], Step [225300/414113], Loss: 3.2718, Perplexity: 26.358273\n",
      "Epoch [1/3], Step [225400/414113], Loss: 5.8879, Perplexity: 360.6531\n",
      "Epoch [1/3], Step [225500/414113], Loss: 3.2153, Perplexity: 24.91047\n",
      "Epoch [1/3], Step [225600/414113], Loss: 5.7997, Perplexity: 330.19271\n",
      "Epoch [1/3], Step [225700/414113], Loss: 6.5985, Perplexity: 733.9929\n",
      "Epoch [1/3], Step [225800/414113], Loss: 1.7584, Perplexity: 5.8034110\n",
      "Epoch [1/3], Step [225900/414113], Loss: 1.9926, Perplexity: 7.334853\n",
      "Epoch [1/3], Step [226000/414113], Loss: 4.0587, Perplexity: 57.900184\n",
      "Epoch [1/3], Step [226100/414113], Loss: 1.6823, Perplexity: 5.377851\n",
      "Epoch [1/3], Step [226200/414113], Loss: 3.5765, Perplexity: 35.749784\n",
      "Epoch [1/3], Step [226300/414113], Loss: 2.0870, Perplexity: 8.060750\n",
      "Epoch [1/3], Step [226400/414113], Loss: 3.5858, Perplexity: 36.08105\n",
      "Epoch [1/3], Step [226500/414113], Loss: 3.2965, Perplexity: 27.01679\n",
      "Epoch [1/3], Step [226600/414113], Loss: 1.0732, Perplexity: 2.9247613\n",
      "Epoch [1/3], Step [226700/414113], Loss: 2.2712, Perplexity: 9.6910169\n",
      "Epoch [1/3], Step [226800/414113], Loss: 3.6539, Perplexity: 38.62544\n",
      "Epoch [1/3], Step [226900/414113], Loss: 2.0856, Perplexity: 8.049658\n",
      "Epoch [1/3], Step [227000/414113], Loss: 1.6146, Perplexity: 5.026125\n",
      "Epoch [1/3], Step [227100/414113], Loss: 3.4137, Perplexity: 30.37886\n",
      "Epoch [1/3], Step [227200/414113], Loss: 2.6647, Perplexity: 14.363263\n",
      "Epoch [1/3], Step [227300/414113], Loss: 1.9345, Perplexity: 6.920500\n",
      "Epoch [1/3], Step [227400/414113], Loss: 2.8816, Perplexity: 17.842413\n",
      "Epoch [1/3], Step [227500/414113], Loss: 4.4995, Perplexity: 89.971782\n",
      "Epoch [1/3], Step [227600/414113], Loss: 3.1664, Perplexity: 23.720901\n",
      "Epoch [1/3], Step [227700/414113], Loss: 4.4364, Perplexity: 84.470311\n",
      "Epoch [1/3], Step [227800/414113], Loss: 2.9306, Perplexity: 18.738528\n",
      "Epoch [1/3], Step [227900/414113], Loss: 3.2519, Perplexity: 25.838736\n",
      "Epoch [1/3], Step [228000/414113], Loss: 2.0771, Perplexity: 7.981553\n",
      "Epoch [1/3], Step [228100/414113], Loss: 2.4647, Perplexity: 11.75955\n",
      "Epoch [1/3], Step [228200/414113], Loss: 3.3551, Perplexity: 28.649343\n",
      "Epoch [1/3], Step [228300/414113], Loss: 1.3710, Perplexity: 3.9392224\n",
      "Epoch [1/3], Step [228400/414113], Loss: 2.1931, Perplexity: 8.9633966\n",
      "Epoch [1/3], Step [228500/414113], Loss: 1.7824, Perplexity: 5.944324\n",
      "Epoch [1/3], Step [228600/414113], Loss: 3.6689, Perplexity: 39.20811\n",
      "Epoch [1/3], Step [228700/414113], Loss: 3.8955, Perplexity: 49.18095\n",
      "Epoch [1/3], Step [228800/414113], Loss: 2.7099, Perplexity: 15.02732\n",
      "Epoch [1/3], Step [228900/414113], Loss: 4.9394, Perplexity: 139.68768\n",
      "Epoch [1/3], Step [228941/414113], Loss: 1.8834, Perplexity: 6.575937"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# temporary\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "## running the training locally\n",
    "#old_time = time.time()\n",
    "#response = requests.request(\"GET\", \n",
    "#                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "#                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "\n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        ## running the training locally\n",
    "        #if time.time() - old_time > 60:\n",
    "        #    old_time = time.time()\n",
    "        #    requests.request(\"POST\", \n",
    "        #                     \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "        #                     headers={'Authorization': \"STAR \" + response.text})\n",
    "\n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "\n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "\n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "\n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "\n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.contiguous().view(-1, vocab_size), captions.contiguous().view(-1))\n",
    "\n",
    "        # Backward pass.\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "\n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "\n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "\n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
