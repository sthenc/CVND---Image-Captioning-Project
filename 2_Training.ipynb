{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** The default looks reasonable, although I have some doubts as to whether it makes sense to discard the data around the edge in this case. \n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sthenc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "[0/414113] Tokenizing captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 151876/414113 [00:30<00:26, 9799.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100000/414113] Tokenizing captions...\n",
      "[200000/414113] Tokenizing captions...\n",
      "[300000/414113] Tokenizing captions...\n",
      "[400000/414113] Tokenizing captions...\n",
      "loading annotations into memory...\n",
      "Done (t=0.52s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 943/414113 [00:00<00:43, 9428.68it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1810/414113 [00:00<00:44, 9184.90it/s]\u001b[A\n",
      "  1%|          | 2678/414113 [00:00<00:45, 9022.86it/s]\u001b[A\n",
      "  1%|          | 3589/414113 [00:00<00:45, 9046.64it/s]\u001b[A\n",
      "  1%|          | 4514/414113 [00:00<00:44, 9106.31it/s]\u001b[A\n",
      "  1%|▏         | 5444/414113 [00:00<00:44, 9162.05it/s]\u001b[A\n",
      "  2%|▏         | 6271/414113 [00:00<00:45, 8872.44it/s]\u001b[A\n",
      "  2%|▏         | 7084/414113 [00:00<00:48, 8338.77it/s]\u001b[A\n",
      "  2%|▏         | 7884/414113 [00:00<00:49, 8231.99it/s]\u001b[A\n",
      "  2%|▏         | 8763/414113 [00:01<00:48, 8389.56it/s]\u001b[A\n",
      "  2%|▏         | 9631/414113 [00:01<00:47, 8474.19it/s]\u001b[A\n",
      "  3%|▎         | 10594/414113 [00:01<00:45, 8789.08it/s]\u001b[A\n",
      "  3%|▎         | 11528/414113 [00:01<00:44, 8946.80it/s]\u001b[A\n",
      "  3%|▎         | 12419/414113 [00:01<00:45, 8844.77it/s]\u001b[A\n",
      "  3%|▎         | 13319/414113 [00:01<00:45, 8889.08it/s]\u001b[A\n",
      "  3%|▎         | 14255/414113 [00:01<00:44, 9024.88it/s]\u001b[A\n",
      "  4%|▎         | 15157/414113 [00:01<00:44, 8946.59it/s]\u001b[A\n",
      "  4%|▍         | 16065/414113 [00:01<00:44, 8983.70it/s]\u001b[A\n",
      "  4%|▍         | 16964/414113 [00:01<00:44, 8980.98it/s]\u001b[A\n",
      "  4%|▍         | 17868/414113 [00:02<00:44, 8996.38it/s]\u001b[A\n",
      "  5%|▍         | 18768/414113 [00:02<00:45, 8726.73it/s]\u001b[A\n",
      "  5%|▍         | 19705/414113 [00:02<00:44, 8908.14it/s]\u001b[A\n",
      "  5%|▍         | 20632/414113 [00:02<00:43, 9009.45it/s]\u001b[A\n",
      "  5%|▌         | 21537/414113 [00:02<00:43, 9019.03it/s]\u001b[A\n",
      "  5%|▌         | 22467/414113 [00:02<00:43, 9101.07it/s]\u001b[A\n",
      "  6%|▌         | 23416/414113 [00:02<00:42, 9211.92it/s]\u001b[A\n",
      "  6%|▌         | 24339/414113 [00:02<00:42, 9177.73it/s]\u001b[A\n",
      "  6%|▌         | 25258/414113 [00:02<00:42, 9073.85it/s]\u001b[A\n",
      "  6%|▋         | 26184/414113 [00:02<00:42, 9126.29it/s]\u001b[A\n",
      "  7%|▋         | 27098/414113 [00:03<00:42, 9089.57it/s]\u001b[A\n",
      "  7%|▋         | 28008/414113 [00:03<00:43, 8917.65it/s]\u001b[A\n",
      "  7%|▋         | 28981/414113 [00:03<00:42, 9146.12it/s]\u001b[A\n",
      "  7%|▋         | 29898/414113 [00:03<00:42, 9065.66it/s]\u001b[A\n",
      "  7%|▋         | 30868/414113 [00:03<00:41, 9246.04it/s]\u001b[A\n",
      "  8%|▊         | 31795/414113 [00:03<00:41, 9156.29it/s]\u001b[A\n",
      "  8%|▊         | 32713/414113 [00:03<01:08, 5585.39it/s]\u001b[A\n",
      "  8%|▊         | 33629/414113 [00:03<01:00, 6324.66it/s]\u001b[A\n",
      "  8%|▊         | 34580/414113 [00:04<00:53, 7031.03it/s]\u001b[A\n",
      "  9%|▊         | 35486/414113 [00:04<00:50, 7535.58it/s]\u001b[A\n",
      "  9%|▉         | 36394/414113 [00:04<00:47, 7938.59it/s]\u001b[A\n",
      "  9%|▉         | 37313/414113 [00:04<00:45, 8275.55it/s]\u001b[A\n",
      "  9%|▉         | 38261/414113 [00:04<00:43, 8601.49it/s]\u001b[A\n",
      "  9%|▉         | 39166/414113 [00:04<00:43, 8710.54it/s]\u001b[A\n",
      " 10%|▉         | 40069/414113 [00:04<00:43, 8501.67it/s]\u001b[A\n",
      " 10%|▉         | 40943/414113 [00:04<00:44, 8383.44it/s]\u001b[A\n",
      " 10%|█         | 41871/414113 [00:04<00:43, 8632.94it/s]\u001b[A\n",
      " 10%|█         | 42748/414113 [00:04<00:43, 8632.74it/s]\u001b[A\n",
      " 11%|█         | 43673/414113 [00:05<00:42, 8807.72it/s]\u001b[A\n",
      " 11%|█         | 44562/414113 [00:05<00:41, 8802.91it/s]\u001b[A\n",
      " 11%|█         | 45487/414113 [00:05<00:41, 8931.11it/s]\u001b[A\n",
      " 11%|█         | 46410/414113 [00:05<00:40, 9017.86it/s]\u001b[A\n",
      " 11%|█▏        | 47350/414113 [00:05<00:40, 9128.35it/s]\u001b[A\n",
      " 12%|█▏        | 48295/414113 [00:05<00:39, 9219.62it/s]\u001b[A\n",
      " 12%|█▏        | 49223/414113 [00:05<00:39, 9236.53it/s]\u001b[A\n",
      " 12%|█▏        | 50193/414113 [00:05<00:38, 9370.66it/s]\u001b[A\n",
      " 12%|█▏        | 51132/414113 [00:05<00:39, 9254.32it/s]\u001b[A\n",
      " 13%|█▎        | 52072/414113 [00:05<00:38, 9297.54it/s]\u001b[A\n",
      " 13%|█▎        | 53003/414113 [00:06<00:39, 9165.28it/s]\u001b[A\n",
      " 13%|█▎        | 53951/414113 [00:06<00:38, 9256.22it/s]\u001b[A\n",
      " 13%|█▎        | 54926/414113 [00:06<00:38, 9396.74it/s]\u001b[A\n",
      " 13%|█▎        | 55881/414113 [00:06<00:37, 9441.53it/s]\u001b[A\n",
      " 14%|█▎        | 56848/414113 [00:06<00:37, 9508.30it/s]\u001b[A\n",
      " 14%|█▍        | 57800/414113 [00:06<00:37, 9425.33it/s]\u001b[A\n",
      " 14%|█▍        | 58753/414113 [00:06<00:37, 9456.08it/s]\u001b[A\n",
      " 14%|█▍        | 59700/414113 [00:06<00:37, 9451.04it/s]\u001b[A\n",
      " 15%|█▍        | 60646/414113 [00:06<00:37, 9379.06it/s]\u001b[A\n",
      " 15%|█▍        | 61585/414113 [00:07<00:37, 9307.43it/s]\u001b[A\n",
      " 15%|█▌        | 62517/414113 [00:07<00:38, 9067.82it/s]\u001b[A\n",
      " 15%|█▌        | 63426/414113 [00:07<00:39, 8772.69it/s]\u001b[A\n",
      " 16%|█▌        | 64367/414113 [00:07<00:39, 8948.28it/s]\u001b[A\n",
      " 16%|█▌        | 65268/414113 [00:07<00:38, 8964.93it/s]\u001b[A\n",
      " 16%|█▌        | 66167/414113 [00:07<00:39, 8896.75it/s]\u001b[A\n",
      " 16%|█▌        | 67108/414113 [00:07<00:38, 9044.31it/s]\u001b[A\n",
      " 16%|█▋        | 68022/414113 [00:07<00:38, 9069.94it/s]\u001b[A\n",
      " 17%|█▋        | 68944/414113 [00:07<00:37, 9114.39it/s]\u001b[A\n",
      " 17%|█▋        | 69857/414113 [00:07<00:38, 9050.98it/s]\u001b[A\n",
      " 17%|█▋        | 70807/414113 [00:08<00:37, 9180.58it/s]\u001b[A\n",
      " 17%|█▋        | 71774/414113 [00:08<00:36, 9315.30it/s]\u001b[A\n",
      " 18%|█▊        | 72707/414113 [00:08<00:37, 9078.18it/s]\u001b[A\n",
      " 18%|█▊        | 73661/414113 [00:08<00:36, 9211.03it/s]\u001b[A\n",
      " 18%|█▊        | 74585/414113 [00:08<00:36, 9193.80it/s]\u001b[A\n",
      " 18%|█▊        | 75537/414113 [00:08<00:36, 9288.68it/s]\u001b[A\n",
      " 18%|█▊        | 76486/414113 [00:08<00:36, 9346.31it/s]\u001b[A\n",
      " 19%|█▊        | 77454/414113 [00:08<00:35, 9443.00it/s]\u001b[A\n",
      " 19%|█▉        | 78416/414113 [00:08<00:35, 9492.41it/s]\u001b[A\n",
      " 19%|█▉        | 79367/414113 [00:08<00:35, 9496.71it/s]\u001b[A\n",
      " 19%|█▉        | 80318/414113 [00:09<00:35, 9497.24it/s]\u001b[A\n",
      " 20%|█▉        | 81269/414113 [00:09<00:35, 9479.78it/s]\u001b[A\n",
      " 20%|█▉        | 82218/414113 [00:09<00:35, 9336.90it/s]\u001b[A\n",
      " 20%|██        | 83153/414113 [00:09<00:36, 9110.93it/s]\u001b[A\n",
      " 20%|██        | 84107/414113 [00:09<00:35, 9234.11it/s]\u001b[A\n",
      " 21%|██        | 85081/414113 [00:09<00:35, 9378.81it/s]\u001b[A\n",
      " 21%|██        | 86034/414113 [00:09<00:34, 9421.64it/s]\u001b[A\n",
      " 21%|██        | 87016/414113 [00:09<00:34, 9536.81it/s]\u001b[A\n",
      " 21%|██        | 87971/414113 [00:09<00:34, 9368.56it/s]\u001b[A\n",
      " 21%|██▏       | 88925/414113 [00:09<00:34, 9418.88it/s]\u001b[A\n",
      " 22%|██▏       | 89879/414113 [00:10<00:34, 9453.31it/s]\u001b[A\n",
      " 22%|██▏       | 90826/414113 [00:10<00:35, 9183.44it/s]\u001b[A\n",
      " 22%|██▏       | 91763/414113 [00:10<00:34, 9234.79it/s]\u001b[A\n",
      " 22%|██▏       | 92689/414113 [00:10<00:35, 9154.59it/s]\u001b[A\n",
      " 23%|██▎       | 93631/414113 [00:10<00:34, 9231.34it/s]\u001b[A\n",
      " 23%|██▎       | 94607/414113 [00:10<00:34, 9382.14it/s]\u001b[A\n",
      " 23%|██▎       | 95575/414113 [00:10<00:33, 9469.16it/s]\u001b[A\n",
      " 23%|██▎       | 96524/414113 [00:10<00:33, 9442.26it/s]\u001b[A\n",
      " 24%|██▎       | 97487/414113 [00:10<00:33, 9496.52it/s]\u001b[A\n",
      " 24%|██▍       | 98438/414113 [00:10<00:34, 9163.97it/s]\u001b[A\n",
      " 24%|██▍       | 99374/414113 [00:11<00:34, 9220.41it/s]\u001b[A\n",
      " 24%|██▍       | 100299/414113 [00:11<00:34, 9112.67it/s]\u001b[A\n",
      " 24%|██▍       | 101233/414113 [00:11<00:34, 9176.89it/s]\u001b[A\n",
      " 25%|██▍       | 102153/414113 [00:11<00:34, 9014.15it/s]\u001b[A\n",
      " 25%|██▍       | 103087/414113 [00:11<00:34, 9107.91it/s]\u001b[A\n",
      " 25%|██▌       | 104022/414113 [00:11<00:33, 9178.30it/s]\u001b[A\n",
      " 25%|██▌       | 104941/414113 [00:11<00:33, 9120.59it/s]\u001b[A\n",
      " 26%|██▌       | 105854/414113 [00:11<00:35, 8579.78it/s]\u001b[A\n",
      " 26%|██▌       | 106736/414113 [00:11<00:35, 8649.71it/s]\u001b[A\n",
      " 26%|██▌       | 107615/414113 [00:12<00:35, 8685.90it/s]\u001b[A\n",
      " 26%|██▌       | 108572/414113 [00:12<00:34, 8932.45it/s]\u001b[A\n",
      " 26%|██▋       | 109470/414113 [00:12<00:34, 8793.74it/s]\u001b[A\n",
      " 27%|██▋       | 110398/414113 [00:12<00:34, 8931.08it/s]\u001b[A\n",
      " 27%|██▋       | 111323/414113 [00:12<00:33, 9021.92it/s]\u001b[A\n",
      " 27%|██▋       | 112275/414113 [00:12<00:32, 9163.75it/s]\u001b[A\n",
      " 27%|██▋       | 113235/414113 [00:12<00:32, 9289.21it/s]\u001b[A\n",
      " 28%|██▊       | 114168/414113 [00:12<00:32, 9299.59it/s]\u001b[A\n",
      " 28%|██▊       | 115105/414113 [00:12<00:32, 9318.74it/s]\u001b[A\n",
      " 28%|██▊       | 116038/414113 [00:12<00:32, 9094.73it/s]\u001b[A\n",
      " 28%|██▊       | 117016/414113 [00:13<00:31, 9288.62it/s]\u001b[A\n",
      " 28%|██▊       | 118008/414113 [00:13<00:31, 9467.67it/s]\u001b[A\n",
      " 29%|██▊       | 118958/414113 [00:13<00:31, 9303.37it/s]\u001b[A\n",
      " 29%|██▉       | 119948/414113 [00:13<00:31, 9473.29it/s]\u001b[A\n",
      " 29%|██▉       | 120903/414113 [00:13<00:30, 9495.98it/s]\u001b[A\n",
      " 29%|██▉       | 121900/414113 [00:13<00:30, 9632.08it/s]\u001b[A\n",
      " 30%|██▉       | 122865/414113 [00:13<00:30, 9626.38it/s]\u001b[A\n",
      " 30%|██▉       | 123829/414113 [00:13<00:30, 9587.57it/s]\u001b[A\n",
      " 30%|███       | 124821/414113 [00:13<00:29, 9684.51it/s]\u001b[A\n",
      " 30%|███       | 125819/414113 [00:13<00:29, 9770.86it/s]\u001b[A\n",
      " 31%|███       | 126813/414113 [00:14<00:29, 9820.51it/s]\u001b[A\n",
      " 31%|███       | 127796/414113 [00:14<00:29, 9754.73it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 128784/414113 [00:14<00:29, 9790.29it/s]\u001b[A\n",
      " 31%|███▏      | 129764/414113 [00:14<00:29, 9785.93it/s]\u001b[A\n",
      " 32%|███▏      | 130743/414113 [00:14<00:29, 9747.38it/s]\u001b[A\n",
      " 32%|███▏      | 131718/414113 [00:14<00:29, 9692.61it/s]\u001b[A\n",
      " 32%|███▏      | 132688/414113 [00:14<00:29, 9551.25it/s]\u001b[A\n",
      " 32%|███▏      | 133644/414113 [00:14<00:29, 9541.66it/s]\u001b[A\n",
      " 33%|███▎      | 134599/414113 [00:14<00:29, 9318.48it/s]\u001b[A\n",
      " 33%|███▎      | 135547/414113 [00:14<00:29, 9365.18it/s]\u001b[A\n",
      " 33%|███▎      | 136540/414113 [00:15<00:29, 9525.49it/s]\u001b[A\n",
      " 33%|███▎      | 137518/414113 [00:15<00:28, 9600.26it/s]\u001b[A\n",
      " 33%|███▎      | 138482/414113 [00:15<00:28, 9611.94it/s]\u001b[A\n",
      " 34%|███▎      | 139444/414113 [00:15<00:28, 9542.55it/s]\u001b[A\n",
      " 34%|███▍      | 140399/414113 [00:15<00:28, 9457.45it/s]\u001b[A\n",
      " 34%|███▍      | 141346/414113 [00:15<00:29, 9290.61it/s]\u001b[A\n",
      " 34%|███▍      | 142277/414113 [00:15<00:29, 9276.40it/s]\u001b[A\n",
      " 35%|███▍      | 143206/414113 [00:15<00:29, 9260.67it/s]\u001b[A\n",
      " 35%|███▍      | 144169/414113 [00:15<00:28, 9366.54it/s]\u001b[A\n",
      " 35%|███▌      | 145109/414113 [00:15<00:28, 9376.11it/s]\u001b[A\n",
      " 35%|███▌      | 146048/414113 [00:16<00:28, 9303.45it/s]\u001b[A\n",
      " 35%|███▌      | 146979/414113 [00:16<00:29, 9177.83it/s]\u001b[A\n",
      " 36%|███▌      | 147955/414113 [00:16<00:28, 9344.52it/s]\u001b[A\n",
      " 36%|███▌      | 148918/414113 [00:16<00:28, 9426.87it/s]\u001b[A\n",
      " 36%|███▌      | 149862/414113 [00:16<00:48, 5474.14it/s]\u001b[A\n",
      " 36%|███▋      | 150847/414113 [00:16<00:41, 6315.62it/s]\u001b[A\n",
      " 37%|███▋      | 151832/414113 [00:16<00:37, 7076.14it/s]\u001b[A\n",
      " 37%|███▋      | 152819/414113 [00:17<00:33, 7730.74it/s]\u001b[A\n",
      " 37%|███▋      | 153744/414113 [00:17<00:32, 8130.34it/s]\u001b[A\n",
      " 37%|███▋      | 154699/414113 [00:17<00:30, 8508.39it/s]\u001b[A\n",
      " 38%|███▊      | 155622/414113 [00:17<00:29, 8653.10it/s]\u001b[A\n",
      " 38%|███▊      | 156564/414113 [00:17<00:29, 8867.78it/s]\u001b[A\n",
      " 38%|███▊      | 157494/414113 [00:17<00:28, 8991.98it/s]\u001b[A\n",
      " 38%|███▊      | 158420/414113 [00:17<00:28, 8890.85it/s]\u001b[A\n",
      " 38%|███▊      | 159397/414113 [00:17<00:27, 9136.52it/s]\u001b[A\n",
      " 39%|███▊      | 160363/414113 [00:17<00:27, 9286.54it/s]\u001b[A\n",
      " 39%|███▉      | 161303/414113 [00:17<00:27, 9157.15it/s]\u001b[A\n",
      " 39%|███▉      | 162246/414113 [00:18<00:27, 9237.24it/s]\u001b[A\n",
      " 39%|███▉      | 163178/414113 [00:18<00:27, 9260.17it/s]\u001b[A\n",
      " 40%|███▉      | 164109/414113 [00:18<00:28, 8921.58it/s]\u001b[A\n",
      " 40%|███▉      | 165034/414113 [00:18<00:27, 9016.96it/s]\u001b[A\n",
      " 40%|████      | 165966/414113 [00:18<00:27, 9097.35it/s]\u001b[A\n",
      " 40%|████      | 166902/414113 [00:18<00:26, 9173.28it/s]\u001b[A\n",
      " 41%|████      | 167822/414113 [00:18<00:27, 9051.29it/s]\u001b[A\n",
      " 41%|████      | 168757/414113 [00:18<00:26, 9137.87it/s]\u001b[A\n",
      " 41%|████      | 169692/414113 [00:18<00:26, 9195.21it/s]\u001b[A\n",
      " 41%|████      | 170613/414113 [00:18<00:27, 8862.20it/s]\u001b[A\n",
      " 41%|████▏     | 171564/414113 [00:19<00:26, 9046.42it/s]\u001b[A\n",
      " 42%|████▏     | 172531/414113 [00:19<00:26, 9224.42it/s]\u001b[A\n",
      " 42%|████▏     | 173458/414113 [00:19<00:26, 9237.56it/s]\u001b[A\n",
      " 42%|████▏     | 174384/414113 [00:19<00:26, 8947.39it/s]\u001b[A\n",
      " 42%|████▏     | 175347/414113 [00:19<00:26, 9141.05it/s]\u001b[A\n",
      " 43%|████▎     | 176265/414113 [00:19<00:26, 8872.36it/s]\u001b[A\n",
      " 43%|████▎     | 177242/414113 [00:19<00:25, 9123.59it/s]\u001b[A\n",
      " 43%|████▎     | 178213/414113 [00:19<00:25, 9290.55it/s]\u001b[A\n",
      " 43%|████▎     | 179181/414113 [00:19<00:24, 9402.73it/s]\u001b[A\n",
      " 43%|████▎     | 180126/414113 [00:19<00:24, 9414.69it/s]\u001b[A\n",
      " 44%|████▎     | 181070/414113 [00:20<00:25, 9180.03it/s]\u001b[A\n",
      " 44%|████▍     | 182026/414113 [00:20<00:24, 9289.34it/s]\u001b[A\n",
      " 44%|████▍     | 182975/414113 [00:20<00:24, 9346.54it/s]\u001b[A\n",
      " 44%|████▍     | 183927/414113 [00:20<00:24, 9397.01it/s]\u001b[A\n",
      " 45%|████▍     | 184868/414113 [00:20<00:24, 9303.19it/s]\u001b[A\n",
      " 45%|████▍     | 185852/414113 [00:20<00:24, 9455.05it/s]\u001b[A\n",
      " 45%|████▌     | 186807/414113 [00:20<00:23, 9482.10it/s]\u001b[A\n",
      " 45%|████▌     | 187757/414113 [00:20<00:24, 9308.97it/s]\u001b[A\n",
      " 46%|████▌     | 188690/414113 [00:20<00:24, 9163.77it/s]\u001b[A\n",
      " 46%|████▌     | 189651/414113 [00:21<00:24, 9290.93it/s]\u001b[A\n",
      " 46%|████▌     | 190640/414113 [00:21<00:23, 9462.86it/s]\u001b[A\n",
      " 46%|████▋     | 191600/414113 [00:21<00:23, 9500.23it/s]\u001b[A\n",
      " 46%|████▋     | 192560/414113 [00:21<00:23, 9528.66it/s]\u001b[A\n",
      " 47%|████▋     | 193514/414113 [00:21<00:23, 9524.78it/s]\u001b[A\n",
      " 47%|████▋     | 194500/414113 [00:21<00:22, 9620.54it/s]\u001b[A\n",
      " 47%|████▋     | 195492/414113 [00:21<00:22, 9705.93it/s]\u001b[A\n",
      " 47%|████▋     | 196464/414113 [00:21<00:22, 9651.50it/s]\u001b[A\n",
      " 48%|████▊     | 197430/414113 [00:21<00:22, 9602.39it/s]\u001b[A\n",
      " 48%|████▊     | 198397/414113 [00:21<00:22, 9620.87it/s]\u001b[A\n",
      " 48%|████▊     | 199360/414113 [00:22<00:22, 9538.00it/s]\u001b[A\n",
      " 48%|████▊     | 200320/414113 [00:22<00:22, 9554.77it/s]\u001b[A\n",
      " 49%|████▊     | 201304/414113 [00:22<00:22, 9638.55it/s]\u001b[A\n",
      " 49%|████▉     | 202296/414113 [00:22<00:21, 9720.14it/s]\u001b[A\n",
      " 49%|████▉     | 203287/414113 [00:22<00:21, 9775.25it/s]\u001b[A\n",
      " 49%|████▉     | 204265/414113 [00:22<00:21, 9750.52it/s]\u001b[A\n",
      " 50%|████▉     | 205241/414113 [00:22<00:21, 9734.25it/s]\u001b[A\n",
      " 50%|████▉     | 206221/414113 [00:22<00:21, 9752.50it/s]\u001b[A\n",
      " 50%|█████     | 207197/414113 [00:22<00:21, 9751.24it/s]\u001b[A\n",
      " 50%|█████     | 208173/414113 [00:22<00:21, 9726.53it/s]\u001b[A\n",
      " 51%|█████     | 209161/414113 [00:23<00:20, 9770.24it/s]\u001b[A\n",
      " 51%|█████     | 210139/414113 [00:23<00:21, 9690.23it/s]\u001b[A\n",
      " 51%|█████     | 211116/414113 [00:23<00:20, 9712.61it/s]\u001b[A\n",
      " 51%|█████     | 212088/414113 [00:23<00:21, 9607.13it/s]\u001b[A\n",
      " 51%|█████▏    | 213050/414113 [00:23<00:21, 9520.85it/s]\u001b[A\n",
      " 52%|█████▏    | 214003/414113 [00:23<00:21, 9328.58it/s]\u001b[A\n",
      " 52%|█████▏    | 214938/414113 [00:23<00:21, 9274.50it/s]\u001b[A\n",
      " 52%|█████▏    | 215867/414113 [00:23<00:21, 9196.43it/s]\u001b[A\n",
      " 52%|█████▏    | 216788/414113 [00:23<00:22, 8723.16it/s]\u001b[A\n",
      " 53%|█████▎    | 217666/414113 [00:23<00:22, 8583.25it/s]\u001b[A\n",
      " 53%|█████▎    | 218596/414113 [00:24<00:22, 8785.92it/s]\u001b[A\n",
      " 53%|█████▎    | 219604/414113 [00:24<00:21, 9137.79it/s]\u001b[A\n",
      " 53%|█████▎    | 220596/414113 [00:24<00:20, 9358.70it/s]\u001b[A\n",
      " 54%|█████▎    | 221583/414113 [00:24<00:20, 9505.46it/s]\u001b[A\n",
      " 54%|█████▎    | 222565/414113 [00:24<00:19, 9597.53it/s]\u001b[A\n",
      " 54%|█████▍    | 223529/414113 [00:24<00:19, 9597.23it/s]\u001b[A\n",
      " 54%|█████▍    | 224492/414113 [00:24<00:19, 9565.54it/s]\u001b[A\n",
      " 54%|█████▍    | 225451/414113 [00:24<00:19, 9491.53it/s]\u001b[A\n",
      " 55%|█████▍    | 226402/414113 [00:24<00:19, 9406.01it/s]\u001b[A\n",
      " 55%|█████▍    | 227369/414113 [00:24<00:19, 9482.28it/s]\u001b[A\n",
      " 55%|█████▌    | 228319/414113 [00:25<00:19, 9390.38it/s]\u001b[A\n",
      " 55%|█████▌    | 229269/414113 [00:25<00:19, 9421.53it/s]\u001b[A\n",
      " 56%|█████▌    | 230212/414113 [00:25<00:19, 9391.16it/s]\u001b[A\n",
      " 56%|█████▌    | 231152/414113 [00:25<00:19, 9354.79it/s]\u001b[A\n",
      " 56%|█████▌    | 232088/414113 [00:25<00:19, 9278.85it/s]\u001b[A\n",
      " 56%|█████▋    | 233017/414113 [00:25<00:19, 9252.40it/s]\u001b[A\n",
      " 56%|█████▋    | 233968/414113 [00:25<00:19, 9327.17it/s]\u001b[A\n",
      " 57%|█████▋    | 234907/414113 [00:25<00:19, 9344.00it/s]\u001b[A\n",
      " 57%|█████▋    | 235871/414113 [00:25<00:18, 9430.73it/s]\u001b[A\n",
      " 57%|█████▋    | 236843/414113 [00:25<00:18, 9515.35it/s]\u001b[A\n",
      " 57%|█████▋    | 237795/414113 [00:26<00:18, 9516.26it/s]\u001b[A\n",
      " 58%|█████▊    | 238747/414113 [00:26<00:18, 9368.81it/s]\u001b[A\n",
      " 58%|█████▊    | 239711/414113 [00:26<00:18, 9448.13it/s]\u001b[A\n",
      " 58%|█████▊    | 240657/414113 [00:26<00:18, 9434.04it/s]\u001b[A\n",
      " 58%|█████▊    | 241601/414113 [00:26<00:18, 9309.45it/s]\u001b[A\n",
      " 59%|█████▊    | 242562/414113 [00:26<00:18, 9396.62it/s]\u001b[A\n",
      " 59%|█████▉    | 243504/414113 [00:26<00:18, 9401.96it/s]\u001b[A\n",
      " 59%|█████▉    | 244445/414113 [00:26<00:18, 9088.00it/s]\u001b[A\n",
      " 59%|█████▉    | 245357/414113 [00:26<00:18, 9073.02it/s]\u001b[A\n",
      " 59%|█████▉    | 246273/414113 [00:27<00:18, 9094.05it/s]\u001b[A\n",
      " 60%|█████▉    | 247184/414113 [00:27<00:18, 8805.18it/s]\u001b[A\n",
      " 60%|█████▉    | 248094/414113 [00:27<00:18, 8890.30it/s]\u001b[A\n",
      " 60%|██████    | 248986/414113 [00:27<00:18, 8875.91it/s]\u001b[A\n",
      " 60%|██████    | 249938/414113 [00:27<00:18, 9058.32it/s]\u001b[A\n",
      " 61%|██████    | 250898/414113 [00:27<00:17, 9210.08it/s]\u001b[A\n",
      " 61%|██████    | 251851/414113 [00:27<00:17, 9301.39it/s]\u001b[A\n",
      " 61%|██████    | 252820/414113 [00:27<00:17, 9412.90it/s]\u001b[A\n",
      " 61%|██████▏   | 253777/414113 [00:27<00:16, 9459.23it/s]\u001b[A\n",
      " 62%|██████▏   | 254725/414113 [00:27<00:17, 9345.11it/s]\u001b[A\n",
      " 62%|██████▏   | 255661/414113 [00:28<00:17, 9201.94it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 256583/414113 [00:28<00:17, 9118.38it/s]\u001b[A\n",
      " 62%|██████▏   | 257496/414113 [00:28<00:17, 8894.73it/s]\u001b[A\n",
      " 62%|██████▏   | 258428/414113 [00:28<00:17, 9016.13it/s]\u001b[A\n",
      " 63%|██████▎   | 259332/414113 [00:28<00:17, 8888.98it/s]\u001b[A\n",
      " 63%|██████▎   | 260302/414113 [00:28<00:16, 9116.75it/s]\u001b[A\n",
      " 63%|██████▎   | 261242/414113 [00:28<00:16, 9197.60it/s]\u001b[A\n",
      " 63%|██████▎   | 262164/414113 [00:28<00:16, 9135.86it/s]\u001b[A\n",
      " 64%|██████▎   | 263084/414113 [00:28<00:16, 9151.23it/s]\u001b[A\n",
      " 64%|██████▍   | 264001/414113 [00:28<00:16, 9152.89it/s]\u001b[A\n",
      " 64%|██████▍   | 264943/414113 [00:29<00:16, 9230.58it/s]\u001b[A\n",
      " 64%|██████▍   | 265868/414113 [00:29<00:16, 9234.10it/s]\u001b[A\n",
      " 64%|██████▍   | 266845/414113 [00:29<00:15, 9384.73it/s]\u001b[A\n",
      " 65%|██████▍   | 267822/414113 [00:29<00:15, 9496.23it/s]\u001b[A\n",
      " 65%|██████▍   | 268773/414113 [00:29<00:15, 9464.40it/s]\u001b[A\n",
      " 65%|██████▌   | 269721/414113 [00:29<00:15, 9464.74it/s]\u001b[A\n",
      " 65%|██████▌   | 270668/414113 [00:29<00:15, 9437.78it/s]\u001b[A\n",
      " 66%|██████▌   | 271627/414113 [00:29<00:15, 9482.20it/s]\u001b[A\n",
      " 66%|██████▌   | 272580/414113 [00:29<00:14, 9496.08it/s]\u001b[A\n",
      " 66%|██████▌   | 273530/414113 [00:29<00:14, 9455.91it/s]\u001b[A\n",
      " 66%|██████▋   | 274476/414113 [00:30<00:14, 9347.20it/s]\u001b[A\n",
      " 67%|██████▋   | 275456/414113 [00:30<00:14, 9477.75it/s]\u001b[A\n",
      " 67%|██████▋   | 276411/414113 [00:30<00:14, 9497.81it/s]\u001b[A\n",
      " 67%|██████▋   | 277384/414113 [00:30<00:14, 9563.08it/s]\u001b[A\n",
      " 67%|██████▋   | 278341/414113 [00:30<00:14, 9532.71it/s]\u001b[A\n",
      " 67%|██████▋   | 279295/414113 [00:30<00:14, 9448.11it/s]\u001b[A\n",
      " 68%|██████▊   | 280265/414113 [00:30<00:14, 9520.89it/s]\u001b[A\n",
      " 68%|██████▊   | 281218/414113 [00:30<00:14, 9310.26it/s]\u001b[A\n",
      " 68%|██████▊   | 282169/414113 [00:30<00:14, 9368.44it/s]\u001b[A\n",
      " 68%|██████▊   | 283127/414113 [00:30<00:13, 9430.60it/s]\u001b[A\n",
      " 69%|██████▊   | 284096/414113 [00:31<00:13, 9501.50it/s]\u001b[A\n",
      " 69%|██████▉   | 285047/414113 [00:31<00:13, 9430.21it/s]\u001b[A\n",
      " 69%|██████▉   | 285991/414113 [00:31<00:13, 9425.22it/s]\u001b[A\n",
      " 69%|██████▉   | 286956/414113 [00:31<00:13, 9484.52it/s]\u001b[A\n",
      " 70%|██████▉   | 287908/414113 [00:31<00:13, 9492.46it/s]\u001b[A\n",
      " 70%|██████▉   | 288862/414113 [00:31<00:13, 9505.68it/s]\u001b[A\n",
      " 70%|██████▉   | 289839/414113 [00:31<00:12, 9582.44it/s]\u001b[A\n",
      " 70%|███████   | 290809/414113 [00:31<00:12, 9615.22it/s]\u001b[A\n",
      " 70%|███████   | 291771/414113 [00:32<00:23, 5181.98it/s]\u001b[A\n",
      " 71%|███████   | 292720/414113 [00:32<00:20, 5996.85it/s]\u001b[A\n",
      " 71%|███████   | 293677/414113 [00:32<00:17, 6752.56it/s]\u001b[A\n",
      " 71%|███████   | 294613/414113 [00:32<00:16, 7368.04it/s]\u001b[A\n",
      " 71%|███████▏  | 295573/414113 [00:32<00:14, 7918.59it/s]\u001b[A\n",
      " 72%|███████▏  | 296498/414113 [00:32<00:14, 8273.87it/s]\u001b[A\n",
      " 72%|███████▏  | 297420/414113 [00:32<00:13, 8534.67it/s]\u001b[A\n",
      " 72%|███████▏  | 298333/414113 [00:32<00:13, 8687.92it/s]\u001b[A\n",
      " 72%|███████▏  | 299251/414113 [00:32<00:13, 8827.64it/s]\u001b[A\n",
      " 72%|███████▏  | 300184/414113 [00:33<00:12, 8971.62it/s]\u001b[A\n",
      " 73%|███████▎  | 301103/414113 [00:33<00:12, 8948.79it/s]\u001b[A\n",
      " 73%|███████▎  | 302044/414113 [00:33<00:12, 9081.33it/s]\u001b[A\n",
      " 73%|███████▎  | 303022/414113 [00:33<00:11, 9279.35it/s]\u001b[A\n",
      " 73%|███████▎  | 303965/414113 [00:33<00:11, 9318.29it/s]\u001b[A\n",
      " 74%|███████▎  | 304904/414113 [00:33<00:11, 9328.55it/s]\u001b[A\n",
      " 74%|███████▍  | 305843/414113 [00:33<00:11, 9346.21it/s]\u001b[A\n",
      " 74%|███████▍  | 306781/414113 [00:33<00:11, 9341.74it/s]\u001b[A\n",
      " 74%|███████▍  | 307749/414113 [00:33<00:11, 9438.91it/s]\u001b[A\n",
      " 75%|███████▍  | 308695/414113 [00:33<00:11, 9430.04it/s]\u001b[A\n",
      " 75%|███████▍  | 309640/414113 [00:34<00:11, 9425.69it/s]\u001b[A\n",
      " 75%|███████▌  | 310590/414113 [00:34<00:10, 9446.72it/s]\u001b[A\n",
      " 75%|███████▌  | 311550/414113 [00:34<00:10, 9491.11it/s]\u001b[A\n",
      " 75%|███████▌  | 312521/414113 [00:34<00:10, 9552.69it/s]\u001b[A\n",
      " 76%|███████▌  | 313483/414113 [00:34<00:10, 9571.60it/s]\u001b[A\n",
      " 76%|███████▌  | 314441/414113 [00:34<00:10, 9450.88it/s]\u001b[A\n",
      " 76%|███████▌  | 315396/414113 [00:34<00:10, 9478.80it/s]\u001b[A\n",
      " 76%|███████▋  | 316362/414113 [00:34<00:10, 9532.07it/s]\u001b[A\n",
      " 77%|███████▋  | 317354/414113 [00:34<00:10, 9644.95it/s]\u001b[A\n",
      " 77%|███████▋  | 318320/414113 [00:34<00:10, 9559.13it/s]\u001b[A\n",
      " 77%|███████▋  | 319277/414113 [00:35<00:09, 9511.72it/s]\u001b[A\n",
      " 77%|███████▋  | 320229/414113 [00:35<00:10, 9348.01it/s]\u001b[A\n",
      " 78%|███████▊  | 321185/414113 [00:35<00:09, 9405.67it/s]\u001b[A\n",
      " 78%|███████▊  | 322137/414113 [00:35<00:09, 9437.62it/s]\u001b[A\n",
      " 78%|███████▊  | 323086/414113 [00:35<00:09, 9452.64it/s]\u001b[A\n",
      " 78%|███████▊  | 324032/414113 [00:35<00:09, 9439.51it/s]\u001b[A\n",
      " 78%|███████▊  | 324977/414113 [00:35<00:09, 9368.29it/s]\u001b[A\n",
      " 79%|███████▊  | 325938/414113 [00:35<00:09, 9439.21it/s]\u001b[A\n",
      " 79%|███████▉  | 326917/414113 [00:35<00:09, 9540.22it/s]\u001b[A\n",
      " 79%|███████▉  | 327885/414113 [00:35<00:09, 9580.29it/s]\u001b[A\n",
      " 79%|███████▉  | 328844/414113 [00:36<00:08, 9509.29it/s]\u001b[A\n",
      " 80%|███████▉  | 329796/414113 [00:36<00:08, 9454.80it/s]\u001b[A\n",
      " 80%|███████▉  | 330742/414113 [00:36<00:08, 9372.92it/s]\u001b[A\n",
      " 80%|████████  | 331680/414113 [00:36<00:09, 9029.54it/s]\u001b[A\n",
      " 80%|████████  | 332621/414113 [00:36<00:08, 9138.47it/s]\u001b[A\n",
      " 81%|████████  | 333576/414113 [00:36<00:08, 9256.75it/s]\u001b[A\n",
      " 81%|████████  | 334504/414113 [00:36<00:08, 9211.29it/s]\u001b[A\n",
      " 81%|████████  | 335427/414113 [00:36<00:08, 9006.53it/s]\u001b[A\n",
      " 81%|████████  | 336330/414113 [00:36<00:08, 9006.89it/s]\u001b[A\n",
      " 81%|████████▏ | 337233/414113 [00:37<00:08, 8754.48it/s]\u001b[A\n",
      " 82%|████████▏ | 338146/414113 [00:37<00:08, 8860.46it/s]\u001b[A\n",
      " 82%|████████▏ | 339066/414113 [00:37<00:08, 8959.29it/s]\u001b[A\n",
      " 82%|████████▏ | 339964/414113 [00:37<00:08, 8896.23it/s]\u001b[A\n",
      " 82%|████████▏ | 340927/414113 [00:37<00:08, 9103.72it/s]\u001b[A\n",
      " 83%|████████▎ | 341847/414113 [00:37<00:07, 9126.19it/s]\u001b[A\n",
      " 83%|████████▎ | 342777/414113 [00:37<00:07, 9176.27it/s]\u001b[A\n",
      " 83%|████████▎ | 343722/414113 [00:37<00:07, 9254.70it/s]\u001b[A\n",
      " 83%|████████▎ | 344660/414113 [00:37<00:07, 9291.37it/s]\u001b[A\n",
      " 83%|████████▎ | 345598/414113 [00:37<00:07, 9316.17it/s]\u001b[A\n",
      " 84%|████████▎ | 346541/414113 [00:38<00:07, 9349.31it/s]\u001b[A\n",
      " 84%|████████▍ | 347477/414113 [00:38<00:07, 9346.50it/s]\u001b[A\n",
      " 84%|████████▍ | 348433/414113 [00:38<00:06, 9409.44it/s]\u001b[A\n",
      " 84%|████████▍ | 349395/414113 [00:38<00:06, 9470.14it/s]\u001b[A\n",
      " 85%|████████▍ | 350343/414113 [00:38<00:06, 9388.01it/s]\u001b[A\n",
      " 85%|████████▍ | 351289/414113 [00:38<00:06, 9407.87it/s]\u001b[A\n",
      " 85%|████████▌ | 352232/414113 [00:38<00:06, 9411.63it/s]\u001b[A\n",
      " 85%|████████▌ | 353175/414113 [00:38<00:06, 9415.62it/s]\u001b[A\n",
      " 86%|████████▌ | 354149/414113 [00:38<00:06, 9508.50it/s]\u001b[A\n",
      " 86%|████████▌ | 355101/414113 [00:38<00:06, 9506.34it/s]\u001b[A\n",
      " 86%|████████▌ | 356053/414113 [00:39<00:06, 9510.18it/s]\u001b[A\n",
      " 86%|████████▌ | 357005/414113 [00:39<00:06, 9450.18it/s]\u001b[A\n",
      " 86%|████████▋ | 357951/414113 [00:39<00:06, 9301.81it/s]\u001b[A\n",
      " 87%|████████▋ | 358883/414113 [00:39<00:05, 9303.62it/s]\u001b[A\n",
      " 87%|████████▋ | 359814/414113 [00:39<00:05, 9279.82it/s]\u001b[A\n",
      " 87%|████████▋ | 360743/414113 [00:39<00:05, 9209.65it/s]\u001b[A\n",
      " 87%|████████▋ | 361665/414113 [00:39<00:05, 9159.36it/s]\u001b[A\n",
      " 88%|████████▊ | 362630/414113 [00:39<00:05, 9299.89it/s]\u001b[A\n",
      " 88%|████████▊ | 363561/414113 [00:39<00:05, 9294.48it/s]\u001b[A\n",
      " 88%|████████▊ | 364491/414113 [00:39<00:05, 9278.75it/s]\u001b[A\n",
      " 88%|████████▊ | 365432/414113 [00:40<00:05, 9313.80it/s]\u001b[A\n",
      " 88%|████████▊ | 366364/414113 [00:40<00:05, 9304.41it/s]\u001b[A\n",
      " 89%|████████▊ | 367295/414113 [00:40<00:05, 9263.39it/s]\u001b[A\n",
      " 89%|████████▉ | 368222/414113 [00:40<00:04, 9248.77it/s]\u001b[A\n",
      " 89%|████████▉ | 369155/414113 [00:40<00:04, 9272.95it/s]\u001b[A\n",
      " 89%|████████▉ | 370083/414113 [00:40<00:04, 9240.35it/s]\u001b[A\n",
      " 90%|████████▉ | 371008/414113 [00:40<00:04, 9193.94it/s]\u001b[A\n",
      " 90%|████████▉ | 371947/414113 [00:40<00:04, 9250.88it/s]\u001b[A\n",
      " 90%|█████████ | 372873/414113 [00:40<00:04, 9230.25it/s]\u001b[A\n",
      " 90%|█████████ | 373801/414113 [00:40<00:04, 9242.85it/s]\u001b[A\n",
      " 90%|█████████ | 374726/414113 [00:41<00:04, 9197.83it/s]\u001b[A\n",
      " 91%|█████████ | 375672/414113 [00:41<00:04, 9274.30it/s]\u001b[A\n",
      " 91%|█████████ | 376600/414113 [00:41<00:04, 9263.18it/s]\u001b[A\n",
      " 91%|█████████ | 377536/414113 [00:41<00:03, 9289.75it/s]\u001b[A\n",
      " 91%|█████████▏| 378504/414113 [00:41<00:03, 9400.00it/s]\u001b[A\n",
      " 92%|█████████▏| 379463/414113 [00:41<00:03, 9455.48it/s]\u001b[A\n",
      " 92%|█████████▏| 380409/414113 [00:41<00:03, 9427.19it/s]\u001b[A\n",
      " 92%|█████████▏| 381352/414113 [00:41<00:03, 9401.26it/s]\u001b[A\n",
      " 92%|█████████▏| 382293/414113 [00:41<00:03, 9107.88it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 383206/414113 [00:41<00:03, 9062.79it/s]\u001b[A\n",
      " 93%|█████████▎| 384135/414113 [00:42<00:03, 9126.32it/s]\u001b[A\n",
      " 93%|█████████▎| 385095/414113 [00:42<00:03, 9261.55it/s]\u001b[A\n",
      " 93%|█████████▎| 386023/414113 [00:42<00:03, 9124.92it/s]\u001b[A\n",
      " 93%|█████████▎| 386972/414113 [00:42<00:02, 9227.95it/s]\u001b[A\n",
      " 94%|█████████▎| 387927/414113 [00:42<00:02, 9319.77it/s]\u001b[A\n",
      " 94%|█████████▍| 388868/414113 [00:42<00:02, 9345.06it/s]\u001b[A\n",
      " 94%|█████████▍| 389811/414113 [00:42<00:02, 9369.25it/s]\u001b[A\n",
      " 94%|█████████▍| 390749/414113 [00:42<00:02, 9369.73it/s]\u001b[A\n",
      " 95%|█████████▍| 391687/414113 [00:42<00:02, 9336.33it/s]\u001b[A\n",
      " 95%|█████████▍| 392654/414113 [00:42<00:02, 9432.48it/s]\u001b[A\n",
      " 95%|█████████▌| 393608/414113 [00:43<00:02, 9461.78it/s]\u001b[A\n",
      " 95%|█████████▌| 394563/414113 [00:43<00:02, 9488.04it/s]\u001b[A\n",
      " 96%|█████████▌| 395513/414113 [00:43<00:02, 9261.45it/s]\u001b[A\n",
      " 96%|█████████▌| 396450/414113 [00:43<00:01, 9292.83it/s]\u001b[A\n",
      " 96%|█████████▌| 397419/414113 [00:43<00:01, 9406.54it/s]\u001b[A\n",
      " 96%|█████████▌| 398374/414113 [00:43<00:01, 9449.02it/s]\u001b[A\n",
      " 96%|█████████▋| 399320/414113 [00:43<00:01, 9361.55it/s]\u001b[A\n",
      " 97%|█████████▋| 400257/414113 [00:43<00:01, 9350.99it/s]\u001b[A\n",
      " 97%|█████████▋| 401193/414113 [00:43<00:01, 9345.21it/s]\u001b[A\n",
      " 97%|█████████▋| 402133/414113 [00:44<00:01, 9360.71it/s]\u001b[A\n",
      " 97%|█████████▋| 403101/414113 [00:44<00:01, 9453.76it/s]\u001b[A\n",
      " 98%|█████████▊| 404064/414113 [00:44<00:01, 9505.50it/s]\u001b[A\n",
      " 98%|█████████▊| 405015/414113 [00:44<00:00, 9436.48it/s]\u001b[A\n",
      " 98%|█████████▊| 405978/414113 [00:44<00:00, 9490.97it/s]\u001b[A\n",
      " 98%|█████████▊| 406928/414113 [00:44<00:00, 9490.29it/s]\u001b[A\n",
      " 98%|█████████▊| 407889/414113 [00:44<00:00, 9523.66it/s]\u001b[A\n",
      " 99%|█████████▊| 408842/414113 [00:44<00:00, 9158.78it/s]\u001b[A\n",
      " 99%|█████████▉| 409779/414113 [00:44<00:00, 9218.17it/s]\u001b[A\n",
      " 99%|█████████▉| 410712/414113 [00:44<00:00, 9249.92it/s]\u001b[A\n",
      " 99%|█████████▉| 411682/414113 [00:45<00:00, 9378.61it/s]\u001b[A\n",
      "100%|█████████▉| 412644/414113 [00:45<00:00, 9449.61it/s]\u001b[A\n",
      "100%|█████████▉| 413591/414113 [00:45<00:00, 9332.58it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [00:45<00:00, 9143.49it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size=10\n",
    "#batch_size = 64          # batch size, we have 10GB of GPU memory, let's use it\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = False    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 25             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size, max_batch_size=batch_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) + list(encoder.bn.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "#optimizer = torch.optim.SGD(params, lr=0.01)\n",
    "\n",
    "# this data is probably pretty sparse, and defaults are probably ok\n",
    "#http://ruder.io/optimizing-gradient-descent/\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Epoch [1/25], Step [100/41412], Loss: 4.4867, Perplexity: 88.8297\n",
      "Epoch [1/25], Step [200/41412], Loss: 4.0446, Perplexity: 57.08937\n",
      "Epoch [1/25], Step [300/41412], Loss: 3.7327, Perplexity: 41.79326\n",
      "Epoch [1/25], Step [400/41412], Loss: 4.2026, Perplexity: 66.8612\n",
      "Epoch [1/25], Step [500/41412], Loss: 4.0259, Perplexity: 56.0289\n",
      "Epoch [1/25], Step [600/41412], Loss: 3.3031, Perplexity: 27.19644\n",
      "Epoch [1/25], Step [700/41412], Loss: 3.5537, Perplexity: 34.9435\n",
      "Epoch [1/25], Step [800/41412], Loss: 3.8278, Perplexity: 45.9632\n",
      "Epoch [1/25], Step [900/41412], Loss: 2.8911, Perplexity: 18.0137\n",
      "Epoch [1/25], Step [1000/41412], Loss: 3.3596, Perplexity: 28.7786\n",
      "Epoch [1/25], Step [1100/41412], Loss: 2.5576, Perplexity: 12.9045\n",
      "Epoch [1/25], Step [1200/41412], Loss: 3.7884, Perplexity: 44.1878\n",
      "Epoch [1/25], Step [1300/41412], Loss: 3.5841, Perplexity: 36.0227\n",
      "Epoch [1/25], Step [1400/41412], Loss: 2.8287, Perplexity: 16.9238\n",
      "Epoch [1/25], Step [1500/41412], Loss: 3.3712, Perplexity: 29.1142\n",
      "Epoch [1/25], Step [1600/41412], Loss: 3.0335, Perplexity: 20.7692\n",
      "Epoch [1/25], Step [1700/41412], Loss: 3.5085, Perplexity: 33.3989\n",
      "Epoch [1/25], Step [1800/41412], Loss: 4.3171, Perplexity: 74.9690\n",
      "Epoch [1/25], Step [1900/41412], Loss: 2.8091, Perplexity: 16.5944\n",
      "Epoch [1/25], Step [2000/41412], Loss: 3.1560, Perplexity: 23.4768\n",
      "Epoch [1/25], Step [2100/41412], Loss: 2.7011, Perplexity: 14.8966\n",
      "Epoch [1/25], Step [2200/41412], Loss: 2.6581, Perplexity: 14.26873\n",
      "Epoch [1/25], Step [2300/41412], Loss: 3.1612, Perplexity: 23.5981\n",
      "Epoch [1/25], Step [2400/41412], Loss: 2.8158, Perplexity: 16.7068\n",
      "Epoch [1/25], Step [2500/41412], Loss: 3.5951, Perplexity: 36.4178\n",
      "Epoch [1/25], Step [2600/41412], Loss: 3.7397, Perplexity: 42.0833\n",
      "Epoch [1/25], Step [2700/41412], Loss: 2.1792, Perplexity: 8.83920\n",
      "Epoch [1/25], Step [2800/41412], Loss: 2.5493, Perplexity: 12.7986\n",
      "Epoch [1/25], Step [2900/41412], Loss: 2.7628, Perplexity: 15.8442\n",
      "Epoch [1/25], Step [3000/41412], Loss: 2.4650, Perplexity: 11.7630\n",
      "Epoch [1/25], Step [3100/41412], Loss: 3.4600, Perplexity: 31.8170\n",
      "Epoch [1/25], Step [3200/41412], Loss: 2.7243, Perplexity: 15.2450\n",
      "Epoch [1/25], Step [3300/41412], Loss: 2.6781, Perplexity: 14.5578\n",
      "Epoch [1/25], Step [3400/41412], Loss: 2.8449, Perplexity: 17.1995\n",
      "Epoch [1/25], Step [3500/41412], Loss: 2.8464, Perplexity: 17.2253\n",
      "Epoch [1/25], Step [3600/41412], Loss: 2.7008, Perplexity: 14.8918\n",
      "Epoch [1/25], Step [3700/41412], Loss: 3.6014, Perplexity: 36.6506\n",
      "Epoch [1/25], Step [3800/41412], Loss: 2.7217, Perplexity: 15.2057\n",
      "Epoch [1/25], Step [3900/41412], Loss: 2.9245, Perplexity: 18.6252\n",
      "Epoch [1/25], Step [4000/41412], Loss: 2.9220, Perplexity: 18.5788\n",
      "Epoch [1/25], Step [4100/41412], Loss: 2.3946, Perplexity: 10.9636\n",
      "Epoch [1/25], Step [4200/41412], Loss: 2.8266, Perplexity: 16.8881\n",
      "Epoch [1/25], Step [4300/41412], Loss: 2.7947, Perplexity: 16.3584\n",
      "Epoch [1/25], Step [4400/41412], Loss: 3.2386, Perplexity: 25.49843\n",
      "Epoch [1/25], Step [4500/41412], Loss: 2.9516, Perplexity: 19.1358\n",
      "Epoch [1/25], Step [4600/41412], Loss: 2.5735, Perplexity: 13.1112\n",
      "Epoch [1/25], Step [4700/41412], Loss: 3.3253, Perplexity: 27.8064\n",
      "Epoch [1/25], Step [4800/41412], Loss: 2.5192, Perplexity: 12.4190\n",
      "Epoch [1/25], Step [4900/41412], Loss: 2.0527, Perplexity: 7.78926\n",
      "Epoch [1/25], Step [5000/41412], Loss: 2.7193, Perplexity: 15.1694\n",
      "Epoch [1/25], Step [5100/41412], Loss: 2.2271, Perplexity: 9.27328\n",
      "Epoch [1/25], Step [5200/41412], Loss: 2.3200, Perplexity: 10.1759\n",
      "Epoch [1/25], Step [5300/41412], Loss: 2.2924, Perplexity: 9.89890\n",
      "Epoch [1/25], Step [5400/41412], Loss: 2.5660, Perplexity: 13.0133\n",
      "Epoch [1/25], Step [5500/41412], Loss: 2.4855, Perplexity: 12.0068\n",
      "Epoch [1/25], Step [5600/41412], Loss: 2.2792, Perplexity: 9.769031\n",
      "Epoch [1/25], Step [5700/41412], Loss: 2.5947, Perplexity: 13.3931\n",
      "Epoch [1/25], Step [5800/41412], Loss: 2.8389, Perplexity: 17.09757\n",
      "Epoch [1/25], Step [5900/41412], Loss: 2.4299, Perplexity: 11.3581\n",
      "Epoch [1/25], Step [6000/41412], Loss: 2.4396, Perplexity: 11.4684\n",
      "Epoch [1/25], Step [6100/41412], Loss: 2.6000, Perplexity: 13.4641\n",
      "Epoch [1/25], Step [6200/41412], Loss: 3.0510, Perplexity: 21.1374\n",
      "Epoch [1/25], Step [6300/41412], Loss: 2.2087, Perplexity: 9.10423\n",
      "Epoch [1/25], Step [6400/41412], Loss: 2.4487, Perplexity: 11.5737\n",
      "Epoch [1/25], Step [6500/41412], Loss: 2.7253, Perplexity: 15.2611\n",
      "Epoch [1/25], Step [6600/41412], Loss: 2.2631, Perplexity: 9.61304\n",
      "Epoch [1/25], Step [6700/41412], Loss: 2.5207, Perplexity: 12.4378\n",
      "Epoch [1/25], Step [6800/41412], Loss: 2.8862, Perplexity: 17.9248\n",
      "Epoch [1/25], Step [6900/41412], Loss: 2.5680, Perplexity: 13.0398\n",
      "Epoch [1/25], Step [7000/41412], Loss: 3.1405, Perplexity: 23.1148\n",
      "Epoch [1/25], Step [7100/41412], Loss: 2.1297, Perplexity: 8.41256\n",
      "Epoch [1/25], Step [7200/41412], Loss: 2.5137, Perplexity: 12.3503\n",
      "Epoch [1/25], Step [7300/41412], Loss: 1.9646, Perplexity: 7.13221\n",
      "Epoch [1/25], Step [7400/41412], Loss: 2.8054, Perplexity: 16.5335\n",
      "Epoch [1/25], Step [7500/41412], Loss: 2.8024, Perplexity: 16.48380\n",
      "Epoch [1/25], Step [7600/41412], Loss: 2.0884, Perplexity: 8.07186\n",
      "Epoch [1/25], Step [7700/41412], Loss: 2.9381, Perplexity: 18.8808\n",
      "Epoch [1/25], Step [7800/41412], Loss: 2.9713, Perplexity: 19.5182\n",
      "Epoch [1/25], Step [7900/41412], Loss: 2.0757, Perplexity: 7.97005\n",
      "Epoch [1/25], Step [8000/41412], Loss: 3.1674, Perplexity: 23.7456\n",
      "Epoch [1/25], Step [8100/41412], Loss: 2.0997, Perplexity: 8.16342\n",
      "Epoch [1/25], Step [8200/41412], Loss: 2.4381, Perplexity: 11.4512\n",
      "Epoch [1/25], Step [8300/41412], Loss: 2.4771, Perplexity: 11.9072\n",
      "Epoch [1/25], Step [8400/41412], Loss: 2.3593, Perplexity: 10.5832\n",
      "Epoch [1/25], Step [8500/41412], Loss: 3.7771, Perplexity: 43.6879\n",
      "Epoch [1/25], Step [8600/41412], Loss: 2.9868, Perplexity: 19.8216\n",
      "Epoch [1/25], Step [8700/41412], Loss: 2.2656, Perplexity: 9.63715\n",
      "Epoch [1/25], Step [8800/41412], Loss: 2.5709, Perplexity: 13.0774\n",
      "Epoch [1/25], Step [8900/41412], Loss: 2.4660, Perplexity: 11.7749\n",
      "Epoch [1/25], Step [9000/41412], Loss: 2.4427, Perplexity: 11.5041\n",
      "Epoch [1/25], Step [9100/41412], Loss: 2.1450, Perplexity: 8.54165\n",
      "Epoch [1/25], Step [9200/41412], Loss: 1.9943, Perplexity: 7.34684\n",
      "Epoch [1/25], Step [9300/41412], Loss: 2.3262, Perplexity: 10.2386\n",
      "Epoch [1/25], Step [9400/41412], Loss: 2.8479, Perplexity: 17.2509\n",
      "Epoch [1/25], Step [9500/41412], Loss: 2.4543, Perplexity: 11.6378\n",
      "Epoch [1/25], Step [9600/41412], Loss: 2.3020, Perplexity: 9.99451\n",
      "Epoch [1/25], Step [9700/41412], Loss: 2.4826, Perplexity: 11.9722\n",
      "Epoch [1/25], Step [9800/41412], Loss: 2.4071, Perplexity: 11.1015\n",
      "Epoch [1/25], Step [9900/41412], Loss: 3.1462, Perplexity: 23.2471\n",
      "Epoch [1/25], Step [10000/41412], Loss: 3.0757, Perplexity: 21.6652\n",
      "Epoch [1/25], Step [10100/41412], Loss: 2.8408, Perplexity: 17.1291\n",
      "Epoch [1/25], Step [10200/41412], Loss: 2.9191, Perplexity: 18.5244\n",
      "Epoch [1/25], Step [10300/41412], Loss: 2.4787, Perplexity: 11.9261\n",
      "Epoch [1/25], Step [10400/41412], Loss: 2.2106, Perplexity: 9.12154\n",
      "Epoch [1/25], Step [10500/41412], Loss: 2.4838, Perplexity: 11.9871\n",
      "Epoch [1/25], Step [10600/41412], Loss: 2.7444, Perplexity: 15.5557\n",
      "Epoch [1/25], Step [10700/41412], Loss: 2.2330, Perplexity: 9.32809\n",
      "Epoch [1/25], Step [10800/41412], Loss: 2.4928, Perplexity: 12.0953\n",
      "Epoch [1/25], Step [10900/41412], Loss: 2.2539, Perplexity: 9.52494\n",
      "Epoch [1/25], Step [11000/41412], Loss: 2.4938, Perplexity: 12.1071\n",
      "Epoch [1/25], Step [11100/41412], Loss: 3.2615, Perplexity: 26.0893\n",
      "Epoch [1/25], Step [11200/41412], Loss: 2.3591, Perplexity: 10.5811\n",
      "Epoch [1/25], Step [11300/41412], Loss: 2.0297, Perplexity: 7.61203\n",
      "Epoch [1/25], Step [11400/41412], Loss: 2.1017, Perplexity: 8.17984\n",
      "Epoch [1/25], Step [11500/41412], Loss: 3.0756, Perplexity: 21.6633\n",
      "Epoch [1/25], Step [11600/41412], Loss: 2.0493, Perplexity: 7.76241\n",
      "Epoch [1/25], Step [11700/41412], Loss: 2.6700, Perplexity: 14.4394\n",
      "Epoch [1/25], Step [11800/41412], Loss: 2.6144, Perplexity: 13.6591\n",
      "Epoch [1/25], Step [11900/41412], Loss: 3.0087, Perplexity: 20.2609\n",
      "Epoch [1/25], Step [12000/41412], Loss: 2.6853, Perplexity: 14.6620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [12100/41412], Loss: 2.5063, Perplexity: 12.2601\n",
      "Epoch [1/25], Step [12200/41412], Loss: 2.4971, Perplexity: 12.1468\n",
      "Epoch [1/25], Step [12300/41412], Loss: 2.1686, Perplexity: 8.74586\n",
      "Epoch [1/25], Step [12400/41412], Loss: 2.5789, Perplexity: 13.1820\n",
      "Epoch [1/25], Step [12500/41412], Loss: 2.3958, Perplexity: 10.9772\n",
      "Epoch [1/25], Step [12600/41412], Loss: 3.1249, Perplexity: 22.7570\n",
      "Epoch [1/25], Step [12700/41412], Loss: 2.6593, Perplexity: 14.2860\n",
      "Epoch [1/25], Step [12800/41412], Loss: 3.3241, Perplexity: 27.7746\n",
      "Epoch [1/25], Step [12900/41412], Loss: 2.4258, Perplexity: 11.3112\n",
      "Epoch [1/25], Step [13000/41412], Loss: 1.9556, Perplexity: 7.06794\n",
      "Epoch [1/25], Step [13100/41412], Loss: 2.7004, Perplexity: 14.8857\n",
      "Epoch [1/25], Step [13200/41412], Loss: 2.1548, Perplexity: 8.62640\n",
      "Epoch [1/25], Step [13300/41412], Loss: 2.5604, Perplexity: 12.9410\n",
      "Epoch [1/25], Step [13400/41412], Loss: 2.2975, Perplexity: 9.94906\n",
      "Epoch [1/25], Step [13500/41412], Loss: 2.3957, Perplexity: 10.9761\n",
      "Epoch [1/25], Step [13600/41412], Loss: 2.0504, Perplexity: 7.77091\n",
      "Epoch [1/25], Step [13700/41412], Loss: 2.5982, Perplexity: 13.4398\n",
      "Epoch [1/25], Step [13800/41412], Loss: 2.4246, Perplexity: 11.2979\n",
      "Epoch [1/25], Step [13900/41412], Loss: 2.2613, Perplexity: 9.595229\n",
      "Epoch [1/25], Step [14000/41412], Loss: 2.7753, Perplexity: 16.0430\n",
      "Epoch [1/25], Step [14100/41412], Loss: 2.3618, Perplexity: 10.61028\n",
      "Epoch [1/25], Step [14200/41412], Loss: 2.5884, Perplexity: 13.3086\n",
      "Epoch [1/25], Step [14300/41412], Loss: 2.2890, Perplexity: 9.86485\n",
      "Epoch [1/25], Step [14400/41412], Loss: 3.1734, Perplexity: 23.8888\n",
      "Epoch [1/25], Step [14500/41412], Loss: 2.6688, Perplexity: 14.4229\n",
      "Epoch [1/25], Step [14600/41412], Loss: 2.2622, Perplexity: 9.60422\n",
      "Epoch [1/25], Step [14700/41412], Loss: 2.5018, Perplexity: 12.2048\n",
      "Epoch [1/25], Step [14800/41412], Loss: 1.8522, Perplexity: 6.37406\n",
      "Epoch [1/25], Step [14900/41412], Loss: 2.5439, Perplexity: 12.7287\n",
      "Epoch [1/25], Step [15000/41412], Loss: 2.0360, Perplexity: 7.66037\n",
      "Epoch [1/25], Step [15100/41412], Loss: 2.1696, Perplexity: 8.75486\n",
      "Epoch [1/25], Step [15200/41412], Loss: 2.8003, Perplexity: 16.4497\n",
      "Epoch [1/25], Step [15300/41412], Loss: 2.9723, Perplexity: 19.5364\n",
      "Epoch [1/25], Step [15400/41412], Loss: 2.1020, Perplexity: 8.18276\n",
      "Epoch [1/25], Step [15500/41412], Loss: 2.8349, Perplexity: 17.0284\n",
      "Epoch [1/25], Step [15600/41412], Loss: 2.9418, Perplexity: 18.9507\n",
      "Epoch [1/25], Step [15700/41412], Loss: 2.1976, Perplexity: 9.00357\n",
      "Epoch [1/25], Step [15800/41412], Loss: 2.2057, Perplexity: 9.07674\n",
      "Epoch [1/25], Step [15900/41412], Loss: 2.1483, Perplexity: 8.56997\n",
      "Epoch [1/25], Step [16000/41412], Loss: 2.4658, Perplexity: 11.7733\n",
      "Epoch [1/25], Step [16100/41412], Loss: 2.3102, Perplexity: 10.0767\n",
      "Epoch [1/25], Step [16200/41412], Loss: 2.9366, Perplexity: 18.8521\n",
      "Epoch [1/25], Step [16300/41412], Loss: 2.2339, Perplexity: 9.33653\n",
      "Epoch [1/25], Step [16400/41412], Loss: 2.8092, Perplexity: 16.5970\n",
      "Epoch [1/25], Step [16500/41412], Loss: 2.2822, Perplexity: 9.79809\n",
      "Epoch [1/25], Step [16600/41412], Loss: 2.5158, Perplexity: 12.3770\n",
      "Epoch [1/25], Step [16700/41412], Loss: 1.9782, Perplexity: 7.22959\n",
      "Epoch [1/25], Step [16800/41412], Loss: 2.8530, Perplexity: 17.3400\n",
      "Epoch [1/25], Step [16900/41412], Loss: 2.6914, Perplexity: 14.7519\n",
      "Epoch [1/25], Step [17000/41412], Loss: 2.0392, Perplexity: 7.68452\n",
      "Epoch [1/25], Step [17100/41412], Loss: 2.0131, Perplexity: 7.48669\n",
      "Epoch [1/25], Step [17200/41412], Loss: 2.2329, Perplexity: 9.32716\n",
      "Epoch [1/25], Step [17300/41412], Loss: 2.6794, Perplexity: 14.5766\n",
      "Epoch [1/25], Step [17400/41412], Loss: 2.4234, Perplexity: 11.2844\n",
      "Epoch [1/25], Step [17500/41412], Loss: 2.3506, Perplexity: 10.4919\n",
      "Epoch [1/25], Step [17600/41412], Loss: 1.9647, Perplexity: 7.13317\n",
      "Epoch [1/25], Step [17700/41412], Loss: 3.0006, Perplexity: 20.0969\n",
      "Epoch [1/25], Step [17800/41412], Loss: 2.6688, Perplexity: 14.4222\n",
      "Epoch [1/25], Step [17900/41412], Loss: 2.2940, Perplexity: 9.91466\n",
      "Epoch [1/25], Step [18000/41412], Loss: 2.1838, Perplexity: 8.88038\n",
      "Epoch [1/25], Step [18100/41412], Loss: 3.0584, Perplexity: 21.2937\n",
      "Epoch [1/25], Step [18200/41412], Loss: 2.8608, Perplexity: 17.4752\n",
      "Epoch [1/25], Step [18300/41412], Loss: 2.1447, Perplexity: 8.53964\n",
      "Epoch [1/25], Step [18400/41412], Loss: 2.2932, Perplexity: 9.906476\n",
      "Epoch [1/25], Step [18500/41412], Loss: 2.1807, Perplexity: 8.85243\n",
      "Epoch [1/25], Step [18600/41412], Loss: 2.0690, Perplexity: 7.91674\n",
      "Epoch [1/25], Step [18700/41412], Loss: 2.9389, Perplexity: 18.8959\n",
      "Epoch [1/25], Step [18800/41412], Loss: 1.7912, Perplexity: 5.99669\n",
      "Epoch [1/25], Step [18900/41412], Loss: 2.4925, Perplexity: 12.0910\n",
      "Epoch [1/25], Step [19000/41412], Loss: 2.2602, Perplexity: 9.58460\n",
      "Epoch [1/25], Step [19100/41412], Loss: 2.0888, Perplexity: 8.07510\n",
      "Epoch [1/25], Step [19200/41412], Loss: 3.3240, Perplexity: 27.7725\n",
      "Epoch [1/25], Step [19300/41412], Loss: 2.3554, Perplexity: 10.5424\n",
      "Epoch [1/25], Step [19400/41412], Loss: 2.3821, Perplexity: 10.8279\n",
      "Epoch [1/25], Step [19500/41412], Loss: 2.2177, Perplexity: 9.186156\n",
      "Epoch [1/25], Step [19600/41412], Loss: 1.8960, Perplexity: 6.65941\n",
      "Epoch [1/25], Step [19700/41412], Loss: 2.1347, Perplexity: 8.45422\n",
      "Epoch [1/25], Step [19800/41412], Loss: 2.0036, Perplexity: 7.41574\n",
      "Epoch [1/25], Step [19900/41412], Loss: 2.0956, Perplexity: 8.13052\n",
      "Epoch [1/25], Step [20000/41412], Loss: 2.3771, Perplexity: 10.7731\n",
      "Epoch [1/25], Step [20100/41412], Loss: 2.6559, Perplexity: 14.2383\n",
      "Epoch [1/25], Step [20200/41412], Loss: 2.6565, Perplexity: 14.24708\n",
      "Epoch [1/25], Step [20300/41412], Loss: 2.5555, Perplexity: 12.8771\n",
      "Epoch [1/25], Step [20400/41412], Loss: 2.1332, Perplexity: 8.44151\n",
      "Epoch [1/25], Step [20500/41412], Loss: 2.5740, Perplexity: 13.1179\n",
      "Epoch [1/25], Step [20600/41412], Loss: 2.1703, Perplexity: 8.76081\n",
      "Epoch [1/25], Step [20700/41412], Loss: 2.2993, Perplexity: 9.96708\n",
      "Epoch [1/25], Step [20800/41412], Loss: 2.3092, Perplexity: 10.0665\n",
      "Epoch [1/25], Step [20900/41412], Loss: 2.3189, Perplexity: 10.1645\n",
      "Epoch [1/25], Step [21000/41412], Loss: 2.4956, Perplexity: 12.1287\n",
      "Epoch [1/25], Step [21100/41412], Loss: 2.8397, Perplexity: 17.1102\n",
      "Epoch [1/25], Step [21200/41412], Loss: 2.0876, Perplexity: 8.06553\n",
      "Epoch [1/25], Step [21300/41412], Loss: 2.4400, Perplexity: 11.4735\n",
      "Epoch [1/25], Step [21400/41412], Loss: 2.1451, Perplexity: 8.54296\n",
      "Epoch [1/25], Step [21500/41412], Loss: 2.0304, Perplexity: 7.61681\n",
      "Epoch [1/25], Step [21600/41412], Loss: 2.6088, Perplexity: 13.5828\n",
      "Epoch [1/25], Step [21700/41412], Loss: 2.4967, Perplexity: 12.1424\n",
      "Epoch [1/25], Step [21800/41412], Loss: 1.8170, Perplexity: 6.15363\n",
      "Epoch [1/25], Step [21900/41412], Loss: 2.6100, Perplexity: 13.5994\n",
      "Epoch [1/25], Step [22000/41412], Loss: 2.5075, Perplexity: 12.2739\n",
      "Epoch [1/25], Step [22100/41412], Loss: 2.2573, Perplexity: 9.55735\n",
      "Epoch [1/25], Step [22200/41412], Loss: 2.6189, Perplexity: 13.7200\n",
      "Epoch [1/25], Step [22300/41412], Loss: 2.1055, Perplexity: 8.21150\n",
      "Epoch [1/25], Step [22400/41412], Loss: 2.3400, Perplexity: 10.3812\n",
      "Epoch [1/25], Step [22500/41412], Loss: 2.2388, Perplexity: 9.38224\n",
      "Epoch [1/25], Step [22600/41412], Loss: 2.6179, Perplexity: 13.7066\n",
      "Epoch [1/25], Step [22700/41412], Loss: 2.2204, Perplexity: 9.21065\n",
      "Epoch [1/25], Step [22800/41412], Loss: 2.2086, Perplexity: 9.10256\n",
      "Epoch [1/25], Step [22900/41412], Loss: 2.0567, Perplexity: 7.82009\n",
      "Epoch [1/25], Step [23000/41412], Loss: 2.3353, Perplexity: 10.3323\n",
      "Epoch [1/25], Step [23100/41412], Loss: 1.8417, Perplexity: 6.30752\n",
      "Epoch [1/25], Step [23200/41412], Loss: 2.3369, Perplexity: 10.3491\n",
      "Epoch [1/25], Step [23300/41412], Loss: 2.1564, Perplexity: 8.63976\n",
      "Epoch [1/25], Step [23400/41412], Loss: 2.5505, Perplexity: 12.8137\n",
      "Epoch [1/25], Step [23500/41412], Loss: 2.1099, Perplexity: 8.24720\n",
      "Epoch [1/25], Step [23600/41412], Loss: 2.4107, Perplexity: 11.1422\n",
      "Epoch [1/25], Step [23700/41412], Loss: 2.0865, Perplexity: 8.05703\n",
      "Epoch [1/25], Step [23800/41412], Loss: 2.6916, Perplexity: 14.7552\n",
      "Epoch [1/25], Step [23900/41412], Loss: 2.0613, Perplexity: 7.85626\n",
      "Epoch [1/25], Step [24000/41412], Loss: 2.5174, Perplexity: 12.3964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [24100/41412], Loss: 2.3175, Perplexity: 10.1506\n",
      "Epoch [1/25], Step [24200/41412], Loss: 2.6511, Perplexity: 14.1691\n",
      "Epoch [1/25], Step [24300/41412], Loss: 2.1793, Perplexity: 8.84007\n",
      "Epoch [1/25], Step [24400/41412], Loss: 2.2747, Perplexity: 9.72490\n",
      "Epoch [1/25], Step [24500/41412], Loss: 2.5413, Perplexity: 12.6961\n",
      "Epoch [1/25], Step [24600/41412], Loss: 2.3133, Perplexity: 10.1077\n",
      "Epoch [1/25], Step [24700/41412], Loss: 2.2860, Perplexity: 9.83538\n",
      "Epoch [1/25], Step [24800/41412], Loss: 1.8260, Perplexity: 6.20927\n",
      "Epoch [1/25], Step [24900/41412], Loss: 2.4143, Perplexity: 11.1818\n",
      "Epoch [1/25], Step [25000/41412], Loss: 2.1111, Perplexity: 8.25732\n",
      "Epoch [1/25], Step [25100/41412], Loss: 2.4265, Perplexity: 11.3192\n",
      "Epoch [1/25], Step [25200/41412], Loss: 2.2929, Perplexity: 9.90333\n",
      "Epoch [1/25], Step [25300/41412], Loss: 2.1054, Perplexity: 8.21081\n",
      "Epoch [1/25], Step [25400/41412], Loss: 2.5464, Perplexity: 12.7612\n",
      "Epoch [1/25], Step [25500/41412], Loss: 1.8714, Perplexity: 6.49730\n",
      "Epoch [1/25], Step [25600/41412], Loss: 2.3839, Perplexity: 10.8467\n",
      "Epoch [1/25], Step [25700/41412], Loss: 3.1090, Perplexity: 22.3984\n",
      "Epoch [1/25], Step [25800/41412], Loss: 2.4477, Perplexity: 11.5621\n",
      "Epoch [1/25], Step [25900/41412], Loss: 2.0187, Perplexity: 7.52824\n",
      "Epoch [1/25], Step [26000/41412], Loss: 2.0667, Perplexity: 7.89878\n",
      "Epoch [1/25], Step [26100/41412], Loss: 2.6133, Perplexity: 13.6434\n",
      "Epoch [1/25], Step [26200/41412], Loss: 2.4841, Perplexity: 11.9905\n",
      "Epoch [1/25], Step [26300/41412], Loss: 1.9050, Perplexity: 6.71958\n",
      "Epoch [1/25], Step [26400/41412], Loss: 3.1262, Perplexity: 22.7881\n",
      "Epoch [1/25], Step [26500/41412], Loss: 2.4114, Perplexity: 11.1491\n",
      "Epoch [1/25], Step [26600/41412], Loss: 1.7236, Perplexity: 5.60468\n",
      "Epoch [1/25], Step [26700/41412], Loss: 2.1944, Perplexity: 8.97460\n",
      "Epoch [1/25], Step [26800/41412], Loss: 2.1502, Perplexity: 8.58699\n",
      "Epoch [1/25], Step [26900/41412], Loss: 2.3485, Perplexity: 10.4696\n",
      "Epoch [1/25], Step [27000/41412], Loss: 3.4751, Perplexity: 32.3013\n",
      "Epoch [1/25], Step [27100/41412], Loss: 2.3808, Perplexity: 10.8138\n",
      "Epoch [1/25], Step [27200/41412], Loss: 1.8698, Perplexity: 6.48677\n",
      "Epoch [1/25], Step [27300/41412], Loss: 2.5165, Perplexity: 12.3854\n",
      "Epoch [1/25], Step [27400/41412], Loss: 3.0755, Perplexity: 21.6602\n",
      "Epoch [1/25], Step [27500/41412], Loss: 2.0991, Perplexity: 8.15893\n",
      "Epoch [1/25], Step [27600/41412], Loss: 2.1035, Perplexity: 8.19500\n",
      "Epoch [1/25], Step [27700/41412], Loss: 2.3155, Perplexity: 10.1303\n",
      "Epoch [1/25], Step [27800/41412], Loss: 2.8411, Perplexity: 17.1339\n",
      "Epoch [1/25], Step [27900/41412], Loss: 2.1349, Perplexity: 8.45585\n",
      "Epoch [1/25], Step [28000/41412], Loss: 2.2885, Perplexity: 9.85994\n",
      "Epoch [1/25], Step [28100/41412], Loss: 2.1327, Perplexity: 8.43762\n",
      "Epoch [1/25], Step [28200/41412], Loss: 2.4241, Perplexity: 11.2924\n",
      "Epoch [1/25], Step [28300/41412], Loss: 1.9305, Perplexity: 6.89294\n",
      "Epoch [1/25], Step [28400/41412], Loss: 2.0385, Perplexity: 7.67945\n",
      "Epoch [1/25], Step [28500/41412], Loss: 1.9663, Perplexity: 7.14398\n",
      "Epoch [1/25], Step [28600/41412], Loss: 1.9274, Perplexity: 6.87194\n",
      "Epoch [1/25], Step [28700/41412], Loss: 2.6166, Perplexity: 13.6894\n",
      "Epoch [1/25], Step [28800/41412], Loss: 2.5612, Perplexity: 12.95196\n",
      "Epoch [1/25], Step [28900/41412], Loss: 3.0481, Perplexity: 21.0755\n",
      "Epoch [1/25], Step [29000/41412], Loss: 2.2664, Perplexity: 9.64421\n",
      "Epoch [1/25], Step [29100/41412], Loss: 2.6919, Perplexity: 14.7594\n",
      "Epoch [1/25], Step [29200/41412], Loss: 2.1917, Perplexity: 8.95008\n",
      "Epoch [1/25], Step [29300/41412], Loss: 2.1361, Perplexity: 8.46661\n",
      "Epoch [1/25], Step [29400/41412], Loss: 3.2486, Perplexity: 25.7541\n",
      "Epoch [1/25], Step [29500/41412], Loss: 2.0014, Perplexity: 7.39985\n",
      "Epoch [1/25], Step [29600/41412], Loss: 1.9518, Perplexity: 7.04150\n",
      "Epoch [1/25], Step [29700/41412], Loss: 2.1563, Perplexity: 8.63926\n",
      "Epoch [1/25], Step [29800/41412], Loss: 2.2971, Perplexity: 9.94497\n",
      "Epoch [1/25], Step [29900/41412], Loss: 3.2691, Perplexity: 26.2884\n",
      "Epoch [1/25], Step [30000/41412], Loss: 2.1580, Perplexity: 8.65379\n",
      "Epoch [1/25], Step [30100/41412], Loss: 1.7551, Perplexity: 5.78392\n",
      "Epoch [1/25], Step [30200/41412], Loss: 1.7387, Perplexity: 5.69006\n",
      "Epoch [1/25], Step [30300/41412], Loss: 2.7583, Perplexity: 15.7727\n",
      "Epoch [1/25], Step [30400/41412], Loss: 2.3102, Perplexity: 10.0764\n",
      "Epoch [1/25], Step [30500/41412], Loss: 2.0473, Perplexity: 7.74692\n",
      "Epoch [1/25], Step [30600/41412], Loss: 2.5287, Perplexity: 12.5374\n",
      "Epoch [1/25], Step [30700/41412], Loss: 1.9155, Perplexity: 6.79045\n",
      "Epoch [1/25], Step [30800/41412], Loss: 1.9096, Perplexity: 6.75066\n",
      "Epoch [1/25], Step [30900/41412], Loss: 2.8496, Perplexity: 17.2804\n",
      "Epoch [1/25], Step [31000/41412], Loss: 2.2834, Perplexity: 9.81010\n",
      "Epoch [1/25], Step [31100/41412], Loss: 1.9774, Perplexity: 7.22396\n",
      "Epoch [1/25], Step [31200/41412], Loss: 2.0770, Perplexity: 7.98073\n",
      "Epoch [1/25], Step [31300/41412], Loss: 2.0722, Perplexity: 7.942042\n",
      "Epoch [1/25], Step [31400/41412], Loss: 2.2974, Perplexity: 9.94791\n",
      "Epoch [1/25], Step [31500/41412], Loss: 2.7437, Perplexity: 15.5447\n",
      "Epoch [1/25], Step [31600/41412], Loss: 2.4397, Perplexity: 11.4701\n",
      "Epoch [1/25], Step [31700/41412], Loss: 2.4330, Perplexity: 11.3930\n",
      "Epoch [1/25], Step [31800/41412], Loss: 2.3716, Perplexity: 10.7144\n",
      "Epoch [1/25], Step [31900/41412], Loss: 2.2452, Perplexity: 9.44251\n",
      "Epoch [1/25], Step [32000/41412], Loss: 2.3093, Perplexity: 10.0671\n",
      "Epoch [1/25], Step [32100/41412], Loss: 2.7770, Perplexity: 16.0708\n",
      "Epoch [1/25], Step [32200/41412], Loss: 2.7673, Perplexity: 15.9153\n",
      "Epoch [1/25], Step [32300/41412], Loss: 2.3152, Perplexity: 10.1271\n",
      "Epoch [1/25], Step [32400/41412], Loss: 1.6716, Perplexity: 5.32069\n",
      "Epoch [1/25], Step [32500/41412], Loss: 2.3904, Perplexity: 10.9177\n",
      "Epoch [1/25], Step [32600/41412], Loss: 1.8769, Perplexity: 6.53325\n",
      "Epoch [1/25], Step [32700/41412], Loss: 2.8457, Perplexity: 17.2145\n",
      "Epoch [1/25], Step [32800/41412], Loss: 2.1327, Perplexity: 8.43775\n",
      "Epoch [1/25], Step [32900/41412], Loss: 2.8731, Perplexity: 17.6910\n",
      "Epoch [1/25], Step [33000/41412], Loss: 2.2165, Perplexity: 9.17473\n",
      "Epoch [1/25], Step [33100/41412], Loss: 2.0778, Perplexity: 7.98692\n",
      "Epoch [1/25], Step [33200/41412], Loss: 2.6199, Perplexity: 13.7342\n",
      "Epoch [1/25], Step [33300/41412], Loss: 2.7809, Perplexity: 16.1336\n",
      "Epoch [1/25], Step [33400/41412], Loss: 2.7497, Perplexity: 15.6383\n",
      "Epoch [1/25], Step [33500/41412], Loss: 1.7280, Perplexity: 5.62942\n",
      "Epoch [1/25], Step [33600/41412], Loss: 2.7620, Perplexity: 15.8321\n",
      "Epoch [1/25], Step [33700/41412], Loss: 2.0859, Perplexity: 8.05224\n",
      "Epoch [1/25], Step [33800/41412], Loss: 2.5618, Perplexity: 12.9585\n",
      "Epoch [1/25], Step [33900/41412], Loss: 1.7714, Perplexity: 5.87912\n",
      "Epoch [1/25], Step [34000/41412], Loss: 2.0677, Perplexity: 7.90641\n",
      "Epoch [1/25], Step [34100/41412], Loss: 2.5047, Perplexity: 12.2403\n",
      "Epoch [1/25], Step [34200/41412], Loss: 2.4310, Perplexity: 11.3708\n",
      "Epoch [1/25], Step [34300/41412], Loss: 1.8142, Perplexity: 6.13633\n",
      "Epoch [1/25], Step [34400/41412], Loss: 2.1324, Perplexity: 8.43486\n",
      "Epoch [1/25], Step [34500/41412], Loss: 1.7601, Perplexity: 5.81311\n",
      "Epoch [1/25], Step [34600/41412], Loss: 2.0904, Perplexity: 8.08826\n",
      "Epoch [1/25], Step [34700/41412], Loss: 1.8825, Perplexity: 6.56973\n",
      "Epoch [1/25], Step [34800/41412], Loss: 2.0013, Perplexity: 7.39878\n",
      "Epoch [1/25], Step [34900/41412], Loss: 2.2458, Perplexity: 9.44781\n",
      "Epoch [1/25], Step [35000/41412], Loss: 1.6692, Perplexity: 5.30811\n",
      "Epoch [1/25], Step [35100/41412], Loss: 2.0688, Perplexity: 7.91503\n",
      "Epoch [1/25], Step [35200/41412], Loss: 2.4476, Perplexity: 11.5608\n",
      "Epoch [1/25], Step [35300/41412], Loss: 2.3042, Perplexity: 10.0162\n",
      "Epoch [1/25], Step [35400/41412], Loss: 1.7718, Perplexity: 5.88155\n",
      "Epoch [1/25], Step [35500/41412], Loss: 1.9062, Perplexity: 6.72738\n",
      "Epoch [1/25], Step [35600/41412], Loss: 2.3229, Perplexity: 10.2053\n",
      "Epoch [1/25], Step [35700/41412], Loss: 2.4013, Perplexity: 11.0380\n",
      "Epoch [1/25], Step [35800/41412], Loss: 2.5435, Perplexity: 12.7237\n",
      "Epoch [1/25], Step [35900/41412], Loss: 2.3757, Perplexity: 10.7585\n",
      "Epoch [1/25], Step [36000/41412], Loss: 2.0090, Perplexity: 7.45624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Step [36100/41412], Loss: 2.0179, Perplexity: 7.52243\n",
      "Epoch [1/25], Step [36200/41412], Loss: 2.1142, Perplexity: 8.28262\n",
      "Epoch [1/25], Step [36300/41412], Loss: 3.1995, Perplexity: 24.5212\n",
      "Epoch [1/25], Step [36400/41412], Loss: 2.4477, Perplexity: 11.5618\n",
      "Epoch [1/25], Step [36500/41412], Loss: 2.1331, Perplexity: 8.44097\n",
      "Epoch [1/25], Step [36600/41412], Loss: 2.1254, Perplexity: 8.37616\n",
      "Epoch [1/25], Step [36700/41412], Loss: 2.1860, Perplexity: 8.89994\n",
      "Epoch [1/25], Step [36800/41412], Loss: 2.4551, Perplexity: 11.6472\n",
      "Epoch [1/25], Step [36900/41412], Loss: 1.9135, Perplexity: 6.77717\n",
      "Epoch [1/25], Step [37000/41412], Loss: 2.1792, Perplexity: 8.83909\n",
      "Epoch [1/25], Step [37100/41412], Loss: 1.9393, Perplexity: 6.95381\n",
      "Epoch [1/25], Step [37200/41412], Loss: 2.5538, Perplexity: 12.8554\n",
      "Epoch [1/25], Step [37300/41412], Loss: 2.5879, Perplexity: 13.3020\n",
      "Epoch [1/25], Step [37400/41412], Loss: 2.2268, Perplexity: 9.27055\n",
      "Epoch [1/25], Step [37500/41412], Loss: 1.7550, Perplexity: 5.78348\n",
      "Epoch [1/25], Step [37600/41412], Loss: 2.5159, Perplexity: 12.3784\n",
      "Epoch [1/25], Step [37700/41412], Loss: 2.0875, Perplexity: 8.06472\n",
      "Epoch [1/25], Step [37800/41412], Loss: 1.8298, Perplexity: 6.23253\n",
      "Epoch [1/25], Step [37900/41412], Loss: 2.1255, Perplexity: 8.37716\n",
      "Epoch [1/25], Step [38000/41412], Loss: 2.8771, Perplexity: 17.7624\n",
      "Epoch [1/25], Step [38100/41412], Loss: 2.9983, Perplexity: 20.0514\n",
      "Epoch [1/25], Step [38200/41412], Loss: 2.3668, Perplexity: 10.6631\n",
      "Epoch [1/25], Step [38300/41412], Loss: 1.9070, Perplexity: 6.73263\n",
      "Epoch [1/25], Step [38400/41412], Loss: 2.5719, Perplexity: 13.0909\n",
      "Epoch [1/25], Step [38500/41412], Loss: 2.3192, Perplexity: 10.1680\n",
      "Epoch [1/25], Step [38600/41412], Loss: 2.1782, Perplexity: 8.83015\n",
      "Epoch [1/25], Step [38700/41412], Loss: 2.5014, Perplexity: 12.2000\n",
      "Epoch [1/25], Step [38800/41412], Loss: 2.0518, Perplexity: 7.78173\n",
      "Epoch [1/25], Step [38900/41412], Loss: 1.6488, Perplexity: 5.20107\n",
      "Epoch [1/25], Step [39000/41412], Loss: 2.2693, Perplexity: 9.67312\n",
      "Epoch [1/25], Step [39100/41412], Loss: 1.8119, Perplexity: 6.12209\n",
      "Epoch [1/25], Step [39200/41412], Loss: 2.3456, Perplexity: 10.4390\n",
      "Epoch [1/25], Step [39300/41412], Loss: 1.8044, Perplexity: 6.07612\n",
      "Epoch [1/25], Step [39400/41412], Loss: 2.1508, Perplexity: 8.59146\n",
      "Epoch [1/25], Step [39500/41412], Loss: 1.9830, Perplexity: 7.26485\n",
      "Epoch [1/25], Step [39600/41412], Loss: 2.1297, Perplexity: 8.41218\n",
      "Epoch [1/25], Step [39700/41412], Loss: 1.9559, Perplexity: 7.070002\n",
      "Epoch [1/25], Step [39800/41412], Loss: 2.0204, Perplexity: 7.54174\n",
      "Epoch [1/25], Step [39900/41412], Loss: 2.0217, Perplexity: 7.55134\n",
      "Epoch [1/25], Step [40000/41412], Loss: 2.6013, Perplexity: 13.4811\n",
      "Epoch [1/25], Step [40100/41412], Loss: 2.2992, Perplexity: 9.96597\n",
      "Epoch [1/25], Step [40200/41412], Loss: 2.3273, Perplexity: 10.2502\n",
      "Epoch [1/25], Step [40300/41412], Loss: 2.4259, Perplexity: 11.3121\n",
      "Epoch [1/25], Step [40400/41412], Loss: 2.0850, Perplexity: 8.04489\n",
      "Epoch [1/25], Step [40500/41412], Loss: 2.3005, Perplexity: 9.97890\n",
      "Epoch [1/25], Step [40600/41412], Loss: 1.8189, Perplexity: 6.16491\n",
      "Epoch [1/25], Step [40700/41412], Loss: 2.3894, Perplexity: 10.9068\n",
      "Epoch [1/25], Step [40800/41412], Loss: 2.7203, Perplexity: 15.1845\n",
      "Epoch [1/25], Step [40900/41412], Loss: 1.9844, Perplexity: 7.27498\n",
      "Epoch [1/25], Step [41000/41412], Loss: 1.9370, Perplexity: 6.93828\n",
      "Epoch [1/25], Step [41100/41412], Loss: 2.3037, Perplexity: 10.0107\n",
      "Epoch [1/25], Step [41200/41412], Loss: 1.8720, Perplexity: 6.50123\n",
      "Epoch [1/25], Step [41300/41412], Loss: 1.6782, Perplexity: 5.35626\n",
      "Epoch [1/25], Step [41400/41412], Loss: 1.8053, Perplexity: 6.08182\n",
      "Epoch [2/25], Step [100/41412], Loss: 1.9564, Perplexity: 7.0738001\n",
      "Epoch [2/25], Step [200/41412], Loss: 2.4883, Perplexity: 12.0409\n",
      "Epoch [2/25], Step [300/41412], Loss: 1.9987, Perplexity: 7.37988\n",
      "Epoch [2/25], Step [400/41412], Loss: 2.2342, Perplexity: 9.33868\n",
      "Epoch [2/25], Step [500/41412], Loss: 1.9223, Perplexity: 6.83669\n",
      "Epoch [2/25], Step [600/41412], Loss: 2.2011, Perplexity: 9.03537\n",
      "Epoch [2/25], Step [700/41412], Loss: 1.9096, Perplexity: 6.75049\n",
      "Epoch [2/25], Step [800/41412], Loss: 2.1523, Perplexity: 8.60431\n",
      "Epoch [2/25], Step [900/41412], Loss: 2.1035, Perplexity: 8.19508\n",
      "Epoch [2/25], Step [1000/41412], Loss: 1.9355, Perplexity: 6.9275\n",
      "Epoch [2/25], Step [1100/41412], Loss: 2.8399, Perplexity: 17.1143\n",
      "Epoch [2/25], Step [1200/41412], Loss: 2.3059, Perplexity: 10.0328\n",
      "Epoch [2/25], Step [1300/41412], Loss: 1.9960, Perplexity: 7.35998\n",
      "Epoch [2/25], Step [1400/41412], Loss: 2.2580, Perplexity: 9.56399\n",
      "Epoch [2/25], Step [1500/41412], Loss: 2.1609, Perplexity: 8.67891\n",
      "Epoch [2/25], Step [1600/41412], Loss: 1.9530, Perplexity: 7.05014\n",
      "Epoch [2/25], Step [1700/41412], Loss: 2.2114, Perplexity: 9.12812\n",
      "Epoch [2/25], Step [1800/41412], Loss: 1.9563, Perplexity: 7.07296\n",
      "Epoch [2/25], Step [1900/41412], Loss: 2.2645, Perplexity: 9.62621\n",
      "Epoch [2/25], Step [2000/41412], Loss: 2.8180, Perplexity: 16.7433\n",
      "Epoch [2/25], Step [2100/41412], Loss: 2.0706, Perplexity: 7.92932\n",
      "Epoch [2/25], Step [2200/41412], Loss: 1.8721, Perplexity: 6.50172\n",
      "Epoch [2/25], Step [2300/41412], Loss: 2.4234, Perplexity: 11.2841\n",
      "Epoch [2/25], Step [2400/41412], Loss: 1.8310, Perplexity: 6.23998\n",
      "Epoch [2/25], Step [2500/41412], Loss: 2.4091, Perplexity: 11.1235\n",
      "Epoch [2/25], Step [2600/41412], Loss: 1.9736, Perplexity: 7.19641\n",
      "Epoch [2/25], Step [2700/41412], Loss: 2.0288, Perplexity: 7.60475\n",
      "Epoch [2/25], Step [2800/41412], Loss: 2.5318, Perplexity: 12.5756\n",
      "Epoch [2/25], Step [2900/41412], Loss: 1.9885, Perplexity: 7.30452\n",
      "Epoch [2/25], Step [3000/41412], Loss: 2.7668, Perplexity: 15.9073\n",
      "Epoch [2/25], Step [3100/41412], Loss: 2.3675, Perplexity: 10.6704\n",
      "Epoch [2/25], Step [3200/41412], Loss: 2.0882, Perplexity: 8.07046\n",
      "Epoch [2/25], Step [3300/41412], Loss: 2.2159, Perplexity: 9.16993\n",
      "Epoch [2/25], Step [3400/41412], Loss: 2.1527, Perplexity: 8.60804\n",
      "Epoch [2/25], Step [3500/41412], Loss: 1.8467, Perplexity: 6.33924\n",
      "Epoch [2/25], Step [3600/41412], Loss: 2.0453, Perplexity: 7.73147\n",
      "Epoch [2/25], Step [3700/41412], Loss: 2.2872, Perplexity: 9.84760\n",
      "Epoch [2/25], Step [3800/41412], Loss: 2.6276, Perplexity: 13.8400\n",
      "Epoch [2/25], Step [3900/41412], Loss: 2.6312, Perplexity: 13.8905\n",
      "Epoch [2/25], Step [4000/41412], Loss: 2.0343, Perplexity: 7.64719\n",
      "Epoch [2/25], Step [4100/41412], Loss: 1.8383, Perplexity: 6.28583\n",
      "Epoch [2/25], Step [4200/41412], Loss: 2.4473, Perplexity: 11.5576\n",
      "Epoch [2/25], Step [4300/41412], Loss: 2.3154, Perplexity: 10.1292\n",
      "Epoch [2/25], Step [4400/41412], Loss: 2.2215, Perplexity: 9.22141\n",
      "Epoch [2/25], Step [4500/41412], Loss: 1.9592, Perplexity: 7.09351\n",
      "Epoch [2/25], Step [4600/41412], Loss: 2.1847, Perplexity: 8.88819\n",
      "Epoch [2/25], Step [4700/41412], Loss: 2.0960, Perplexity: 8.13360\n",
      "Epoch [2/25], Step [4800/41412], Loss: 1.8176, Perplexity: 6.15724\n",
      "Epoch [2/25], Step [4900/41412], Loss: 2.1583, Perplexity: 8.65676\n",
      "Epoch [2/25], Step [5000/41412], Loss: 1.8355, Perplexity: 6.26828\n",
      "Epoch [2/25], Step [5100/41412], Loss: 2.1924, Perplexity: 8.95713\n",
      "Epoch [2/25], Step [5200/41412], Loss: 2.2819, Perplexity: 9.79553\n",
      "Epoch [2/25], Step [5300/41412], Loss: 1.8860, Perplexity: 6.59280\n",
      "Epoch [2/25], Step [5400/41412], Loss: 1.8608, Perplexity: 6.42918\n",
      "Epoch [2/25], Step [5500/41412], Loss: 1.9711, Perplexity: 7.17895\n",
      "Epoch [2/25], Step [5600/41412], Loss: 2.4281, Perplexity: 11.3377\n",
      "Epoch [2/25], Step [5700/41412], Loss: 2.6704, Perplexity: 14.4460\n",
      "Epoch [2/25], Step [5800/41412], Loss: 1.8231, Perplexity: 6.19121\n",
      "Epoch [2/25], Step [5900/41412], Loss: 3.2417, Perplexity: 25.5762\n",
      "Epoch [2/25], Step [6000/41412], Loss: 1.5081, Perplexity: 4.51817\n",
      "Epoch [2/25], Step [6100/41412], Loss: 1.9023, Perplexity: 6.70165\n",
      "Epoch [2/25], Step [6200/41412], Loss: 2.1972, Perplexity: 8.99954\n",
      "Epoch [2/25], Step [6300/41412], Loss: 2.1686, Perplexity: 8.74645\n",
      "Epoch [2/25], Step [6400/41412], Loss: 3.1133, Perplexity: 22.4944\n",
      "Epoch [2/25], Step [6500/41412], Loss: 1.8344, Perplexity: 6.26111\n",
      "Epoch [2/25], Step [6600/41412], Loss: 2.6862, Perplexity: 14.6754\n",
      "Epoch [2/25], Step [6700/41412], Loss: 2.0831, Perplexity: 8.02911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Step [6800/41412], Loss: 2.2374, Perplexity: 9.36911\n",
      "Epoch [2/25], Step [6900/41412], Loss: 2.1276, Perplexity: 8.39455\n",
      "Epoch [2/25], Step [7000/41412], Loss: 2.0877, Perplexity: 8.06643\n",
      "Epoch [2/25], Step [7100/41412], Loss: 1.8404, Perplexity: 6.29929\n",
      "Epoch [2/25], Step [7200/41412], Loss: 2.9338, Perplexity: 18.7980\n",
      "Epoch [2/25], Step [7300/41412], Loss: 2.8647, Perplexity: 17.5431\n",
      "Epoch [2/25], Step [7400/41412], Loss: 1.7883, Perplexity: 5.97938\n",
      "Epoch [2/25], Step [7500/41412], Loss: 2.7257, Perplexity: 15.2664\n",
      "Epoch [2/25], Step [7600/41412], Loss: 1.8025, Perplexity: 6.06469\n",
      "Epoch [2/25], Step [7700/41412], Loss: 2.2752, Perplexity: 9.72961\n",
      "Epoch [2/25], Step [7800/41412], Loss: 2.3196, Perplexity: 10.1715\n",
      "Epoch [2/25], Step [7900/41412], Loss: 2.1648, Perplexity: 8.71249\n",
      "Epoch [2/25], Step [8000/41412], Loss: 2.2196, Perplexity: 9.20357\n",
      "Epoch [2/25], Step [8100/41412], Loss: 2.2325, Perplexity: 9.32281\n",
      "Epoch [2/25], Step [8200/41412], Loss: 2.1108, Perplexity: 8.25474\n",
      "Epoch [2/25], Step [8300/41412], Loss: 2.3198, Perplexity: 10.1733\n",
      "Epoch [2/25], Step [8400/41412], Loss: 2.1122, Perplexity: 8.26646\n",
      "Epoch [2/25], Step [8500/41412], Loss: 2.5002, Perplexity: 12.1852\n",
      "Epoch [2/25], Step [8600/41412], Loss: 1.6708, Perplexity: 5.31642\n",
      "Epoch [2/25], Step [8700/41412], Loss: 2.4539, Perplexity: 11.6342\n",
      "Epoch [2/25], Step [8800/41412], Loss: 2.3376, Perplexity: 10.3565\n",
      "Epoch [2/25], Step [8900/41412], Loss: 2.2176, Perplexity: 9.18492\n",
      "Epoch [2/25], Step [9000/41412], Loss: 2.2037, Perplexity: 9.05866\n",
      "Epoch [2/25], Step [9100/41412], Loss: 2.1182, Perplexity: 8.31650\n",
      "Epoch [2/25], Step [9200/41412], Loss: 1.9296, Perplexity: 6.88673\n",
      "Epoch [2/25], Step [9300/41412], Loss: 2.6888, Perplexity: 14.7135\n",
      "Epoch [2/25], Step [9400/41412], Loss: 2.2419, Perplexity: 9.41154\n",
      "Epoch [2/25], Step [9500/41412], Loss: 1.9242, Perplexity: 6.84939\n",
      "Epoch [2/25], Step [9600/41412], Loss: 2.1389, Perplexity: 8.49019\n",
      "Epoch [2/25], Step [9700/41412], Loss: 3.4288, Perplexity: 30.8390\n",
      "Epoch [2/25], Step [9800/41412], Loss: 2.3610, Perplexity: 10.6019\n",
      "Epoch [2/25], Step [9900/41412], Loss: 2.2452, Perplexity: 9.44213\n",
      "Epoch [2/25], Step [10000/41412], Loss: 1.7658, Perplexity: 5.8462\n",
      "Epoch [2/25], Step [10100/41412], Loss: 1.7068, Perplexity: 5.51149\n",
      "Epoch [2/25], Step [10200/41412], Loss: 2.5162, Perplexity: 12.3812\n",
      "Epoch [2/25], Step [10300/41412], Loss: 2.1206, Perplexity: 8.336053\n",
      "Epoch [2/25], Step [10400/41412], Loss: 2.0421, Perplexity: 7.70661\n",
      "Epoch [2/25], Step [10500/41412], Loss: 2.3888, Perplexity: 10.9009\n",
      "Epoch [2/25], Step [10600/41412], Loss: 2.2514, Perplexity: 9.50071\n",
      "Epoch [2/25], Step [10700/41412], Loss: 2.2007, Perplexity: 9.03131\n",
      "Epoch [2/25], Step [10800/41412], Loss: 1.7906, Perplexity: 5.99330\n",
      "Epoch [2/25], Step [10900/41412], Loss: 1.8445, Perplexity: 6.32500\n",
      "Epoch [2/25], Step [11000/41412], Loss: 1.6916, Perplexity: 5.42843\n",
      "Epoch [2/25], Step [11100/41412], Loss: 2.4522, Perplexity: 11.6142\n",
      "Epoch [2/25], Step [11200/41412], Loss: 2.6079, Perplexity: 13.5707\n",
      "Epoch [2/25], Step [11300/41412], Loss: 2.3561, Perplexity: 10.5499\n",
      "Epoch [2/25], Step [11400/41412], Loss: 1.9349, Perplexity: 6.92339\n",
      "Epoch [2/25], Step [11500/41412], Loss: 2.2920, Perplexity: 9.89444\n",
      "Epoch [2/25], Step [11600/41412], Loss: 1.8373, Perplexity: 6.27959\n",
      "Epoch [2/25], Step [11700/41412], Loss: 2.5319, Perplexity: 12.5777\n",
      "Epoch [2/25], Step [11800/41412], Loss: 2.5158, Perplexity: 12.3767\n",
      "Epoch [2/25], Step [11900/41412], Loss: 1.9819, Perplexity: 7.25683\n",
      "Epoch [2/25], Step [12000/41412], Loss: 2.1473, Perplexity: 8.56183\n",
      "Epoch [2/25], Step [12100/41412], Loss: 1.9838, Perplexity: 7.27022\n",
      "Epoch [2/25], Step [12200/41412], Loss: 1.8525, Perplexity: 6.37585\n",
      "Epoch [2/25], Step [12300/41412], Loss: 1.8820, Perplexity: 6.56673\n",
      "Epoch [2/25], Step [12400/41412], Loss: 1.8080, Perplexity: 6.09837\n",
      "Epoch [2/25], Step [12500/41412], Loss: 2.0718, Perplexity: 7.93940\n",
      "Epoch [2/25], Step [12600/41412], Loss: 2.2902, Perplexity: 9.87707\n",
      "Epoch [2/25], Step [12700/41412], Loss: 2.8104, Perplexity: 16.6164\n",
      "Epoch [2/25], Step [12800/41412], Loss: 2.0774, Perplexity: 7.98396\n",
      "Epoch [2/25], Step [12900/41412], Loss: 1.9312, Perplexity: 6.89808\n",
      "Epoch [2/25], Step [13000/41412], Loss: 1.8538, Perplexity: 6.38389\n",
      "Epoch [2/25], Step [13100/41412], Loss: 1.7783, Perplexity: 5.91950\n",
      "Epoch [2/25], Step [13200/41412], Loss: 2.2991, Perplexity: 9.96536\n",
      "Epoch [2/25], Step [13300/41412], Loss: 2.2756, Perplexity: 9.73411\n",
      "Epoch [2/25], Step [13400/41412], Loss: 2.3188, Perplexity: 10.1630\n",
      "Epoch [2/25], Step [13500/41412], Loss: 2.1648, Perplexity: 8.71288\n",
      "Epoch [2/25], Step [13600/41412], Loss: 1.9563, Perplexity: 7.07280\n",
      "Epoch [2/25], Step [13700/41412], Loss: 2.2348, Perplexity: 9.34420\n",
      "Epoch [2/25], Step [13800/41412], Loss: 1.9611, Perplexity: 7.10683\n",
      "Epoch [2/25], Step [13900/41412], Loss: 1.5652, Perplexity: 4.78359\n",
      "Epoch [2/25], Step [14000/41412], Loss: 2.2005, Perplexity: 9.02932\n",
      "Epoch [2/25], Step [14100/41412], Loss: 2.0204, Perplexity: 7.54167\n",
      "Epoch [2/25], Step [14200/41412], Loss: 2.7340, Perplexity: 15.3945\n",
      "Epoch [2/25], Step [14300/41412], Loss: 2.1954, Perplexity: 8.98341\n",
      "Epoch [2/25], Step [14400/41412], Loss: 2.0435, Perplexity: 7.71798\n",
      "Epoch [2/25], Step [14500/41412], Loss: 1.8315, Perplexity: 6.24335\n",
      "Epoch [2/25], Step [14600/41412], Loss: 1.9432, Perplexity: 6.98119\n",
      "Epoch [2/25], Step [14700/41412], Loss: 2.1025, Perplexity: 8.18705\n",
      "Epoch [2/25], Step [14800/41412], Loss: 2.1167, Perplexity: 8.30363\n",
      "Epoch [2/25], Step [14900/41412], Loss: 1.9151, Perplexity: 6.78791\n",
      "Epoch [2/25], Step [15000/41412], Loss: 1.9648, Perplexity: 7.13365\n",
      "Epoch [2/25], Step [15100/41412], Loss: 2.1849, Perplexity: 8.88988\n",
      "Epoch [2/25], Step [15200/41412], Loss: 1.9737, Perplexity: 7.19738\n",
      "Epoch [2/25], Step [15300/41412], Loss: 1.9872, Perplexity: 7.29479\n",
      "Epoch [2/25], Step [15400/41412], Loss: 2.1729, Perplexity: 8.78398\n",
      "Epoch [2/25], Step [15500/41412], Loss: 1.9334, Perplexity: 6.91339\n",
      "Epoch [2/25], Step [15600/41412], Loss: 1.7048, Perplexity: 5.50046\n",
      "Epoch [2/25], Step [15700/41412], Loss: 2.4748, Perplexity: 11.8793\n",
      "Epoch [2/25], Step [15800/41412], Loss: 2.2093, Perplexity: 9.10902\n",
      "Epoch [2/25], Step [15900/41412], Loss: 2.2613, Perplexity: 9.59524\n",
      "Epoch [2/25], Step [16000/41412], Loss: 2.0100, Perplexity: 7.46309\n",
      "Epoch [2/25], Step [16100/41412], Loss: 3.2377, Perplexity: 25.4748\n",
      "Epoch [2/25], Step [16200/41412], Loss: 2.2648, Perplexity: 9.62936\n",
      "Epoch [2/25], Step [16300/41412], Loss: 2.1430, Perplexity: 8.52482\n",
      "Epoch [2/25], Step [16400/41412], Loss: 2.5231, Perplexity: 12.4671\n",
      "Epoch [2/25], Step [16500/41412], Loss: 2.2581, Perplexity: 9.56465\n",
      "Epoch [2/25], Step [16600/41412], Loss: 2.0216, Perplexity: 7.55045\n",
      "Epoch [2/25], Step [16700/41412], Loss: 2.3017, Perplexity: 9.99083\n",
      "Epoch [2/25], Step [16800/41412], Loss: 2.3933, Perplexity: 10.9493\n",
      "Epoch [2/25], Step [16900/41412], Loss: 1.9308, Perplexity: 6.89489\n",
      "Epoch [2/25], Step [17000/41412], Loss: 1.8016, Perplexity: 6.05939\n",
      "Epoch [2/25], Step [17100/41412], Loss: 1.8564, Perplexity: 6.40097\n",
      "Epoch [2/25], Step [17200/41412], Loss: 1.9129, Perplexity: 6.77309\n",
      "Epoch [2/25], Step [17300/41412], Loss: 1.7062, Perplexity: 5.50795\n",
      "Epoch [2/25], Step [17400/41412], Loss: 2.5740, Perplexity: 13.1177\n",
      "Epoch [2/25], Step [17500/41412], Loss: 2.0935, Perplexity: 8.11325\n",
      "Epoch [2/25], Step [17600/41412], Loss: 2.3755, Perplexity: 10.7563\n",
      "Epoch [2/25], Step [17700/41412], Loss: 2.1068, Perplexity: 8.22169\n",
      "Epoch [2/25], Step [17800/41412], Loss: 2.0190, Perplexity: 7.53075\n",
      "Epoch [2/25], Step [17900/41412], Loss: 1.8379, Perplexity: 6.28333\n",
      "Epoch [2/25], Step [18000/41412], Loss: 2.3984, Perplexity: 11.0057\n",
      "Epoch [2/25], Step [18100/41412], Loss: 2.1715, Perplexity: 8.77110\n",
      "Epoch [2/25], Step [18200/41412], Loss: 2.3302, Perplexity: 10.2802\n",
      "Epoch [2/25], Step [18300/41412], Loss: 1.9393, Perplexity: 6.95412\n",
      "Epoch [2/25], Step [18400/41412], Loss: 2.0783, Perplexity: 7.99105\n",
      "Epoch [2/25], Step [18500/41412], Loss: 1.9057, Perplexity: 6.72407\n",
      "Epoch [2/25], Step [18600/41412], Loss: 2.3046, Perplexity: 10.0207\n",
      "Epoch [2/25], Step [18700/41412], Loss: 2.4377, Perplexity: 11.4470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Step [18800/41412], Loss: 2.0579, Perplexity: 7.82972\n",
      "Epoch [2/25], Step [18900/41412], Loss: 2.7128, Perplexity: 15.0714\n",
      "Epoch [2/25], Step [19000/41412], Loss: 2.0114, Perplexity: 7.47408\n",
      "Epoch [2/25], Step [19100/41412], Loss: 1.5080, Perplexity: 4.51779\n",
      "Epoch [2/25], Step [19200/41412], Loss: 1.8150, Perplexity: 6.14146\n",
      "Epoch [2/25], Step [19300/41412], Loss: 2.0956, Perplexity: 8.13021\n",
      "Epoch [2/25], Step [19400/41412], Loss: 1.9458, Perplexity: 6.99923\n",
      "Epoch [2/25], Step [19500/41412], Loss: 1.6256, Perplexity: 5.08147\n",
      "Epoch [2/25], Step [19600/41412], Loss: 1.8927, Perplexity: 6.63741\n",
      "Epoch [2/25], Step [19700/41412], Loss: 2.5966, Perplexity: 13.4181\n",
      "Epoch [2/25], Step [19800/41412], Loss: 2.3014, Perplexity: 9.98784\n",
      "Epoch [2/25], Step [19900/41412], Loss: 2.1958, Perplexity: 8.98737\n",
      "Epoch [2/25], Step [20000/41412], Loss: 2.1339, Perplexity: 8.44762\n",
      "Epoch [2/25], Step [20100/41412], Loss: 1.5842, Perplexity: 4.87551\n",
      "Epoch [2/25], Step [20200/41412], Loss: 2.3842, Perplexity: 10.8502\n",
      "Epoch [2/25], Step [20300/41412], Loss: 2.1636, Perplexity: 8.70274\n",
      "Epoch [2/25], Step [20400/41412], Loss: 2.9427, Perplexity: 18.9678\n",
      "Epoch [2/25], Step [20500/41412], Loss: 2.2518, Perplexity: 9.50463\n",
      "Epoch [2/25], Step [20600/41412], Loss: 2.1904, Perplexity: 8.93841\n",
      "Epoch [2/25], Step [20700/41412], Loss: 2.1407, Perplexity: 8.50522\n",
      "Epoch [2/25], Step [20800/41412], Loss: 1.7802, Perplexity: 5.93121\n",
      "Epoch [2/25], Step [20900/41412], Loss: 2.5359, Perplexity: 12.6277\n",
      "Epoch [2/25], Step [21000/41412], Loss: 1.8953, Perplexity: 6.65433\n",
      "Epoch [2/25], Step [21100/41412], Loss: 2.3199, Perplexity: 10.1750\n",
      "Epoch [2/25], Step [21200/41412], Loss: 1.9701, Perplexity: 7.17124\n",
      "Epoch [2/25], Step [21300/41412], Loss: 2.1091, Perplexity: 8.24090\n",
      "Epoch [2/25], Step [21400/41412], Loss: 2.0498, Perplexity: 7.76623\n",
      "Epoch [2/25], Step [21500/41412], Loss: 1.8558, Perplexity: 6.39693\n",
      "Epoch [2/25], Step [21600/41412], Loss: 2.0898, Perplexity: 8.08342\n",
      "Epoch [2/25], Step [21700/41412], Loss: 1.9915, Perplexity: 7.32655\n",
      "Epoch [2/25], Step [21800/41412], Loss: 2.1844, Perplexity: 8.88578\n",
      "Epoch [2/25], Step [21900/41412], Loss: 2.6239, Perplexity: 13.7890\n",
      "Epoch [2/25], Step [22000/41412], Loss: 1.9424, Perplexity: 6.97589\n",
      "Epoch [2/25], Step [22100/41412], Loss: 2.0660, Perplexity: 7.89329\n",
      "Epoch [2/25], Step [22200/41412], Loss: 2.0586, Perplexity: 7.83485\n",
      "Epoch [2/25], Step [22300/41412], Loss: 2.2245, Perplexity: 9.24926\n",
      "Epoch [2/25], Step [22400/41412], Loss: 2.1384, Perplexity: 8.48610\n",
      "Epoch [2/25], Step [22500/41412], Loss: 2.3122, Perplexity: 10.0963\n",
      "Epoch [2/25], Step [22600/41412], Loss: 1.9204, Perplexity: 6.82377\n",
      "Epoch [2/25], Step [22700/41412], Loss: 2.2159, Perplexity: 9.16944\n",
      "Epoch [2/25], Step [22800/41412], Loss: 2.6612, Perplexity: 14.3133\n",
      "Epoch [2/25], Step [22900/41412], Loss: 2.0446, Perplexity: 7.72606\n",
      "Epoch [2/25], Step [23000/41412], Loss: 2.4470, Perplexity: 11.5541\n",
      "Epoch [2/25], Step [23100/41412], Loss: 1.9858, Perplexity: 7.28451\n",
      "Epoch [2/25], Step [23200/41412], Loss: 1.7506, Perplexity: 5.75797\n",
      "Epoch [2/25], Step [23300/41412], Loss: 1.8295, Perplexity: 6.23081\n",
      "Epoch [2/25], Step [23400/41412], Loss: 2.4956, Perplexity: 12.1294\n",
      "Epoch [2/25], Step [23500/41412], Loss: 2.2090, Perplexity: 9.10685\n",
      "Epoch [2/25], Step [23600/41412], Loss: 1.4242, Perplexity: 4.15446\n",
      "Epoch [2/25], Step [23700/41412], Loss: 1.7070, Perplexity: 5.51269\n",
      "Epoch [2/25], Step [23800/41412], Loss: 1.7914, Perplexity: 5.99794\n",
      "Epoch [2/25], Step [23900/41412], Loss: 2.8400, Perplexity: 17.1149\n",
      "Epoch [2/25], Step [24000/41412], Loss: 2.1706, Perplexity: 8.76312\n",
      "Epoch [2/25], Step [24100/41412], Loss: 1.9319, Perplexity: 6.90260\n",
      "Epoch [2/25], Step [24200/41412], Loss: 1.7355, Perplexity: 5.67203\n",
      "Epoch [2/25], Step [24300/41412], Loss: 1.8978, Perplexity: 6.67098\n",
      "Epoch [2/25], Step [24400/41412], Loss: 2.5853, Perplexity: 13.2674\n",
      "Epoch [2/25], Step [24500/41412], Loss: 1.7134, Perplexity: 5.54793\n",
      "Epoch [2/25], Step [24600/41412], Loss: 1.7642, Perplexity: 5.83716\n",
      "Epoch [2/25], Step [24700/41412], Loss: 2.2114, Perplexity: 9.12868\n",
      "Epoch [2/25], Step [24800/41412], Loss: 2.1635, Perplexity: 8.70119\n",
      "Epoch [2/25], Step [24900/41412], Loss: 2.0817, Perplexity: 8.01776\n",
      "Epoch [2/25], Step [25000/41412], Loss: 2.1120, Perplexity: 8.26507\n",
      "Epoch [2/25], Step [25100/41412], Loss: 2.3546, Perplexity: 10.5339\n",
      "Epoch [2/25], Step [25200/41412], Loss: 2.5711, Perplexity: 13.0808\n",
      "Epoch [2/25], Step [25300/41412], Loss: 1.8628, Perplexity: 6.441589\n",
      "Epoch [2/25], Step [25400/41412], Loss: 2.0792, Perplexity: 7.99785\n",
      "Epoch [2/25], Step [25500/41412], Loss: 1.6580, Perplexity: 5.24904\n",
      "Epoch [2/25], Step [25600/41412], Loss: 2.5036, Perplexity: 12.22696\n",
      "Epoch [2/25], Step [25700/41412], Loss: 1.6715, Perplexity: 5.31999\n",
      "Epoch [2/25], Step [25800/41412], Loss: 1.8646, Perplexity: 6.45319\n",
      "Epoch [2/25], Step [25900/41412], Loss: 2.0031, Perplexity: 7.41239\n",
      "Epoch [2/25], Step [26000/41412], Loss: 1.8003, Perplexity: 6.05134\n",
      "Epoch [2/25], Step [26100/41412], Loss: 2.3282, Perplexity: 10.2592\n",
      "Epoch [2/25], Step [26200/41412], Loss: 2.0663, Perplexity: 7.89595\n",
      "Epoch [2/25], Step [26300/41412], Loss: 2.4086, Perplexity: 11.1187\n",
      "Epoch [2/25], Step [26400/41412], Loss: 2.1307, Perplexity: 8.42058\n",
      "Epoch [2/25], Step [26500/41412], Loss: 2.5344, Perplexity: 12.6093\n",
      "Epoch [2/25], Step [26600/41412], Loss: 2.5029, Perplexity: 12.2182\n",
      "Epoch [2/25], Step [26700/41412], Loss: 1.7059, Perplexity: 5.50658\n",
      "Epoch [2/25], Step [26800/41412], Loss: 1.8488, Perplexity: 6.35255\n",
      "Epoch [2/25], Step [26900/41412], Loss: 1.9269, Perplexity: 6.86801\n",
      "Epoch [2/25], Step [27000/41412], Loss: 2.2142, Perplexity: 9.15405\n",
      "Epoch [2/25], Step [27100/41412], Loss: 2.5289, Perplexity: 12.5395\n",
      "Epoch [2/25], Step [27200/41412], Loss: 2.8788, Perplexity: 17.7928\n",
      "Epoch [2/25], Step [27300/41412], Loss: 1.9876, Perplexity: 7.29828\n",
      "Epoch [2/25], Step [27400/41412], Loss: 1.7648, Perplexity: 5.84065\n",
      "Epoch [2/25], Step [27500/41412], Loss: 2.2848, Perplexity: 9.82373\n",
      "Epoch [2/25], Step [27600/41412], Loss: 2.5090, Perplexity: 12.2925\n",
      "Epoch [2/25], Step [27700/41412], Loss: 2.0206, Perplexity: 7.542607\n",
      "Epoch [2/25], Step [27800/41412], Loss: 1.4590, Perplexity: 4.30178\n",
      "Epoch [2/25], Step [27900/41412], Loss: 2.0254, Perplexity: 7.57909\n",
      "Epoch [2/25], Step [28000/41412], Loss: 2.3020, Perplexity: 9.99448\n",
      "Epoch [2/25], Step [28100/41412], Loss: 2.1420, Perplexity: 8.51647\n",
      "Epoch [2/25], Step [28200/41412], Loss: 1.9866, Perplexity: 7.29068\n",
      "Epoch [2/25], Step [28300/41412], Loss: 2.1560, Perplexity: 8.63689\n",
      "Epoch [2/25], Step [28400/41412], Loss: 2.0410, Perplexity: 7.69856\n",
      "Epoch [2/25], Step [28500/41412], Loss: 2.2988, Perplexity: 9.96261\n",
      "Epoch [2/25], Step [28600/41412], Loss: 2.4101, Perplexity: 11.1346\n",
      "Epoch [2/25], Step [28700/41412], Loss: 2.3976, Perplexity: 10.9964\n",
      "Epoch [2/25], Step [28800/41412], Loss: 2.0730, Perplexity: 7.94848\n",
      "Epoch [2/25], Step [28900/41412], Loss: 2.2861, Perplexity: 9.83705\n",
      "Epoch [2/25], Step [29000/41412], Loss: 2.2555, Perplexity: 9.539768\n",
      "Epoch [2/25], Step [29100/41412], Loss: 1.8795, Perplexity: 6.55034\n",
      "Epoch [2/25], Step [29200/41412], Loss: 2.0308, Perplexity: 7.62041\n",
      "Epoch [2/25], Step [29300/41412], Loss: 2.1660, Perplexity: 8.72378\n",
      "Epoch [2/25], Step [29400/41412], Loss: 1.6504, Perplexity: 5.20891\n",
      "Epoch [2/25], Step [29500/41412], Loss: 1.8194, Perplexity: 6.16843\n",
      "Epoch [2/25], Step [29600/41412], Loss: 1.8395, Perplexity: 6.29355\n",
      "Epoch [2/25], Step [29700/41412], Loss: 2.0508, Perplexity: 7.77383\n",
      "Epoch [2/25], Step [29800/41412], Loss: 2.0854, Perplexity: 8.04770\n",
      "Epoch [2/25], Step [29900/41412], Loss: 2.2609, Perplexity: 9.59214\n",
      "Epoch [2/25], Step [30000/41412], Loss: 2.1657, Perplexity: 8.72052\n",
      "Epoch [2/25], Step [30100/41412], Loss: 1.6766, Perplexity: 5.34756\n",
      "Epoch [2/25], Step [30200/41412], Loss: 1.7978, Perplexity: 6.03654\n",
      "Epoch [2/25], Step [30300/41412], Loss: 2.1175, Perplexity: 8.31053\n",
      "Epoch [2/25], Step [30400/41412], Loss: 2.2393, Perplexity: 9.38682\n",
      "Epoch [2/25], Step [30500/41412], Loss: 1.5859, Perplexity: 4.88354\n",
      "Epoch [2/25], Step [30600/41412], Loss: 2.0126, Perplexity: 7.48273\n",
      "Epoch [2/25], Step [30700/41412], Loss: 2.0295, Perplexity: 7.61069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Step [30800/41412], Loss: 1.8880, Perplexity: 6.60614\n",
      "Epoch [2/25], Step [30900/41412], Loss: 2.3220, Perplexity: 10.1958\n",
      "Epoch [2/25], Step [31000/41412], Loss: 2.2793, Perplexity: 9.76948\n",
      "Epoch [2/25], Step [31100/41412], Loss: 1.5858, Perplexity: 4.88322\n",
      "Epoch [2/25], Step [31200/41412], Loss: 1.9159, Perplexity: 6.79326\n",
      "Epoch [2/25], Step [31300/41412], Loss: 1.5127, Perplexity: 4.53929\n",
      "Epoch [2/25], Step [31400/41412], Loss: 2.1334, Perplexity: 8.44310\n",
      "Epoch [2/25], Step [31500/41412], Loss: 1.7872, Perplexity: 5.97285\n",
      "Epoch [2/25], Step [31600/41412], Loss: 2.2166, Perplexity: 9.17641\n",
      "Epoch [2/25], Step [31700/41412], Loss: 2.2080, Perplexity: 9.09798\n",
      "Epoch [2/25], Step [31800/41412], Loss: 2.1789, Perplexity: 8.83636\n",
      "Epoch [2/25], Step [31900/41412], Loss: 2.2201, Perplexity: 9.20806\n",
      "Epoch [2/25], Step [32000/41412], Loss: 1.8497, Perplexity: 6.35809\n",
      "Epoch [2/25], Step [32100/41412], Loss: 2.1945, Perplexity: 8.97586\n",
      "Epoch [2/25], Step [32200/41412], Loss: 2.3686, Perplexity: 10.6826\n",
      "Epoch [2/25], Step [32300/41412], Loss: 1.8705, Perplexity: 6.49192\n",
      "Epoch [2/25], Step [32400/41412], Loss: 1.7403, Perplexity: 5.69890\n",
      "Epoch [2/25], Step [32500/41412], Loss: 2.3155, Perplexity: 10.1300\n",
      "Epoch [2/25], Step [32600/41412], Loss: 1.9240, Perplexity: 6.84864\n",
      "Epoch [2/25], Step [32700/41412], Loss: 2.8989, Perplexity: 18.1548\n",
      "Epoch [2/25], Step [32800/41412], Loss: 2.1663, Perplexity: 8.72555\n",
      "Epoch [2/25], Step [32900/41412], Loss: 2.1970, Perplexity: 8.99812\n",
      "Epoch [2/25], Step [33000/41412], Loss: 2.2187, Perplexity: 9.19531\n",
      "Epoch [2/25], Step [33100/41412], Loss: 1.9857, Perplexity: 7.28426\n",
      "Epoch [2/25], Step [33200/41412], Loss: 2.6374, Perplexity: 13.9763\n",
      "Epoch [2/25], Step [33300/41412], Loss: 2.0042, Perplexity: 7.42014\n",
      "Epoch [2/25], Step [33400/41412], Loss: 2.0307, Perplexity: 7.61952\n",
      "Epoch [2/25], Step [33500/41412], Loss: 1.8312, Perplexity: 6.24143\n",
      "Epoch [2/25], Step [33600/41412], Loss: 2.1816, Perplexity: 8.86063\n",
      "Epoch [2/25], Step [33700/41412], Loss: 1.9770, Perplexity: 7.22089\n",
      "Epoch [2/25], Step [33800/41412], Loss: 1.9890, Perplexity: 7.30793\n",
      "Epoch [2/25], Step [33900/41412], Loss: 2.0267, Perplexity: 7.58922\n",
      "Epoch [2/25], Step [34000/41412], Loss: 1.8001, Perplexity: 6.05005\n",
      "Epoch [2/25], Step [34100/41412], Loss: 1.9666, Perplexity: 7.14663\n",
      "Epoch [2/25], Step [34200/41412], Loss: 2.2254, Perplexity: 9.25718\n",
      "Epoch [2/25], Step [34300/41412], Loss: 2.6498, Perplexity: 14.1512\n",
      "Epoch [2/25], Step [34400/41412], Loss: 2.1092, Perplexity: 8.24185\n",
      "Epoch [2/25], Step [34500/41412], Loss: 2.3257, Perplexity: 10.2334\n",
      "Epoch [2/25], Step [34600/41412], Loss: 1.8259, Perplexity: 6.20822\n",
      "Epoch [2/25], Step [34700/41412], Loss: 1.8566, Perplexity: 6.40184\n",
      "Epoch [2/25], Step [34800/41412], Loss: 2.2881, Perplexity: 9.85653\n",
      "Epoch [2/25], Step [34900/41412], Loss: 2.1237, Perplexity: 8.36204\n",
      "Epoch [2/25], Step [35000/41412], Loss: 2.5013, Perplexity: 12.1980\n",
      "Epoch [2/25], Step [35100/41412], Loss: 2.5734, Perplexity: 13.1105\n",
      "Epoch [2/25], Step [35200/41412], Loss: 2.0170, Perplexity: 7.51556\n",
      "Epoch [2/25], Step [35300/41412], Loss: 1.7489, Perplexity: 5.74823\n",
      "Epoch [2/25], Step [35400/41412], Loss: 1.4366, Perplexity: 4.20652\n",
      "Epoch [2/25], Step [35500/41412], Loss: 2.7885, Perplexity: 16.2574\n",
      "Epoch [2/25], Step [35600/41412], Loss: 1.5214, Perplexity: 4.57864\n",
      "Epoch [2/25], Step [35700/41412], Loss: 2.5821, Perplexity: 13.2246\n",
      "Epoch [2/25], Step [35800/41412], Loss: 2.0629, Perplexity: 7.86880\n",
      "Epoch [2/25], Step [35900/41412], Loss: 1.6251, Perplexity: 5.07907\n",
      "Epoch [2/25], Step [36000/41412], Loss: 2.2294, Perplexity: 9.29381\n",
      "Epoch [2/25], Step [36100/41412], Loss: 1.7284, Perplexity: 5.63151\n",
      "Epoch [2/25], Step [36200/41412], Loss: 1.7975, Perplexity: 6.03446\n",
      "Epoch [2/25], Step [36300/41412], Loss: 2.1874, Perplexity: 8.91208\n",
      "Epoch [2/25], Step [36400/41412], Loss: 1.9709, Perplexity: 7.17695\n",
      "Epoch [2/25], Step [36500/41412], Loss: 1.8880, Perplexity: 6.60643\n",
      "Epoch [2/25], Step [36600/41412], Loss: 2.3858, Perplexity: 10.8676\n",
      "Epoch [2/25], Step [36700/41412], Loss: 2.3551, Perplexity: 10.5387\n",
      "Epoch [2/25], Step [36800/41412], Loss: 1.9931, Perplexity: 7.33835\n",
      "Epoch [2/25], Step [36900/41412], Loss: 2.4231, Perplexity: 11.2812\n",
      "Epoch [2/25], Step [37000/41412], Loss: 2.5478, Perplexity: 12.7794\n",
      "Epoch [2/25], Step [37100/41412], Loss: 2.3921, Perplexity: 10.9364\n",
      "Epoch [2/25], Step [37200/41412], Loss: 2.3470, Perplexity: 10.4538\n",
      "Epoch [2/25], Step [37300/41412], Loss: 2.1452, Perplexity: 8.54414\n",
      "Epoch [2/25], Step [37400/41412], Loss: 1.7495, Perplexity: 5.75170\n",
      "Epoch [2/25], Step [37500/41412], Loss: 2.0544, Perplexity: 7.80254\n",
      "Epoch [2/25], Step [37600/41412], Loss: 2.0313, Perplexity: 7.62365\n",
      "Epoch [2/25], Step [37700/41412], Loss: 2.2016, Perplexity: 9.03905\n",
      "Epoch [2/25], Step [37800/41412], Loss: 1.9491, Perplexity: 7.02239\n",
      "Epoch [2/25], Step [37900/41412], Loss: 2.2081, Perplexity: 9.09872\n",
      "Epoch [2/25], Step [38000/41412], Loss: 1.6055, Perplexity: 4.98053\n",
      "Epoch [2/25], Step [38100/41412], Loss: 2.7250, Perplexity: 15.2564\n",
      "Epoch [2/25], Step [38200/41412], Loss: 2.2663, Perplexity: 9.64380\n",
      "Epoch [2/25], Step [38300/41412], Loss: 1.7339, Perplexity: 5.66257\n",
      "Epoch [2/25], Step [38400/41412], Loss: 1.9083, Perplexity: 6.74145\n",
      "Epoch [2/25], Step [38500/41412], Loss: 1.8869, Perplexity: 6.59920\n",
      "Epoch [2/25], Step [38600/41412], Loss: 2.4197, Perplexity: 11.2426\n",
      "Epoch [2/25], Step [38700/41412], Loss: 2.1107, Perplexity: 8.25361\n",
      "Epoch [2/25], Step [38800/41412], Loss: 2.3640, Perplexity: 10.6330\n",
      "Epoch [2/25], Step [38900/41412], Loss: 2.5501, Perplexity: 12.8089\n",
      "Epoch [2/25], Step [39000/41412], Loss: 1.7220, Perplexity: 5.59597\n",
      "Epoch [2/25], Step [39100/41412], Loss: 2.3819, Perplexity: 10.8252\n",
      "Epoch [2/25], Step [39200/41412], Loss: 1.5868, Perplexity: 4.88824\n",
      "Epoch [2/25], Step [39300/41412], Loss: 2.5104, Perplexity: 12.3093\n",
      "Epoch [2/25], Step [39400/41412], Loss: 1.5775, Perplexity: 4.84296\n",
      "Epoch [2/25], Step [39500/41412], Loss: 2.2601, Perplexity: 9.58369\n",
      "Epoch [2/25], Step [39600/41412], Loss: 2.5389, Perplexity: 12.6653\n",
      "Epoch [2/25], Step [39700/41412], Loss: 1.7851, Perplexity: 5.96039\n",
      "Epoch [2/25], Step [39800/41412], Loss: 2.4146, Perplexity: 11.1857\n",
      "Epoch [2/25], Step [39900/41412], Loss: 1.8814, Perplexity: 6.56271\n",
      "Epoch [2/25], Step [40000/41412], Loss: 2.4224, Perplexity: 11.2729\n",
      "Epoch [2/25], Step [40100/41412], Loss: 2.0353, Perplexity: 7.65488\n",
      "Epoch [2/25], Step [40200/41412], Loss: 2.1518, Perplexity: 8.60035\n",
      "Epoch [2/25], Step [40300/41412], Loss: 1.8380, Perplexity: 6.28401\n",
      "Epoch [2/25], Step [40400/41412], Loss: 2.0027, Perplexity: 7.40937\n",
      "Epoch [2/25], Step [40500/41412], Loss: 1.6764, Perplexity: 5.34623\n",
      "Epoch [2/25], Step [40600/41412], Loss: 2.1662, Perplexity: 8.72541\n",
      "Epoch [2/25], Step [40700/41412], Loss: 2.4048, Perplexity: 11.0763\n",
      "Epoch [2/25], Step [40800/41412], Loss: 2.1877, Perplexity: 8.91435\n",
      "Epoch [2/25], Step [40900/41412], Loss: 2.1198, Perplexity: 8.32938\n",
      "Epoch [2/25], Step [41000/41412], Loss: 1.7033, Perplexity: 5.49185\n",
      "Epoch [2/25], Step [41100/41412], Loss: 1.6807, Perplexity: 5.36918\n",
      "Epoch [2/25], Step [41200/41412], Loss: 2.1863, Perplexity: 8.90253\n",
      "Epoch [2/25], Step [41300/41412], Loss: 2.0993, Perplexity: 8.16043\n",
      "Epoch [2/25], Step [41400/41412], Loss: 2.7154, Perplexity: 15.1113\n",
      "Epoch [3/25], Step [100/41412], Loss: 2.1213, Perplexity: 8.3419759\n",
      "Epoch [3/25], Step [200/41412], Loss: 2.1158, Perplexity: 8.29645\n",
      "Epoch [3/25], Step [300/41412], Loss: 1.9553, Perplexity: 7.06642\n",
      "Epoch [3/25], Step [400/41412], Loss: 2.2004, Perplexity: 9.02876\n",
      "Epoch [3/25], Step [500/41412], Loss: 1.8436, Perplexity: 6.31927\n",
      "Epoch [3/25], Step [600/41412], Loss: 1.8284, Perplexity: 6.22392\n",
      "Epoch [3/25], Step [700/41412], Loss: 1.8080, Perplexity: 6.09835\n",
      "Epoch [3/25], Step [800/41412], Loss: 2.2276, Perplexity: 9.27710\n",
      "Epoch [3/25], Step [900/41412], Loss: 2.1413, Perplexity: 8.51030\n",
      "Epoch [3/25], Step [1000/41412], Loss: 1.7236, Perplexity: 5.6049\n",
      "Epoch [3/25], Step [1100/41412], Loss: 1.8193, Perplexity: 6.16738\n",
      "Epoch [3/25], Step [1200/41412], Loss: 1.9379, Perplexity: 6.94436\n",
      "Epoch [3/25], Step [1300/41412], Loss: 1.9698, Perplexity: 7.16935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Step [1400/41412], Loss: 2.1421, Perplexity: 8.51768\n",
      "Epoch [3/25], Step [1500/41412], Loss: 2.4416, Perplexity: 11.4918\n",
      "Epoch [3/25], Step [1600/41412], Loss: 1.6957, Perplexity: 5.45078\n",
      "Epoch [3/25], Step [1700/41412], Loss: 2.0754, Perplexity: 7.96777\n",
      "Epoch [3/25], Step [1800/41412], Loss: 1.9974, Perplexity: 7.37010\n",
      "Epoch [3/25], Step [1900/41412], Loss: 2.1672, Perplexity: 8.73385\n",
      "Epoch [3/25], Step [2000/41412], Loss: 2.9432, Perplexity: 18.9765\n",
      "Epoch [3/25], Step [2100/41412], Loss: 2.3834, Perplexity: 10.8416\n",
      "Epoch [3/25], Step [2200/41412], Loss: 2.1123, Perplexity: 8.26758\n",
      "Epoch [3/25], Step [2300/41412], Loss: 2.0312, Perplexity: 7.62357\n",
      "Epoch [3/25], Step [2400/41412], Loss: 1.9827, Perplexity: 7.26231\n",
      "Epoch [3/25], Step [2500/41412], Loss: 2.3494, Perplexity: 10.4789\n",
      "Epoch [3/25], Step [2600/41412], Loss: 2.2748, Perplexity: 9.725734\n",
      "Epoch [3/25], Step [2700/41412], Loss: 2.0141, Perplexity: 7.49417\n",
      "Epoch [3/25], Step [2800/41412], Loss: 2.1233, Perplexity: 8.35873\n",
      "Epoch [3/25], Step [2900/41412], Loss: 2.0991, Perplexity: 8.15902\n",
      "Epoch [3/25], Step [3000/41412], Loss: 2.3872, Perplexity: 10.8833\n",
      "Epoch [3/25], Step [3100/41412], Loss: 2.2802, Perplexity: 9.77841\n",
      "Epoch [3/25], Step [3200/41412], Loss: 1.6745, Perplexity: 5.33604\n",
      "Epoch [3/25], Step [3300/41412], Loss: 2.6618, Perplexity: 14.3223\n",
      "Epoch [3/25], Step [3400/41412], Loss: 2.5874, Perplexity: 13.2952\n",
      "Epoch [3/25], Step [3500/41412], Loss: 2.5477, Perplexity: 12.7783\n",
      "Epoch [3/25], Step [3600/41412], Loss: 1.9625, Perplexity: 7.11735\n",
      "Epoch [3/25], Step [3700/41412], Loss: 2.1161, Perplexity: 8.29833\n",
      "Epoch [3/25], Step [3800/41412], Loss: 2.2146, Perplexity: 9.15762\n",
      "Epoch [3/25], Step [3900/41412], Loss: 1.6937, Perplexity: 5.43941\n",
      "Epoch [3/25], Step [4000/41412], Loss: 2.0409, Perplexity: 7.69767\n",
      "Epoch [3/25], Step [4100/41412], Loss: 2.4828, Perplexity: 11.9751\n",
      "Epoch [3/25], Step [4200/41412], Loss: 1.7079, Perplexity: 5.51721\n",
      "Epoch [3/25], Step [4300/41412], Loss: 2.6961, Perplexity: 14.8214\n",
      "Epoch [3/25], Step [4400/41412], Loss: 1.3953, Perplexity: 4.03648\n",
      "Epoch [3/25], Step [4500/41412], Loss: 1.8542, Perplexity: 6.38644\n",
      "Epoch [3/25], Step [4600/41412], Loss: 1.6526, Perplexity: 5.22048\n",
      "Epoch [3/25], Step [4700/41412], Loss: 2.1616, Perplexity: 8.68533\n",
      "Epoch [3/25], Step [4800/41412], Loss: 2.2317, Perplexity: 9.31583\n",
      "Epoch [3/25], Step [4900/41412], Loss: 2.4258, Perplexity: 11.31189\n",
      "Epoch [3/25], Step [5000/41412], Loss: 1.9534, Perplexity: 7.05308\n",
      "Epoch [3/25], Step [5100/41412], Loss: 2.3284, Perplexity: 10.2616\n",
      "Epoch [3/25], Step [5200/41412], Loss: 1.7379, Perplexity: 5.68524\n",
      "Epoch [3/25], Step [5300/41412], Loss: 2.1470, Perplexity: 8.55936\n",
      "Epoch [3/25], Step [5400/41412], Loss: 1.6539, Perplexity: 5.22722\n",
      "Epoch [3/25], Step [5500/41412], Loss: 1.7138, Perplexity: 5.55011\n",
      "Epoch [3/25], Step [5600/41412], Loss: 2.1981, Perplexity: 9.00775\n",
      "Epoch [3/25], Step [5700/41412], Loss: 1.9279, Perplexity: 6.87472\n",
      "Epoch [3/25], Step [5800/41412], Loss: 2.8446, Perplexity: 17.1947\n",
      "Epoch [3/25], Step [5900/41412], Loss: 2.0547, Perplexity: 7.80478\n",
      "Epoch [3/25], Step [6000/41412], Loss: 1.9037, Perplexity: 6.71096\n",
      "Epoch [3/25], Step [6100/41412], Loss: 2.6396, Perplexity: 14.0072\n",
      "Epoch [3/25], Step [6200/41412], Loss: 2.1798, Perplexity: 8.844664\n",
      "Epoch [3/25], Step [6300/41412], Loss: 1.8387, Perplexity: 6.28829\n",
      "Epoch [3/25], Step [6400/41412], Loss: 1.8456, Perplexity: 6.33221\n",
      "Epoch [3/25], Step [6500/41412], Loss: 1.8673, Perplexity: 6.47106\n",
      "Epoch [3/25], Step [6600/41412], Loss: 2.0306, Perplexity: 7.61871\n",
      "Epoch [3/25], Step [6700/41412], Loss: 1.5801, Perplexity: 4.85563\n",
      "Epoch [3/25], Step [6800/41412], Loss: 1.9368, Perplexity: 6.93659\n",
      "Epoch [3/25], Step [6900/41412], Loss: 2.0555, Perplexity: 7.81110\n",
      "Epoch [3/25], Step [7000/41412], Loss: 2.0642, Perplexity: 7.87911\n",
      "Epoch [3/25], Step [7100/41412], Loss: 2.2754, Perplexity: 9.73195\n",
      "Epoch [3/25], Step [7200/41412], Loss: 3.0977, Perplexity: 22.1477\n",
      "Epoch [3/25], Step [7300/41412], Loss: 1.7059, Perplexity: 5.50647\n",
      "Epoch [3/25], Step [7400/41412], Loss: 2.2205, Perplexity: 9.21194\n",
      "Epoch [3/25], Step [7500/41412], Loss: 2.0559, Perplexity: 7.81423\n",
      "Epoch [3/25], Step [7600/41412], Loss: 2.1945, Perplexity: 8.97520\n",
      "Epoch [3/25], Step [7700/41412], Loss: 2.2152, Perplexity: 9.16375\n",
      "Epoch [3/25], Step [7800/41412], Loss: 1.6309, Perplexity: 5.10838\n",
      "Epoch [3/25], Step [7900/41412], Loss: 2.0412, Perplexity: 7.69996\n",
      "Epoch [3/25], Step [8000/41412], Loss: 1.7076, Perplexity: 5.51543\n",
      "Epoch [3/25], Step [8100/41412], Loss: 1.6037, Perplexity: 4.97164\n",
      "Epoch [3/25], Step [8200/41412], Loss: 2.4085, Perplexity: 11.1169\n",
      "Epoch [3/25], Step [8300/41412], Loss: 1.9027, Perplexity: 6.70385\n",
      "Epoch [3/25], Step [8400/41412], Loss: 1.8733, Perplexity: 6.51009\n",
      "Epoch [3/25], Step [8500/41412], Loss: 2.6148, Perplexity: 13.6638\n",
      "Epoch [3/25], Step [8600/41412], Loss: 1.9736, Perplexity: 7.19646\n",
      "Epoch [3/25], Step [8700/41412], Loss: 1.7553, Perplexity: 5.78535\n",
      "Epoch [3/25], Step [8800/41412], Loss: 2.9080, Perplexity: 18.3198\n",
      "Epoch [3/25], Step [8900/41412], Loss: 2.3423, Perplexity: 10.40489\n",
      "Epoch [3/25], Step [9000/41412], Loss: 1.7413, Perplexity: 5.70461\n",
      "Epoch [3/25], Step [9100/41412], Loss: 1.4571, Perplexity: 4.29371\n",
      "Epoch [3/25], Step [9200/41412], Loss: 2.0577, Perplexity: 7.82777\n",
      "Epoch [3/25], Step [9300/41412], Loss: 2.1629, Perplexity: 8.69651\n",
      "Epoch [3/25], Step [9400/41412], Loss: 2.0376, Perplexity: 7.67243\n",
      "Epoch [3/25], Step [9500/41412], Loss: 2.0289, Perplexity: 7.60555\n",
      "Epoch [3/25], Step [9600/41412], Loss: 2.5176, Perplexity: 12.3991\n",
      "Epoch [3/25], Step [9700/41412], Loss: 2.3993, Perplexity: 11.0157\n",
      "Epoch [3/25], Step [9800/41412], Loss: 1.6307, Perplexity: 5.10754\n",
      "Epoch [3/25], Step [9900/41412], Loss: 2.3677, Perplexity: 10.6733\n",
      "Epoch [3/25], Step [10000/41412], Loss: 2.9827, Perplexity: 19.7415\n",
      "Epoch [3/25], Step [10100/41412], Loss: 2.1529, Perplexity: 8.60947\n",
      "Epoch [3/25], Step [10200/41412], Loss: 1.9430, Perplexity: 6.98002\n",
      "Epoch [3/25], Step [10300/41412], Loss: 1.8194, Perplexity: 6.16804\n",
      "Epoch [3/25], Step [10400/41412], Loss: 2.1519, Perplexity: 8.60140\n",
      "Epoch [3/25], Step [10500/41412], Loss: 2.0569, Perplexity: 7.82169\n",
      "Epoch [3/25], Step [10600/41412], Loss: 1.7135, Perplexity: 5.54841\n",
      "Epoch [3/25], Step [10700/41412], Loss: 1.6695, Perplexity: 5.30944\n",
      "Epoch [3/25], Step [10800/41412], Loss: 1.7121, Perplexity: 5.54055\n",
      "Epoch [3/25], Step [10900/41412], Loss: 2.7952, Perplexity: 16.3663\n",
      "Epoch [3/25], Step [11000/41412], Loss: 2.0580, Perplexity: 7.83072\n",
      "Epoch [3/25], Step [11100/41412], Loss: 2.2767, Perplexity: 9.74456\n",
      "Epoch [3/25], Step [11200/41412], Loss: 2.1907, Perplexity: 8.94157\n",
      "Epoch [3/25], Step [11300/41412], Loss: 2.2474, Perplexity: 9.46320\n",
      "Epoch [3/25], Step [11400/41412], Loss: 2.3282, Perplexity: 10.2592\n",
      "Epoch [3/25], Step [11500/41412], Loss: 2.2986, Perplexity: 9.95992\n",
      "Epoch [3/25], Step [11600/41412], Loss: 2.0382, Perplexity: 7.67697\n",
      "Epoch [3/25], Step [11700/41412], Loss: 2.3090, Perplexity: 10.0646\n",
      "Epoch [3/25], Step [11800/41412], Loss: 1.8396, Perplexity: 6.29383\n",
      "Epoch [3/25], Step [11900/41412], Loss: 1.9979, Perplexity: 7.37356\n",
      "Epoch [3/25], Step [12000/41412], Loss: 1.9489, Perplexity: 7.02125\n",
      "Epoch [3/25], Step [12100/41412], Loss: 2.2802, Perplexity: 9.77877\n",
      "Epoch [3/25], Step [12200/41412], Loss: 2.3464, Perplexity: 10.4479\n",
      "Epoch [3/25], Step [12300/41412], Loss: 1.9793, Perplexity: 7.23731\n",
      "Epoch [3/25], Step [12400/41412], Loss: 2.1519, Perplexity: 8.60125\n",
      "Epoch [3/25], Step [12500/41412], Loss: 1.6072, Perplexity: 4.98889\n",
      "Epoch [3/25], Step [12600/41412], Loss: 1.7847, Perplexity: 5.95807\n",
      "Epoch [3/25], Step [12700/41412], Loss: 2.2944, Perplexity: 9.91871\n",
      "Epoch [3/25], Step [12800/41412], Loss: 1.8740, Perplexity: 6.51468\n",
      "Epoch [3/25], Step [12900/41412], Loss: 2.0289, Perplexity: 7.60571\n",
      "Epoch [3/25], Step [13000/41412], Loss: 1.6619, Perplexity: 5.26942\n",
      "Epoch [3/25], Step [13100/41412], Loss: 2.4350, Perplexity: 11.4162\n",
      "Epoch [3/25], Step [13200/41412], Loss: 2.3474, Perplexity: 10.4587\n",
      "Epoch [3/25], Step [13300/41412], Loss: 2.0832, Perplexity: 8.03059\n",
      "Epoch [3/25], Step [13400/41412], Loss: 2.0048, Perplexity: 7.42466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Step [13500/41412], Loss: 2.0903, Perplexity: 8.08705\n",
      "Epoch [3/25], Step [13600/41412], Loss: 1.7362, Perplexity: 5.67566\n",
      "Epoch [3/25], Step [13700/41412], Loss: 1.9915, Perplexity: 7.32628\n",
      "Epoch [3/25], Step [13800/41412], Loss: 1.5445, Perplexity: 4.68587\n",
      "Epoch [3/25], Step [13900/41412], Loss: 1.9631, Perplexity: 7.12120\n",
      "Epoch [3/25], Step [14000/41412], Loss: 1.9542, Perplexity: 7.05861\n",
      "Epoch [3/25], Step [14100/41412], Loss: 2.0269, Perplexity: 7.59068\n",
      "Epoch [3/25], Step [14200/41412], Loss: 2.2622, Perplexity: 9.60423\n",
      "Epoch [3/25], Step [14300/41412], Loss: 2.1861, Perplexity: 8.90021\n",
      "Epoch [3/25], Step [14400/41412], Loss: 2.3005, Perplexity: 9.97892\n",
      "Epoch [3/25], Step [14500/41412], Loss: 1.8021, Perplexity: 6.06235\n",
      "Epoch [3/25], Step [14600/41412], Loss: 1.8856, Perplexity: 6.59067\n",
      "Epoch [3/25], Step [14700/41412], Loss: 2.1974, Perplexity: 9.00132\n",
      "Epoch [3/25], Step [14800/41412], Loss: 2.1291, Perplexity: 8.40723\n",
      "Epoch [3/25], Step [14900/41412], Loss: 1.8376, Perplexity: 6.28173\n",
      "Epoch [3/25], Step [15000/41412], Loss: 2.0804, Perplexity: 8.00776\n",
      "Epoch [3/25], Step [15100/41412], Loss: 2.2522, Perplexity: 9.50846\n",
      "Epoch [3/25], Step [15200/41412], Loss: 2.0016, Perplexity: 7.40098\n",
      "Epoch [3/25], Step [15300/41412], Loss: 2.8596, Perplexity: 17.4551\n",
      "Epoch [3/25], Step [15400/41412], Loss: 1.7491, Perplexity: 5.74922\n",
      "Epoch [3/25], Step [15500/41412], Loss: 1.8738, Perplexity: 6.51329\n",
      "Epoch [3/25], Step [15600/41412], Loss: 2.2641, Perplexity: 9.62246\n",
      "Epoch [3/25], Step [15700/41412], Loss: 2.1242, Perplexity: 8.36661\n",
      "Epoch [3/25], Step [15800/41412], Loss: 1.9631, Perplexity: 7.12129\n",
      "Epoch [3/25], Step [15900/41412], Loss: 1.7942, Perplexity: 6.01483\n",
      "Epoch [3/25], Step [16000/41412], Loss: 1.8804, Perplexity: 6.55635\n",
      "Epoch [3/25], Step [16100/41412], Loss: 2.1166, Perplexity: 8.30308\n",
      "Epoch [3/25], Step [16200/41412], Loss: 1.8906, Perplexity: 6.62357\n",
      "Epoch [3/25], Step [16300/41412], Loss: 2.5376, Perplexity: 12.6498\n",
      "Epoch [3/25], Step [16400/41412], Loss: 2.4363, Perplexity: 11.4308\n",
      "Epoch [3/25], Step [16500/41412], Loss: 2.2290, Perplexity: 9.29036\n",
      "Epoch [3/25], Step [16600/41412], Loss: 2.1541, Perplexity: 8.62039\n",
      "Epoch [3/25], Step [16700/41412], Loss: 2.2904, Perplexity: 9.87896\n",
      "Epoch [3/25], Step [16800/41412], Loss: 1.6566, Perplexity: 5.24139\n",
      "Epoch [3/25], Step [16900/41412], Loss: 2.1481, Perplexity: 8.56843\n",
      "Epoch [3/25], Step [17000/41412], Loss: 1.6088, Perplexity: 4.99701\n",
      "Epoch [3/25], Step [17100/41412], Loss: 2.2880, Perplexity: 9.85556\n",
      "Epoch [3/25], Step [17200/41412], Loss: 1.7511, Perplexity: 5.76123\n",
      "Epoch [3/25], Step [17300/41412], Loss: 2.3258, Perplexity: 10.2348\n",
      "Epoch [3/25], Step [17400/41412], Loss: 2.1859, Perplexity: 8.89832\n",
      "Epoch [3/25], Step [17500/41412], Loss: 2.3289, Perplexity: 10.2665\n",
      "Epoch [3/25], Step [17600/41412], Loss: 2.2699, Perplexity: 9.67844\n",
      "Epoch [3/25], Step [17700/41412], Loss: 2.2677, Perplexity: 9.65748\n",
      "Epoch [3/25], Step [17800/41412], Loss: 1.8682, Perplexity: 6.47648\n",
      "Epoch [3/25], Step [17900/41412], Loss: 2.4197, Perplexity: 11.2424\n",
      "Epoch [3/25], Step [18000/41412], Loss: 1.2934, Perplexity: 3.64503\n",
      "Epoch [3/25], Step [18100/41412], Loss: 1.9269, Perplexity: 6.86846\n",
      "Epoch [3/25], Step [18200/41412], Loss: 1.9531, Perplexity: 7.05026\n",
      "Epoch [3/25], Step [18300/41412], Loss: 1.3790, Perplexity: 3.97101\n",
      "Epoch [3/25], Step [18400/41412], Loss: 2.2497, Perplexity: 9.48461\n",
      "Epoch [3/25], Step [18500/41412], Loss: 2.0367, Perplexity: 7.66514\n",
      "Epoch [3/25], Step [18600/41412], Loss: 1.5915, Perplexity: 4.91127\n",
      "Epoch [3/25], Step [18700/41412], Loss: 2.4300, Perplexity: 11.3584\n",
      "Epoch [3/25], Step [18800/41412], Loss: 1.9376, Perplexity: 6.942070\n",
      "Epoch [3/25], Step [18900/41412], Loss: 2.0397, Perplexity: 7.68800\n",
      "Epoch [3/25], Step [19000/41412], Loss: 1.9056, Perplexity: 6.72336\n",
      "Epoch [3/25], Step [19100/41412], Loss: 1.9645, Perplexity: 7.13174\n",
      "Epoch [3/25], Step [19200/41412], Loss: 2.0119, Perplexity: 7.47752\n",
      "Epoch [3/25], Step [19300/41412], Loss: 2.1318, Perplexity: 8.43002\n",
      "Epoch [3/25], Step [19400/41412], Loss: 1.7002, Perplexity: 5.47525\n",
      "Epoch [3/25], Step [19500/41412], Loss: 1.8141, Perplexity: 6.13555\n",
      "Epoch [3/25], Step [19600/41412], Loss: 2.1405, Perplexity: 8.50415\n",
      "Epoch [3/25], Step [19700/41412], Loss: 2.1024, Perplexity: 8.18586\n",
      "Epoch [3/25], Step [19800/41412], Loss: 1.8496, Perplexity: 6.35734\n",
      "Epoch [3/25], Step [19900/41412], Loss: 1.9370, Perplexity: 6.93777\n",
      "Epoch [3/25], Step [20000/41412], Loss: 2.1657, Perplexity: 8.72044\n",
      "Epoch [3/25], Step [20100/41412], Loss: 2.2987, Perplexity: 9.96129\n",
      "Epoch [3/25], Step [20200/41412], Loss: 2.0223, Perplexity: 7.55551\n",
      "Epoch [3/25], Step [20300/41412], Loss: 2.0153, Perplexity: 7.50289\n",
      "Epoch [3/25], Step [20400/41412], Loss: 2.0457, Perplexity: 7.73459\n",
      "Epoch [3/25], Step [20500/41412], Loss: 2.3014, Perplexity: 9.98841\n",
      "Epoch [3/25], Step [20600/41412], Loss: 1.9078, Perplexity: 6.73845\n",
      "Epoch [3/25], Step [20700/41412], Loss: 2.5883, Perplexity: 13.3074\n",
      "Epoch [3/25], Step [20800/41412], Loss: 2.0772, Perplexity: 7.98223\n",
      "Epoch [3/25], Step [20900/41412], Loss: 1.8004, Perplexity: 6.05226\n",
      "Epoch [3/25], Step [21000/41412], Loss: 2.7411, Perplexity: 15.5036\n",
      "Epoch [3/25], Step [21100/41412], Loss: 1.9834, Perplexity: 7.26759\n",
      "Epoch [3/25], Step [21200/41412], Loss: 2.4851, Perplexity: 12.0023\n",
      "Epoch [3/25], Step [21300/41412], Loss: 1.8498, Perplexity: 6.35858\n",
      "Epoch [3/25], Step [21400/41412], Loss: 2.0806, Perplexity: 8.00919\n",
      "Epoch [3/25], Step [21500/41412], Loss: 2.4298, Perplexity: 11.3563\n",
      "Epoch [3/25], Step [21600/41412], Loss: 2.2125, Perplexity: 9.13884\n",
      "Epoch [3/25], Step [21700/41412], Loss: 2.0372, Perplexity: 7.66910\n",
      "Epoch [3/25], Step [21800/41412], Loss: 2.0871, Perplexity: 8.06173\n",
      "Epoch [3/25], Step [21900/41412], Loss: 2.1820, Perplexity: 8.86447\n",
      "Epoch [3/25], Step [22000/41412], Loss: 1.8080, Perplexity: 6.09848\n",
      "Epoch [3/25], Step [22100/41412], Loss: 2.3360, Perplexity: 10.3397\n",
      "Epoch [3/25], Step [22200/41412], Loss: 2.0273, Perplexity: 7.59345\n",
      "Epoch [3/25], Step [22300/41412], Loss: 2.0882, Perplexity: 8.07016\n",
      "Epoch [3/25], Step [22400/41412], Loss: 2.2265, Perplexity: 9.26746\n",
      "Epoch [3/25], Step [22500/41412], Loss: 1.9452, Perplexity: 6.99531\n",
      "Epoch [3/25], Step [22600/41412], Loss: 1.8243, Perplexity: 6.19850\n",
      "Epoch [3/25], Step [22700/41412], Loss: 2.0679, Perplexity: 7.90856\n",
      "Epoch [3/25], Step [22800/41412], Loss: 1.9530, Perplexity: 7.05017\n",
      "Epoch [3/25], Step [22900/41412], Loss: 1.7925, Perplexity: 6.00456\n",
      "Epoch [3/25], Step [23000/41412], Loss: 1.8310, Perplexity: 6.24021\n",
      "Epoch [3/25], Step [23100/41412], Loss: 2.0841, Perplexity: 8.03721\n",
      "Epoch [3/25], Step [23200/41412], Loss: 1.9256, Perplexity: 6.85937\n",
      "Epoch [3/25], Step [23300/41412], Loss: 2.0927, Perplexity: 8.10662\n",
      "Epoch [3/25], Step [23400/41412], Loss: 2.2763, Perplexity: 9.74089\n",
      "Epoch [3/25], Step [23500/41412], Loss: 2.1019, Perplexity: 8.18182\n",
      "Epoch [3/25], Step [23600/41412], Loss: 2.5566, Perplexity: 12.8924\n",
      "Epoch [3/25], Step [23700/41412], Loss: 1.9798, Perplexity: 7.24168\n",
      "Epoch [3/25], Step [23800/41412], Loss: 2.5791, Perplexity: 13.1855\n",
      "Epoch [3/25], Step [23900/41412], Loss: 2.1257, Perplexity: 8.37915\n",
      "Epoch [3/25], Step [24000/41412], Loss: 2.4738, Perplexity: 11.8677\n",
      "Epoch [3/25], Step [24100/41412], Loss: 1.6295, Perplexity: 5.10118\n",
      "Epoch [3/25], Step [24200/41412], Loss: 1.9320, Perplexity: 6.90339\n",
      "Epoch [3/25], Step [24300/41412], Loss: 1.9222, Perplexity: 6.83601\n",
      "Epoch [3/25], Step [24400/41412], Loss: 1.4909, Perplexity: 4.44108\n",
      "Epoch [3/25], Step [24500/41412], Loss: 1.9404, Perplexity: 6.96151\n",
      "Epoch [3/25], Step [24600/41412], Loss: 1.7892, Perplexity: 5.98445\n",
      "Epoch [3/25], Step [24700/41412], Loss: 1.4527, Perplexity: 4.27483\n",
      "Epoch [3/25], Step [24800/41412], Loss: 2.0821, Perplexity: 8.02105\n",
      "Epoch [3/25], Step [24900/41412], Loss: 2.8700, Perplexity: 17.6376\n",
      "Epoch [3/25], Step [25000/41412], Loss: 1.6052, Perplexity: 4.97872\n",
      "Epoch [3/25], Step [25100/41412], Loss: 1.6639, Perplexity: 5.27979\n",
      "Epoch [3/25], Step [25200/41412], Loss: 2.3293, Perplexity: 10.2712\n",
      "Epoch [3/25], Step [25300/41412], Loss: 2.4000, Perplexity: 11.0227\n",
      "Epoch [3/25], Step [25400/41412], Loss: 1.5890, Perplexity: 4.89871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Step [25500/41412], Loss: 1.8821, Perplexity: 6.56765\n",
      "Epoch [3/25], Step [25600/41412], Loss: 1.9861, Perplexity: 7.28733\n",
      "Epoch [3/25], Step [25700/41412], Loss: 2.2814, Perplexity: 9.79030\n",
      "Epoch [3/25], Step [25800/41412], Loss: 1.4764, Perplexity: 4.37727\n",
      "Epoch [3/25], Step [25900/41412], Loss: 1.6754, Perplexity: 5.34084\n",
      "Epoch [3/25], Step [26000/41412], Loss: 1.8975, Perplexity: 6.66891\n",
      "Epoch [3/25], Step [26100/41412], Loss: 1.8312, Perplexity: 6.24122\n",
      "Epoch [3/25], Step [26200/41412], Loss: 2.2985, Perplexity: 9.95927\n",
      "Epoch [3/25], Step [26300/41412], Loss: 1.9973, Perplexity: 7.36891\n",
      "Epoch [3/25], Step [26400/41412], Loss: 1.5961, Perplexity: 4.93374\n",
      "Epoch [3/25], Step [26500/41412], Loss: 1.9282, Perplexity: 6.87690\n",
      "Epoch [3/25], Step [26600/41412], Loss: 1.6508, Perplexity: 5.21095\n",
      "Epoch [3/25], Step [26700/41412], Loss: 2.3922, Perplexity: 10.9375\n",
      "Epoch [3/25], Step [26800/41412], Loss: 1.6635, Perplexity: 5.27752\n",
      "Epoch [3/25], Step [26900/41412], Loss: 2.6615, Perplexity: 14.3182\n",
      "Epoch [3/25], Step [27000/41412], Loss: 1.9495, Perplexity: 7.02519\n",
      "Epoch [3/25], Step [27100/41412], Loss: 2.9297, Perplexity: 18.7216\n",
      "Epoch [3/25], Step [27200/41412], Loss: 1.9120, Perplexity: 6.76685\n",
      "Epoch [3/25], Step [27300/41412], Loss: 2.1629, Perplexity: 8.69603\n",
      "Epoch [3/25], Step [27400/41412], Loss: 2.5687, Perplexity: 13.0485\n",
      "Epoch [3/25], Step [27500/41412], Loss: 1.5016, Perplexity: 4.48918\n",
      "Epoch [3/25], Step [27600/41412], Loss: 1.8486, Perplexity: 6.35061\n",
      "Epoch [3/25], Step [27700/41412], Loss: 1.3754, Perplexity: 3.95675\n",
      "Epoch [3/25], Step [27800/41412], Loss: 2.5575, Perplexity: 12.9037\n",
      "Epoch [3/25], Step [27900/41412], Loss: 1.9764, Perplexity: 7.21708\n",
      "Epoch [3/25], Step [28000/41412], Loss: 2.0931, Perplexity: 8.10980\n",
      "Epoch [3/25], Step [28100/41412], Loss: 1.7689, Perplexity: 5.86437\n",
      "Epoch [3/25], Step [28200/41412], Loss: 1.7311, Perplexity: 5.64706\n",
      "Epoch [3/25], Step [28300/41412], Loss: 1.9431, Perplexity: 6.98031\n",
      "Epoch [3/25], Step [28400/41412], Loss: 2.5277, Perplexity: 12.5252\n",
      "Epoch [3/25], Step [28500/41412], Loss: 1.7302, Perplexity: 5.64194\n",
      "Epoch [3/25], Step [28600/41412], Loss: 1.6204, Perplexity: 5.05509\n",
      "Epoch [3/25], Step [28700/41412], Loss: 1.9855, Perplexity: 7.28266\n",
      "Epoch [3/25], Step [28800/41412], Loss: 1.8266, Perplexity: 6.21294\n",
      "Epoch [3/25], Step [28900/41412], Loss: 1.6131, Perplexity: 5.01851\n",
      "Epoch [3/25], Step [29000/41412], Loss: 2.4951, Perplexity: 12.1233\n",
      "Epoch [3/25], Step [29100/41412], Loss: 2.2142, Perplexity: 9.15412\n",
      "Epoch [3/25], Step [29200/41412], Loss: 1.8162, Perplexity: 6.14830\n",
      "Epoch [3/25], Step [29300/41412], Loss: 1.5709, Perplexity: 4.81125\n",
      "Epoch [3/25], Step [29400/41412], Loss: 1.9879, Perplexity: 7.30051\n",
      "Epoch [3/25], Step [29500/41412], Loss: 2.0078, Perplexity: 7.44714\n",
      "Epoch [3/25], Step [29600/41412], Loss: 2.1757, Perplexity: 8.80850\n",
      "Epoch [3/25], Step [29700/41412], Loss: 2.1343, Perplexity: 8.45101\n",
      "Epoch [3/25], Step [29800/41412], Loss: 1.7524, Perplexity: 5.76828\n",
      "Epoch [3/25], Step [29900/41412], Loss: 1.3931, Perplexity: 4.02742\n",
      "Epoch [3/25], Step [30000/41412], Loss: 2.0468, Perplexity: 7.74324\n",
      "Epoch [3/25], Step [30100/41412], Loss: 2.2105, Perplexity: 9.12053\n",
      "Epoch [3/25], Step [30200/41412], Loss: 1.8546, Perplexity: 6.38940\n",
      "Epoch [3/25], Step [30300/41412], Loss: 2.3594, Perplexity: 10.5851\n",
      "Epoch [3/25], Step [30400/41412], Loss: 2.0196, Perplexity: 7.535455\n",
      "Epoch [3/25], Step [30500/41412], Loss: 1.9804, Perplexity: 7.24533\n",
      "Epoch [3/25], Step [30600/41412], Loss: 1.7738, Perplexity: 5.89334\n",
      "Epoch [3/25], Step [30700/41412], Loss: 2.2334, Perplexity: 9.33127\n",
      "Epoch [3/25], Step [30800/41412], Loss: 2.4604, Perplexity: 11.7091\n",
      "Epoch [3/25], Step [30900/41412], Loss: 2.0717, Perplexity: 7.93843\n",
      "Epoch [3/25], Step [31000/41412], Loss: 2.0360, Perplexity: 7.66022\n",
      "Epoch [3/25], Step [31100/41412], Loss: 1.8295, Perplexity: 6.230868\n",
      "Epoch [3/25], Step [31200/41412], Loss: 2.0757, Perplexity: 7.97002\n",
      "Epoch [3/25], Step [31300/41412], Loss: 1.5438, Perplexity: 4.68261\n",
      "Epoch [3/25], Step [31400/41412], Loss: 2.7477, Perplexity: 15.6062\n",
      "Epoch [3/25], Step [31500/41412], Loss: 1.8296, Perplexity: 6.23127\n",
      "Epoch [3/25], Step [31600/41412], Loss: 1.8416, Perplexity: 6.30684\n",
      "Epoch [3/25], Step [31700/41412], Loss: 1.8281, Perplexity: 6.22229\n",
      "Epoch [3/25], Step [31800/41412], Loss: 2.0028, Perplexity: 7.40978\n",
      "Epoch [3/25], Step [31900/41412], Loss: 1.7808, Perplexity: 5.93482\n",
      "Epoch [3/25], Step [32000/41412], Loss: 1.5967, Perplexity: 4.93657\n",
      "Epoch [3/25], Step [32100/41412], Loss: 1.8915, Perplexity: 6.62964\n",
      "Epoch [3/25], Step [32200/41412], Loss: 1.5885, Perplexity: 4.89626\n",
      "Epoch [3/25], Step [32300/41412], Loss: 2.1221, Perplexity: 8.34862\n",
      "Epoch [3/25], Step [32400/41412], Loss: 1.7890, Perplexity: 5.98372\n",
      "Epoch [3/25], Step [32500/41412], Loss: 1.7490, Perplexity: 5.74875\n",
      "Epoch [3/25], Step [32600/41412], Loss: 2.6090, Perplexity: 13.5852\n",
      "Epoch [3/25], Step [32700/41412], Loss: 1.9342, Perplexity: 6.91888\n",
      "Epoch [3/25], Step [32800/41412], Loss: 2.1332, Perplexity: 8.44223\n",
      "Epoch [3/25], Step [32900/41412], Loss: 1.7135, Perplexity: 5.54867\n",
      "Epoch [3/25], Step [33000/41412], Loss: 3.0817, Perplexity: 21.7964\n",
      "Epoch [3/25], Step [33100/41412], Loss: 2.2628, Perplexity: 9.61030\n",
      "Epoch [3/25], Step [33200/41412], Loss: 1.8682, Perplexity: 6.47694\n",
      "Epoch [3/25], Step [33300/41412], Loss: 2.0386, Perplexity: 7.67986\n",
      "Epoch [3/25], Step [33400/41412], Loss: 1.9753, Perplexity: 7.20903\n",
      "Epoch [3/25], Step [33500/41412], Loss: 3.1587, Perplexity: 23.5408\n",
      "Epoch [3/25], Step [33600/41412], Loss: 1.5558, Perplexity: 4.73914\n",
      "Epoch [3/25], Step [33700/41412], Loss: 1.9402, Perplexity: 6.96034\n",
      "Epoch [3/25], Step [33800/41412], Loss: 1.9671, Perplexity: 7.15008\n",
      "Epoch [3/25], Step [33900/41412], Loss: 2.6444, Perplexity: 14.0754\n",
      "Epoch [3/25], Step [34000/41412], Loss: 2.0818, Perplexity: 8.01908\n",
      "Epoch [3/25], Step [34100/41412], Loss: 1.7366, Perplexity: 5.67784\n",
      "Epoch [3/25], Step [34200/41412], Loss: 2.1039, Perplexity: 8.19849\n",
      "Epoch [3/25], Step [34300/41412], Loss: 2.2081, Perplexity: 9.09869\n",
      "Epoch [3/25], Step [34400/41412], Loss: 1.8927, Perplexity: 6.63738\n",
      "Epoch [3/25], Step [34500/41412], Loss: 1.8951, Perplexity: 6.65348\n",
      "Epoch [3/25], Step [34600/41412], Loss: 2.6238, Perplexity: 13.7883\n",
      "Epoch [3/25], Step [34700/41412], Loss: 1.9031, Perplexity: 6.70666\n",
      "Epoch [3/25], Step [34800/41412], Loss: 2.1198, Perplexity: 8.32956\n",
      "Epoch [3/25], Step [34900/41412], Loss: 1.9938, Perplexity: 7.34333\n",
      "Epoch [3/25], Step [35000/41412], Loss: 1.9565, Perplexity: 7.07443\n",
      "Epoch [3/25], Step [35100/41412], Loss: 1.5049, Perplexity: 4.50357\n",
      "Epoch [3/25], Step [35200/41412], Loss: 1.7315, Perplexity: 5.64944\n",
      "Epoch [3/25], Step [35300/41412], Loss: 2.4583, Perplexity: 11.6847\n",
      "Epoch [3/25], Step [35400/41412], Loss: 1.8058, Perplexity: 6.08492\n",
      "Epoch [3/25], Step [35500/41412], Loss: 2.2407, Perplexity: 9.39963\n",
      "Epoch [3/25], Step [35600/41412], Loss: 1.9575, Perplexity: 7.08193\n",
      "Epoch [3/25], Step [35700/41412], Loss: 1.7238, Perplexity: 5.60609\n",
      "Epoch [3/25], Step [35800/41412], Loss: 1.7747, Perplexity: 5.89859\n",
      "Epoch [3/25], Step [35900/41412], Loss: 2.8920, Perplexity: 18.0293\n",
      "Epoch [3/25], Step [36000/41412], Loss: 1.9782, Perplexity: 7.22944\n",
      "Epoch [3/25], Step [36100/41412], Loss: 1.8387, Perplexity: 6.28819\n",
      "Epoch [3/25], Step [36200/41412], Loss: 1.8590, Perplexity: 6.41712\n",
      "Epoch [3/25], Step [36300/41412], Loss: 2.0732, Perplexity: 7.95047\n",
      "Epoch [3/25], Step [36400/41412], Loss: 2.3562, Perplexity: 10.5511\n",
      "Epoch [3/25], Step [36500/41412], Loss: 1.9874, Perplexity: 7.29687\n",
      "Epoch [3/25], Step [36600/41412], Loss: 2.1107, Perplexity: 8.25365\n",
      "Epoch [3/25], Step [36700/41412], Loss: 2.3170, Perplexity: 10.1450\n",
      "Epoch [3/25], Step [36800/41412], Loss: 1.8929, Perplexity: 6.63850\n",
      "Epoch [3/25], Step [36900/41412], Loss: 1.7442, Perplexity: 5.72169\n",
      "Epoch [3/25], Step [37000/41412], Loss: 1.7381, Perplexity: 5.68646\n",
      "Epoch [3/25], Step [37100/41412], Loss: 1.7194, Perplexity: 5.58093\n",
      "Epoch [3/25], Step [37200/41412], Loss: 1.8995, Perplexity: 6.68258\n",
      "Epoch [3/25], Step [37300/41412], Loss: 2.4197, Perplexity: 11.2425\n",
      "Epoch [3/25], Step [37400/41412], Loss: 1.5880, Perplexity: 4.89404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Step [37500/41412], Loss: 2.4871, Perplexity: 12.0269\n",
      "Epoch [3/25], Step [37600/41412], Loss: 2.1923, Perplexity: 8.95554\n",
      "Epoch [3/25], Step [37700/41412], Loss: 2.1422, Perplexity: 8.51849\n",
      "Epoch [3/25], Step [37800/41412], Loss: 2.1083, Perplexity: 8.23430\n",
      "Epoch [3/25], Step [37900/41412], Loss: 1.7443, Perplexity: 5.72216\n",
      "Epoch [3/25], Step [38000/41412], Loss: 2.1075, Perplexity: 8.22735\n",
      "Epoch [3/25], Step [38100/41412], Loss: 2.2031, Perplexity: 9.05324\n",
      "Epoch [3/25], Step [38200/41412], Loss: 2.1597, Perplexity: 8.66901\n",
      "Epoch [3/25], Step [38300/41412], Loss: 2.1803, Perplexity: 8.84867\n",
      "Epoch [3/25], Step [38400/41412], Loss: 1.9546, Perplexity: 7.06130\n",
      "Epoch [3/25], Step [38500/41412], Loss: 2.0967, Perplexity: 8.13943\n",
      "Epoch [3/25], Step [38600/41412], Loss: 2.6103, Perplexity: 13.6031\n",
      "Epoch [3/25], Step [38700/41412], Loss: 1.8275, Perplexity: 6.21822\n",
      "Epoch [3/25], Step [38800/41412], Loss: 1.7231, Perplexity: 5.60210\n",
      "Epoch [3/25], Step [38900/41412], Loss: 1.9889, Perplexity: 7.30786\n",
      "Epoch [3/25], Step [39000/41412], Loss: 1.9520, Perplexity: 7.04283\n",
      "Epoch [3/25], Step [39100/41412], Loss: 2.3690, Perplexity: 10.6867\n",
      "Epoch [3/25], Step [39200/41412], Loss: 1.4790, Perplexity: 4.38847\n",
      "Epoch [3/25], Step [39300/41412], Loss: 1.9912, Perplexity: 7.32479\n",
      "Epoch [3/25], Step [39400/41412], Loss: 1.6457, Perplexity: 5.18475\n",
      "Epoch [3/25], Step [39500/41412], Loss: 1.4907, Perplexity: 4.44003\n",
      "Epoch [3/25], Step [39600/41412], Loss: 1.9571, Perplexity: 7.07881\n",
      "Epoch [3/25], Step [39700/41412], Loss: 2.2036, Perplexity: 9.05791\n",
      "Epoch [3/25], Step [39800/41412], Loss: 1.7132, Perplexity: 5.54656\n",
      "Epoch [3/25], Step [39900/41412], Loss: 1.7158, Perplexity: 5.56112\n",
      "Epoch [3/25], Step [40000/41412], Loss: 1.9685, Perplexity: 7.16009\n",
      "Epoch [3/25], Step [40100/41412], Loss: 1.4591, Perplexity: 4.30221\n",
      "Epoch [3/25], Step [40200/41412], Loss: 2.2784, Perplexity: 9.76084\n",
      "Epoch [3/25], Step [40300/41412], Loss: 3.0281, Perplexity: 20.6583\n",
      "Epoch [3/25], Step [40400/41412], Loss: 2.0724, Perplexity: 7.94427\n",
      "Epoch [3/25], Step [40500/41412], Loss: 1.9451, Perplexity: 6.99414\n",
      "Epoch [3/25], Step [40600/41412], Loss: 2.7951, Perplexity: 16.3635\n",
      "Epoch [3/25], Step [40700/41412], Loss: 2.4925, Perplexity: 12.0917\n",
      "Epoch [3/25], Step [40800/41412], Loss: 1.9505, Perplexity: 7.03256\n",
      "Epoch [3/25], Step [40900/41412], Loss: 1.9021, Perplexity: 6.69972\n",
      "Epoch [3/25], Step [41000/41412], Loss: 2.5453, Perplexity: 12.7476\n",
      "Epoch [3/25], Step [41100/41412], Loss: 2.4268, Perplexity: 11.3223\n",
      "Epoch [3/25], Step [41200/41412], Loss: 3.2735, Perplexity: 26.4026\n",
      "Epoch [3/25], Step [41300/41412], Loss: 2.0345, Perplexity: 7.64840\n",
      "Epoch [3/25], Step [41400/41412], Loss: 1.9545, Perplexity: 7.06037\n",
      "Epoch [4/25], Step [100/41412], Loss: 1.7230, Perplexity: 5.6011575\n",
      "Epoch [4/25], Step [200/41412], Loss: 1.8221, Perplexity: 6.18510\n",
      "Epoch [4/25], Step [300/41412], Loss: 1.5671, Perplexity: 4.79275\n",
      "Epoch [4/25], Step [400/41412], Loss: 1.9799, Perplexity: 7.24210\n",
      "Epoch [4/25], Step [500/41412], Loss: 2.1964, Perplexity: 8.99249\n",
      "Epoch [4/25], Step [600/41412], Loss: 2.0987, Perplexity: 8.15553\n",
      "Epoch [4/25], Step [700/41412], Loss: 2.2786, Perplexity: 9.76318\n",
      "Epoch [4/25], Step [800/41412], Loss: 2.1709, Perplexity: 8.76657\n",
      "Epoch [4/25], Step [900/41412], Loss: 1.4814, Perplexity: 4.39906\n",
      "Epoch [4/25], Step [1000/41412], Loss: 2.0365, Perplexity: 7.6635\n",
      "Epoch [4/25], Step [1100/41412], Loss: 2.4052, Perplexity: 11.0804\n",
      "Epoch [4/25], Step [1200/41412], Loss: 2.2447, Perplexity: 9.43771\n",
      "Epoch [4/25], Step [1300/41412], Loss: 1.8250, Perplexity: 6.20315\n",
      "Epoch [4/25], Step [1400/41412], Loss: 2.3804, Perplexity: 10.8096\n",
      "Epoch [4/25], Step [1500/41412], Loss: 2.1783, Perplexity: 8.83157\n",
      "Epoch [4/25], Step [1600/41412], Loss: 2.0742, Perplexity: 7.95802\n",
      "Epoch [4/25], Step [1700/41412], Loss: 1.7286, Perplexity: 5.63307\n",
      "Epoch [4/25], Step [1800/41412], Loss: 2.1344, Perplexity: 8.45198\n",
      "Epoch [4/25], Step [1900/41412], Loss: 1.8095, Perplexity: 6.10744\n",
      "Epoch [4/25], Step [2000/41412], Loss: 1.8487, Perplexity: 6.35179\n",
      "Epoch [4/25], Step [2100/41412], Loss: 2.0200, Perplexity: 7.53808\n",
      "Epoch [4/25], Step [2200/41412], Loss: 2.5300, Perplexity: 12.5538\n",
      "Epoch [4/25], Step [2300/41412], Loss: 2.3501, Perplexity: 10.4868\n",
      "Epoch [4/25], Step [2400/41412], Loss: 2.4044, Perplexity: 11.0713\n",
      "Epoch [4/25], Step [2500/41412], Loss: 1.7716, Perplexity: 5.88026\n",
      "Epoch [4/25], Step [2600/41412], Loss: 1.9622, Perplexity: 7.11500\n",
      "Epoch [4/25], Step [2700/41412], Loss: 1.6820, Perplexity: 5.37651\n",
      "Epoch [4/25], Step [2800/41412], Loss: 1.7981, Perplexity: 6.03830\n",
      "Epoch [4/25], Step [2900/41412], Loss: 2.8999, Perplexity: 18.1724\n",
      "Epoch [4/25], Step [3000/41412], Loss: 2.0725, Perplexity: 7.94497\n",
      "Epoch [4/25], Step [3100/41412], Loss: 2.2600, Perplexity: 9.58277\n",
      "Epoch [4/25], Step [3200/41412], Loss: 1.9055, Perplexity: 6.72302\n",
      "Epoch [4/25], Step [3300/41412], Loss: 2.6271, Perplexity: 13.8335\n",
      "Epoch [4/25], Step [3400/41412], Loss: 1.7401, Perplexity: 5.69785\n",
      "Epoch [4/25], Step [3500/41412], Loss: 2.2288, Perplexity: 9.28831\n",
      "Epoch [4/25], Step [3600/41412], Loss: 1.5371, Perplexity: 4.65118\n",
      "Epoch [4/25], Step [3700/41412], Loss: 1.8722, Perplexity: 6.50275\n",
      "Epoch [4/25], Step [3800/41412], Loss: 1.7714, Perplexity: 5.87889\n",
      "Epoch [4/25], Step [3900/41412], Loss: 2.5455, Perplexity: 12.7499\n",
      "Epoch [4/25], Step [4000/41412], Loss: 1.9561, Perplexity: 7.07194\n",
      "Epoch [4/25], Step [4100/41412], Loss: 1.9519, Perplexity: 7.04188\n",
      "Epoch [4/25], Step [4200/41412], Loss: 2.3584, Perplexity: 10.5745\n",
      "Epoch [4/25], Step [4300/41412], Loss: 1.7746, Perplexity: 5.89798\n",
      "Epoch [4/25], Step [4400/41412], Loss: 2.4877, Perplexity: 12.0333\n",
      "Epoch [4/25], Step [4500/41412], Loss: 2.2850, Perplexity: 9.82610\n",
      "Epoch [4/25], Step [4600/41412], Loss: 1.7977, Perplexity: 6.03567\n",
      "Epoch [4/25], Step [4700/41412], Loss: 2.2449, Perplexity: 9.43918\n",
      "Epoch [4/25], Step [4800/41412], Loss: 2.3640, Perplexity: 10.6334\n",
      "Epoch [4/25], Step [4900/41412], Loss: 1.6114, Perplexity: 5.00980\n",
      "Epoch [4/25], Step [5000/41412], Loss: 1.8212, Perplexity: 6.17958\n",
      "Epoch [4/25], Step [5100/41412], Loss: 2.3005, Perplexity: 9.97935\n",
      "Epoch [4/25], Step [5200/41412], Loss: 1.9335, Perplexity: 6.91355\n",
      "Epoch [4/25], Step [5300/41412], Loss: 1.9589, Perplexity: 7.09142\n",
      "Epoch [4/25], Step [5400/41412], Loss: 2.3095, Perplexity: 10.0689\n",
      "Epoch [4/25], Step [5500/41412], Loss: 1.9788, Perplexity: 7.23391\n",
      "Epoch [4/25], Step [5600/41412], Loss: 2.1952, Perplexity: 8.98218\n",
      "Epoch [4/25], Step [5700/41412], Loss: 1.9607, Perplexity: 7.10454\n",
      "Epoch [4/25], Step [5800/41412], Loss: 2.2355, Perplexity: 9.35083\n",
      "Epoch [4/25], Step [5900/41412], Loss: 2.0633, Perplexity: 7.87168\n",
      "Epoch [4/25], Step [6000/41412], Loss: 2.0223, Perplexity: 7.55553\n",
      "Epoch [4/25], Step [6100/41412], Loss: 2.1922, Perplexity: 8.95440\n",
      "Epoch [4/25], Step [6200/41412], Loss: 1.5986, Perplexity: 4.946335\n",
      "Epoch [4/25], Step [6300/41412], Loss: 1.7958, Perplexity: 6.02403\n",
      "Epoch [4/25], Step [6400/41412], Loss: 2.2872, Perplexity: 9.84774\n",
      "Epoch [4/25], Step [6500/41412], Loss: 1.6869, Perplexity: 5.40293\n",
      "Epoch [4/25], Step [6600/41412], Loss: 2.0120, Perplexity: 7.47853\n",
      "Epoch [4/25], Step [6700/41412], Loss: 2.2123, Perplexity: 9.13673\n",
      "Epoch [4/25], Step [6800/41412], Loss: 2.2177, Perplexity: 9.18586\n",
      "Epoch [4/25], Step [6900/41412], Loss: 1.6463, Perplexity: 5.18766\n",
      "Epoch [4/25], Step [7000/41412], Loss: 2.0863, Perplexity: 8.05486\n",
      "Epoch [4/25], Step [7100/41412], Loss: 2.1647, Perplexity: 8.71236\n",
      "Epoch [4/25], Step [7200/41412], Loss: 2.1649, Perplexity: 8.71368\n",
      "Epoch [4/25], Step [7300/41412], Loss: 1.8094, Perplexity: 6.10680\n",
      "Epoch [4/25], Step [7400/41412], Loss: 1.8017, Perplexity: 6.06001\n",
      "Epoch [4/25], Step [7500/41412], Loss: 1.6852, Perplexity: 5.39357\n",
      "Epoch [4/25], Step [7600/41412], Loss: 1.7313, Perplexity: 5.64791\n",
      "Epoch [4/25], Step [7700/41412], Loss: 1.8276, Perplexity: 6.21913\n",
      "Epoch [4/25], Step [7800/41412], Loss: 2.1572, Perplexity: 8.64707\n",
      "Epoch [4/25], Step [7900/41412], Loss: 2.3071, Perplexity: 10.0453\n",
      "Epoch [4/25], Step [8000/41412], Loss: 2.3194, Perplexity: 10.1698\n",
      "Epoch [4/25], Step [8100/41412], Loss: 1.8713, Perplexity: 6.49710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Step [8200/41412], Loss: 1.6960, Perplexity: 5.45191\n",
      "Epoch [4/25], Step [8300/41412], Loss: 1.6149, Perplexity: 5.02744\n",
      "Epoch [4/25], Step [8400/41412], Loss: 2.1046, Perplexity: 8.20413\n",
      "Epoch [4/25], Step [8500/41412], Loss: 1.9812, Perplexity: 7.25129\n",
      "Epoch [4/25], Step [8600/41412], Loss: 2.0390, Perplexity: 7.68319\n",
      "Epoch [4/25], Step [8700/41412], Loss: 1.9527, Perplexity: 7.04776\n",
      "Epoch [4/25], Step [8800/41412], Loss: 1.8760, Perplexity: 6.52778\n",
      "Epoch [4/25], Step [8900/41412], Loss: 1.6408, Perplexity: 5.15920\n",
      "Epoch [4/25], Step [9000/41412], Loss: 1.9845, Perplexity: 7.27531\n",
      "Epoch [4/25], Step [9100/41412], Loss: 1.5674, Perplexity: 4.79430\n",
      "Epoch [4/25], Step [9200/41412], Loss: 2.2183, Perplexity: 9.19153\n",
      "Epoch [4/25], Step [9300/41412], Loss: 2.0960, Perplexity: 8.13362\n",
      "Epoch [4/25], Step [9400/41412], Loss: 2.1482, Perplexity: 8.56965\n",
      "Epoch [4/25], Step [9500/41412], Loss: 2.3375, Perplexity: 10.3550\n",
      "Epoch [4/25], Step [9600/41412], Loss: 1.8706, Perplexity: 6.49192\n",
      "Epoch [4/25], Step [9700/41412], Loss: 1.8430, Perplexity: 6.31524\n",
      "Epoch [4/25], Step [9800/41412], Loss: 1.7521, Perplexity: 5.76665\n",
      "Epoch [4/25], Step [9900/41412], Loss: 2.2626, Perplexity: 9.60771\n",
      "Epoch [4/25], Step [10000/41412], Loss: 1.8895, Perplexity: 6.6163\n",
      "Epoch [4/25], Step [10100/41412], Loss: 1.8540, Perplexity: 6.38520\n",
      "Epoch [4/25], Step [10200/41412], Loss: 2.0639, Perplexity: 7.87662\n",
      "Epoch [4/25], Step [10300/41412], Loss: 2.1542, Perplexity: 8.62143\n",
      "Epoch [4/25], Step [10400/41412], Loss: 1.9733, Perplexity: 7.19450\n",
      "Epoch [4/25], Step [10500/41412], Loss: 2.1547, Perplexity: 8.62531\n",
      "Epoch [4/25], Step [10600/41412], Loss: 1.8797, Perplexity: 6.55151\n",
      "Epoch [4/25], Step [10700/41412], Loss: 2.5299, Perplexity: 12.5524\n",
      "Epoch [4/25], Step [10800/41412], Loss: 2.5200, Perplexity: 12.4286\n",
      "Epoch [4/25], Step [10900/41412], Loss: 1.7631, Perplexity: 5.83036\n",
      "Epoch [4/25], Step [11000/41412], Loss: 2.4155, Perplexity: 11.1954\n",
      "Epoch [4/25], Step [11100/41412], Loss: 2.3298, Perplexity: 10.2759\n",
      "Epoch [4/25], Step [11200/41412], Loss: 1.9144, Perplexity: 6.78307\n",
      "Epoch [4/25], Step [11300/41412], Loss: 2.2819, Perplexity: 9.79564\n",
      "Epoch [4/25], Step [11400/41412], Loss: 2.0779, Perplexity: 7.98804\n",
      "Epoch [4/25], Step [11500/41412], Loss: 1.4129, Perplexity: 4.10792\n",
      "Epoch [4/25], Step [11600/41412], Loss: 2.1287, Perplexity: 8.40417\n",
      "Epoch [4/25], Step [11700/41412], Loss: 2.2109, Perplexity: 9.12425\n",
      "Epoch [4/25], Step [11800/41412], Loss: 3.1018, Perplexity: 22.2369\n",
      "Epoch [4/25], Step [11900/41412], Loss: 2.6512, Perplexity: 14.1706\n",
      "Epoch [4/25], Step [12000/41412], Loss: 2.0078, Perplexity: 7.44694\n",
      "Epoch [4/25], Step [12100/41412], Loss: 1.7564, Perplexity: 5.79130\n",
      "Epoch [4/25], Step [12200/41412], Loss: 1.6216, Perplexity: 5.06113\n",
      "Epoch [4/25], Step [12300/41412], Loss: 2.2051, Perplexity: 9.07150\n",
      "Epoch [4/25], Step [12400/41412], Loss: 1.7499, Perplexity: 5.75435\n",
      "Epoch [4/25], Step [12500/41412], Loss: 1.5570, Perplexity: 4.74454\n",
      "Epoch [4/25], Step [12600/41412], Loss: 1.5922, Perplexity: 4.91483\n",
      "Epoch [4/25], Step [12700/41412], Loss: 1.9046, Perplexity: 6.71677\n",
      "Epoch [4/25], Step [12800/41412], Loss: 1.8649, Perplexity: 6.45553\n",
      "Epoch [4/25], Step [12900/41412], Loss: 2.3354, Perplexity: 10.3335\n",
      "Epoch [4/25], Step [13000/41412], Loss: 1.8312, Perplexity: 6.24134\n",
      "Epoch [4/25], Step [13100/41412], Loss: 1.5673, Perplexity: 4.79350\n",
      "Epoch [4/25], Step [13200/41412], Loss: 1.9021, Perplexity: 6.70003\n",
      "Epoch [4/25], Step [13300/41412], Loss: 1.6408, Perplexity: 5.15917\n",
      "Epoch [4/25], Step [13400/41412], Loss: 2.2783, Perplexity: 9.75993\n",
      "Epoch [4/25], Step [13500/41412], Loss: 1.9472, Perplexity: 7.00945\n",
      "Epoch [4/25], Step [13600/41412], Loss: 2.6218, Perplexity: 13.7609\n",
      "Epoch [4/25], Step [13700/41412], Loss: 1.6239, Perplexity: 5.07291\n",
      "Epoch [4/25], Step [13800/41412], Loss: 2.1955, Perplexity: 8.98462\n",
      "Epoch [4/25], Step [13900/41412], Loss: 1.8017, Perplexity: 6.06006\n",
      "Epoch [4/25], Step [14000/41412], Loss: 1.8404, Perplexity: 6.29930\n",
      "Epoch [4/25], Step [14100/41412], Loss: 1.6751, Perplexity: 5.33962\n",
      "Epoch [4/25], Step [14200/41412], Loss: 2.2194, Perplexity: 9.20199\n",
      "Epoch [4/25], Step [14300/41412], Loss: 1.4891, Perplexity: 4.43317\n",
      "Epoch [4/25], Step [14400/41412], Loss: 2.1242, Perplexity: 8.36595\n",
      "Epoch [4/25], Step [14500/41412], Loss: 1.6176, Perplexity: 5.04093\n",
      "Epoch [4/25], Step [14600/41412], Loss: 2.0921, Perplexity: 8.10217\n",
      "Epoch [4/25], Step [14700/41412], Loss: 1.6830, Perplexity: 5.38155\n",
      "Epoch [4/25], Step [14800/41412], Loss: 1.5791, Perplexity: 4.85065\n",
      "Epoch [4/25], Step [14900/41412], Loss: 1.8005, Perplexity: 6.05252\n",
      "Epoch [4/25], Step [15000/41412], Loss: 1.4972, Perplexity: 4.46922\n",
      "Epoch [4/25], Step [15100/41412], Loss: 1.7673, Perplexity: 5.85515\n",
      "Epoch [4/25], Step [15200/41412], Loss: 2.2824, Perplexity: 9.80024\n",
      "Epoch [4/25], Step [15300/41412], Loss: 1.8243, Perplexity: 6.19841\n",
      "Epoch [4/25], Step [15400/41412], Loss: 1.9200, Perplexity: 6.82073\n",
      "Epoch [4/25], Step [15500/41412], Loss: 2.1899, Perplexity: 8.93422\n",
      "Epoch [4/25], Step [15600/41412], Loss: 2.3890, Perplexity: 10.9023\n",
      "Epoch [4/25], Step [15700/41412], Loss: 1.8190, Perplexity: 6.16547\n",
      "Epoch [4/25], Step [15800/41412], Loss: 1.7028, Perplexity: 5.48968\n",
      "Epoch [4/25], Step [15900/41412], Loss: 1.8013, Perplexity: 6.05754\n",
      "Epoch [4/25], Step [16000/41412], Loss: 1.9295, Perplexity: 6.88606\n",
      "Epoch [4/25], Step [16100/41412], Loss: 1.9167, Perplexity: 6.79822\n",
      "Epoch [4/25], Step [16200/41412], Loss: 2.1151, Perplexity: 8.29006\n",
      "Epoch [4/25], Step [16300/41412], Loss: 1.6652, Perplexity: 5.28702\n",
      "Epoch [4/25], Step [16400/41412], Loss: 2.1026, Perplexity: 8.18788\n",
      "Epoch [4/25], Step [16500/41412], Loss: 1.5577, Perplexity: 4.74819\n",
      "Epoch [4/25], Step [16600/41412], Loss: 1.8897, Perplexity: 6.61727\n",
      "Epoch [4/25], Step [16700/41412], Loss: 1.8897, Perplexity: 6.61771\n",
      "Epoch [4/25], Step [16800/41412], Loss: 2.3735, Perplexity: 10.7345\n",
      "Epoch [4/25], Step [16900/41412], Loss: 2.0367, Perplexity: 7.66514\n",
      "Epoch [4/25], Step [17000/41412], Loss: 2.1311, Perplexity: 8.42402\n",
      "Epoch [4/25], Step [17100/41412], Loss: 1.9657, Perplexity: 7.13990\n",
      "Epoch [4/25], Step [17200/41412], Loss: 2.1139, Perplexity: 8.28044\n",
      "Epoch [4/25], Step [17300/41412], Loss: 1.7832, Perplexity: 5.94915\n",
      "Epoch [4/25], Step [17400/41412], Loss: 1.7460, Perplexity: 5.73178\n",
      "Epoch [4/25], Step [17500/41412], Loss: 1.7341, Perplexity: 5.66369\n",
      "Epoch [4/25], Step [17600/41412], Loss: 1.8653, Perplexity: 6.45781\n",
      "Epoch [4/25], Step [17700/41412], Loss: 1.9187, Perplexity: 6.81194\n",
      "Epoch [4/25], Step [17800/41412], Loss: 1.9748, Perplexity: 7.20494\n",
      "Epoch [4/25], Step [17900/41412], Loss: 2.1081, Perplexity: 8.23233\n",
      "Epoch [4/25], Step [18000/41412], Loss: 2.0204, Perplexity: 7.54160\n",
      "Epoch [4/25], Step [18100/41412], Loss: 2.1488, Perplexity: 8.57466\n",
      "Epoch [4/25], Step [18200/41412], Loss: 1.6390, Perplexity: 5.15028\n",
      "Epoch [4/25], Step [18300/41412], Loss: 2.2312, Perplexity: 9.31143\n",
      "Epoch [4/25], Step [18400/41412], Loss: 2.0158, Perplexity: 7.50702\n",
      "Epoch [4/25], Step [18500/41412], Loss: 1.7953, Perplexity: 6.02103\n",
      "Epoch [4/25], Step [18600/41412], Loss: 2.1811, Perplexity: 8.85609\n",
      "Epoch [4/25], Step [18700/41412], Loss: 2.4068, Perplexity: 11.0981\n",
      "Epoch [4/25], Step [18800/41412], Loss: 2.0109, Perplexity: 7.47000\n",
      "Epoch [4/25], Step [18900/41412], Loss: 2.2885, Perplexity: 9.86049\n",
      "Epoch [4/25], Step [19000/41412], Loss: 1.4768, Perplexity: 4.37889\n",
      "Epoch [4/25], Step [19100/41412], Loss: 2.0930, Perplexity: 8.10892\n",
      "Epoch [4/25], Step [19200/41412], Loss: 1.9068, Perplexity: 6.73126\n",
      "Epoch [4/25], Step [19300/41412], Loss: 2.3348, Perplexity: 10.3270\n",
      "Epoch [4/25], Step [19400/41412], Loss: 2.0099, Perplexity: 7.46267\n",
      "Epoch [4/25], Step [19500/41412], Loss: 1.8985, Perplexity: 6.67588\n",
      "Epoch [4/25], Step [19600/41412], Loss: 2.1575, Perplexity: 8.64932\n",
      "Epoch [4/25], Step [19700/41412], Loss: 1.6627, Perplexity: 5.27338\n",
      "Epoch [4/25], Step [19800/41412], Loss: 2.0237, Perplexity: 7.56604\n",
      "Epoch [4/25], Step [19900/41412], Loss: 2.2873, Perplexity: 9.84867\n",
      "Epoch [4/25], Step [20000/41412], Loss: 1.5036, Perplexity: 4.49809\n",
      "Epoch [4/25], Step [20100/41412], Loss: 1.9632, Perplexity: 7.12235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Step [20200/41412], Loss: 1.6667, Perplexity: 5.29450\n",
      "Epoch [4/25], Step [20300/41412], Loss: 2.4770, Perplexity: 11.9050\n",
      "Epoch [4/25], Step [20400/41412], Loss: 2.0926, Perplexity: 8.10578\n",
      "Epoch [4/25], Step [20500/41412], Loss: 1.9760, Perplexity: 7.21354\n",
      "Epoch [4/25], Step [20600/41412], Loss: 1.8712, Perplexity: 6.49594\n",
      "Epoch [4/25], Step [20700/41412], Loss: 1.7550, Perplexity: 5.78334\n",
      "Epoch [4/25], Step [20800/41412], Loss: 1.4319, Perplexity: 4.18655\n",
      "Epoch [4/25], Step [20900/41412], Loss: 2.2054, Perplexity: 9.07392\n",
      "Epoch [4/25], Step [21000/41412], Loss: 2.3491, Perplexity: 10.4766\n",
      "Epoch [4/25], Step [21100/41412], Loss: 1.9302, Perplexity: 6.89063\n",
      "Epoch [4/25], Step [21200/41412], Loss: 2.4397, Perplexity: 11.4697\n",
      "Epoch [4/25], Step [21300/41412], Loss: 2.1072, Perplexity: 8.22489\n",
      "Epoch [4/25], Step [21400/41412], Loss: 2.1690, Perplexity: 8.74992\n",
      "Epoch [4/25], Step [21500/41412], Loss: 2.1399, Perplexity: 8.49833\n",
      "Epoch [4/25], Step [21600/41412], Loss: 1.8724, Perplexity: 6.50378\n",
      "Epoch [4/25], Step [21700/41412], Loss: 1.9615, Perplexity: 7.11017\n",
      "Epoch [4/25], Step [21800/41412], Loss: 2.4786, Perplexity: 11.9241\n",
      "Epoch [4/25], Step [21900/41412], Loss: 1.9597, Perplexity: 7.09729\n",
      "Epoch [4/25], Step [22000/41412], Loss: 1.5022, Perplexity: 4.49158\n",
      "Epoch [4/25], Step [22100/41412], Loss: 2.0914, Perplexity: 8.09604\n",
      "Epoch [4/25], Step [22200/41412], Loss: 1.6318, Perplexity: 5.11337\n",
      "Epoch [4/25], Step [22300/41412], Loss: 2.2781, Perplexity: 9.75847\n",
      "Epoch [4/25], Step [22400/41412], Loss: 2.0455, Perplexity: 7.73302\n",
      "Epoch [4/25], Step [22500/41412], Loss: 2.0542, Perplexity: 7.80048\n",
      "Epoch [4/25], Step [22600/41412], Loss: 1.8592, Perplexity: 6.41839\n",
      "Epoch [4/25], Step [22700/41412], Loss: 2.4681, Perplexity: 11.8005\n",
      "Epoch [4/25], Step [22800/41412], Loss: 1.7153, Perplexity: 5.55840\n",
      "Epoch [4/25], Step [22900/41412], Loss: 2.0679, Perplexity: 7.90827\n",
      "Epoch [4/25], Step [23000/41412], Loss: 1.9913, Perplexity: 7.32474\n",
      "Epoch [4/25], Step [23100/41412], Loss: 2.4427, Perplexity: 11.5045\n",
      "Epoch [4/25], Step [23200/41412], Loss: 1.9594, Perplexity: 7.09499\n",
      "Epoch [4/25], Step [23300/41412], Loss: 1.5830, Perplexity: 4.86945\n",
      "Epoch [4/25], Step [23400/41412], Loss: 1.6263, Perplexity: 5.08516\n",
      "Epoch [4/25], Step [23500/41412], Loss: 1.7842, Perplexity: 5.95461\n",
      "Epoch [4/25], Step [23600/41412], Loss: 1.8506, Perplexity: 6.36357\n",
      "Epoch [4/25], Step [23700/41412], Loss: 1.9227, Perplexity: 6.83940\n",
      "Epoch [4/25], Step [23800/41412], Loss: 2.0915, Perplexity: 8.09711\n",
      "Epoch [4/25], Step [23900/41412], Loss: 1.7550, Perplexity: 5.78359\n",
      "Epoch [4/25], Step [24000/41412], Loss: 1.8876, Perplexity: 6.60362\n",
      "Epoch [4/25], Step [24100/41412], Loss: 1.8879, Perplexity: 6.60541\n",
      "Epoch [4/25], Step [24200/41412], Loss: 1.8988, Perplexity: 6.67805\n",
      "Epoch [4/25], Step [24300/41412], Loss: 2.0450, Perplexity: 7.729289\n",
      "Epoch [4/25], Step [24400/41412], Loss: 2.0838, Perplexity: 8.03505\n",
      "Epoch [4/25], Step [24500/41412], Loss: 2.5213, Perplexity: 12.4449\n",
      "Epoch [4/25], Step [24600/41412], Loss: 1.8751, Perplexity: 6.52126\n",
      "Epoch [4/25], Step [24700/41412], Loss: 1.7895, Perplexity: 5.98673\n",
      "Epoch [4/25], Step [24800/41412], Loss: 1.8278, Perplexity: 6.22038\n",
      "Epoch [4/25], Step [24900/41412], Loss: 1.8889, Perplexity: 6.61228\n",
      "Epoch [4/25], Step [25000/41412], Loss: 1.7160, Perplexity: 5.56247\n",
      "Epoch [4/25], Step [25100/41412], Loss: 1.6290, Perplexity: 5.09881\n",
      "Epoch [4/25], Step [25200/41412], Loss: 2.2197, Perplexity: 9.20445\n",
      "Epoch [4/25], Step [25300/41412], Loss: 1.7551, Perplexity: 5.78425\n",
      "Epoch [4/25], Step [25400/41412], Loss: 1.8407, Perplexity: 6.30088\n",
      "Epoch [4/25], Step [25500/41412], Loss: 2.3393, Perplexity: 10.3742\n",
      "Epoch [4/25], Step [25600/41412], Loss: 2.1301, Perplexity: 8.41576\n",
      "Epoch [4/25], Step [25700/41412], Loss: 2.1914, Perplexity: 8.94763\n",
      "Epoch [4/25], Step [25800/41412], Loss: 1.9284, Perplexity: 6.87873\n",
      "Epoch [4/25], Step [25900/41412], Loss: 1.9284, Perplexity: 6.87855\n",
      "Epoch [4/25], Step [26000/41412], Loss: 1.6802, Perplexity: 5.36652\n",
      "Epoch [4/25], Step [26100/41412], Loss: 2.5396, Perplexity: 12.6741\n",
      "Epoch [4/25], Step [26200/41412], Loss: 2.0520, Perplexity: 7.78384\n",
      "Epoch [4/25], Step [26300/41412], Loss: 2.0327, Perplexity: 7.63471\n",
      "Epoch [4/25], Step [26400/41412], Loss: 1.8809, Perplexity: 6.55910\n",
      "Epoch [4/25], Step [26500/41412], Loss: 1.9412, Perplexity: 6.96699\n",
      "Epoch [4/25], Step [26600/41412], Loss: 2.0315, Perplexity: 7.62543\n",
      "Epoch [4/25], Step [26700/41412], Loss: 2.5960, Perplexity: 13.4102\n",
      "Epoch [4/25], Step [26800/41412], Loss: 1.7124, Perplexity: 5.54238\n",
      "Epoch [4/25], Step [26900/41412], Loss: 1.9388, Perplexity: 6.95016\n",
      "Epoch [4/25], Step [27000/41412], Loss: 2.6823, Perplexity: 14.6186\n",
      "Epoch [4/25], Step [27100/41412], Loss: 2.2375, Perplexity: 9.36958\n",
      "Epoch [4/25], Step [27200/41412], Loss: 2.0835, Perplexity: 8.03252\n",
      "Epoch [4/25], Step [27300/41412], Loss: 1.9753, Perplexity: 7.20899\n",
      "Epoch [4/25], Step [27400/41412], Loss: 1.8122, Perplexity: 6.12414\n",
      "Epoch [4/25], Step [27500/41412], Loss: 2.2624, Perplexity: 9.60600\n",
      "Epoch [4/25], Step [27600/41412], Loss: 2.0644, Perplexity: 7.88046\n",
      "Epoch [4/25], Step [27700/41412], Loss: 2.5840, Perplexity: 13.2499\n",
      "Epoch [4/25], Step [27800/41412], Loss: 1.9680, Perplexity: 7.15649\n",
      "Epoch [4/25], Step [27900/41412], Loss: 1.7388, Perplexity: 5.69064\n",
      "Epoch [4/25], Step [28000/41412], Loss: 1.7806, Perplexity: 5.93379\n",
      "Epoch [4/25], Step [28100/41412], Loss: 2.0960, Perplexity: 8.13375\n",
      "Epoch [4/25], Step [28200/41412], Loss: 2.6887, Perplexity: 14.7120\n",
      "Epoch [4/25], Step [28300/41412], Loss: 1.6231, Perplexity: 5.06900\n",
      "Epoch [4/25], Step [28400/41412], Loss: 1.8454, Perplexity: 6.33059\n",
      "Epoch [4/25], Step [28500/41412], Loss: 1.7946, Perplexity: 6.01729\n",
      "Epoch [4/25], Step [28600/41412], Loss: 1.6734, Perplexity: 5.33035\n",
      "Epoch [4/25], Step [28700/41412], Loss: 1.7929, Perplexity: 6.00714\n",
      "Epoch [4/25], Step [28800/41412], Loss: 2.2684, Perplexity: 9.66363\n",
      "Epoch [4/25], Step [28900/41412], Loss: 1.7641, Perplexity: 5.83646\n",
      "Epoch [4/25], Step [29000/41412], Loss: 2.2138, Perplexity: 9.15059\n",
      "Epoch [4/25], Step [29100/41412], Loss: 1.8869, Perplexity: 6.59919\n",
      "Epoch [4/25], Step [29200/41412], Loss: 1.3658, Perplexity: 3.91880\n",
      "Epoch [4/25], Step [29300/41412], Loss: 2.1352, Perplexity: 8.45898\n",
      "Epoch [4/25], Step [29400/41412], Loss: 1.4658, Perplexity: 4.33123\n",
      "Epoch [4/25], Step [29500/41412], Loss: 1.9580, Perplexity: 7.08544\n",
      "Epoch [4/25], Step [29600/41412], Loss: 1.9860, Perplexity: 7.28649\n",
      "Epoch [4/25], Step [29700/41412], Loss: 2.3252, Perplexity: 10.2286\n",
      "Epoch [4/25], Step [29800/41412], Loss: 2.6713, Perplexity: 14.4594\n",
      "Epoch [4/25], Step [29900/41412], Loss: 2.1526, Perplexity: 8.60733\n",
      "Epoch [4/25], Step [30000/41412], Loss: 1.9146, Perplexity: 6.78403\n",
      "Epoch [4/25], Step [30100/41412], Loss: 1.8434, Perplexity: 6.31789\n",
      "Epoch [4/25], Step [30200/41412], Loss: 1.6041, Perplexity: 4.97321\n",
      "Epoch [4/25], Step [30300/41412], Loss: 2.2956, Perplexity: 9.93044\n",
      "Epoch [4/25], Step [30400/41412], Loss: 1.9507, Perplexity: 7.03392\n",
      "Epoch [4/25], Step [30500/41412], Loss: 1.7301, Perplexity: 5.64095\n",
      "Epoch [4/25], Step [30600/41412], Loss: 2.3549, Perplexity: 10.5369\n",
      "Epoch [4/25], Step [30700/41412], Loss: 1.7862, Perplexity: 5.96661\n",
      "Epoch [4/25], Step [30800/41412], Loss: 1.9427, Perplexity: 6.97736\n",
      "Epoch [4/25], Step [30900/41412], Loss: 2.2646, Perplexity: 9.62698\n",
      "Epoch [4/25], Step [31000/41412], Loss: 1.8490, Perplexity: 6.35359\n",
      "Epoch [4/25], Step [31100/41412], Loss: 1.8203, Perplexity: 6.17395\n",
      "Epoch [4/25], Step [31200/41412], Loss: 1.7742, Perplexity: 5.89589\n",
      "Epoch [4/25], Step [31300/41412], Loss: 2.2441, Perplexity: 9.43184\n",
      "Epoch [4/25], Step [31400/41412], Loss: 2.0498, Perplexity: 7.76610\n",
      "Epoch [4/25], Step [31500/41412], Loss: 1.8315, Perplexity: 6.24331\n",
      "Epoch [4/25], Step [31600/41412], Loss: 1.9392, Perplexity: 6.95334\n",
      "Epoch [4/25], Step [31700/41412], Loss: 1.8408, Perplexity: 6.30180\n",
      "Epoch [4/25], Step [31800/41412], Loss: 1.7367, Perplexity: 5.67879\n",
      "Epoch [4/25], Step [31900/41412], Loss: 1.8303, Perplexity: 6.23602\n",
      "Epoch [4/25], Step [32000/41412], Loss: 2.4207, Perplexity: 11.2539\n",
      "Epoch [4/25], Step [32100/41412], Loss: 2.0609, Perplexity: 7.85297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Step [32200/41412], Loss: 1.9675, Perplexity: 7.15279\n",
      "Epoch [4/25], Step [32300/41412], Loss: 1.9351, Perplexity: 6.92454\n",
      "Epoch [4/25], Step [32400/41412], Loss: 2.2790, Perplexity: 9.76675\n",
      "Epoch [4/25], Step [32500/41412], Loss: 1.5860, Perplexity: 4.88430\n",
      "Epoch [4/25], Step [32600/41412], Loss: 2.1605, Perplexity: 8.67569\n",
      "Epoch [4/25], Step [32700/41412], Loss: 2.0284, Perplexity: 7.60160\n",
      "Epoch [4/25], Step [32800/41412], Loss: 2.1473, Perplexity: 8.56153\n",
      "Epoch [4/25], Step [32900/41412], Loss: 1.4850, Perplexity: 4.41494\n",
      "Epoch [4/25], Step [33000/41412], Loss: 1.7106, Perplexity: 5.53252\n",
      "Epoch [4/25], Step [33100/41412], Loss: 1.9767, Perplexity: 7.21908\n",
      "Epoch [4/25], Step [33200/41412], Loss: 1.9731, Perplexity: 7.19320\n",
      "Epoch [4/25], Step [33300/41412], Loss: 1.7518, Perplexity: 5.76490\n",
      "Epoch [4/25], Step [33400/41412], Loss: 1.6560, Perplexity: 5.23837\n",
      "Epoch [4/25], Step [33500/41412], Loss: 1.4773, Perplexity: 4.38109\n",
      "Epoch [4/25], Step [33600/41412], Loss: 1.6704, Perplexity: 5.31450\n",
      "Epoch [4/25], Step [33700/41412], Loss: 2.3906, Perplexity: 10.9197\n",
      "Epoch [4/25], Step [33800/41412], Loss: 1.6859, Perplexity: 5.39736\n",
      "Epoch [4/25], Step [33900/41412], Loss: 1.8889, Perplexity: 6.61212\n",
      "Epoch [4/25], Step [34000/41412], Loss: 2.3804, Perplexity: 10.8090\n",
      "Epoch [4/25], Step [34100/41412], Loss: 1.9291, Perplexity: 6.88320\n",
      "Epoch [4/25], Step [34200/41412], Loss: 1.8685, Perplexity: 6.47885\n",
      "Epoch [4/25], Step [34300/41412], Loss: 1.8890, Perplexity: 6.612728\n",
      "Epoch [4/25], Step [34400/41412], Loss: 1.4889, Perplexity: 4.43218\n",
      "Epoch [4/25], Step [34500/41412], Loss: 2.1841, Perplexity: 8.88282\n",
      "Epoch [4/25], Step [34600/41412], Loss: 1.5372, Perplexity: 4.65158\n",
      "Epoch [4/25], Step [34700/41412], Loss: 2.5276, Perplexity: 12.5236\n",
      "Epoch [4/25], Step [34800/41412], Loss: 2.0283, Perplexity: 7.60139\n",
      "Epoch [4/25], Step [34900/41412], Loss: 2.1201, Perplexity: 8.33216\n",
      "Epoch [4/25], Step [35000/41412], Loss: 1.9123, Perplexity: 6.76847\n",
      "Epoch [4/25], Step [35100/41412], Loss: 1.8107, Perplexity: 6.11509\n",
      "Epoch [4/25], Step [35200/41412], Loss: 2.3113, Perplexity: 10.0875\n",
      "Epoch [4/25], Step [35300/41412], Loss: 2.1272, Perplexity: 8.39148\n",
      "Epoch [4/25], Step [35400/41412], Loss: 1.6726, Perplexity: 5.32600\n",
      "Epoch [4/25], Step [35500/41412], Loss: 1.7595, Perplexity: 5.80940\n",
      "Epoch [4/25], Step [35600/41412], Loss: 2.3425, Perplexity: 10.4076\n",
      "Epoch [4/25], Step [35700/41412], Loss: 1.9714, Perplexity: 7.18056\n",
      "Epoch [4/25], Step [35800/41412], Loss: 1.5485, Perplexity: 4.70460\n",
      "Epoch [4/25], Step [35900/41412], Loss: 2.6655, Perplexity: 14.3747\n",
      "Epoch [4/25], Step [36000/41412], Loss: 2.2542, Perplexity: 9.52733\n",
      "Epoch [4/25], Step [36100/41412], Loss: 2.1732, Perplexity: 8.78615\n",
      "Epoch [4/25], Step [36200/41412], Loss: 1.9003, Perplexity: 6.68813\n",
      "Epoch [4/25], Step [36300/41412], Loss: 2.2302, Perplexity: 9.30155\n",
      "Epoch [4/25], Step [36400/41412], Loss: 2.0651, Perplexity: 7.88626\n",
      "Epoch [4/25], Step [36500/41412], Loss: 2.1454, Perplexity: 8.54576\n",
      "Epoch [4/25], Step [36600/41412], Loss: 2.0388, Perplexity: 7.68121\n",
      "Epoch [4/25], Step [36700/41412], Loss: 2.7034, Perplexity: 14.9300\n",
      "Epoch [4/25], Step [36800/41412], Loss: 1.7587, Perplexity: 5.80502\n",
      "Epoch [4/25], Step [36900/41412], Loss: 1.9195, Perplexity: 6.81751\n",
      "Epoch [4/25], Step [37000/41412], Loss: 1.7839, Perplexity: 5.95287\n",
      "Epoch [4/25], Step [37100/41412], Loss: 1.9376, Perplexity: 6.94200\n",
      "Epoch [4/25], Step [37200/41412], Loss: 1.9750, Perplexity: 7.20694\n",
      "Epoch [4/25], Step [37300/41412], Loss: 1.9379, Perplexity: 6.94425\n",
      "Epoch [4/25], Step [37400/41412], Loss: 1.9792, Perplexity: 7.23688\n",
      "Epoch [4/25], Step [37500/41412], Loss: 1.7097, Perplexity: 5.52726\n",
      "Epoch [4/25], Step [37600/41412], Loss: 2.2038, Perplexity: 9.05983\n",
      "Epoch [4/25], Step [37700/41412], Loss: 2.1083, Perplexity: 8.23448\n",
      "Epoch [4/25], Step [37800/41412], Loss: 2.3409, Perplexity: 10.3907\n",
      "Epoch [4/25], Step [37900/41412], Loss: 2.3197, Perplexity: 10.1723\n",
      "Epoch [4/25], Step [38000/41412], Loss: 1.8817, Perplexity: 6.56485\n",
      "Epoch [4/25], Step [38100/41412], Loss: 1.8613, Perplexity: 6.43216\n",
      "Epoch [4/25], Step [38200/41412], Loss: 1.8464, Perplexity: 6.33699\n",
      "Epoch [4/25], Step [38300/41412], Loss: 1.7361, Perplexity: 5.67499\n",
      "Epoch [4/25], Step [38400/41412], Loss: 2.2922, Perplexity: 9.89633\n",
      "Epoch [4/25], Step [38500/41412], Loss: 1.8004, Perplexity: 6.05180\n",
      "Epoch [4/25], Step [38600/41412], Loss: 1.8091, Perplexity: 6.10487\n",
      "Epoch [4/25], Step [38700/41412], Loss: 2.2296, Perplexity: 9.29667\n",
      "Epoch [4/25], Step [38800/41412], Loss: 2.8241, Perplexity: 16.8463\n",
      "Epoch [4/25], Step [38900/41412], Loss: 2.0174, Perplexity: 7.51853\n",
      "Epoch [4/25], Step [39000/41412], Loss: 2.7288, Perplexity: 15.3149\n",
      "Epoch [4/25], Step [39100/41412], Loss: 1.6915, Perplexity: 5.42785\n",
      "Epoch [4/25], Step [39200/41412], Loss: 1.7319, Perplexity: 5.65151\n",
      "Epoch [4/25], Step [39300/41412], Loss: 2.3037, Perplexity: 10.0113\n",
      "Epoch [4/25], Step [39400/41412], Loss: 1.9461, Perplexity: 7.00109\n",
      "Epoch [4/25], Step [39500/41412], Loss: 1.4819, Perplexity: 4.40159\n",
      "Epoch [4/25], Step [39600/41412], Loss: 1.5992, Perplexity: 4.94917\n",
      "Epoch [4/25], Step [39700/41412], Loss: 2.3461, Perplexity: 10.4448\n",
      "Epoch [4/25], Step [39800/41412], Loss: 2.4396, Perplexity: 11.4679\n",
      "Epoch [4/25], Step [39900/41412], Loss: 1.6184, Perplexity: 5.04511\n",
      "Epoch [4/25], Step [40000/41412], Loss: 1.9329, Perplexity: 6.90925\n",
      "Epoch [4/25], Step [40100/41412], Loss: 1.7087, Perplexity: 5.52196\n",
      "Epoch [4/25], Step [40200/41412], Loss: 1.7281, Perplexity: 5.63010\n",
      "Epoch [4/25], Step [40300/41412], Loss: 2.1336, Perplexity: 8.44569\n",
      "Epoch [4/25], Step [40400/41412], Loss: 1.5279, Perplexity: 4.60877\n",
      "Epoch [4/25], Step [40500/41412], Loss: 2.0619, Perplexity: 7.86095\n",
      "Epoch [4/25], Step [40600/41412], Loss: 2.0148, Perplexity: 7.49966\n",
      "Epoch [4/25], Step [40700/41412], Loss: 1.6869, Perplexity: 5.40251\n",
      "Epoch [4/25], Step [40800/41412], Loss: 2.1688, Perplexity: 8.74743\n",
      "Epoch [4/25], Step [40900/41412], Loss: 1.7468, Perplexity: 5.73615\n",
      "Epoch [4/25], Step [41000/41412], Loss: 2.5995, Perplexity: 13.4573\n",
      "Epoch [4/25], Step [41100/41412], Loss: 1.6307, Perplexity: 5.10723\n",
      "Epoch [4/25], Step [41200/41412], Loss: 1.8742, Perplexity: 6.51591\n",
      "Epoch [4/25], Step [41300/41412], Loss: 2.5267, Perplexity: 12.5117\n",
      "Epoch [4/25], Step [41400/41412], Loss: 1.8085, Perplexity: 6.10149\n",
      "Epoch [5/25], Step [100/41412], Loss: 1.9042, Perplexity: 6.7138580\n",
      "Epoch [5/25], Step [200/41412], Loss: 2.1344, Perplexity: 8.45188\n",
      "Epoch [5/25], Step [300/41412], Loss: 1.9831, Perplexity: 7.26512\n",
      "Epoch [5/25], Step [400/41412], Loss: 2.2888, Perplexity: 9.86281\n",
      "Epoch [5/25], Step [500/41412], Loss: 1.4282, Perplexity: 4.17126\n",
      "Epoch [5/25], Step [600/41412], Loss: 2.0545, Perplexity: 7.80266\n",
      "Epoch [5/25], Step [700/41412], Loss: 1.8460, Perplexity: 6.33478\n",
      "Epoch [5/25], Step [800/41412], Loss: 2.2635, Perplexity: 9.61641\n",
      "Epoch [5/25], Step [900/41412], Loss: 1.7168, Perplexity: 5.56664\n",
      "Epoch [5/25], Step [1000/41412], Loss: 2.5708, Perplexity: 13.0769\n",
      "Epoch [5/25], Step [1100/41412], Loss: 1.4437, Perplexity: 4.23652\n",
      "Epoch [5/25], Step [1200/41412], Loss: 2.1641, Perplexity: 8.70686\n",
      "Epoch [5/25], Step [1300/41412], Loss: 1.6678, Perplexity: 5.30056\n",
      "Epoch [5/25], Step [1400/41412], Loss: 2.2149, Perplexity: 9.16072\n",
      "Epoch [5/25], Step [1500/41412], Loss: 2.1470, Perplexity: 8.55900\n",
      "Epoch [5/25], Step [1600/41412], Loss: 2.0458, Perplexity: 7.73515\n",
      "Epoch [5/25], Step [1700/41412], Loss: 2.2307, Perplexity: 9.30640\n",
      "Epoch [5/25], Step [1800/41412], Loss: 2.0924, Perplexity: 8.10478\n",
      "Epoch [5/25], Step [1900/41412], Loss: 1.9125, Perplexity: 6.77003\n",
      "Epoch [5/25], Step [2000/41412], Loss: 1.9708, Perplexity: 7.17620\n",
      "Epoch [5/25], Step [2100/41412], Loss: 2.0873, Perplexity: 8.06331\n",
      "Epoch [5/25], Step [2200/41412], Loss: 1.6767, Perplexity: 5.34805\n",
      "Epoch [5/25], Step [2300/41412], Loss: 1.6830, Perplexity: 5.38187\n",
      "Epoch [5/25], Step [2400/41412], Loss: 2.0071, Perplexity: 7.44164\n",
      "Epoch [5/25], Step [2500/41412], Loss: 2.1773, Perplexity: 8.82215\n",
      "Epoch [5/25], Step [2600/41412], Loss: 1.8327, Perplexity: 6.25091\n",
      "Epoch [5/25], Step [2700/41412], Loss: 1.9952, Perplexity: 7.35379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Step [2800/41412], Loss: 1.8802, Perplexity: 6.55484\n",
      "Epoch [5/25], Step [2900/41412], Loss: 2.0746, Perplexity: 7.96118\n",
      "Epoch [5/25], Step [3000/41412], Loss: 1.9318, Perplexity: 6.90193\n",
      "Epoch [5/25], Step [3100/41412], Loss: 1.8510, Perplexity: 6.36627\n",
      "Epoch [5/25], Step [3200/41412], Loss: 2.2853, Perplexity: 9.82914\n",
      "Epoch [5/25], Step [3300/41412], Loss: 2.0056, Perplexity: 7.43062\n",
      "Epoch [5/25], Step [3400/41412], Loss: 1.8574, Perplexity: 6.40684\n",
      "Epoch [5/25], Step [3500/41412], Loss: 2.0561, Perplexity: 7.81557\n",
      "Epoch [5/25], Step [3600/41412], Loss: 1.6683, Perplexity: 5.30319\n",
      "Epoch [5/25], Step [3700/41412], Loss: 1.8676, Perplexity: 6.47251\n",
      "Epoch [5/25], Step [3800/41412], Loss: 1.8744, Perplexity: 6.51677\n",
      "Epoch [5/25], Step [3900/41412], Loss: 1.9232, Perplexity: 6.84257\n",
      "Epoch [5/25], Step [4000/41412], Loss: 1.8227, Perplexity: 6.18832\n",
      "Epoch [5/25], Step [4100/41412], Loss: 1.8157, Perplexity: 6.14563\n",
      "Epoch [5/25], Step [4200/41412], Loss: 1.7119, Perplexity: 5.53976\n",
      "Epoch [5/25], Step [4300/41412], Loss: 2.1342, Perplexity: 8.44991\n",
      "Epoch [5/25], Step [4400/41412], Loss: 1.3606, Perplexity: 3.89873\n",
      "Epoch [5/25], Step [4500/41412], Loss: 1.9124, Perplexity: 6.76957\n",
      "Epoch [5/25], Step [4600/41412], Loss: 1.9697, Perplexity: 7.16899\n",
      "Epoch [5/25], Step [4700/41412], Loss: 1.4021, Perplexity: 4.06366\n",
      "Epoch [5/25], Step [4800/41412], Loss: 2.0764, Perplexity: 7.97531\n",
      "Epoch [5/25], Step [4900/41412], Loss: 2.0323, Perplexity: 7.63134\n",
      "Epoch [5/25], Step [5000/41412], Loss: 1.8344, Perplexity: 6.26168\n",
      "Epoch [5/25], Step [5100/41412], Loss: 1.7626, Perplexity: 5.827556\n",
      "Epoch [5/25], Step [5200/41412], Loss: 1.7293, Perplexity: 5.63666\n",
      "Epoch [5/25], Step [5300/41412], Loss: 1.8849, Perplexity: 6.58547\n",
      "Epoch [5/25], Step [5400/41412], Loss: 1.9557, Perplexity: 7.06871\n",
      "Epoch [5/25], Step [5500/41412], Loss: 2.2611, Perplexity: 9.59398\n",
      "Epoch [5/25], Step [5600/41412], Loss: 1.9995, Perplexity: 7.38526\n",
      "Epoch [5/25], Step [5700/41412], Loss: 2.6077, Perplexity: 13.5674\n",
      "Epoch [5/25], Step [5800/41412], Loss: 1.6694, Perplexity: 5.30913\n",
      "Epoch [5/25], Step [5900/41412], Loss: 1.7543, Perplexity: 5.77923\n",
      "Epoch [5/25], Step [6000/41412], Loss: 2.1795, Perplexity: 8.84187\n",
      "Epoch [5/25], Step [6100/41412], Loss: 1.8852, Perplexity: 6.58770\n",
      "Epoch [5/25], Step [6200/41412], Loss: 1.9687, Perplexity: 7.16123\n",
      "Epoch [5/25], Step [6300/41412], Loss: 1.9520, Perplexity: 7.04262\n",
      "Epoch [5/25], Step [6400/41412], Loss: 2.2382, Perplexity: 9.37641\n",
      "Epoch [5/25], Step [6500/41412], Loss: 1.8738, Perplexity: 6.51296\n",
      "Epoch [5/25], Step [6600/41412], Loss: 2.3171, Perplexity: 10.1464\n",
      "Epoch [5/25], Step [6700/41412], Loss: 2.0332, Perplexity: 7.63874\n",
      "Epoch [5/25], Step [6800/41412], Loss: 2.1720, Perplexity: 8.77583\n",
      "Epoch [5/25], Step [6900/41412], Loss: 2.1112, Perplexity: 8.25794\n",
      "Epoch [5/25], Step [7000/41412], Loss: 1.7465, Perplexity: 5.73441\n",
      "Epoch [5/25], Step [7100/41412], Loss: 2.2541, Perplexity: 9.52644\n",
      "Epoch [5/25], Step [7200/41412], Loss: 1.6813, Perplexity: 5.37247\n",
      "Epoch [5/25], Step [7300/41412], Loss: 1.9543, Perplexity: 7.05874\n",
      "Epoch [5/25], Step [7400/41412], Loss: 2.4966, Perplexity: 12.1415\n",
      "Epoch [5/25], Step [7500/41412], Loss: 1.5817, Perplexity: 4.86332\n",
      "Epoch [5/25], Step [7600/41412], Loss: 2.0980, Perplexity: 8.15001\n",
      "Epoch [5/25], Step [7700/41412], Loss: 1.8638, Perplexity: 6.44852\n",
      "Epoch [5/25], Step [7800/41412], Loss: 1.7883, Perplexity: 5.97925\n",
      "Epoch [5/25], Step [7900/41412], Loss: 1.4599, Perplexity: 4.30560\n",
      "Epoch [5/25], Step [8000/41412], Loss: 1.8112, Perplexity: 6.11753\n",
      "Epoch [5/25], Step [8100/41412], Loss: 2.3465, Perplexity: 10.4489\n",
      "Epoch [5/25], Step [8200/41412], Loss: 1.8934, Perplexity: 6.64184\n",
      "Epoch [5/25], Step [8300/41412], Loss: 2.0101, Perplexity: 7.46437\n",
      "Epoch [5/25], Step [8400/41412], Loss: 1.7601, Perplexity: 5.81297\n",
      "Epoch [5/25], Step [8500/41412], Loss: 1.6026, Perplexity: 4.96608\n",
      "Epoch [5/25], Step [8600/41412], Loss: 2.0348, Perplexity: 7.65064\n",
      "Epoch [5/25], Step [8700/41412], Loss: 2.1474, Perplexity: 8.56289\n",
      "Epoch [5/25], Step [8800/41412], Loss: 2.1337, Perplexity: 8.44612\n",
      "Epoch [5/25], Step [8900/41412], Loss: 2.2429, Perplexity: 9.42092\n",
      "Epoch [5/25], Step [9000/41412], Loss: 1.7886, Perplexity: 5.98128\n",
      "Epoch [5/25], Step [9100/41412], Loss: 2.0247, Perplexity: 7.57388\n",
      "Epoch [5/25], Step [9200/41412], Loss: 2.3042, Perplexity: 10.0159\n",
      "Epoch [5/25], Step [9300/41412], Loss: 1.5095, Perplexity: 4.52470\n",
      "Epoch [5/25], Step [9400/41412], Loss: 1.9112, Perplexity: 6.76107\n",
      "Epoch [5/25], Step [9500/41412], Loss: 1.4503, Perplexity: 4.26433\n",
      "Epoch [5/25], Step [9600/41412], Loss: 2.5061, Perplexity: 12.2565\n",
      "Epoch [5/25], Step [9700/41412], Loss: 1.7123, Perplexity: 5.54163\n",
      "Epoch [5/25], Step [9800/41412], Loss: 1.7058, Perplexity: 5.50562\n",
      "Epoch [5/25], Step [9900/41412], Loss: 1.8552, Perplexity: 6.39297\n",
      "Epoch [5/25], Step [10000/41412], Loss: 1.6484, Perplexity: 5.1985\n",
      "Epoch [5/25], Step [10100/41412], Loss: 1.6648, Perplexity: 5.28482\n",
      "Epoch [5/25], Step [10200/41412], Loss: 2.3173, Perplexity: 10.1487\n",
      "Epoch [5/25], Step [10300/41412], Loss: 1.4076, Perplexity: 4.08636\n",
      "Epoch [5/25], Step [10400/41412], Loss: 2.2719, Perplexity: 9.69788\n",
      "Epoch [5/25], Step [10500/41412], Loss: 2.2068, Perplexity: 9.08643\n",
      "Epoch [5/25], Step [10600/41412], Loss: 2.1000, Perplexity: 8.16629\n",
      "Epoch [5/25], Step [10700/41412], Loss: 1.7231, Perplexity: 5.60204\n",
      "Epoch [5/25], Step [10800/41412], Loss: 1.9295, Perplexity: 6.88597\n",
      "Epoch [5/25], Step [10900/41412], Loss: 2.0264, Perplexity: 7.58676\n",
      "Epoch [5/25], Step [11000/41412], Loss: 2.0311, Perplexity: 7.622180\n",
      "Epoch [5/25], Step [11100/41412], Loss: 1.8145, Perplexity: 6.13791\n",
      "Epoch [5/25], Step [11200/41412], Loss: 1.8719, Perplexity: 6.50045\n",
      "Epoch [5/25], Step [11300/41412], Loss: 2.0609, Perplexity: 7.85288\n",
      "Epoch [5/25], Step [11400/41412], Loss: 2.0143, Perplexity: 7.49588\n",
      "Epoch [5/25], Step [11500/41412], Loss: 1.9274, Perplexity: 6.87169\n",
      "Epoch [5/25], Step [11600/41412], Loss: 1.6865, Perplexity: 5.40047\n",
      "Epoch [5/25], Step [11700/41412], Loss: 2.0660, Perplexity: 7.89295\n",
      "Epoch [5/25], Step [11800/41412], Loss: 3.0158, Perplexity: 20.4060\n",
      "Epoch [5/25], Step [11900/41412], Loss: 2.0208, Perplexity: 7.54453\n",
      "Epoch [5/25], Step [12000/41412], Loss: 1.9689, Perplexity: 7.16270\n",
      "Epoch [5/25], Step [12100/41412], Loss: 1.8955, Perplexity: 6.65573\n",
      "Epoch [5/25], Step [12200/41412], Loss: 1.5913, Perplexity: 4.91022\n",
      "Epoch [5/25], Step [12300/41412], Loss: 1.5733, Perplexity: 4.82274\n",
      "Epoch [5/25], Step [12400/41412], Loss: 2.3781, Perplexity: 10.7841\n",
      "Epoch [5/25], Step [12500/41412], Loss: 1.8198, Perplexity: 6.17073\n",
      "Epoch [5/25], Step [12600/41412], Loss: 1.8036, Perplexity: 6.07188\n",
      "Epoch [5/25], Step [12700/41412], Loss: 1.9174, Perplexity: 6.80319\n",
      "Epoch [5/25], Step [12800/41412], Loss: 1.5663, Perplexity: 4.78873\n",
      "Epoch [5/25], Step [12900/41412], Loss: 1.9772, Perplexity: 7.22293\n",
      "Epoch [5/25], Step [13000/41412], Loss: 1.9983, Perplexity: 7.37699\n",
      "Epoch [5/25], Step [13100/41412], Loss: 1.0787, Perplexity: 2.94093\n",
      "Epoch [5/25], Step [13200/41412], Loss: 2.0998, Perplexity: 8.16484\n",
      "Epoch [5/25], Step [13300/41412], Loss: 1.7766, Perplexity: 5.91009\n",
      "Epoch [5/25], Step [13400/41412], Loss: 1.9382, Perplexity: 6.94607\n",
      "Epoch [5/25], Step [13500/41412], Loss: 1.9831, Perplexity: 7.26540\n",
      "Epoch [5/25], Step [13600/41412], Loss: 2.0261, Perplexity: 7.58450\n",
      "Epoch [5/25], Step [13700/41412], Loss: 2.1809, Perplexity: 8.85415\n",
      "Epoch [5/25], Step [13800/41412], Loss: 2.4052, Perplexity: 11.0807\n",
      "Epoch [5/25], Step [13900/41412], Loss: 2.0526, Perplexity: 7.78801\n",
      "Epoch [5/25], Step [14000/41412], Loss: 2.2468, Perplexity: 9.45786\n",
      "Epoch [5/25], Step [14100/41412], Loss: 2.3029, Perplexity: 10.0028\n",
      "Epoch [5/25], Step [14200/41412], Loss: 2.2575, Perplexity: 9.55949\n",
      "Epoch [5/25], Step [14300/41412], Loss: 1.9880, Perplexity: 7.30115\n",
      "Epoch [5/25], Step [14400/41412], Loss: 1.7280, Perplexity: 5.62931\n",
      "Epoch [5/25], Step [14500/41412], Loss: 1.8014, Perplexity: 6.05845\n",
      "Epoch [5/25], Step [14600/41412], Loss: 2.8393, Perplexity: 17.1043\n",
      "Epoch [5/25], Step [14700/41412], Loss: 1.6006, Perplexity: 4.95602\n",
      "Epoch [5/25], Step [14800/41412], Loss: 1.9835, Perplexity: 7.26842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Step [14900/41412], Loss: 2.4379, Perplexity: 11.4495\n",
      "Epoch [5/25], Step [15000/41412], Loss: 1.7691, Perplexity: 5.86569\n",
      "Epoch [5/25], Step [15100/41412], Loss: 1.5701, Perplexity: 4.80718\n",
      "Epoch [5/25], Step [15200/41412], Loss: 2.0227, Perplexity: 7.55897\n",
      "Epoch [5/25], Step [15300/41412], Loss: 1.6998, Perplexity: 5.47319\n",
      "Epoch [5/25], Step [15400/41412], Loss: 1.7549, Perplexity: 5.78294\n",
      "Epoch [5/25], Step [15500/41412], Loss: 1.7964, Perplexity: 6.02788\n",
      "Epoch [5/25], Step [15600/41412], Loss: 2.1809, Perplexity: 8.85391\n",
      "Epoch [5/25], Step [15700/41412], Loss: 2.0690, Perplexity: 7.91709\n",
      "Epoch [5/25], Step [15800/41412], Loss: 1.8212, Perplexity: 6.17906\n",
      "Epoch [5/25], Step [15900/41412], Loss: 2.2694, Perplexity: 9.67377\n",
      "Epoch [5/25], Step [16000/41412], Loss: 2.0199, Perplexity: 7.53799\n",
      "Epoch [5/25], Step [16100/41412], Loss: 1.7793, Perplexity: 5.92590\n",
      "Epoch [5/25], Step [16200/41412], Loss: 2.5399, Perplexity: 12.6788\n",
      "Epoch [5/25], Step [16300/41412], Loss: 1.9081, Perplexity: 6.74024\n",
      "Epoch [5/25], Step [16400/41412], Loss: 2.6541, Perplexity: 14.2126\n",
      "Epoch [5/25], Step [16500/41412], Loss: 1.6399, Perplexity: 5.15480\n",
      "Epoch [5/25], Step [16600/41412], Loss: 2.2483, Perplexity: 9.47146\n",
      "Epoch [5/25], Step [16700/41412], Loss: 1.6438, Perplexity: 5.17486\n",
      "Epoch [5/25], Step [16800/41412], Loss: 2.3372, Perplexity: 10.3517\n",
      "Epoch [5/25], Step [16900/41412], Loss: 2.4739, Perplexity: 11.8684\n",
      "Epoch [5/25], Step [17000/41412], Loss: 1.7746, Perplexity: 5.89788\n",
      "Epoch [5/25], Step [17100/41412], Loss: 1.4344, Perplexity: 4.19725\n",
      "Epoch [5/25], Step [17200/41412], Loss: 1.5760, Perplexity: 4.83573\n",
      "Epoch [5/25], Step [17300/41412], Loss: 1.8465, Perplexity: 6.33776\n",
      "Epoch [5/25], Step [17400/41412], Loss: 2.0105, Perplexity: 7.46723\n",
      "Epoch [5/25], Step [17500/41412], Loss: 2.3515, Perplexity: 10.5017\n",
      "Epoch [5/25], Step [17600/41412], Loss: 2.4805, Perplexity: 11.9473\n",
      "Epoch [5/25], Step [17700/41412], Loss: 2.0325, Perplexity: 7.63284\n",
      "Epoch [5/25], Step [17800/41412], Loss: 1.9460, Perplexity: 7.00104\n",
      "Epoch [5/25], Step [17900/41412], Loss: 1.6022, Perplexity: 4.96378\n",
      "Epoch [5/25], Step [18000/41412], Loss: 2.1958, Perplexity: 8.98695\n",
      "Epoch [5/25], Step [18100/41412], Loss: 2.4268, Perplexity: 11.3228\n",
      "Epoch [5/25], Step [18200/41412], Loss: 1.9448, Perplexity: 6.99222\n",
      "Epoch [5/25], Step [18300/41412], Loss: 1.8065, Perplexity: 6.08943\n",
      "Epoch [5/25], Step [18400/41412], Loss: 2.1129, Perplexity: 8.27247\n",
      "Epoch [5/25], Step [18500/41412], Loss: 2.0877, Perplexity: 8.06642\n",
      "Epoch [5/25], Step [18600/41412], Loss: 1.6951, Perplexity: 5.44721\n",
      "Epoch [5/25], Step [18700/41412], Loss: 2.2775, Perplexity: 9.75258\n",
      "Epoch [5/25], Step [18800/41412], Loss: 1.7842, Perplexity: 5.95471\n",
      "Epoch [5/25], Step [18900/41412], Loss: 2.3471, Perplexity: 10.4549\n",
      "Epoch [5/25], Step [19000/41412], Loss: 1.9690, Perplexity: 7.16370\n",
      "Epoch [5/25], Step [19100/41412], Loss: 1.9615, Perplexity: 7.11010\n",
      "Epoch [5/25], Step [19200/41412], Loss: 2.2436, Perplexity: 9.42685\n",
      "Epoch [5/25], Step [19300/41412], Loss: 2.0519, Perplexity: 7.78267\n",
      "Epoch [5/25], Step [19400/41412], Loss: 1.7475, Perplexity: 5.74011\n",
      "Epoch [5/25], Step [19500/41412], Loss: 2.0508, Perplexity: 7.77459\n",
      "Epoch [5/25], Step [19600/41412], Loss: 1.7164, Perplexity: 5.56426\n",
      "Epoch [5/25], Step [19700/41412], Loss: 2.1172, Perplexity: 8.30825\n",
      "Epoch [5/25], Step [19800/41412], Loss: 1.9477, Perplexity: 7.01246\n",
      "Epoch [5/25], Step [19900/41412], Loss: 2.0908, Perplexity: 8.09176\n",
      "Epoch [5/25], Step [20000/41412], Loss: 2.2390, Perplexity: 9.38401\n",
      "Epoch [5/25], Step [20100/41412], Loss: 2.1786, Perplexity: 8.83375\n",
      "Epoch [5/25], Step [20200/41412], Loss: 1.9243, Perplexity: 6.85064\n",
      "Epoch [5/25], Step [20300/41412], Loss: 1.7235, Perplexity: 5.60415\n",
      "Epoch [5/25], Step [20400/41412], Loss: 2.4798, Perplexity: 11.9388\n",
      "Epoch [5/25], Step [20500/41412], Loss: 2.1293, Perplexity: 8.40866\n",
      "Epoch [5/25], Step [20600/41412], Loss: 2.1984, Perplexity: 9.01077\n",
      "Epoch [5/25], Step [20700/41412], Loss: 1.5712, Perplexity: 4.81247\n",
      "Epoch [5/25], Step [20800/41412], Loss: 1.8013, Perplexity: 6.05734\n",
      "Epoch [5/25], Step [20900/41412], Loss: 2.4750, Perplexity: 11.8820\n",
      "Epoch [5/25], Step [21000/41412], Loss: 2.1148, Perplexity: 8.28774\n",
      "Epoch [5/25], Step [21100/41412], Loss: 1.6201, Perplexity: 5.05380\n",
      "Epoch [5/25], Step [21200/41412], Loss: 1.7815, Perplexity: 5.93857\n",
      "Epoch [5/25], Step [21300/41412], Loss: 2.0988, Perplexity: 8.15624\n",
      "Epoch [5/25], Step [21400/41412], Loss: 1.8794, Perplexity: 6.54997\n",
      "Epoch [5/25], Step [21500/41412], Loss: 1.8513, Perplexity: 6.36784\n",
      "Epoch [5/25], Step [21600/41412], Loss: 2.4149, Perplexity: 11.1890\n",
      "Epoch [5/25], Step [21700/41412], Loss: 2.0935, Perplexity: 8.11321\n",
      "Epoch [5/25], Step [21800/41412], Loss: 1.5303, Perplexity: 4.61976\n",
      "Epoch [5/25], Step [21900/41412], Loss: 1.9827, Perplexity: 7.26250\n",
      "Epoch [5/25], Step [22000/41412], Loss: 1.9658, Perplexity: 7.14073\n",
      "Epoch [5/25], Step [22100/41412], Loss: 2.1548, Perplexity: 8.62605\n",
      "Epoch [5/25], Step [22200/41412], Loss: 1.7280, Perplexity: 5.62927\n",
      "Epoch [5/25], Step [22300/41412], Loss: 1.9364, Perplexity: 6.93412\n",
      "Epoch [5/25], Step [22400/41412], Loss: 1.6712, Perplexity: 5.31849\n",
      "Epoch [5/25], Step [22500/41412], Loss: 1.4633, Perplexity: 4.32035\n",
      "Epoch [5/25], Step [22600/41412], Loss: 2.0929, Perplexity: 8.10861\n",
      "Epoch [5/25], Step [22700/41412], Loss: 1.8770, Perplexity: 6.53361\n",
      "Epoch [5/25], Step [22800/41412], Loss: 2.7310, Perplexity: 15.3484\n",
      "Epoch [5/25], Step [22900/41412], Loss: 1.6527, Perplexity: 5.22080\n",
      "Epoch [5/25], Step [23000/41412], Loss: 1.7896, Perplexity: 5.98746\n",
      "Epoch [5/25], Step [23100/41412], Loss: 1.5080, Perplexity: 4.51762\n",
      "Epoch [5/25], Step [23200/41412], Loss: 2.4944, Perplexity: 12.1145\n",
      "Epoch [5/25], Step [23300/41412], Loss: 2.1107, Perplexity: 8.25360\n",
      "Epoch [5/25], Step [23400/41412], Loss: 2.2147, Perplexity: 9.15842\n",
      "Epoch [5/25], Step [23500/41412], Loss: 2.8208, Perplexity: 16.7899\n",
      "Epoch [5/25], Step [23600/41412], Loss: 1.5241, Perplexity: 4.59084\n",
      "Epoch [5/25], Step [23700/41412], Loss: 1.7145, Perplexity: 5.55386\n",
      "Epoch [5/25], Step [23800/41412], Loss: 2.3127, Perplexity: 10.1013\n",
      "Epoch [5/25], Step [23900/41412], Loss: 2.0636, Perplexity: 7.87445\n",
      "Epoch [5/25], Step [24000/41412], Loss: 1.8137, Perplexity: 6.13326\n",
      "Epoch [5/25], Step [24100/41412], Loss: 1.8641, Perplexity: 6.44993\n",
      "Epoch [5/25], Step [24200/41412], Loss: 2.1661, Perplexity: 8.72464\n",
      "Epoch [5/25], Step [24300/41412], Loss: 2.0668, Perplexity: 7.89991\n",
      "Epoch [5/25], Step [24400/41412], Loss: 1.8062, Perplexity: 6.08713\n",
      "Epoch [5/25], Step [24500/41412], Loss: 2.3612, Perplexity: 10.6040\n",
      "Epoch [5/25], Step [24600/41412], Loss: 2.1975, Perplexity: 9.00235\n",
      "Epoch [5/25], Step [24700/41412], Loss: 3.5700, Perplexity: 35.5163\n",
      "Epoch [5/25], Step [24800/41412], Loss: 1.9435, Perplexity: 6.98334\n",
      "Epoch [5/25], Step [24900/41412], Loss: 1.8209, Perplexity: 6.17755\n",
      "Epoch [5/25], Step [25000/41412], Loss: 2.3038, Perplexity: 10.0118\n",
      "Epoch [5/25], Step [25100/41412], Loss: 2.2583, Perplexity: 9.56688\n",
      "Epoch [5/25], Step [25200/41412], Loss: 1.7835, Perplexity: 5.95061\n",
      "Epoch [5/25], Step [25300/41412], Loss: 1.9738, Perplexity: 7.19819\n",
      "Epoch [5/25], Step [25400/41412], Loss: 1.9166, Perplexity: 6.79783\n",
      "Epoch [5/25], Step [25500/41412], Loss: 2.1633, Perplexity: 8.69963\n",
      "Epoch [5/25], Step [25600/41412], Loss: 1.5883, Perplexity: 4.89523\n",
      "Epoch [5/25], Step [25700/41412], Loss: 1.7345, Perplexity: 5.66627\n",
      "Epoch [5/25], Step [25800/41412], Loss: 2.1262, Perplexity: 8.38282\n",
      "Epoch [5/25], Step [25900/41412], Loss: 1.4976, Perplexity: 4.47109\n",
      "Epoch [5/25], Step [26000/41412], Loss: 2.2584, Perplexity: 9.56730\n",
      "Epoch [5/25], Step [26100/41412], Loss: 2.2149, Perplexity: 9.16071\n",
      "Epoch [5/25], Step [26200/41412], Loss: 2.9363, Perplexity: 18.8463\n",
      "Epoch [5/25], Step [26300/41412], Loss: 2.2344, Perplexity: 9.34087\n",
      "Epoch [5/25], Step [26400/41412], Loss: 2.1531, Perplexity: 8.61132\n",
      "Epoch [5/25], Step [26500/41412], Loss: 1.9245, Perplexity: 6.85189\n",
      "Epoch [5/25], Step [26600/41412], Loss: 1.6149, Perplexity: 5.02768\n",
      "Epoch [5/25], Step [26700/41412], Loss: 1.9937, Perplexity: 7.34265\n",
      "Epoch [5/25], Step [26800/41412], Loss: 2.2287, Perplexity: 9.28759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Step [26900/41412], Loss: 2.3497, Perplexity: 10.4825\n",
      "Epoch [5/25], Step [27000/41412], Loss: 2.2311, Perplexity: 9.30970\n",
      "Epoch [5/25], Step [27100/41412], Loss: 1.7163, Perplexity: 5.56399\n",
      "Epoch [5/25], Step [27200/41412], Loss: 1.9929, Perplexity: 7.33697\n",
      "Epoch [5/25], Step [27300/41412], Loss: 2.0127, Perplexity: 7.48325\n",
      "Epoch [5/25], Step [27400/41412], Loss: 2.8311, Perplexity: 16.9641\n",
      "Epoch [5/25], Step [27500/41412], Loss: 1.8262, Perplexity: 6.21050\n",
      "Epoch [5/25], Step [27600/41412], Loss: 1.8681, Perplexity: 6.47611\n",
      "Epoch [5/25], Step [27700/41412], Loss: 1.8485, Perplexity: 6.35047\n",
      "Epoch [5/25], Step [27800/41412], Loss: 2.5858, Perplexity: 13.2737\n",
      "Epoch [5/25], Step [27900/41412], Loss: 2.6113, Perplexity: 13.6168\n",
      "Epoch [5/25], Step [28000/41412], Loss: 2.0555, Perplexity: 7.81074\n",
      "Epoch [5/25], Step [28100/41412], Loss: 2.2617, Perplexity: 9.59901\n",
      "Epoch [5/25], Step [28200/41412], Loss: 1.7318, Perplexity: 5.65073\n",
      "Epoch [5/25], Step [28300/41412], Loss: 2.3202, Perplexity: 10.1780\n",
      "Epoch [5/25], Step [28400/41412], Loss: 1.4821, Perplexity: 4.40208\n",
      "Epoch [5/25], Step [28500/41412], Loss: 1.6199, Perplexity: 5.05243\n",
      "Epoch [5/25], Step [28600/41412], Loss: 1.8985, Perplexity: 6.67585\n",
      "Epoch [5/25], Step [28700/41412], Loss: 2.2386, Perplexity: 9.38012\n",
      "Epoch [5/25], Step [28800/41412], Loss: 2.0046, Perplexity: 7.42328\n",
      "Epoch [5/25], Step [28900/41412], Loss: 2.1222, Perplexity: 8.34991\n",
      "Epoch [5/25], Step [29000/41412], Loss: 1.9965, Perplexity: 7.36304\n",
      "Epoch [5/25], Step [29100/41412], Loss: 1.6730, Perplexity: 5.32810\n",
      "Epoch [5/25], Step [29200/41412], Loss: 1.9357, Perplexity: 6.92869\n",
      "Epoch [5/25], Step [29300/41412], Loss: 2.3533, Perplexity: 10.5206\n",
      "Epoch [5/25], Step [29400/41412], Loss: 2.0911, Perplexity: 8.09366\n",
      "Epoch [5/25], Step [29500/41412], Loss: 1.7935, Perplexity: 6.01039\n",
      "Epoch [5/25], Step [29600/41412], Loss: 2.3103, Perplexity: 10.0779\n",
      "Epoch [5/25], Step [29700/41412], Loss: 2.3170, Perplexity: 10.1455\n",
      "Epoch [5/25], Step [29800/41412], Loss: 1.6970, Perplexity: 5.45789\n",
      "Epoch [5/25], Step [29900/41412], Loss: 3.6585, Perplexity: 38.8042\n",
      "Epoch [5/25], Step [30000/41412], Loss: 1.8407, Perplexity: 6.30074\n",
      "Epoch [5/25], Step [30100/41412], Loss: 2.0961, Perplexity: 8.13407\n",
      "Epoch [5/25], Step [30200/41412], Loss: 1.6134, Perplexity: 5.01974\n",
      "Epoch [5/25], Step [30300/41412], Loss: 1.8640, Perplexity: 6.44974\n",
      "Epoch [5/25], Step [30400/41412], Loss: 1.5824, Perplexity: 4.86678\n",
      "Epoch [5/25], Step [30500/41412], Loss: 2.1487, Perplexity: 8.57372\n",
      "Epoch [5/25], Step [30600/41412], Loss: 2.2669, Perplexity: 9.64929\n",
      "Epoch [5/25], Step [30700/41412], Loss: 1.5329, Perplexity: 4.63145\n",
      "Epoch [5/25], Step [30800/41412], Loss: 1.7347, Perplexity: 5.66720\n",
      "Epoch [5/25], Step [30900/41412], Loss: 1.7320, Perplexity: 5.65175\n",
      "Epoch [5/25], Step [31000/41412], Loss: 2.6907, Perplexity: 14.7418\n",
      "Epoch [5/25], Step [31100/41412], Loss: 1.9414, Perplexity: 6.96821\n",
      "Epoch [5/25], Step [31200/41412], Loss: 2.5721, Perplexity: 13.0929\n",
      "Epoch [5/25], Step [31300/41412], Loss: 2.4716, Perplexity: 11.8420\n",
      "Epoch [5/25], Step [31400/41412], Loss: 1.9207, Perplexity: 6.82572\n",
      "Epoch [5/25], Step [31500/41412], Loss: 1.7356, Perplexity: 5.67251\n",
      "Epoch [5/25], Step [31600/41412], Loss: 2.2045, Perplexity: 9.06593\n",
      "Epoch [5/25], Step [31700/41412], Loss: 2.5264, Perplexity: 12.5087\n",
      "Epoch [5/25], Step [31800/41412], Loss: 2.0220, Perplexity: 7.55386\n",
      "Epoch [5/25], Step [31900/41412], Loss: 1.6888, Perplexity: 5.41283\n",
      "Epoch [5/25], Step [32000/41412], Loss: 1.9891, Perplexity: 7.30899\n",
      "Epoch [5/25], Step [32100/41412], Loss: 1.8645, Perplexity: 6.45250\n",
      "Epoch [5/25], Step [32200/41412], Loss: 1.8080, Perplexity: 6.09835\n",
      "Epoch [5/25], Step [32300/41412], Loss: 2.2392, Perplexity: 9.38576\n",
      "Epoch [5/25], Step [32400/41412], Loss: 1.8020, Perplexity: 6.06182\n",
      "Epoch [5/25], Step [32500/41412], Loss: 2.2167, Perplexity: 9.17694\n",
      "Epoch [5/25], Step [32600/41412], Loss: 1.8858, Perplexity: 6.59172\n",
      "Epoch [5/25], Step [32700/41412], Loss: 2.1165, Perplexity: 8.30165\n",
      "Epoch [5/25], Step [32800/41412], Loss: 1.9140, Perplexity: 6.78031\n",
      "Epoch [5/25], Step [32900/41412], Loss: 2.1710, Perplexity: 8.76666\n",
      "Epoch [5/25], Step [33000/41412], Loss: 2.1670, Perplexity: 8.73204\n",
      "Epoch [5/25], Step [33100/41412], Loss: 1.6153, Perplexity: 5.02926\n",
      "Epoch [5/25], Step [33200/41412], Loss: 2.4638, Perplexity: 11.7492\n",
      "Epoch [5/25], Step [33300/41412], Loss: 2.1744, Perplexity: 8.79722\n",
      "Epoch [5/25], Step [33400/41412], Loss: 2.1977, Perplexity: 9.00396\n",
      "Epoch [5/25], Step [33500/41412], Loss: 1.6110, Perplexity: 5.00788\n",
      "Epoch [5/25], Step [33600/41412], Loss: 2.1538, Perplexity: 8.61774\n",
      "Epoch [5/25], Step [33700/41412], Loss: 1.4353, Perplexity: 4.20105\n",
      "Epoch [5/25], Step [33800/41412], Loss: 1.9613, Perplexity: 7.10884\n",
      "Epoch [5/25], Step [33900/41412], Loss: 1.6166, Perplexity: 5.03628\n",
      "Epoch [5/25], Step [34000/41412], Loss: 2.3479, Perplexity: 10.4638\n",
      "Epoch [5/25], Step [34100/41412], Loss: 1.4341, Perplexity: 4.19574\n",
      "Epoch [5/25], Step [34200/41412], Loss: 2.2709, Perplexity: 9.68797\n",
      "Epoch [5/25], Step [34300/41412], Loss: 2.3101, Perplexity: 10.0756\n",
      "Epoch [5/25], Step [34400/41412], Loss: 2.3004, Perplexity: 9.97810\n",
      "Epoch [5/25], Step [34500/41412], Loss: 1.9301, Perplexity: 6.89003\n",
      "Epoch [5/25], Step [34600/41412], Loss: 1.7581, Perplexity: 5.80152\n",
      "Epoch [5/25], Step [34700/41412], Loss: 2.4836, Perplexity: 11.9845\n",
      "Epoch [5/25], Step [34800/41412], Loss: 2.2225, Perplexity: 9.23087\n",
      "Epoch [5/25], Step [34900/41412], Loss: 1.5685, Perplexity: 4.79934\n",
      "Epoch [5/25], Step [35000/41412], Loss: 1.4953, Perplexity: 4.46078\n",
      "Epoch [5/25], Step [35100/41412], Loss: 1.7976, Perplexity: 6.03509\n",
      "Epoch [5/25], Step [35200/41412], Loss: 1.5311, Perplexity: 4.62351\n",
      "Epoch [5/25], Step [35300/41412], Loss: 2.4006, Perplexity: 11.0302\n",
      "Epoch [5/25], Step [35400/41412], Loss: 1.7819, Perplexity: 5.94129\n",
      "Epoch [5/25], Step [35500/41412], Loss: 1.5349, Perplexity: 4.640870\n",
      "Epoch [5/25], Step [35600/41412], Loss: 2.2359, Perplexity: 9.35480\n",
      "Epoch [5/25], Step [35700/41412], Loss: 1.6230, Perplexity: 5.06856\n",
      "Epoch [5/25], Step [35800/41412], Loss: 2.2604, Perplexity: 9.58677\n",
      "Epoch [5/25], Step [35900/41412], Loss: 2.0312, Perplexity: 7.62366\n",
      "Epoch [5/25], Step [36000/41412], Loss: 2.0394, Perplexity: 7.68574\n",
      "Epoch [5/25], Step [36100/41412], Loss: 1.7795, Perplexity: 5.92703\n",
      "Epoch [5/25], Step [36200/41412], Loss: 2.0937, Perplexity: 8.11461\n",
      "Epoch [5/25], Step [36300/41412], Loss: 2.2018, Perplexity: 9.04103\n",
      "Epoch [5/25], Step [36400/41412], Loss: 2.2869, Perplexity: 9.84421\n",
      "Epoch [5/25], Step [36500/41412], Loss: 2.0491, Perplexity: 7.76066\n",
      "Epoch [5/25], Step [36600/41412], Loss: 2.0271, Perplexity: 7.59225\n",
      "Epoch [5/25], Step [36700/41412], Loss: 2.3226, Perplexity: 10.2018\n",
      "Epoch [5/25], Step [36800/41412], Loss: 2.2303, Perplexity: 9.30283\n",
      "Epoch [5/25], Step [36900/41412], Loss: 2.1157, Perplexity: 8.29543\n",
      "Epoch [5/25], Step [37000/41412], Loss: 1.4107, Perplexity: 4.09907\n",
      "Epoch [5/25], Step [37100/41412], Loss: 2.0257, Perplexity: 7.58127\n",
      "Epoch [5/25], Step [37200/41412], Loss: 1.5971, Perplexity: 4.93879\n",
      "Epoch [5/25], Step [37300/41412], Loss: 1.9468, Perplexity: 7.00610\n",
      "Epoch [5/25], Step [37400/41412], Loss: 1.7582, Perplexity: 5.80224\n",
      "Epoch [5/25], Step [37500/41412], Loss: 2.2731, Perplexity: 9.70936\n",
      "Epoch [5/25], Step [37600/41412], Loss: 1.8267, Perplexity: 6.21374\n",
      "Epoch [5/25], Step [37700/41412], Loss: 1.7855, Perplexity: 5.96248\n",
      "Epoch [5/25], Step [37800/41412], Loss: 2.5888, Perplexity: 13.3133\n",
      "Epoch [5/25], Step [37900/41412], Loss: 2.0308, Perplexity: 7.62030\n",
      "Epoch [5/25], Step [38000/41412], Loss: 1.9178, Perplexity: 6.80608\n",
      "Epoch [5/25], Step [38100/41412], Loss: 2.3768, Perplexity: 10.7702\n",
      "Epoch [5/25], Step [38200/41412], Loss: 1.9573, Perplexity: 7.08001\n",
      "Epoch [5/25], Step [38300/41412], Loss: 2.3938, Perplexity: 10.9555\n",
      "Epoch [5/25], Step [38400/41412], Loss: 2.7604, Perplexity: 15.8054\n",
      "Epoch [5/25], Step [38500/41412], Loss: 1.8532, Perplexity: 6.38027\n",
      "Epoch [5/25], Step [38600/41412], Loss: 2.0899, Perplexity: 8.08442\n",
      "Epoch [5/25], Step [38700/41412], Loss: 2.0481, Perplexity: 7.75343\n",
      "Epoch [5/25], Step [38800/41412], Loss: 2.2385, Perplexity: 9.37896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Step [38900/41412], Loss: 2.0758, Perplexity: 7.97075\n",
      "Epoch [5/25], Step [39000/41412], Loss: 2.4607, Perplexity: 11.7129\n",
      "Epoch [5/25], Step [39100/41412], Loss: 1.9833, Perplexity: 7.26696\n",
      "Epoch [5/25], Step [39200/41412], Loss: 1.9039, Perplexity: 6.71216\n",
      "Epoch [5/25], Step [39300/41412], Loss: 2.4510, Perplexity: 11.5994\n",
      "Epoch [5/25], Step [39400/41412], Loss: 1.8373, Perplexity: 6.27958\n",
      "Epoch [5/25], Step [39500/41412], Loss: 2.7639, Perplexity: 15.8609\n",
      "Epoch [5/25], Step [39600/41412], Loss: 1.8712, Perplexity: 6.49629\n",
      "Epoch [5/25], Step [39700/41412], Loss: 1.8757, Perplexity: 6.52557\n",
      "Epoch [5/25], Step [39800/41412], Loss: 1.5729, Perplexity: 4.82040\n",
      "Epoch [5/25], Step [39900/41412], Loss: 2.0524, Perplexity: 7.78650\n",
      "Epoch [5/25], Step [40000/41412], Loss: 1.6563, Perplexity: 5.24002\n",
      "Epoch [5/25], Step [40100/41412], Loss: 1.8137, Perplexity: 6.13293\n",
      "Epoch [5/25], Step [40200/41412], Loss: 1.9313, Perplexity: 6.89860\n",
      "Epoch [5/25], Step [40300/41412], Loss: 1.7391, Perplexity: 5.69230\n",
      "Epoch [5/25], Step [40400/41412], Loss: 1.6004, Perplexity: 4.95500\n",
      "Epoch [5/25], Step [40500/41412], Loss: 1.5507, Perplexity: 4.71503\n",
      "Epoch [5/25], Step [40600/41412], Loss: 1.9761, Perplexity: 7.21435\n",
      "Epoch [5/25], Step [40700/41412], Loss: 1.9005, Perplexity: 6.68917\n",
      "Epoch [5/25], Step [40800/41412], Loss: 2.0224, Perplexity: 7.55649\n",
      "Epoch [5/25], Step [40900/41412], Loss: 1.7541, Perplexity: 5.77840\n",
      "Epoch [5/25], Step [41000/41412], Loss: 2.1943, Perplexity: 8.97359\n",
      "Epoch [5/25], Step [41100/41412], Loss: 1.9932, Perplexity: 7.33891\n",
      "Epoch [5/25], Step [41200/41412], Loss: 1.8963, Perplexity: 6.66094\n",
      "Epoch [5/25], Step [41300/41412], Loss: 1.7305, Perplexity: 5.64325\n",
      "Epoch [5/25], Step [41400/41412], Loss: 1.9006, Perplexity: 6.68994\n",
      "Epoch [6/25], Step [100/41412], Loss: 2.1828, Perplexity: 8.8715207\n",
      "Epoch [6/25], Step [200/41412], Loss: 2.4398, Perplexity: 11.4704\n",
      "Epoch [6/25], Step [300/41412], Loss: 2.4881, Perplexity: 12.0380\n",
      "Epoch [6/25], Step [400/41412], Loss: 2.6018, Perplexity: 13.4881\n",
      "Epoch [6/25], Step [500/41412], Loss: 1.6788, Perplexity: 5.35946\n",
      "Epoch [6/25], Step [600/41412], Loss: 2.0635, Perplexity: 7.87335\n",
      "Epoch [6/25], Step [700/41412], Loss: 1.9575, Perplexity: 7.08153\n",
      "Epoch [6/25], Step [800/41412], Loss: 1.6600, Perplexity: 5.25920\n",
      "Epoch [6/25], Step [900/41412], Loss: 1.4761, Perplexity: 4.375863\n",
      "Epoch [6/25], Step [1000/41412], Loss: 1.6249, Perplexity: 5.0778\n",
      "Epoch [6/25], Step [1100/41412], Loss: 2.4920, Perplexity: 12.0859\n",
      "Epoch [6/25], Step [1200/41412], Loss: 1.7601, Perplexity: 5.81277\n",
      "Epoch [6/25], Step [1300/41412], Loss: 1.8475, Perplexity: 6.34384\n",
      "Epoch [6/25], Step [1400/41412], Loss: 2.2763, Perplexity: 9.74041\n",
      "Epoch [6/25], Step [1500/41412], Loss: 2.1359, Perplexity: 8.46458\n",
      "Epoch [6/25], Step [1600/41412], Loss: 2.5133, Perplexity: 12.3456\n",
      "Epoch [6/25], Step [1700/41412], Loss: 1.6744, Perplexity: 5.33545\n",
      "Epoch [6/25], Step [1800/41412], Loss: 1.7316, Perplexity: 5.64976\n",
      "Epoch [6/25], Step [1900/41412], Loss: 2.0679, Perplexity: 7.90806\n",
      "Epoch [6/25], Step [2000/41412], Loss: 2.3407, Perplexity: 10.3881\n",
      "Epoch [6/25], Step [2100/41412], Loss: 2.3626, Perplexity: 10.6185\n",
      "Epoch [6/25], Step [2200/41412], Loss: 1.6194, Perplexity: 5.05022\n",
      "Epoch [6/25], Step [2300/41412], Loss: 1.9955, Perplexity: 7.35560\n",
      "Epoch [6/25], Step [2400/41412], Loss: 1.7023, Perplexity: 5.48677\n",
      "Epoch [6/25], Step [2500/41412], Loss: 1.4903, Perplexity: 4.43849\n",
      "Epoch [6/25], Step [2600/41412], Loss: 1.9249, Perplexity: 6.85488\n",
      "Epoch [6/25], Step [2700/41412], Loss: 2.0161, Perplexity: 7.50930\n",
      "Epoch [6/25], Step [2800/41412], Loss: 2.1658, Perplexity: 8.72141\n",
      "Epoch [6/25], Step [2900/41412], Loss: 2.4350, Perplexity: 11.4163\n",
      "Epoch [6/25], Step [3000/41412], Loss: 2.1250, Perplexity: 8.37258\n",
      "Epoch [6/25], Step [3100/41412], Loss: 1.9643, Perplexity: 7.13017\n",
      "Epoch [6/25], Step [3200/41412], Loss: 2.2174, Perplexity: 9.18385\n",
      "Epoch [6/25], Step [3300/41412], Loss: 2.2157, Perplexity: 9.16829\n",
      "Epoch [6/25], Step [3400/41412], Loss: 2.1566, Perplexity: 8.64179\n",
      "Epoch [6/25], Step [3500/41412], Loss: 1.7353, Perplexity: 5.67091\n",
      "Epoch [6/25], Step [3600/41412], Loss: 1.9392, Perplexity: 6.95337\n",
      "Epoch [6/25], Step [3700/41412], Loss: 1.8088, Perplexity: 6.10339\n",
      "Epoch [6/25], Step [3800/41412], Loss: 1.9043, Perplexity: 6.71474\n",
      "Epoch [6/25], Step [3900/41412], Loss: 1.7990, Perplexity: 6.04348\n",
      "Epoch [6/25], Step [4000/41412], Loss: 1.8538, Perplexity: 6.38398\n",
      "Epoch [6/25], Step [4100/41412], Loss: 1.6843, Perplexity: 5.38870\n",
      "Epoch [6/25], Step [4200/41412], Loss: 2.2696, Perplexity: 9.67551\n",
      "Epoch [6/25], Step [4300/41412], Loss: 3.0637, Perplexity: 21.4056\n",
      "Epoch [6/25], Step [4400/41412], Loss: 1.9944, Perplexity: 7.34815\n",
      "Epoch [6/25], Step [4500/41412], Loss: 2.2391, Perplexity: 9.38473\n",
      "Epoch [6/25], Step [4600/41412], Loss: 1.7795, Perplexity: 5.92678\n",
      "Epoch [6/25], Step [4700/41412], Loss: 2.6517, Perplexity: 14.1781\n",
      "Epoch [6/25], Step [4800/41412], Loss: 1.8010, Perplexity: 6.05542\n",
      "Epoch [6/25], Step [4900/41412], Loss: 1.9645, Perplexity: 7.13159\n",
      "Epoch [6/25], Step [5000/41412], Loss: 2.7040, Perplexity: 14.9387\n",
      "Epoch [6/25], Step [5100/41412], Loss: 2.1220, Perplexity: 8.34765\n",
      "Epoch [6/25], Step [5200/41412], Loss: 1.5503, Perplexity: 4.71270\n",
      "Epoch [6/25], Step [5300/41412], Loss: 2.3811, Perplexity: 10.8166\n",
      "Epoch [6/25], Step [5400/41412], Loss: 3.9727, Perplexity: 53.1269\n",
      "Epoch [6/25], Step [5500/41412], Loss: 1.7063, Perplexity: 5.50849\n",
      "Epoch [6/25], Step [5600/41412], Loss: 1.7531, Perplexity: 5.77231\n",
      "Epoch [6/25], Step [5700/41412], Loss: 1.8581, Perplexity: 6.41169\n",
      "Epoch [6/25], Step [5800/41412], Loss: 1.8668, Perplexity: 6.46768\n",
      "Epoch [6/25], Step [5900/41412], Loss: 2.0254, Perplexity: 7.57943\n",
      "Epoch [6/25], Step [6000/41412], Loss: 1.6930, Perplexity: 5.43557\n",
      "Epoch [6/25], Step [6100/41412], Loss: 2.4263, Perplexity: 11.3175\n",
      "Epoch [6/25], Step [6200/41412], Loss: 2.0693, Perplexity: 7.91951\n",
      "Epoch [6/25], Step [6300/41412], Loss: 1.8815, Perplexity: 6.56320\n",
      "Epoch [6/25], Step [6400/41412], Loss: 2.3112, Perplexity: 10.0868\n",
      "Epoch [6/25], Step [6500/41412], Loss: 2.2059, Perplexity: 9.07868\n",
      "Epoch [6/25], Step [6600/41412], Loss: 2.2511, Perplexity: 9.49797\n",
      "Epoch [6/25], Step [6700/41412], Loss: 2.0146, Perplexity: 7.49772\n",
      "Epoch [6/25], Step [6800/41412], Loss: 1.7929, Perplexity: 6.00710\n",
      "Epoch [6/25], Step [6900/41412], Loss: 2.9070, Perplexity: 18.3014\n",
      "Epoch [6/25], Step [7000/41412], Loss: 1.8462, Perplexity: 6.33559\n",
      "Epoch [6/25], Step [7100/41412], Loss: 2.3214, Perplexity: 10.1904\n",
      "Epoch [6/25], Step [7200/41412], Loss: 1.5337, Perplexity: 4.63534\n",
      "Epoch [6/25], Step [7300/41412], Loss: 1.3975, Perplexity: 4.04491\n",
      "Epoch [6/25], Step [7400/41412], Loss: 1.6324, Perplexity: 5.11635\n",
      "Epoch [6/25], Step [7500/41412], Loss: 1.9223, Perplexity: 6.83667\n",
      "Epoch [6/25], Step [7600/41412], Loss: 1.7678, Perplexity: 5.85814\n",
      "Epoch [6/25], Step [7700/41412], Loss: 2.3328, Perplexity: 10.3071\n",
      "Epoch [6/25], Step [7800/41412], Loss: 2.1943, Perplexity: 8.97383\n",
      "Epoch [6/25], Step [7900/41412], Loss: 2.1282, Perplexity: 8.39946\n",
      "Epoch [6/25], Step [8000/41412], Loss: 1.9973, Perplexity: 7.36930\n",
      "Epoch [6/25], Step [8100/41412], Loss: 2.1236, Perplexity: 8.36094\n",
      "Epoch [6/25], Step [8200/41412], Loss: 1.1963, Perplexity: 3.30772\n",
      "Epoch [6/25], Step [8300/41412], Loss: 1.8455, Perplexity: 6.33144\n",
      "Epoch [6/25], Step [8400/41412], Loss: 2.0908, Perplexity: 8.09126\n",
      "Epoch [6/25], Step [8500/41412], Loss: 2.1528, Perplexity: 8.60906\n",
      "Epoch [6/25], Step [8600/41412], Loss: 1.9178, Perplexity: 6.80606\n",
      "Epoch [6/25], Step [8700/41412], Loss: 1.8164, Perplexity: 6.14961\n",
      "Epoch [6/25], Step [8800/41412], Loss: 1.9280, Perplexity: 6.87603\n",
      "Epoch [6/25], Step [8900/41412], Loss: 1.8242, Perplexity: 6.19768\n",
      "Epoch [6/25], Step [9000/41412], Loss: 1.7326, Perplexity: 5.65525\n",
      "Epoch [6/25], Step [9100/41412], Loss: 1.7487, Perplexity: 5.74743\n",
      "Epoch [6/25], Step [9200/41412], Loss: 2.0710, Perplexity: 7.93308\n",
      "Epoch [6/25], Step [9300/41412], Loss: 1.9897, Perplexity: 7.31353\n",
      "Epoch [6/25], Step [9400/41412], Loss: 1.9868, Perplexity: 7.29244\n",
      "Epoch [6/25], Step [9500/41412], Loss: 1.9731, Perplexity: 7.192650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Step [9600/41412], Loss: 1.8948, Perplexity: 6.65106\n",
      "Epoch [6/25], Step [9700/41412], Loss: 2.4594, Perplexity: 11.6972\n",
      "Epoch [6/25], Step [9800/41412], Loss: 1.7080, Perplexity: 5.51807\n",
      "Epoch [6/25], Step [9900/41412], Loss: 1.7137, Perplexity: 5.54924\n",
      "Epoch [6/25], Step [10000/41412], Loss: 1.6104, Perplexity: 5.0046\n",
      "Epoch [6/25], Step [10100/41412], Loss: 1.8342, Perplexity: 6.26042\n",
      "Epoch [6/25], Step [10200/41412], Loss: 1.8666, Perplexity: 6.46661\n",
      "Epoch [6/25], Step [10300/41412], Loss: 1.8221, Perplexity: 6.18473\n",
      "Epoch [6/25], Step [10400/41412], Loss: 2.0444, Perplexity: 7.72489\n",
      "Epoch [6/25], Step [10500/41412], Loss: 1.5519, Perplexity: 4.72069\n",
      "Epoch [6/25], Step [10600/41412], Loss: 2.2971, Perplexity: 9.94568\n",
      "Epoch [6/25], Step [10700/41412], Loss: 2.4399, Perplexity: 11.4720\n",
      "Epoch [6/25], Step [10800/41412], Loss: 1.9049, Perplexity: 6.71871\n",
      "Epoch [6/25], Step [10900/41412], Loss: 2.0504, Perplexity: 7.77060\n",
      "Epoch [6/25], Step [11000/41412], Loss: 1.8011, Perplexity: 6.05630\n",
      "Epoch [6/25], Step [11100/41412], Loss: 1.5435, Perplexity: 4.68087\n",
      "Epoch [6/25], Step [11200/41412], Loss: 1.6916, Perplexity: 5.42826\n",
      "Epoch [6/25], Step [11300/41412], Loss: 1.8414, Perplexity: 6.30519\n",
      "Epoch [6/25], Step [11400/41412], Loss: 2.0735, Perplexity: 7.95267\n",
      "Epoch [6/25], Step [11500/41412], Loss: 1.6217, Perplexity: 5.06174\n",
      "Epoch [6/25], Step [11600/41412], Loss: 2.4119, Perplexity: 11.1547\n",
      "Epoch [6/25], Step [11700/41412], Loss: 1.8546, Perplexity: 6.38922\n",
      "Epoch [6/25], Step [11800/41412], Loss: 2.0037, Perplexity: 7.41652\n",
      "Epoch [6/25], Step [11900/41412], Loss: 2.0655, Perplexity: 7.88912\n",
      "Epoch [6/25], Step [12000/41412], Loss: 1.5013, Perplexity: 4.48772\n",
      "Epoch [6/25], Step [12100/41412], Loss: 1.7340, Perplexity: 5.66324\n",
      "Epoch [6/25], Step [12200/41412], Loss: 2.4235, Perplexity: 11.2851\n",
      "Epoch [6/25], Step [12300/41412], Loss: 1.7768, Perplexity: 5.91107\n",
      "Epoch [6/25], Step [12400/41412], Loss: 2.0134, Perplexity: 7.48849\n",
      "Epoch [6/25], Step [12500/41412], Loss: 2.0789, Perplexity: 7.99557\n",
      "Epoch [6/25], Step [12600/41412], Loss: 1.9909, Perplexity: 7.32253\n",
      "Epoch [6/25], Step [12700/41412], Loss: 1.6142, Perplexity: 5.02400\n",
      "Epoch [6/25], Step [12800/41412], Loss: 1.3301, Perplexity: 3.78163\n",
      "Epoch [6/25], Step [12900/41412], Loss: 2.0834, Perplexity: 8.03169\n",
      "Epoch [6/25], Step [13000/41412], Loss: 2.5228, Perplexity: 12.4629\n",
      "Epoch [6/25], Step [13100/41412], Loss: 1.5707, Perplexity: 4.80985\n",
      "Epoch [6/25], Step [13200/41412], Loss: 1.7151, Perplexity: 5.55721\n",
      "Epoch [6/25], Step [13300/41412], Loss: 2.0556, Perplexity: 7.81179\n",
      "Epoch [6/25], Step [13400/41412], Loss: 2.4730, Perplexity: 11.8576\n",
      "Epoch [6/25], Step [13500/41412], Loss: 1.9593, Perplexity: 7.09430\n",
      "Epoch [6/25], Step [13600/41412], Loss: 2.0772, Perplexity: 7.98239\n",
      "Epoch [6/25], Step [13700/41412], Loss: 2.1165, Perplexity: 8.30217\n",
      "Epoch [6/25], Step [13800/41412], Loss: 1.9371, Perplexity: 6.93865\n",
      "Epoch [6/25], Step [13900/41412], Loss: 1.9323, Perplexity: 6.90553\n",
      "Epoch [6/25], Step [14000/41412], Loss: 2.5154, Perplexity: 12.3710\n",
      "Epoch [6/25], Step [14100/41412], Loss: 1.9722, Perplexity: 7.18613\n",
      "Epoch [6/25], Step [14200/41412], Loss: 1.7125, Perplexity: 5.54298\n",
      "Epoch [6/25], Step [14300/41412], Loss: 1.4600, Perplexity: 4.30595\n",
      "Epoch [6/25], Step [14400/41412], Loss: 1.1966, Perplexity: 3.30896\n",
      "Epoch [6/25], Step [14500/41412], Loss: 2.0347, Perplexity: 7.65016\n",
      "Epoch [6/25], Step [14600/41412], Loss: 2.5080, Perplexity: 12.2807\n",
      "Epoch [6/25], Step [14700/41412], Loss: 2.0459, Perplexity: 7.73657\n",
      "Epoch [6/25], Step [14800/41412], Loss: 1.9086, Perplexity: 6.74396\n",
      "Epoch [6/25], Step [14900/41412], Loss: 2.1643, Perplexity: 8.70862\n",
      "Epoch [6/25], Step [15000/41412], Loss: 2.0500, Perplexity: 7.76831\n",
      "Epoch [6/25], Step [15100/41412], Loss: 2.0445, Perplexity: 7.72568\n",
      "Epoch [6/25], Step [15200/41412], Loss: 1.9216, Perplexity: 6.83170\n",
      "Epoch [6/25], Step [15300/41412], Loss: 1.9583, Perplexity: 7.08753\n",
      "Epoch [6/25], Step [15400/41412], Loss: 2.2202, Perplexity: 9.20888\n",
      "Epoch [6/25], Step [15500/41412], Loss: 1.9575, Perplexity: 7.08175\n",
      "Epoch [6/25], Step [15600/41412], Loss: 2.1212, Perplexity: 8.34098\n",
      "Epoch [6/25], Step [15700/41412], Loss: 2.3562, Perplexity: 10.5504\n",
      "Epoch [6/25], Step [15800/41412], Loss: 1.7813, Perplexity: 5.93780\n",
      "Epoch [6/25], Step [15900/41412], Loss: 1.9023, Perplexity: 6.70142\n",
      "Epoch [6/25], Step [16000/41412], Loss: 2.2040, Perplexity: 9.06152\n",
      "Epoch [6/25], Step [16100/41412], Loss: 2.3510, Perplexity: 10.4959\n",
      "Epoch [6/25], Step [16200/41412], Loss: 2.4869, Perplexity: 12.0241\n",
      "Epoch [6/25], Step [16300/41412], Loss: 1.6450, Perplexity: 5.18096\n",
      "Epoch [6/25], Step [16400/41412], Loss: 1.9627, Perplexity: 7.11879\n",
      "Epoch [6/25], Step [16500/41412], Loss: 1.8725, Perplexity: 6.50432\n",
      "Epoch [6/25], Step [16600/41412], Loss: 1.8181, Perplexity: 6.16033\n",
      "Epoch [6/25], Step [16700/41412], Loss: 1.6797, Perplexity: 5.36397\n",
      "Epoch [6/25], Step [16800/41412], Loss: 1.6782, Perplexity: 5.35606\n",
      "Epoch [6/25], Step [16900/41412], Loss: 1.9576, Perplexity: 7.08218\n",
      "Epoch [6/25], Step [17000/41412], Loss: 1.8702, Perplexity: 6.48980\n",
      "Epoch [6/25], Step [17100/41412], Loss: 2.1214, Perplexity: 8.34258\n",
      "Epoch [6/25], Step [17200/41412], Loss: 1.9458, Perplexity: 6.99908\n",
      "Epoch [6/25], Step [17300/41412], Loss: 2.0998, Perplexity: 8.16429\n",
      "Epoch [6/25], Step [17400/41412], Loss: 2.0584, Perplexity: 7.83314\n",
      "Epoch [6/25], Step [17500/41412], Loss: 2.3353, Perplexity: 10.3323\n",
      "Epoch [6/25], Step [17600/41412], Loss: 1.5220, Perplexity: 4.58152\n",
      "Epoch [6/25], Step [17700/41412], Loss: 1.9894, Perplexity: 7.31148\n",
      "Epoch [6/25], Step [17800/41412], Loss: 1.6919, Perplexity: 5.43008\n",
      "Epoch [6/25], Step [17900/41412], Loss: 2.2394, Perplexity: 9.38724\n",
      "Epoch [6/25], Step [18000/41412], Loss: 1.9186, Perplexity: 6.81180\n",
      "Epoch [6/25], Step [18100/41412], Loss: 2.1621, Perplexity: 8.68927\n",
      "Epoch [6/25], Step [18200/41412], Loss: 2.3286, Perplexity: 10.2634\n",
      "Epoch [6/25], Step [18300/41412], Loss: 1.7837, Perplexity: 5.95215\n",
      "Epoch [6/25], Step [18400/41412], Loss: 2.4788, Perplexity: 11.9273\n",
      "Epoch [6/25], Step [18500/41412], Loss: 2.3791, Perplexity: 10.7947\n",
      "Epoch [6/25], Step [18600/41412], Loss: 2.2341, Perplexity: 9.33809\n",
      "Epoch [6/25], Step [18700/41412], Loss: 1.7172, Perplexity: 5.56921\n",
      "Epoch [6/25], Step [18800/41412], Loss: 1.5045, Perplexity: 4.50181\n",
      "Epoch [6/25], Step [18900/41412], Loss: 2.1376, Perplexity: 8.47932\n",
      "Epoch [6/25], Step [19000/41412], Loss: 1.9584, Perplexity: 7.08832\n",
      "Epoch [6/25], Step [19100/41412], Loss: 1.6333, Perplexity: 5.12069\n",
      "Epoch [6/25], Step [19200/41412], Loss: 1.6490, Perplexity: 5.20173\n",
      "Epoch [6/25], Step [19300/41412], Loss: 1.8784, Perplexity: 6.54277\n",
      "Epoch [6/25], Step [19400/41412], Loss: 2.2558, Perplexity: 9.54283\n",
      "Epoch [6/25], Step [19500/41412], Loss: 2.2211, Perplexity: 9.21790\n",
      "Epoch [6/25], Step [19600/41412], Loss: 1.9764, Perplexity: 7.21642\n",
      "Epoch [6/25], Step [19700/41412], Loss: 2.3158, Perplexity: 10.1334\n",
      "Epoch [6/25], Step [19800/41412], Loss: 2.7936, Perplexity: 16.3401\n",
      "Epoch [6/25], Step [19900/41412], Loss: 2.2443, Perplexity: 9.43380\n",
      "Epoch [6/25], Step [20000/41412], Loss: 2.1184, Perplexity: 8.31815\n",
      "Epoch [6/25], Step [20100/41412], Loss: 2.0229, Perplexity: 7.56025\n",
      "Epoch [6/25], Step [20200/41412], Loss: 2.0193, Perplexity: 7.53310\n",
      "Epoch [6/25], Step [20300/41412], Loss: 2.0866, Perplexity: 8.05742\n",
      "Epoch [6/25], Step [20400/41412], Loss: 1.8281, Perplexity: 6.22233\n",
      "Epoch [6/25], Step [20500/41412], Loss: 1.9099, Perplexity: 6.75230\n",
      "Epoch [6/25], Step [20600/41412], Loss: 1.6247, Perplexity: 5.07673\n",
      "Epoch [6/25], Step [20700/41412], Loss: 1.7870, Perplexity: 5.97165\n",
      "Epoch [6/25], Step [20800/41412], Loss: 2.0774, Perplexity: 7.98379\n",
      "Epoch [6/25], Step [20900/41412], Loss: 2.6396, Perplexity: 14.0072\n",
      "Epoch [6/25], Step [21000/41412], Loss: 2.0705, Perplexity: 7.92918\n",
      "Epoch [6/25], Step [21100/41412], Loss: 1.6087, Perplexity: 4.99659\n",
      "Epoch [6/25], Step [21200/41412], Loss: 1.9703, Perplexity: 7.17319\n",
      "Epoch [6/25], Step [21300/41412], Loss: 1.9535, Perplexity: 7.05362\n",
      "Epoch [6/25], Step [21400/41412], Loss: 1.4792, Perplexity: 4.38953\n",
      "Epoch [6/25], Step [21500/41412], Loss: 2.2557, Perplexity: 9.54164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Step [21600/41412], Loss: 2.3562, Perplexity: 10.5512\n",
      "Epoch [6/25], Step [21700/41412], Loss: 2.2336, Perplexity: 9.33389\n",
      "Epoch [6/25], Step [21800/41412], Loss: 1.4012, Perplexity: 4.06013\n",
      "Epoch [6/25], Step [21900/41412], Loss: 1.6930, Perplexity: 5.43602\n",
      "Epoch [6/25], Step [22000/41412], Loss: 2.0204, Perplexity: 7.54118\n",
      "Epoch [6/25], Step [22100/41412], Loss: 2.1197, Perplexity: 8.32875\n",
      "Epoch [6/25], Step [22200/41412], Loss: 1.9125, Perplexity: 6.770260\n",
      "Epoch [6/25], Step [22300/41412], Loss: 1.8127, Perplexity: 6.12723\n",
      "Epoch [6/25], Step [22400/41412], Loss: 2.0148, Perplexity: 7.49940\n",
      "Epoch [6/25], Step [22500/41412], Loss: 2.3498, Perplexity: 10.4839\n",
      "Epoch [6/25], Step [22600/41412], Loss: 1.6266, Perplexity: 5.08666\n",
      "Epoch [6/25], Step [22700/41412], Loss: 2.5182, Perplexity: 12.4057\n",
      "Epoch [6/25], Step [22800/41412], Loss: 1.7255, Perplexity: 5.61535\n",
      "Epoch [6/25], Step [22900/41412], Loss: 2.0351, Perplexity: 7.65321\n",
      "Epoch [6/25], Step [23000/41412], Loss: 1.3883, Perplexity: 4.00805\n",
      "Epoch [6/25], Step [23100/41412], Loss: 1.9086, Perplexity: 6.74388\n",
      "Epoch [6/25], Step [23200/41412], Loss: 1.6151, Perplexity: 5.02840\n",
      "Epoch [6/25], Step [23300/41412], Loss: 1.4213, Perplexity: 4.14270\n",
      "Epoch [6/25], Step [23400/41412], Loss: 1.8285, Perplexity: 6.22480\n",
      "Epoch [6/25], Step [23500/41412], Loss: 1.3395, Perplexity: 3.81711\n",
      "Epoch [6/25], Step [23600/41412], Loss: 1.8925, Perplexity: 6.63582\n",
      "Epoch [6/25], Step [23700/41412], Loss: 1.8733, Perplexity: 6.50957\n",
      "Epoch [6/25], Step [23800/41412], Loss: 1.9930, Perplexity: 7.33740\n",
      "Epoch [6/25], Step [23900/41412], Loss: 1.8491, Perplexity: 6.35442\n",
      "Epoch [6/25], Step [24000/41412], Loss: 1.7800, Perplexity: 5.92995\n",
      "Epoch [6/25], Step [24100/41412], Loss: 2.3527, Perplexity: 10.5143\n",
      "Epoch [6/25], Step [24200/41412], Loss: 2.2239, Perplexity: 9.24327\n",
      "Epoch [6/25], Step [24300/41412], Loss: 2.2487, Perplexity: 9.47513\n",
      "Epoch [6/25], Step [24400/41412], Loss: 2.0679, Perplexity: 7.90854\n",
      "Epoch [6/25], Step [24500/41412], Loss: 1.8039, Perplexity: 6.07302\n",
      "Epoch [6/25], Step [24600/41412], Loss: 1.9955, Perplexity: 7.35615\n",
      "Epoch [6/25], Step [24700/41412], Loss: 2.1672, Perplexity: 8.73416\n",
      "Epoch [6/25], Step [24800/41412], Loss: 1.9714, Perplexity: 7.18099\n",
      "Epoch [6/25], Step [24900/41412], Loss: 1.7863, Perplexity: 5.96747\n",
      "Epoch [6/25], Step [25000/41412], Loss: 2.2606, Perplexity: 9.58899\n",
      "Epoch [6/25], Step [25100/41412], Loss: 1.6324, Perplexity: 5.11631\n",
      "Epoch [6/25], Step [25200/41412], Loss: 2.2816, Perplexity: 9.79193\n",
      "Epoch [6/25], Step [25300/41412], Loss: 1.6961, Perplexity: 5.45273\n",
      "Epoch [6/25], Step [25400/41412], Loss: 2.0794, Perplexity: 7.99976\n",
      "Epoch [6/25], Step [25500/41412], Loss: 2.1010, Perplexity: 8.17473\n",
      "Epoch [6/25], Step [25600/41412], Loss: 1.7585, Perplexity: 5.80409\n",
      "Epoch [6/25], Step [25700/41412], Loss: 2.1054, Perplexity: 8.21060\n",
      "Epoch [6/25], Step [25800/41412], Loss: 2.7718, Perplexity: 15.9867\n",
      "Epoch [6/25], Step [25900/41412], Loss: 2.0276, Perplexity: 7.59582\n",
      "Epoch [6/25], Step [26000/41412], Loss: 1.9090, Perplexity: 6.74635\n",
      "Epoch [6/25], Step [26100/41412], Loss: 2.0142, Perplexity: 7.49467\n",
      "Epoch [6/25], Step [26200/41412], Loss: 1.8460, Perplexity: 6.33426\n",
      "Epoch [6/25], Step [26300/41412], Loss: 2.2912, Perplexity: 9.88688\n",
      "Epoch [6/25], Step [26400/41412], Loss: 1.7813, Perplexity: 5.93737\n",
      "Epoch [6/25], Step [26500/41412], Loss: 1.8517, Perplexity: 6.37079\n",
      "Epoch [6/25], Step [26600/41412], Loss: 1.7475, Perplexity: 5.74026\n",
      "Epoch [6/25], Step [26700/41412], Loss: 1.8927, Perplexity: 6.63749\n",
      "Epoch [6/25], Step [26800/41412], Loss: 1.8938, Perplexity: 6.64471\n",
      "Epoch [6/25], Step [26900/41412], Loss: 2.1719, Perplexity: 8.77475\n",
      "Epoch [6/25], Step [27000/41412], Loss: 1.6894, Perplexity: 5.41649\n",
      "Epoch [6/25], Step [27100/41412], Loss: 2.2403, Perplexity: 9.39626\n",
      "Epoch [6/25], Step [27200/41412], Loss: 2.1023, Perplexity: 8.18519\n",
      "Epoch [6/25], Step [27300/41412], Loss: 1.3253, Perplexity: 3.76315\n",
      "Epoch [6/25], Step [27400/41412], Loss: 1.7340, Perplexity: 5.66345\n",
      "Epoch [6/25], Step [27500/41412], Loss: 1.6895, Perplexity: 5.41667\n",
      "Epoch [6/25], Step [27600/41412], Loss: 2.0267, Perplexity: 7.58924\n",
      "Epoch [6/25], Step [27700/41412], Loss: 2.0406, Perplexity: 7.69512\n",
      "Epoch [6/25], Step [27800/41412], Loss: 1.9691, Perplexity: 7.16429\n",
      "Epoch [6/25], Step [27900/41412], Loss: 2.2652, Perplexity: 9.63288\n",
      "Epoch [6/25], Step [28000/41412], Loss: 1.8413, Perplexity: 6.30459\n",
      "Epoch [6/25], Step [28100/41412], Loss: 1.9444, Perplexity: 6.98973\n",
      "Epoch [6/25], Step [28200/41412], Loss: 2.1579, Perplexity: 8.65336\n",
      "Epoch [6/25], Step [28300/41412], Loss: 2.0198, Perplexity: 7.53662\n",
      "Epoch [6/25], Step [28400/41412], Loss: 2.4516, Perplexity: 11.6064\n",
      "Epoch [6/25], Step [28500/41412], Loss: 2.3222, Perplexity: 10.1981\n",
      "Epoch [6/25], Step [28600/41412], Loss: 2.3856, Perplexity: 10.8661\n",
      "Epoch [6/25], Step [28700/41412], Loss: 1.9660, Perplexity: 7.14216\n",
      "Epoch [6/25], Step [28800/41412], Loss: 1.8030, Perplexity: 6.06777\n",
      "Epoch [6/25], Step [28900/41412], Loss: 1.7192, Perplexity: 5.58004\n",
      "Epoch [6/25], Step [29000/41412], Loss: 1.9721, Perplexity: 7.18588\n",
      "Epoch [6/25], Step [29100/41412], Loss: 1.7659, Perplexity: 5.84660\n",
      "Epoch [6/25], Step [29200/41412], Loss: 1.9785, Perplexity: 7.23213\n",
      "Epoch [6/25], Step [29300/41412], Loss: 2.1701, Perplexity: 8.75876\n",
      "Epoch [6/25], Step [29400/41412], Loss: 1.5679, Perplexity: 4.79685\n",
      "Epoch [6/25], Step [29500/41412], Loss: 1.6104, Perplexity: 5.00481\n",
      "Epoch [6/25], Step [29600/41412], Loss: 1.7345, Perplexity: 5.66611\n",
      "Epoch [6/25], Step [29700/41412], Loss: 1.8697, Perplexity: 6.48619\n",
      "Epoch [6/25], Step [29800/41412], Loss: 2.2206, Perplexity: 9.21240\n",
      "Epoch [6/25], Step [29900/41412], Loss: 2.3686, Perplexity: 10.6824\n",
      "Epoch [6/25], Step [30000/41412], Loss: 1.7441, Perplexity: 5.72066\n",
      "Epoch [6/25], Step [30100/41412], Loss: 2.1411, Perplexity: 8.50918\n",
      "Epoch [6/25], Step [30200/41412], Loss: 2.2789, Perplexity: 9.76639\n",
      "Epoch [6/25], Step [30300/41412], Loss: 2.4678, Perplexity: 11.7961\n",
      "Epoch [6/25], Step [30400/41412], Loss: 2.2825, Perplexity: 9.80107\n",
      "Epoch [6/25], Step [30500/41412], Loss: 2.4488, Perplexity: 11.5748\n",
      "Epoch [6/25], Step [30600/41412], Loss: 1.7767, Perplexity: 5.91019\n",
      "Epoch [6/25], Step [30700/41412], Loss: 2.0692, Perplexity: 7.91832\n",
      "Epoch [6/25], Step [30800/41412], Loss: 2.1273, Perplexity: 8.39209\n",
      "Epoch [6/25], Step [30900/41412], Loss: 1.8829, Perplexity: 6.57280\n",
      "Epoch [6/25], Step [31000/41412], Loss: 2.3678, Perplexity: 10.6744\n",
      "Epoch [6/25], Step [31100/41412], Loss: 1.7537, Perplexity: 5.77585\n",
      "Epoch [6/25], Step [31200/41412], Loss: 1.5645, Perplexity: 4.78026\n",
      "Epoch [6/25], Step [31300/41412], Loss: 1.6581, Perplexity: 5.24947\n",
      "Epoch [6/25], Step [31400/41412], Loss: 2.3427, Perplexity: 10.4092\n",
      "Epoch [6/25], Step [31500/41412], Loss: 2.0595, Perplexity: 7.84238\n",
      "Epoch [6/25], Step [31600/41412], Loss: 1.6413, Perplexity: 5.16204\n",
      "Epoch [6/25], Step [31700/41412], Loss: 1.8190, Perplexity: 6.16556\n",
      "Epoch [6/25], Step [31800/41412], Loss: 2.0259, Perplexity: 7.58263\n",
      "Epoch [6/25], Step [31900/41412], Loss: 1.3644, Perplexity: 3.91335\n",
      "Epoch [6/25], Step [32000/41412], Loss: 1.8458, Perplexity: 6.33292\n",
      "Epoch [6/25], Step [32100/41412], Loss: 1.8321, Perplexity: 6.24720\n",
      "Epoch [6/25], Step [32200/41412], Loss: 2.2288, Perplexity: 9.28835\n",
      "Epoch [6/25], Step [32300/41412], Loss: 2.0004, Perplexity: 7.39216\n",
      "Epoch [6/25], Step [32400/41412], Loss: 2.1462, Perplexity: 8.55235\n",
      "Epoch [6/25], Step [32500/41412], Loss: 1.8297, Perplexity: 6.23228\n",
      "Epoch [6/25], Step [32600/41412], Loss: 1.5602, Perplexity: 4.75991\n",
      "Epoch [6/25], Step [32700/41412], Loss: 1.6217, Perplexity: 5.06166\n",
      "Epoch [6/25], Step [32800/41412], Loss: 2.1833, Perplexity: 8.87554\n",
      "Epoch [6/25], Step [32900/41412], Loss: 1.7147, Perplexity: 5.55506\n",
      "Epoch [6/25], Step [33000/41412], Loss: 2.2986, Perplexity: 9.96024\n",
      "Epoch [6/25], Step [33100/41412], Loss: 1.9292, Perplexity: 6.88371\n",
      "Epoch [6/25], Step [33200/41412], Loss: 1.8748, Perplexity: 6.51932\n",
      "Epoch [6/25], Step [33300/41412], Loss: 1.6143, Perplexity: 5.02449\n",
      "Epoch [6/25], Step [33400/41412], Loss: 1.9754, Perplexity: 7.20979\n",
      "Epoch [6/25], Step [33500/41412], Loss: 2.2021, Perplexity: 9.04369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Step [33600/41412], Loss: 2.0266, Perplexity: 7.58824\n",
      "Epoch [6/25], Step [33700/41412], Loss: 1.8561, Perplexity: 6.39909\n",
      "Epoch [6/25], Step [33800/41412], Loss: 1.7432, Perplexity: 5.71583\n",
      "Epoch [6/25], Step [33900/41412], Loss: 1.7284, Perplexity: 5.63177\n",
      "Epoch [6/25], Step [34000/41412], Loss: 1.9912, Perplexity: 7.32464\n",
      "Epoch [6/25], Step [34100/41412], Loss: 2.3126, Perplexity: 10.1008\n",
      "Epoch [6/25], Step [34200/41412], Loss: 2.1191, Perplexity: 8.32376\n",
      "Epoch [6/25], Step [34300/41412], Loss: 2.1959, Perplexity: 8.98773\n",
      "Epoch [6/25], Step [34400/41412], Loss: 1.7971, Perplexity: 6.03238\n",
      "Epoch [6/25], Step [34500/41412], Loss: 1.5561, Perplexity: 4.74049\n",
      "Epoch [6/25], Step [34600/41412], Loss: 1.9327, Perplexity: 6.90823\n",
      "Epoch [6/25], Step [34700/41412], Loss: 1.5184, Perplexity: 4.56481\n",
      "Epoch [6/25], Step [34800/41412], Loss: 1.9380, Perplexity: 6.94487\n",
      "Epoch [6/25], Step [34900/41412], Loss: 2.1780, Perplexity: 8.82900\n",
      "Epoch [6/25], Step [35000/41412], Loss: 1.8511, Perplexity: 6.36663\n",
      "Epoch [6/25], Step [35100/41412], Loss: 1.7503, Perplexity: 5.75614\n",
      "Epoch [6/25], Step [35200/41412], Loss: 1.6006, Perplexity: 4.95628\n",
      "Epoch [6/25], Step [35300/41412], Loss: 1.6294, Perplexity: 5.10079\n",
      "Epoch [6/25], Step [35400/41412], Loss: 2.3023, Perplexity: 9.99702\n",
      "Epoch [6/25], Step [35500/41412], Loss: 1.7227, Perplexity: 5.59952\n",
      "Epoch [6/25], Step [35600/41412], Loss: 1.9203, Perplexity: 6.82300\n",
      "Epoch [6/25], Step [35700/41412], Loss: 1.9755, Perplexity: 7.21015\n",
      "Epoch [6/25], Step [35800/41412], Loss: 1.9600, Perplexity: 7.09965\n",
      "Epoch [6/25], Step [35900/41412], Loss: 2.1668, Perplexity: 8.73058\n",
      "Epoch [6/25], Step [36000/41412], Loss: 1.8490, Perplexity: 6.35345\n",
      "Epoch [6/25], Step [36100/41412], Loss: 1.2675, Perplexity: 3.55211\n",
      "Epoch [6/25], Step [36200/41412], Loss: 2.1414, Perplexity: 8.51135\n",
      "Epoch [6/25], Step [36300/41412], Loss: 1.5546, Perplexity: 4.73307\n",
      "Epoch [6/25], Step [36400/41412], Loss: 1.7701, Perplexity: 5.87176\n",
      "Epoch [6/25], Step [36500/41412], Loss: 1.8122, Perplexity: 6.12420\n",
      "Epoch [6/25], Step [36600/41412], Loss: 1.7624, Perplexity: 5.82647\n",
      "Epoch [6/25], Step [36700/41412], Loss: 1.7777, Perplexity: 5.91609\n",
      "Epoch [6/25], Step [36800/41412], Loss: 2.0212, Perplexity: 7.54763\n",
      "Epoch [6/25], Step [36900/41412], Loss: 2.1039, Perplexity: 8.19832\n",
      "Epoch [6/25], Step [37000/41412], Loss: 2.0799, Perplexity: 8.00386\n",
      "Epoch [6/25], Step [37100/41412], Loss: 2.4280, Perplexity: 11.3364\n",
      "Epoch [6/25], Step [37200/41412], Loss: 1.7212, Perplexity: 5.59132\n",
      "Epoch [6/25], Step [37300/41412], Loss: 1.8461, Perplexity: 6.33534\n",
      "Epoch [6/25], Step [37400/41412], Loss: 2.2165, Perplexity: 9.17492\n",
      "Epoch [6/25], Step [37500/41412], Loss: 1.6218, Perplexity: 5.06237\n",
      "Epoch [6/25], Step [37600/41412], Loss: 2.6721, Perplexity: 14.4699\n",
      "Epoch [6/25], Step [37700/41412], Loss: 3.0809, Perplexity: 21.7778\n",
      "Epoch [6/25], Step [37800/41412], Loss: 2.7014, Perplexity: 14.9003\n",
      "Epoch [6/25], Step [37900/41412], Loss: 1.8355, Perplexity: 6.26855\n",
      "Epoch [6/25], Step [38000/41412], Loss: 1.6005, Perplexity: 4.95579\n",
      "Epoch [6/25], Step [38100/41412], Loss: 1.8371, Perplexity: 6.27824\n",
      "Epoch [6/25], Step [38200/41412], Loss: 2.1172, Perplexity: 8.30819\n",
      "Epoch [6/25], Step [38300/41412], Loss: 2.3329, Perplexity: 10.3079\n",
      "Epoch [6/25], Step [38400/41412], Loss: 1.4911, Perplexity: 4.44210\n",
      "Epoch [6/25], Step [38500/41412], Loss: 2.2921, Perplexity: 9.89551\n",
      "Epoch [6/25], Step [38600/41412], Loss: 1.6864, Perplexity: 5.40000\n",
      "Epoch [6/25], Step [38700/41412], Loss: 1.9852, Perplexity: 7.28088\n",
      "Epoch [6/25], Step [38800/41412], Loss: 1.8139, Perplexity: 6.13411\n",
      "Epoch [6/25], Step [38900/41412], Loss: 1.7547, Perplexity: 5.78193\n",
      "Epoch [6/25], Step [39000/41412], Loss: 1.7818, Perplexity: 5.94040\n",
      "Epoch [6/25], Step [39100/41412], Loss: 2.3247, Perplexity: 10.2239\n",
      "Epoch [6/25], Step [39200/41412], Loss: 2.1181, Perplexity: 8.31576\n",
      "Epoch [6/25], Step [39300/41412], Loss: 1.5807, Perplexity: 4.85857\n",
      "Epoch [6/25], Step [39400/41412], Loss: 2.6528, Perplexity: 14.1940\n",
      "Epoch [6/25], Step [39500/41412], Loss: 1.7128, Perplexity: 5.54446\n",
      "Epoch [6/25], Step [39600/41412], Loss: 1.7257, Perplexity: 5.61662\n",
      "Epoch [6/25], Step [39700/41412], Loss: 1.8801, Perplexity: 6.55413\n",
      "Epoch [6/25], Step [39800/41412], Loss: 1.9959, Perplexity: 7.35907\n",
      "Epoch [6/25], Step [39900/41412], Loss: 1.8531, Perplexity: 6.37970\n",
      "Epoch [6/25], Step [40000/41412], Loss: 1.9499, Perplexity: 7.028074\n",
      "Epoch [6/25], Step [40100/41412], Loss: 2.0513, Perplexity: 7.77824\n",
      "Epoch [6/25], Step [40200/41412], Loss: 2.2041, Perplexity: 9.06251\n",
      "Epoch [6/25], Step [40300/41412], Loss: 1.7734, Perplexity: 5.89076\n",
      "Epoch [6/25], Step [40400/41412], Loss: 1.9847, Perplexity: 7.27717\n",
      "Epoch [6/25], Step [40500/41412], Loss: 2.8230, Perplexity: 16.8277\n",
      "Epoch [6/25], Step [40600/41412], Loss: 2.2169, Perplexity: 9.17889\n",
      "Epoch [6/25], Step [40700/41412], Loss: 1.9927, Perplexity: 7.33507\n",
      "Epoch [6/25], Step [40800/41412], Loss: 2.3433, Perplexity: 10.4152\n",
      "Epoch [6/25], Step [40900/41412], Loss: 1.9501, Perplexity: 7.02942\n",
      "Epoch [6/25], Step [41000/41412], Loss: 2.0963, Perplexity: 8.13583\n",
      "Epoch [6/25], Step [41100/41412], Loss: 2.0663, Perplexity: 7.89582\n",
      "Epoch [6/25], Step [41200/41412], Loss: 2.4622, Perplexity: 11.7311\n",
      "Epoch [6/25], Step [41300/41412], Loss: 1.9332, Perplexity: 6.91191\n",
      "Epoch [6/25], Step [41400/41412], Loss: 2.2155, Perplexity: 9.16586\n",
      "Epoch [7/25], Step [100/41412], Loss: 2.3418, Perplexity: 10.399617\n",
      "Epoch [7/25], Step [200/41412], Loss: 1.9194, Perplexity: 6.81724\n",
      "Epoch [7/25], Step [300/41412], Loss: 1.8365, Perplexity: 6.27468\n",
      "Epoch [7/25], Step [400/41412], Loss: 1.8119, Perplexity: 6.12196\n",
      "Epoch [7/25], Step [500/41412], Loss: 1.6729, Perplexity: 5.32769\n",
      "Epoch [7/25], Step [600/41412], Loss: 1.8050, Perplexity: 6.07976\n",
      "Epoch [7/25], Step [700/41412], Loss: 2.4874, Perplexity: 12.0295\n",
      "Epoch [7/25], Step [800/41412], Loss: 1.6773, Perplexity: 5.35110\n",
      "Epoch [7/25], Step [900/41412], Loss: 1.7988, Perplexity: 6.04233\n",
      "Epoch [7/25], Step [1000/41412], Loss: 2.1951, Perplexity: 8.9809\n",
      "Epoch [7/25], Step [1100/41412], Loss: 2.0658, Perplexity: 7.89183\n",
      "Epoch [7/25], Step [1200/41412], Loss: 2.1838, Perplexity: 8.87967\n",
      "Epoch [7/25], Step [1300/41412], Loss: 2.4942, Perplexity: 12.1115\n",
      "Epoch [7/25], Step [1400/41412], Loss: 2.1371, Perplexity: 8.47465\n",
      "Epoch [7/25], Step [1500/41412], Loss: 2.4169, Perplexity: 11.2109\n",
      "Epoch [7/25], Step [1600/41412], Loss: 2.0299, Perplexity: 7.61304\n",
      "Epoch [7/25], Step [1700/41412], Loss: 1.8719, Perplexity: 6.50080\n",
      "Epoch [7/25], Step [1800/41412], Loss: 2.4007, Perplexity: 11.0307\n",
      "Epoch [7/25], Step [1900/41412], Loss: 1.6194, Perplexity: 5.05021\n",
      "Epoch [7/25], Step [2000/41412], Loss: 1.8907, Perplexity: 6.62429\n",
      "Epoch [7/25], Step [2100/41412], Loss: 2.0255, Perplexity: 7.58029\n",
      "Epoch [7/25], Step [2200/41412], Loss: 2.1432, Perplexity: 8.52706\n",
      "Epoch [7/25], Step [2300/41412], Loss: 2.1149, Perplexity: 8.28878\n",
      "Epoch [7/25], Step [2400/41412], Loss: 2.5933, Perplexity: 13.3743\n",
      "Epoch [7/25], Step [2500/41412], Loss: 1.4515, Perplexity: 4.26962\n",
      "Epoch [7/25], Step [2600/41412], Loss: 2.2333, Perplexity: 9.33064\n",
      "Epoch [7/25], Step [2700/41412], Loss: 1.9429, Perplexity: 6.97878\n",
      "Epoch [7/25], Step [2800/41412], Loss: 1.9777, Perplexity: 7.226316\n",
      "Epoch [7/25], Step [2900/41412], Loss: 2.2622, Perplexity: 9.60440\n",
      "Epoch [7/25], Step [3000/41412], Loss: 1.6795, Perplexity: 5.36314\n",
      "Epoch [7/25], Step [3100/41412], Loss: 1.8270, Perplexity: 6.21558\n",
      "Epoch [7/25], Step [3200/41412], Loss: 2.0934, Perplexity: 8.11239\n",
      "Epoch [7/25], Step [3300/41412], Loss: 1.8879, Perplexity: 6.60572\n",
      "Epoch [7/25], Step [3400/41412], Loss: 1.8610, Perplexity: 6.43028\n",
      "Epoch [7/25], Step [3500/41412], Loss: 1.4756, Perplexity: 4.37383\n",
      "Epoch [7/25], Step [3600/41412], Loss: 1.4857, Perplexity: 4.41804\n",
      "Epoch [7/25], Step [3700/41412], Loss: 2.1313, Perplexity: 8.42589\n",
      "Epoch [7/25], Step [3800/41412], Loss: 1.4231, Perplexity: 4.14984\n",
      "Epoch [7/25], Step [3900/41412], Loss: 1.9565, Perplexity: 7.07465\n",
      "Epoch [7/25], Step [4000/41412], Loss: 1.6394, Perplexity: 5.15214\n",
      "Epoch [7/25], Step [4100/41412], Loss: 1.8008, Perplexity: 6.05477\n",
      "Epoch [7/25], Step [4200/41412], Loss: 1.9117, Perplexity: 6.76468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Step [4300/41412], Loss: 1.5734, Perplexity: 4.82301\n",
      "Epoch [7/25], Step [4400/41412], Loss: 2.1155, Perplexity: 8.29366\n",
      "Epoch [7/25], Step [4500/41412], Loss: 2.1238, Perplexity: 8.36276\n",
      "Epoch [7/25], Step [4600/41412], Loss: 1.9471, Perplexity: 7.00859\n",
      "Epoch [7/25], Step [4700/41412], Loss: 1.9633, Perplexity: 7.12316\n",
      "Epoch [7/25], Step [4800/41412], Loss: 2.6271, Perplexity: 13.8342\n",
      "Epoch [7/25], Step [4900/41412], Loss: 1.6269, Perplexity: 5.08816\n",
      "Epoch [7/25], Step [5000/41412], Loss: 1.5289, Perplexity: 4.61320\n",
      "Epoch [7/25], Step [5100/41412], Loss: 2.3962, Perplexity: 10.9812\n",
      "Epoch [7/25], Step [5200/41412], Loss: 2.0394, Perplexity: 7.68612\n",
      "Epoch [7/25], Step [5300/41412], Loss: 2.7512, Perplexity: 15.6611\n",
      "Epoch [7/25], Step [5400/41412], Loss: 2.3208, Perplexity: 10.1835\n",
      "Epoch [7/25], Step [5500/41412], Loss: 2.2206, Perplexity: 9.21257\n",
      "Epoch [7/25], Step [5600/41412], Loss: 2.2129, Perplexity: 9.14211\n",
      "Epoch [7/25], Step [5700/41412], Loss: 1.9026, Perplexity: 6.70344\n",
      "Epoch [7/25], Step [5800/41412], Loss: 1.8471, Perplexity: 6.34148\n",
      "Epoch [7/25], Step [5900/41412], Loss: 2.0099, Perplexity: 7.46235\n",
      "Epoch [7/25], Step [6000/41412], Loss: 1.9376, Perplexity: 6.94225\n",
      "Epoch [7/25], Step [6100/41412], Loss: 1.7076, Perplexity: 5.51574\n",
      "Epoch [7/25], Step [6200/41412], Loss: 1.7327, Perplexity: 5.65607\n",
      "Epoch [7/25], Step [6300/41412], Loss: 1.9309, Perplexity: 6.89597\n",
      "Epoch [7/25], Step [6400/41412], Loss: 2.3349, Perplexity: 10.3282\n",
      "Epoch [7/25], Step [6500/41412], Loss: 2.4655, Perplexity: 11.7689\n",
      "Epoch [7/25], Step [6600/41412], Loss: 1.9156, Perplexity: 6.79075\n",
      "Epoch [7/25], Step [6700/41412], Loss: 2.0926, Perplexity: 8.10572\n",
      "Epoch [7/25], Step [6800/41412], Loss: 2.2571, Perplexity: 9.55577\n",
      "Epoch [7/25], Step [6900/41412], Loss: 1.6659, Perplexity: 5.29047\n",
      "Epoch [7/25], Step [7000/41412], Loss: 1.6140, Perplexity: 5.02297\n",
      "Epoch [7/25], Step [7100/41412], Loss: 1.8399, Perplexity: 6.29598\n",
      "Epoch [7/25], Step [7200/41412], Loss: 1.3730, Perplexity: 3.94715\n",
      "Epoch [7/25], Step [7300/41412], Loss: 2.1019, Perplexity: 8.18158\n",
      "Epoch [7/25], Step [7400/41412], Loss: 1.6968, Perplexity: 5.45663\n",
      "Epoch [7/25], Step [7500/41412], Loss: 1.6690, Perplexity: 5.30717\n",
      "Epoch [7/25], Step [7600/41412], Loss: 2.0629, Perplexity: 7.86883\n",
      "Epoch [7/25], Step [7700/41412], Loss: 1.7465, Perplexity: 5.73473\n",
      "Epoch [7/25], Step [7800/41412], Loss: 1.8528, Perplexity: 6.37782\n",
      "Epoch [7/25], Step [7900/41412], Loss: 2.6686, Perplexity: 14.4193\n",
      "Epoch [7/25], Step [8000/41412], Loss: 1.8588, Perplexity: 6.41603\n",
      "Epoch [7/25], Step [8100/41412], Loss: 1.7690, Perplexity: 5.86486\n",
      "Epoch [7/25], Step [8200/41412], Loss: 1.4876, Perplexity: 4.42665\n",
      "Epoch [7/25], Step [8300/41412], Loss: 1.7361, Perplexity: 5.67519\n",
      "Epoch [7/25], Step [8400/41412], Loss: 2.1022, Perplexity: 8.18417\n",
      "Epoch [7/25], Step [8500/41412], Loss: 2.4490, Perplexity: 11.5773\n",
      "Epoch [7/25], Step [8600/41412], Loss: 1.6001, Perplexity: 4.95377\n",
      "Epoch [7/25], Step [8700/41412], Loss: 2.6891, Perplexity: 14.7188\n",
      "Epoch [7/25], Step [8800/41412], Loss: 2.1435, Perplexity: 8.52945\n",
      "Epoch [7/25], Step [8900/41412], Loss: 1.6995, Perplexity: 5.47144\n",
      "Epoch [7/25], Step [9000/41412], Loss: 2.0058, Perplexity: 7.43210\n",
      "Epoch [7/25], Step [9100/41412], Loss: 2.7498, Perplexity: 15.6391\n",
      "Epoch [7/25], Step [9200/41412], Loss: 2.3112, Perplexity: 10.0866\n",
      "Epoch [7/25], Step [9300/41412], Loss: 1.9421, Perplexity: 6.97342\n",
      "Epoch [7/25], Step [9400/41412], Loss: 1.8416, Perplexity: 6.30641\n",
      "Epoch [7/25], Step [9500/41412], Loss: 1.9339, Perplexity: 6.91617\n",
      "Epoch [7/25], Step [9600/41412], Loss: 2.0269, Perplexity: 7.59075\n",
      "Epoch [7/25], Step [9700/41412], Loss: 2.2956, Perplexity: 9.92995\n",
      "Epoch [7/25], Step [9800/41412], Loss: 1.7118, Perplexity: 5.53875\n",
      "Epoch [7/25], Step [9900/41412], Loss: 1.5476, Perplexity: 4.69994\n",
      "Epoch [7/25], Step [10000/41412], Loss: 1.8114, Perplexity: 6.1187\n",
      "Epoch [7/25], Step [10100/41412], Loss: 2.4631, Perplexity: 11.7415\n",
      "Epoch [7/25], Step [10200/41412], Loss: 1.8418, Perplexity: 6.30779\n",
      "Epoch [7/25], Step [10300/41412], Loss: 1.6649, Perplexity: 5.28520\n",
      "Epoch [7/25], Step [10400/41412], Loss: 2.2683, Perplexity: 9.66310\n",
      "Epoch [7/25], Step [10500/41412], Loss: 1.8674, Perplexity: 6.47128\n",
      "Epoch [7/25], Step [10600/41412], Loss: 2.1496, Perplexity: 8.58144\n",
      "Epoch [7/25], Step [10700/41412], Loss: 2.1296, Perplexity: 8.41188\n",
      "Epoch [7/25], Step [10800/41412], Loss: 1.8858, Perplexity: 6.59171\n",
      "Epoch [7/25], Step [10900/41412], Loss: 2.1661, Perplexity: 8.72416\n",
      "Epoch [7/25], Step [11000/41412], Loss: 2.0636, Perplexity: 7.87439\n",
      "Epoch [7/25], Step [11100/41412], Loss: 1.4712, Perplexity: 4.35447\n",
      "Epoch [7/25], Step [11200/41412], Loss: 1.5932, Perplexity: 4.91957\n",
      "Epoch [7/25], Step [11300/41412], Loss: 2.2414, Perplexity: 9.40663\n",
      "Epoch [7/25], Step [11400/41412], Loss: 2.4032, Perplexity: 11.0588\n",
      "Epoch [7/25], Step [11500/41412], Loss: 2.0955, Perplexity: 8.12954\n",
      "Epoch [7/25], Step [11600/41412], Loss: 1.6645, Perplexity: 5.28282\n",
      "Epoch [7/25], Step [11700/41412], Loss: 2.1336, Perplexity: 8.44552\n",
      "Epoch [7/25], Step [11800/41412], Loss: 2.0981, Perplexity: 8.15060\n",
      "Epoch [7/25], Step [11900/41412], Loss: 2.1080, Perplexity: 8.23211\n",
      "Epoch [7/25], Step [12000/41412], Loss: 1.7164, Perplexity: 5.56425\n",
      "Epoch [7/25], Step [12100/41412], Loss: 1.9331, Perplexity: 6.91090\n",
      "Epoch [7/25], Step [12200/41412], Loss: 1.6444, Perplexity: 5.17811\n",
      "Epoch [7/25], Step [12300/41412], Loss: 1.9052, Perplexity: 6.72101\n",
      "Epoch [7/25], Step [12400/41412], Loss: 1.7006, Perplexity: 5.47731\n",
      "Epoch [7/25], Step [12500/41412], Loss: 2.1581, Perplexity: 8.65448\n",
      "Epoch [7/25], Step [12600/41412], Loss: 1.7300, Perplexity: 5.64041\n",
      "Epoch [7/25], Step [12700/41412], Loss: 1.7988, Perplexity: 6.04234\n",
      "Epoch [7/25], Step [12800/41412], Loss: 1.8763, Perplexity: 6.52912\n",
      "Epoch [7/25], Step [12900/41412], Loss: 2.1204, Perplexity: 8.33423\n",
      "Epoch [7/25], Step [13000/41412], Loss: 1.5715, Perplexity: 4.81390\n",
      "Epoch [7/25], Step [13100/41412], Loss: 1.8813, Perplexity: 6.56197\n",
      "Epoch [7/25], Step [13200/41412], Loss: 1.9632, Perplexity: 7.12184\n",
      "Epoch [7/25], Step [13300/41412], Loss: 2.2036, Perplexity: 9.05746\n",
      "Epoch [7/25], Step [13400/41412], Loss: 1.9543, Perplexity: 7.05900\n",
      "Epoch [7/25], Step [13500/41412], Loss: 2.1657, Perplexity: 8.72089\n",
      "Epoch [7/25], Step [13600/41412], Loss: 2.0150, Perplexity: 7.50042\n",
      "Epoch [7/25], Step [13700/41412], Loss: 1.9095, Perplexity: 6.74945\n",
      "Epoch [7/25], Step [13800/41412], Loss: 1.5241, Perplexity: 4.59126\n",
      "Epoch [7/25], Step [13900/41412], Loss: 2.4910, Perplexity: 12.0730\n",
      "Epoch [7/25], Step [14000/41412], Loss: 1.8315, Perplexity: 6.24300\n",
      "Epoch [7/25], Step [14100/41412], Loss: 2.0422, Perplexity: 7.70772\n",
      "Epoch [7/25], Step [14200/41412], Loss: 1.9923, Perplexity: 7.33268\n",
      "Epoch [7/25], Step [14300/41412], Loss: 1.8941, Perplexity: 6.64631\n",
      "Epoch [7/25], Step [14400/41412], Loss: 1.7284, Perplexity: 5.63140\n",
      "Epoch [7/25], Step [14500/41412], Loss: 1.8728, Perplexity: 6.50664\n",
      "Epoch [7/25], Step [14600/41412], Loss: 1.9809, Perplexity: 7.24958\n",
      "Epoch [7/25], Step [14700/41412], Loss: 2.1205, Perplexity: 8.33517\n",
      "Epoch [7/25], Step [14800/41412], Loss: 3.2966, Perplexity: 27.0216\n",
      "Epoch [7/25], Step [14900/41412], Loss: 2.0101, Perplexity: 7.46409\n",
      "Epoch [7/25], Step [15000/41412], Loss: 2.5538, Perplexity: 12.8565\n",
      "Epoch [7/25], Step [15100/41412], Loss: 2.1340, Perplexity: 8.44884\n",
      "Epoch [7/25], Step [15200/41412], Loss: 1.6527, Perplexity: 5.22135\n",
      "Epoch [7/25], Step [15300/41412], Loss: 1.6270, Perplexity: 5.08875\n",
      "Epoch [7/25], Step [15400/41412], Loss: 2.1676, Perplexity: 8.73779\n",
      "Epoch [7/25], Step [15500/41412], Loss: 1.8619, Perplexity: 6.43585\n",
      "Epoch [7/25], Step [15600/41412], Loss: 1.8982, Perplexity: 6.67423\n",
      "Epoch [7/25], Step [15700/41412], Loss: 1.3843, Perplexity: 3.99209\n",
      "Epoch [7/25], Step [15800/41412], Loss: 1.5790, Perplexity: 4.85028\n",
      "Epoch [7/25], Step [15900/41412], Loss: 1.9834, Perplexity: 7.26777\n",
      "Epoch [7/25], Step [16000/41412], Loss: 1.6761, Perplexity: 5.34496\n",
      "Epoch [7/25], Step [16100/41412], Loss: 1.9056, Perplexity: 6.72326\n",
      "Epoch [7/25], Step [16200/41412], Loss: 1.6971, Perplexity: 5.45832\n",
      "Epoch [7/25], Step [16300/41412], Loss: 1.6254, Perplexity: 5.08077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Step [16400/41412], Loss: 1.9970, Perplexity: 7.36662\n",
      "Epoch [7/25], Step [16500/41412], Loss: 1.7869, Perplexity: 5.97094\n",
      "Epoch [7/25], Step [16600/41412], Loss: 1.6925, Perplexity: 5.43312\n",
      "Epoch [7/25], Step [16700/41412], Loss: 1.5428, Perplexity: 4.67761\n",
      "Epoch [7/25], Step [16800/41412], Loss: 2.3334, Perplexity: 10.3125\n",
      "Epoch [7/25], Step [16900/41412], Loss: 2.2452, Perplexity: 9.44194\n",
      "Epoch [7/25], Step [17000/41412], Loss: 1.7011, Perplexity: 5.47978\n",
      "Epoch [7/25], Step [17100/41412], Loss: 1.8869, Perplexity: 6.59890\n",
      "Epoch [7/25], Step [17200/41412], Loss: 2.1855, Perplexity: 8.89480\n",
      "Epoch [7/25], Step [17300/41412], Loss: 2.1981, Perplexity: 9.00824\n",
      "Epoch [7/25], Step [17400/41412], Loss: 1.7692, Perplexity: 5.86601\n",
      "Epoch [7/25], Step [17500/41412], Loss: 1.9966, Perplexity: 7.36410\n",
      "Epoch [7/25], Step [17600/41412], Loss: 2.0977, Perplexity: 8.14719\n",
      "Epoch [7/25], Step [17700/41412], Loss: 1.6606, Perplexity: 5.26236\n",
      "Epoch [7/25], Step [17800/41412], Loss: 1.9830, Perplexity: 7.26477\n",
      "Epoch [7/25], Step [17900/41412], Loss: 1.9165, Perplexity: 6.79738\n",
      "Epoch [7/25], Step [18000/41412], Loss: 2.3476, Perplexity: 10.4608\n",
      "Epoch [7/25], Step [18100/41412], Loss: 1.5886, Perplexity: 4.89710\n",
      "Epoch [7/25], Step [18200/41412], Loss: 1.9046, Perplexity: 6.71685\n",
      "Epoch [7/25], Step [18300/41412], Loss: 1.7289, Perplexity: 5.63445\n",
      "Epoch [7/25], Step [18400/41412], Loss: 2.0406, Perplexity: 7.69558\n",
      "Epoch [7/25], Step [18500/41412], Loss: 2.0528, Perplexity: 7.78984\n",
      "Epoch [7/25], Step [18600/41412], Loss: 2.1075, Perplexity: 8.22801\n",
      "Epoch [7/25], Step [18700/41412], Loss: 1.7423, Perplexity: 5.71068\n",
      "Epoch [7/25], Step [18800/41412], Loss: 1.6947, Perplexity: 5.44483\n",
      "Epoch [7/25], Step [18900/41412], Loss: 2.3007, Perplexity: 9.98136\n",
      "Epoch [7/25], Step [19000/41412], Loss: 1.9050, Perplexity: 6.71950\n",
      "Epoch [7/25], Step [19100/41412], Loss: 2.0830, Perplexity: 8.02885\n",
      "Epoch [7/25], Step [19200/41412], Loss: 2.6769, Perplexity: 14.5403\n",
      "Epoch [7/25], Step [19300/41412], Loss: 2.1652, Perplexity: 8.71634\n",
      "Epoch [7/25], Step [19400/41412], Loss: 2.2664, Perplexity: 9.64444\n",
      "Epoch [7/25], Step [19500/41412], Loss: 2.0662, Perplexity: 7.89475\n",
      "Epoch [7/25], Step [19600/41412], Loss: 1.8823, Perplexity: 6.56845\n",
      "Epoch [7/25], Step [19700/41412], Loss: 2.5564, Perplexity: 12.8891\n",
      "Epoch [7/25], Step [19800/41412], Loss: 2.0569, Perplexity: 7.82169\n",
      "Epoch [7/25], Step [19900/41412], Loss: 1.9818, Perplexity: 7.25604\n",
      "Epoch [7/25], Step [20000/41412], Loss: 2.2262, Perplexity: 9.26494\n",
      "Epoch [7/25], Step [20100/41412], Loss: 2.5419, Perplexity: 12.7036\n",
      "Epoch [7/25], Step [20200/41412], Loss: 1.9510, Perplexity: 7.03574\n",
      "Epoch [7/25], Step [20300/41412], Loss: 1.5852, Perplexity: 4.88031\n",
      "Epoch [7/25], Step [20400/41412], Loss: 1.8306, Perplexity: 6.23730\n",
      "Epoch [7/25], Step [20500/41412], Loss: 1.8135, Perplexity: 6.13177\n",
      "Epoch [7/25], Step [20600/41412], Loss: 2.2674, Perplexity: 9.65459\n",
      "Epoch [7/25], Step [20700/41412], Loss: 2.8093, Perplexity: 16.5989\n",
      "Epoch [7/25], Step [20800/41412], Loss: 1.5918, Perplexity: 4.91268\n",
      "Epoch [7/25], Step [20900/41412], Loss: 1.9463, Perplexity: 7.00277\n",
      "Epoch [7/25], Step [21000/41412], Loss: 1.7829, Perplexity: 5.94748\n",
      "Epoch [7/25], Step [21100/41412], Loss: 1.8421, Perplexity: 6.30997\n",
      "Epoch [7/25], Step [21200/41412], Loss: 1.8845, Perplexity: 6.58302\n",
      "Epoch [7/25], Step [21300/41412], Loss: 1.8112, Perplexity: 6.11774\n",
      "Epoch [7/25], Step [21400/41412], Loss: 2.0673, Perplexity: 7.90348\n",
      "Epoch [7/25], Step [21500/41412], Loss: 2.2006, Perplexity: 9.03009\n",
      "Epoch [7/25], Step [21600/41412], Loss: 2.3766, Perplexity: 10.7680\n",
      "Epoch [7/25], Step [21700/41412], Loss: 2.0905, Perplexity: 8.08921\n",
      "Epoch [7/25], Step [21800/41412], Loss: 1.9243, Perplexity: 6.85040\n",
      "Epoch [7/25], Step [21900/41412], Loss: 1.8408, Perplexity: 6.30164\n",
      "Epoch [7/25], Step [22000/41412], Loss: 1.9303, Perplexity: 6.89166\n",
      "Epoch [7/25], Step [22100/41412], Loss: 2.2364, Perplexity: 9.35948\n",
      "Epoch [7/25], Step [22200/41412], Loss: 1.6954, Perplexity: 5.44905\n",
      "Epoch [7/25], Step [22300/41412], Loss: 1.5809, Perplexity: 4.85914\n",
      "Epoch [7/25], Step [22400/41412], Loss: 1.6988, Perplexity: 5.46727\n",
      "Epoch [7/25], Step [22500/41412], Loss: 2.2985, Perplexity: 9.95892\n",
      "Epoch [7/25], Step [22600/41412], Loss: 1.9077, Perplexity: 6.73733\n",
      "Epoch [7/25], Step [22700/41412], Loss: 1.8008, Perplexity: 6.05444\n",
      "Epoch [7/25], Step [22800/41412], Loss: 2.5396, Perplexity: 12.6742\n",
      "Epoch [7/25], Step [22900/41412], Loss: 1.6977, Perplexity: 5.46138\n",
      "Epoch [7/25], Step [23000/41412], Loss: 1.8223, Perplexity: 6.18602\n",
      "Epoch [7/25], Step [23100/41412], Loss: 1.7446, Perplexity: 5.72364\n",
      "Epoch [7/25], Step [23200/41412], Loss: 2.7826, Perplexity: 16.1617\n",
      "Epoch [7/25], Step [23300/41412], Loss: 1.6762, Perplexity: 5.34534\n",
      "Epoch [7/25], Step [23400/41412], Loss: 2.6622, Perplexity: 14.3279\n",
      "Epoch [7/25], Step [23500/41412], Loss: 2.0748, Perplexity: 7.96286\n",
      "Epoch [7/25], Step [23600/41412], Loss: 1.8186, Perplexity: 6.16323\n",
      "Epoch [7/25], Step [23700/41412], Loss: 1.5949, Perplexity: 4.92802\n",
      "Epoch [7/25], Step [23800/41412], Loss: 2.7644, Perplexity: 15.8694\n",
      "Epoch [7/25], Step [23900/41412], Loss: 1.5784, Perplexity: 4.84735\n",
      "Epoch [7/25], Step [24000/41412], Loss: 1.7886, Perplexity: 5.98108\n",
      "Epoch [7/25], Step [24100/41412], Loss: 1.6701, Perplexity: 5.31279\n",
      "Epoch [7/25], Step [24200/41412], Loss: 2.1538, Perplexity: 8.61789\n",
      "Epoch [7/25], Step [24300/41412], Loss: 2.0245, Perplexity: 7.57264\n",
      "Epoch [7/25], Step [24400/41412], Loss: 2.0708, Perplexity: 7.93150\n",
      "Epoch [7/25], Step [24500/41412], Loss: 1.5501, Perplexity: 4.71204\n",
      "Epoch [7/25], Step [24600/41412], Loss: 1.6983, Perplexity: 5.46474\n",
      "Epoch [7/25], Step [24700/41412], Loss: 1.4081, Perplexity: 4.08803\n",
      "Epoch [7/25], Step [24800/41412], Loss: 1.8639, Perplexity: 6.44902\n",
      "Epoch [7/25], Step [24900/41412], Loss: 1.6083, Perplexity: 4.99414\n",
      "Epoch [7/25], Step [25000/41412], Loss: 2.4335, Perplexity: 11.3990\n",
      "Epoch [7/25], Step [25100/41412], Loss: 1.9114, Perplexity: 6.76273\n",
      "Epoch [7/25], Step [25200/41412], Loss: 2.2108, Perplexity: 9.12339\n",
      "Epoch [7/25], Step [25300/41412], Loss: 2.1382, Perplexity: 8.48452\n",
      "Epoch [7/25], Step [25400/41412], Loss: 1.6103, Perplexity: 5.00417\n",
      "Epoch [7/25], Step [25500/41412], Loss: 2.1026, Perplexity: 8.18769\n",
      "Epoch [7/25], Step [25600/41412], Loss: 2.0430, Perplexity: 7.71347\n",
      "Epoch [7/25], Step [25700/41412], Loss: 1.9996, Perplexity: 7.38642\n",
      "Epoch [7/25], Step [25800/41412], Loss: 2.1212, Perplexity: 8.34081\n",
      "Epoch [7/25], Step [25900/41412], Loss: 1.7634, Perplexity: 5.83201\n",
      "Epoch [7/25], Step [26000/41412], Loss: 2.2223, Perplexity: 9.22816\n",
      "Epoch [7/25], Step [26100/41412], Loss: 2.5059, Perplexity: 12.2548\n",
      "Epoch [7/25], Step [26200/41412], Loss: 2.0428, Perplexity: 7.71253\n",
      "Epoch [7/25], Step [26300/41412], Loss: 2.0783, Perplexity: 7.99066\n",
      "Epoch [7/25], Step [26400/41412], Loss: 2.1338, Perplexity: 8.44720\n",
      "Epoch [7/25], Step [26500/41412], Loss: 2.3342, Perplexity: 10.3212\n",
      "Epoch [7/25], Step [26600/41412], Loss: 1.8952, Perplexity: 6.65395\n",
      "Epoch [7/25], Step [26700/41412], Loss: 1.7245, Perplexity: 5.60978\n",
      "Epoch [7/25], Step [26800/41412], Loss: 1.7141, Perplexity: 5.55189\n",
      "Epoch [7/25], Step [26900/41412], Loss: 2.1615, Perplexity: 8.68395\n",
      "Epoch [7/25], Step [27000/41412], Loss: 2.2522, Perplexity: 9.50893\n",
      "Epoch [7/25], Step [27100/41412], Loss: 2.7858, Perplexity: 16.2134\n",
      "Epoch [7/25], Step [27200/41412], Loss: 1.7551, Perplexity: 5.78416\n",
      "Epoch [7/25], Step [27300/41412], Loss: 2.2511, Perplexity: 9.49862\n",
      "Epoch [7/25], Step [27400/41412], Loss: 2.3215, Perplexity: 10.1913\n",
      "Epoch [7/25], Step [27500/41412], Loss: 2.4810, Perplexity: 11.9528\n",
      "Epoch [7/25], Step [27600/41412], Loss: 2.3413, Perplexity: 10.3950\n",
      "Epoch [7/25], Step [27700/41412], Loss: 2.8855, Perplexity: 17.9127\n",
      "Epoch [7/25], Step [27800/41412], Loss: 1.7179, Perplexity: 5.57310\n",
      "Epoch [7/25], Step [27900/41412], Loss: 2.5033, Perplexity: 12.2233\n",
      "Epoch [7/25], Step [28000/41412], Loss: 1.9921, Perplexity: 7.33063\n",
      "Epoch [7/25], Step [28100/41412], Loss: 1.6001, Perplexity: 4.95340\n",
      "Epoch [7/25], Step [28200/41412], Loss: 2.2205, Perplexity: 9.21227\n",
      "Epoch [7/25], Step [28300/41412], Loss: 2.3777, Perplexity: 10.7796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Step [28400/41412], Loss: 1.8780, Perplexity: 6.54014\n",
      "Epoch [7/25], Step [28500/41412], Loss: 1.8614, Perplexity: 6.432902\n",
      "Epoch [7/25], Step [28600/41412], Loss: 1.9867, Perplexity: 7.29115\n",
      "Epoch [7/25], Step [28700/41412], Loss: 2.1078, Perplexity: 8.229976\n",
      "Epoch [7/25], Step [28800/41412], Loss: 1.9358, Perplexity: 6.92937\n",
      "Epoch [7/25], Step [28900/41412], Loss: 2.2815, Perplexity: 9.79121\n",
      "Epoch [7/25], Step [29000/41412], Loss: 1.9435, Perplexity: 6.98308\n",
      "Epoch [7/25], Step [29100/41412], Loss: 1.7552, Perplexity: 5.78445\n",
      "Epoch [7/25], Step [29200/41412], Loss: 2.6797, Perplexity: 14.5800\n",
      "Epoch [7/25], Step [29300/41412], Loss: 2.0899, Perplexity: 8.08389\n",
      "Epoch [7/25], Step [29400/41412], Loss: 2.0870, Perplexity: 8.06077\n",
      "Epoch [7/25], Step [29500/41412], Loss: 1.8618, Perplexity: 6.43515\n",
      "Epoch [7/25], Step [29600/41412], Loss: 1.8425, Perplexity: 6.31200\n",
      "Epoch [7/25], Step [29700/41412], Loss: 2.5208, Perplexity: 12.4389\n",
      "Epoch [7/25], Step [29800/41412], Loss: 1.6296, Perplexity: 5.10202\n",
      "Epoch [7/25], Step [29900/41412], Loss: 1.9417, Perplexity: 6.97035\n",
      "Epoch [7/25], Step [30000/41412], Loss: 1.8834, Perplexity: 6.57590\n",
      "Epoch [7/25], Step [30100/41412], Loss: 1.9969, Perplexity: 7.36644\n",
      "Epoch [7/25], Step [30200/41412], Loss: 1.7110, Perplexity: 5.53459\n",
      "Epoch [7/25], Step [30300/41412], Loss: 1.5651, Perplexity: 4.78335\n",
      "Epoch [7/25], Step [30400/41412], Loss: 1.8832, Perplexity: 6.57456\n",
      "Epoch [7/25], Step [30500/41412], Loss: 1.9121, Perplexity: 6.76715\n",
      "Epoch [7/25], Step [30600/41412], Loss: 2.1132, Perplexity: 8.27512\n",
      "Epoch [7/25], Step [30700/41412], Loss: 1.8665, Perplexity: 6.46586\n",
      "Epoch [7/25], Step [30800/41412], Loss: 1.6283, Perplexity: 5.09515\n",
      "Epoch [7/25], Step [30900/41412], Loss: 1.6372, Perplexity: 5.14051\n",
      "Epoch [7/25], Step [31000/41412], Loss: 1.7165, Perplexity: 5.56518\n",
      "Epoch [7/25], Step [31100/41412], Loss: 1.7599, Perplexity: 5.81197\n",
      "Epoch [7/25], Step [31200/41412], Loss: 2.3658, Perplexity: 10.6527\n",
      "Epoch [7/25], Step [31300/41412], Loss: 1.6262, Perplexity: 5.08430\n",
      "Epoch [7/25], Step [31400/41412], Loss: 2.2371, Perplexity: 9.36629\n",
      "Epoch [7/25], Step [31500/41412], Loss: 1.8892, Perplexity: 6.61406\n",
      "Epoch [7/25], Step [31600/41412], Loss: 2.1144, Perplexity: 8.28475\n",
      "Epoch [7/25], Step [31700/41412], Loss: 1.9169, Perplexity: 6.79979\n",
      "Epoch [7/25], Step [31800/41412], Loss: 1.7127, Perplexity: 5.54375\n",
      "Epoch [7/25], Step [31900/41412], Loss: 1.8302, Perplexity: 6.23519\n",
      "Epoch [7/25], Step [32000/41412], Loss: 2.2059, Perplexity: 9.07830\n",
      "Epoch [7/25], Step [32100/41412], Loss: 1.6158, Perplexity: 5.03170\n",
      "Epoch [7/25], Step [32200/41412], Loss: 2.1921, Perplexity: 8.95383\n",
      "Epoch [7/25], Step [32300/41412], Loss: 2.1031, Perplexity: 8.19177\n",
      "Epoch [7/25], Step [32400/41412], Loss: 1.9073, Perplexity: 6.73512\n",
      "Epoch [7/25], Step [32500/41412], Loss: 1.6371, Perplexity: 5.14039\n",
      "Epoch [7/25], Step [32600/41412], Loss: 2.4081, Perplexity: 11.1132\n",
      "Epoch [7/25], Step [32700/41412], Loss: 1.7999, Perplexity: 6.04901\n",
      "Epoch [7/25], Step [32800/41412], Loss: 2.0557, Perplexity: 7.81252\n",
      "Epoch [7/25], Step [32900/41412], Loss: 1.9214, Perplexity: 6.83063\n",
      "Epoch [7/25], Step [33000/41412], Loss: 1.7919, Perplexity: 6.00107\n",
      "Epoch [7/25], Step [33100/41412], Loss: 1.9105, Perplexity: 6.75656\n",
      "Epoch [7/25], Step [33200/41412], Loss: 1.8942, Perplexity: 6.64706\n",
      "Epoch [7/25], Step [33300/41412], Loss: 1.9215, Perplexity: 6.83125\n",
      "Epoch [7/25], Step [33400/41412], Loss: 1.9240, Perplexity: 6.84806\n",
      "Epoch [7/25], Step [33500/41412], Loss: 2.2434, Perplexity: 9.42508\n",
      "Epoch [7/25], Step [33600/41412], Loss: 1.7634, Perplexity: 5.83238\n",
      "Epoch [7/25], Step [33700/41412], Loss: 2.1694, Perplexity: 8.75263\n",
      "Epoch [7/25], Step [33800/41412], Loss: 1.7450, Perplexity: 5.72599\n",
      "Epoch [7/25], Step [33900/41412], Loss: 1.8656, Perplexity: 6.459529\n",
      "Epoch [7/25], Step [34000/41412], Loss: 2.2547, Perplexity: 9.53268\n",
      "Epoch [7/25], Step [34100/41412], Loss: 1.7146, Perplexity: 5.55437\n",
      "Epoch [7/25], Step [34200/41412], Loss: 2.3926, Perplexity: 10.9414\n",
      "Epoch [7/25], Step [34300/41412], Loss: 2.4117, Perplexity: 11.1528\n",
      "Epoch [7/25], Step [34400/41412], Loss: 2.0211, Perplexity: 7.54698\n",
      "Epoch [7/25], Step [34500/41412], Loss: 2.1007, Perplexity: 8.17205\n",
      "Epoch [7/25], Step [34600/41412], Loss: 2.1733, Perplexity: 8.78729\n",
      "Epoch [7/25], Step [34700/41412], Loss: 1.8799, Perplexity: 6.55252\n",
      "Epoch [7/25], Step [34800/41412], Loss: 1.6847, Perplexity: 5.39104\n",
      "Epoch [7/25], Step [34900/41412], Loss: 1.5330, Perplexity: 4.63226\n",
      "Epoch [7/25], Step [35000/41412], Loss: 2.2910, Perplexity: 9.88489\n",
      "Epoch [7/25], Step [35100/41412], Loss: 2.0292, Perplexity: 7.60782\n",
      "Epoch [7/25], Step [35200/41412], Loss: 2.2751, Perplexity: 9.72879\n",
      "Epoch [7/25], Step [35300/41412], Loss: 1.7281, Perplexity: 5.63022\n",
      "Epoch [7/25], Step [35400/41412], Loss: 1.6818, Perplexity: 5.37557\n",
      "Epoch [7/25], Step [35500/41412], Loss: 2.1280, Perplexity: 8.39845\n",
      "Epoch [7/25], Step [35600/41412], Loss: 1.8705, Perplexity: 6.49161\n",
      "Epoch [7/25], Step [35700/41412], Loss: 1.4657, Perplexity: 4.33069\n",
      "Epoch [7/25], Step [35800/41412], Loss: 1.6606, Perplexity: 5.26246\n",
      "Epoch [7/25], Step [35900/41412], Loss: 1.5740, Perplexity: 4.82616\n",
      "Epoch [7/25], Step [36000/41412], Loss: 2.0003, Perplexity: 7.39153\n",
      "Epoch [7/25], Step [36100/41412], Loss: 2.2184, Perplexity: 9.19289\n",
      "Epoch [7/25], Step [36200/41412], Loss: 2.4608, Perplexity: 11.7140\n",
      "Epoch [7/25], Step [36300/41412], Loss: 1.8884, Perplexity: 6.60855\n",
      "Epoch [7/25], Step [36400/41412], Loss: 2.8765, Perplexity: 17.7519\n",
      "Epoch [7/25], Step [36500/41412], Loss: 2.8036, Perplexity: 16.5040\n",
      "Epoch [7/25], Step [36600/41412], Loss: 2.0468, Perplexity: 7.74343\n",
      "Epoch [7/25], Step [36700/41412], Loss: 1.8504, Perplexity: 6.36275\n",
      "Epoch [7/25], Step [36800/41412], Loss: 1.6818, Perplexity: 5.37532\n",
      "Epoch [7/25], Step [36900/41412], Loss: 2.1389, Perplexity: 8.49027\n",
      "Epoch [7/25], Step [37000/41412], Loss: 1.9418, Perplexity: 6.97147\n",
      "Epoch [7/25], Step [37100/41412], Loss: 1.6794, Perplexity: 5.36238\n",
      "Epoch [7/25], Step [37200/41412], Loss: 2.2920, Perplexity: 9.89488\n",
      "Epoch [7/25], Step [37300/41412], Loss: 2.3352, Perplexity: 10.3318\n",
      "Epoch [7/25], Step [37400/41412], Loss: 2.4739, Perplexity: 11.8681\n",
      "Epoch [7/25], Step [37500/41412], Loss: 2.1471, Perplexity: 8.56009\n",
      "Epoch [7/25], Step [37600/41412], Loss: 1.9984, Perplexity: 7.37739\n",
      "Epoch [7/25], Step [37700/41412], Loss: 1.6398, Perplexity: 5.154041\n",
      "Epoch [7/25], Step [37800/41412], Loss: 2.0812, Perplexity: 8.01374\n",
      "Epoch [7/25], Step [37900/41412], Loss: 2.0993, Perplexity: 8.16075\n",
      "Epoch [7/25], Step [38000/41412], Loss: 2.0173, Perplexity: 7.51808\n",
      "Epoch [7/25], Step [38100/41412], Loss: 2.5089, Perplexity: 12.2918\n",
      "Epoch [7/25], Step [38200/41412], Loss: 2.1898, Perplexity: 8.93360\n",
      "Epoch [7/25], Step [38300/41412], Loss: 2.4685, Perplexity: 11.8042\n",
      "Epoch [7/25], Step [38400/41412], Loss: 2.0228, Perplexity: 7.55958\n",
      "Epoch [7/25], Step [38500/41412], Loss: 1.8292, Perplexity: 6.22916\n",
      "Epoch [7/25], Step [38600/41412], Loss: 2.3641, Perplexity: 10.6349\n",
      "Epoch [7/25], Step [38700/41412], Loss: 1.9347, Perplexity: 6.92210\n",
      "Epoch [7/25], Step [38800/41412], Loss: 2.0589, Perplexity: 7.83733\n",
      "Epoch [7/25], Step [38900/41412], Loss: 1.8281, Perplexity: 6.22200\n",
      "Epoch [7/25], Step [39000/41412], Loss: 1.9347, Perplexity: 6.92179\n",
      "Epoch [7/25], Step [39100/41412], Loss: 2.2885, Perplexity: 9.86054\n",
      "Epoch [7/25], Step [39200/41412], Loss: 1.9950, Perplexity: 7.35253\n",
      "Epoch [7/25], Step [39300/41412], Loss: 1.4788, Perplexity: 4.38761\n",
      "Epoch [7/25], Step [39400/41412], Loss: 1.8635, Perplexity: 6.44639\n",
      "Epoch [7/25], Step [39500/41412], Loss: 1.6187, Perplexity: 5.046555\n",
      "Epoch [7/25], Step [39600/41412], Loss: 2.4213, Perplexity: 11.2603\n",
      "Epoch [7/25], Step [39700/41412], Loss: 1.8015, Perplexity: 6.05865\n",
      "Epoch [7/25], Step [39800/41412], Loss: 1.7782, Perplexity: 5.91906\n",
      "Epoch [7/25], Step [39900/41412], Loss: 1.9913, Perplexity: 7.32530\n",
      "Epoch [7/25], Step [40000/41412], Loss: 2.1035, Perplexity: 8.19475\n",
      "Epoch [7/25], Step [40100/41412], Loss: 1.8314, Perplexity: 6.24233\n",
      "Epoch [7/25], Step [40200/41412], Loss: 1.9215, Perplexity: 6.83129\n",
      "Epoch [7/25], Step [40300/41412], Loss: 2.3672, Perplexity: 10.6675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Step [40400/41412], Loss: 2.5385, Perplexity: 12.6611\n",
      "Epoch [7/25], Step [40500/41412], Loss: 2.0324, Perplexity: 7.63220\n",
      "Epoch [7/25], Step [40600/41412], Loss: 1.8337, Perplexity: 6.25702\n",
      "Epoch [7/25], Step [40700/41412], Loss: 1.8797, Perplexity: 6.55183\n",
      "Epoch [7/25], Step [40800/41412], Loss: 1.9669, Perplexity: 7.14881\n",
      "Epoch [7/25], Step [40900/41412], Loss: 2.2799, Perplexity: 9.77544\n",
      "Epoch [7/25], Step [41000/41412], Loss: 2.4608, Perplexity: 11.7142\n",
      "Epoch [7/25], Step [41100/41412], Loss: 2.0295, Perplexity: 7.61038\n",
      "Epoch [7/25], Step [41200/41412], Loss: 1.8026, Perplexity: 6.06531\n",
      "Epoch [7/25], Step [41300/41412], Loss: 2.3226, Perplexity: 10.2025\n",
      "Epoch [7/25], Step [41400/41412], Loss: 1.7036, Perplexity: 5.49341\n",
      "Epoch [8/25], Step [100/41412], Loss: 2.5088, Perplexity: 12.289760\n",
      "Epoch [8/25], Step [200/41412], Loss: 1.9036, Perplexity: 6.70993\n",
      "Epoch [8/25], Step [300/41412], Loss: 1.8618, Perplexity: 6.43502\n",
      "Epoch [8/25], Step [400/41412], Loss: 1.8300, Perplexity: 6.23364\n",
      "Epoch [8/25], Step [500/41412], Loss: 1.5918, Perplexity: 4.91289\n",
      "Epoch [8/25], Step [600/41412], Loss: 1.9932, Perplexity: 7.33900\n",
      "Epoch [8/25], Step [700/41412], Loss: 2.0757, Perplexity: 7.97042\n",
      "Epoch [8/25], Step [800/41412], Loss: 3.4786, Perplexity: 32.4149\n",
      "Epoch [8/25], Step [900/41412], Loss: 2.8029, Perplexity: 16.4927\n",
      "Epoch [8/25], Step [1000/41412], Loss: 1.7688, Perplexity: 5.8640\n",
      "Epoch [8/25], Step [1100/41412], Loss: 1.9554, Perplexity: 7.06699\n",
      "Epoch [8/25], Step [1200/41412], Loss: 1.8867, Perplexity: 6.59740\n",
      "Epoch [8/25], Step [1300/41412], Loss: 1.7920, Perplexity: 6.00146\n",
      "Epoch [8/25], Step [1400/41412], Loss: 1.8366, Perplexity: 6.27509\n",
      "Epoch [8/25], Step [1500/41412], Loss: 2.3165, Perplexity: 10.1405\n",
      "Epoch [8/25], Step [1600/41412], Loss: 1.8197, Perplexity: 6.16999\n",
      "Epoch [8/25], Step [1700/41412], Loss: 2.0269, Perplexity: 7.59047\n",
      "Epoch [8/25], Step [1800/41412], Loss: 1.6534, Perplexity: 5.22469\n",
      "Epoch [8/25], Step [1900/41412], Loss: 2.1262, Perplexity: 8.38317\n",
      "Epoch [8/25], Step [2000/41412], Loss: 1.9141, Perplexity: 6.78080\n",
      "Epoch [8/25], Step [2100/41412], Loss: 2.2426, Perplexity: 9.41771\n",
      "Epoch [8/25], Step [2200/41412], Loss: 2.0769, Perplexity: 7.97992\n",
      "Epoch [8/25], Step [2300/41412], Loss: 2.1166, Perplexity: 8.30299\n",
      "Epoch [8/25], Step [2400/41412], Loss: 2.0187, Perplexity: 7.52867\n",
      "Epoch [8/25], Step [2500/41412], Loss: 1.8698, Perplexity: 6.48689\n",
      "Epoch [8/25], Step [2600/41412], Loss: 1.5165, Perplexity: 4.55629\n",
      "Epoch [8/25], Step [2700/41412], Loss: 2.1184, Perplexity: 8.31775\n",
      "Epoch [8/25], Step [2800/41412], Loss: 2.2684, Perplexity: 9.66373\n",
      "Epoch [8/25], Step [2900/41412], Loss: 1.9823, Perplexity: 7.25955\n",
      "Epoch [8/25], Step [3000/41412], Loss: 2.1035, Perplexity: 8.19461\n",
      "Epoch [8/25], Step [3100/41412], Loss: 1.9567, Perplexity: 7.07593\n",
      "Epoch [8/25], Step [3200/41412], Loss: 2.4380, Perplexity: 11.4505\n",
      "Epoch [8/25], Step [3300/41412], Loss: 1.8667, Perplexity: 6.46667\n",
      "Epoch [8/25], Step [3400/41412], Loss: 1.9392, Perplexity: 6.95294\n",
      "Epoch [8/25], Step [3500/41412], Loss: 2.1904, Perplexity: 8.93927\n",
      "Epoch [8/25], Step [3600/41412], Loss: 1.7487, Perplexity: 5.74715\n",
      "Epoch [8/25], Step [3700/41412], Loss: 2.1997, Perplexity: 9.02232\n",
      "Epoch [8/25], Step [3800/41412], Loss: 1.8849, Perplexity: 6.58551\n",
      "Epoch [8/25], Step [3900/41412], Loss: 2.0086, Perplexity: 7.45290\n",
      "Epoch [8/25], Step [4000/41412], Loss: 2.1484, Perplexity: 8.57081\n",
      "Epoch [8/25], Step [4100/41412], Loss: 1.8741, Perplexity: 6.51506\n",
      "Epoch [8/25], Step [4200/41412], Loss: 1.5798, Perplexity: 4.85388\n",
      "Epoch [8/25], Step [4300/41412], Loss: 1.8872, Perplexity: 6.60095\n",
      "Epoch [8/25], Step [4400/41412], Loss: 1.9987, Perplexity: 7.37931\n",
      "Epoch [8/25], Step [4500/41412], Loss: 2.1189, Perplexity: 8.32231\n",
      "Epoch [8/25], Step [4600/41412], Loss: 1.8146, Perplexity: 6.13875\n",
      "Epoch [8/25], Step [4700/41412], Loss: 2.0501, Perplexity: 7.76900\n",
      "Epoch [8/25], Step [4800/41412], Loss: 2.2757, Perplexity: 9.73421\n",
      "Epoch [8/25], Step [4900/41412], Loss: 1.7074, Perplexity: 5.51486\n",
      "Epoch [8/25], Step [5000/41412], Loss: 2.1099, Perplexity: 8.24724\n",
      "Epoch [8/25], Step [5100/41412], Loss: 1.8576, Perplexity: 6.40858\n",
      "Epoch [8/25], Step [5200/41412], Loss: 1.8474, Perplexity: 6.34344\n",
      "Epoch [8/25], Step [5300/41412], Loss: 1.8631, Perplexity: 6.44409\n",
      "Epoch [8/25], Step [5400/41412], Loss: 2.0689, Perplexity: 7.91624\n",
      "Epoch [8/25], Step [5500/41412], Loss: 1.8852, Perplexity: 6.58804\n",
      "Epoch [8/25], Step [5600/41412], Loss: 2.0025, Perplexity: 7.40781\n",
      "Epoch [8/25], Step [5700/41412], Loss: 3.9190, Perplexity: 50.3476\n",
      "Epoch [8/25], Step [5800/41412], Loss: 2.0145, Perplexity: 7.49736\n",
      "Epoch [8/25], Step [5900/41412], Loss: 1.8525, Perplexity: 6.37576\n",
      "Epoch [8/25], Step [6000/41412], Loss: 2.3137, Perplexity: 10.1116\n",
      "Epoch [8/25], Step [6100/41412], Loss: 2.0052, Perplexity: 7.42778\n",
      "Epoch [8/25], Step [6200/41412], Loss: 1.9969, Perplexity: 7.36627\n",
      "Epoch [8/25], Step [6300/41412], Loss: 1.9749, Perplexity: 7.20581\n",
      "Epoch [8/25], Step [6400/41412], Loss: 2.0756, Perplexity: 7.96918\n",
      "Epoch [8/25], Step [6500/41412], Loss: 2.2673, Perplexity: 9.65362\n",
      "Epoch [8/25], Step [6600/41412], Loss: 2.0616, Perplexity: 7.85884\n",
      "Epoch [8/25], Step [6700/41412], Loss: 2.1076, Perplexity: 8.22850\n",
      "Epoch [8/25], Step [6800/41412], Loss: 2.4888, Perplexity: 12.0468\n",
      "Epoch [8/25], Step [6900/41412], Loss: 2.1004, Perplexity: 8.16957\n",
      "Epoch [8/25], Step [7000/41412], Loss: 2.4588, Perplexity: 11.6903\n",
      "Epoch [8/25], Step [7100/41412], Loss: 2.1489, Perplexity: 8.57566\n",
      "Epoch [8/25], Step [7200/41412], Loss: 1.7353, Perplexity: 5.67047\n",
      "Epoch [8/25], Step [7300/41412], Loss: 1.5478, Perplexity: 4.70133\n",
      "Epoch [8/25], Step [7400/41412], Loss: 2.3453, Perplexity: 10.4363\n",
      "Epoch [8/25], Step [7500/41412], Loss: 2.0245, Perplexity: 7.57207\n",
      "Epoch [8/25], Step [7600/41412], Loss: 2.2587, Perplexity: 9.57027\n",
      "Epoch [8/25], Step [7700/41412], Loss: 1.9236, Perplexity: 6.84559\n",
      "Epoch [8/25], Step [7800/41412], Loss: 1.8515, Perplexity: 6.36966\n",
      "Epoch [8/25], Step [7900/41412], Loss: 1.8733, Perplexity: 6.51001\n",
      "Epoch [8/25], Step [8000/41412], Loss: 2.1173, Perplexity: 8.30894\n",
      "Epoch [8/25], Step [8100/41412], Loss: 1.8565, Perplexity: 6.40158\n",
      "Epoch [8/25], Step [8200/41412], Loss: 1.7016, Perplexity: 5.48283\n",
      "Epoch [8/25], Step [8300/41412], Loss: 1.8419, Perplexity: 6.30865\n",
      "Epoch [8/25], Step [8400/41412], Loss: 1.9770, Perplexity: 7.22085\n",
      "Epoch [8/25], Step [8500/41412], Loss: 1.9939, Perplexity: 7.34382\n",
      "Epoch [8/25], Step [8600/41412], Loss: 2.3635, Perplexity: 10.6285\n",
      "Epoch [8/25], Step [8700/41412], Loss: 1.5310, Perplexity: 4.62264\n",
      "Epoch [8/25], Step [8800/41412], Loss: 2.0592, Perplexity: 7.83947\n",
      "Epoch [8/25], Step [8900/41412], Loss: 1.9595, Perplexity: 7.09601\n",
      "Epoch [8/25], Step [9000/41412], Loss: 2.4850, Perplexity: 12.0012\n",
      "Epoch [8/25], Step [9100/41412], Loss: 2.3718, Perplexity: 10.7171\n",
      "Epoch [8/25], Step [9200/41412], Loss: 1.7365, Perplexity: 5.67732\n",
      "Epoch [8/25], Step [9300/41412], Loss: 2.1227, Perplexity: 8.35339\n",
      "Epoch [8/25], Step [9400/41412], Loss: 2.0965, Perplexity: 8.13751\n",
      "Epoch [8/25], Step [9500/41412], Loss: 2.1385, Perplexity: 8.48664\n",
      "Epoch [8/25], Step [9600/41412], Loss: 2.0142, Perplexity: 7.49517\n",
      "Epoch [8/25], Step [9700/41412], Loss: 2.2571, Perplexity: 9.55490\n",
      "Epoch [8/25], Step [9800/41412], Loss: 1.9706, Perplexity: 7.17501\n",
      "Epoch [8/25], Step [9900/41412], Loss: 1.9124, Perplexity: 6.76932\n",
      "Epoch [8/25], Step [10000/41412], Loss: 2.1639, Perplexity: 8.7051\n",
      "Epoch [8/25], Step [10100/41412], Loss: 1.7205, Perplexity: 5.58731\n",
      "Epoch [8/25], Step [10200/41412], Loss: 1.9471, Perplexity: 7.00817\n",
      "Epoch [8/25], Step [10300/41412], Loss: 2.3469, Perplexity: 10.4527\n",
      "Epoch [8/25], Step [10400/41412], Loss: 1.6300, Perplexity: 5.10388\n",
      "Epoch [8/25], Step [10500/41412], Loss: 1.7588, Perplexity: 5.80552\n",
      "Epoch [8/25], Step [10600/41412], Loss: 1.9992, Perplexity: 7.38317\n",
      "Epoch [8/25], Step [10700/41412], Loss: 1.5426, Perplexity: 4.67666\n",
      "Epoch [8/25], Step [10800/41412], Loss: 1.8641, Perplexity: 6.450409\n",
      "Epoch [8/25], Step [10900/41412], Loss: 1.8212, Perplexity: 6.17918\n",
      "Epoch [8/25], Step [11000/41412], Loss: 1.7185, Perplexity: 5.57633\n",
      "Epoch [8/25], Step [11100/41412], Loss: 1.8459, Perplexity: 6.33402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Step [11200/41412], Loss: 1.5516, Perplexity: 4.71924\n",
      "Epoch [8/25], Step [11300/41412], Loss: 1.8013, Perplexity: 6.05763\n",
      "Epoch [8/25], Step [11400/41412], Loss: 2.0080, Perplexity: 7.44855\n",
      "Epoch [8/25], Step [11500/41412], Loss: 2.5656, Perplexity: 13.0087\n",
      "Epoch [8/25], Step [11600/41412], Loss: 1.8232, Perplexity: 6.19154\n",
      "Epoch [8/25], Step [11700/41412], Loss: 1.5191, Perplexity: 4.56823\n",
      "Epoch [8/25], Step [11800/41412], Loss: 2.3020, Perplexity: 9.99379\n",
      "Epoch [8/25], Step [11900/41412], Loss: 2.0750, Perplexity: 7.96451\n",
      "Epoch [8/25], Step [12000/41412], Loss: 1.8101, Perplexity: 6.11110\n",
      "Epoch [8/25], Step [12100/41412], Loss: 1.8553, Perplexity: 6.39341\n",
      "Epoch [8/25], Step [12200/41412], Loss: 1.4843, Perplexity: 4.41189\n",
      "Epoch [8/25], Step [12300/41412], Loss: 2.5675, Perplexity: 13.0330\n",
      "Epoch [8/25], Step [12400/41412], Loss: 2.5873, Perplexity: 13.2941\n",
      "Epoch [8/25], Step [12500/41412], Loss: 2.1127, Perplexity: 8.27098\n",
      "Epoch [8/25], Step [12600/41412], Loss: 2.2134, Perplexity: 9.14717\n",
      "Epoch [8/25], Step [12700/41412], Loss: 1.9788, Perplexity: 7.23399\n",
      "Epoch [8/25], Step [12800/41412], Loss: 2.0447, Perplexity: 7.72677\n",
      "Epoch [8/25], Step [12900/41412], Loss: 1.6846, Perplexity: 5.39056\n",
      "Epoch [8/25], Step [13000/41412], Loss: 2.0200, Perplexity: 7.53805\n",
      "Epoch [8/25], Step [13100/41412], Loss: 2.3924, Perplexity: 10.9399\n",
      "Epoch [8/25], Step [13200/41412], Loss: 1.8513, Perplexity: 6.36827\n",
      "Epoch [8/25], Step [13300/41412], Loss: 2.0933, Perplexity: 8.11199\n",
      "Epoch [8/25], Step [13400/41412], Loss: 2.0850, Perplexity: 8.04478\n",
      "Epoch [8/25], Step [13500/41412], Loss: 2.2417, Perplexity: 9.40947\n",
      "Epoch [8/25], Step [13600/41412], Loss: 1.9783, Perplexity: 7.23039\n",
      "Epoch [8/25], Step [13700/41412], Loss: 1.7066, Perplexity: 5.51056\n",
      "Epoch [8/25], Step [13800/41412], Loss: 1.5816, Perplexity: 4.86272\n",
      "Epoch [8/25], Step [13900/41412], Loss: 1.8631, Perplexity: 6.44405\n",
      "Epoch [8/25], Step [14000/41412], Loss: 1.4750, Perplexity: 4.37109\n",
      "Epoch [8/25], Step [14100/41412], Loss: 2.9080, Perplexity: 18.3210\n",
      "Epoch [8/25], Step [14200/41412], Loss: 2.0726, Perplexity: 7.94522\n",
      "Epoch [8/25], Step [14300/41412], Loss: 1.9463, Perplexity: 7.00307\n",
      "Epoch [8/25], Step [14400/41412], Loss: 1.9240, Perplexity: 6.84859\n",
      "Epoch [8/25], Step [14500/41412], Loss: 1.7193, Perplexity: 5.58054\n",
      "Epoch [8/25], Step [14600/41412], Loss: 1.8308, Perplexity: 6.23915\n",
      "Epoch [8/25], Step [14700/41412], Loss: 2.1100, Perplexity: 8.24833\n",
      "Epoch [8/25], Step [14800/41412], Loss: 2.1282, Perplexity: 8.39966\n",
      "Epoch [8/25], Step [14900/41412], Loss: 1.7446, Perplexity: 5.72386\n",
      "Epoch [8/25], Step [15000/41412], Loss: 1.6906, Perplexity: 5.42282\n",
      "Epoch [8/25], Step [15100/41412], Loss: 2.3233, Perplexity: 10.2097\n",
      "Epoch [8/25], Step [15200/41412], Loss: 2.2528, Perplexity: 9.51430\n",
      "Epoch [8/25], Step [15300/41412], Loss: 1.7158, Perplexity: 5.56128\n",
      "Epoch [8/25], Step [15400/41412], Loss: 2.0360, Perplexity: 7.65960\n",
      "Epoch [8/25], Step [15500/41412], Loss: 2.0511, Perplexity: 7.77674\n",
      "Epoch [8/25], Step [15600/41412], Loss: 1.8143, Perplexity: 6.13652\n",
      "Epoch [8/25], Step [15700/41412], Loss: 1.8748, Perplexity: 6.51971\n",
      "Epoch [8/25], Step [15800/41412], Loss: 1.7981, Perplexity: 6.037932\n",
      "Epoch [8/25], Step [15900/41412], Loss: 3.3576, Perplexity: 28.7205\n",
      "Epoch [8/25], Step [16000/41412], Loss: 2.0197, Perplexity: 7.53622\n",
      "Epoch [8/25], Step [16100/41412], Loss: 2.1442, Perplexity: 8.53559\n",
      "Epoch [8/25], Step [16200/41412], Loss: 2.6186, Perplexity: 13.7164\n",
      "Epoch [8/25], Step [16300/41412], Loss: 2.2477, Perplexity: 9.46592\n",
      "Epoch [8/25], Step [16400/41412], Loss: 1.8742, Perplexity: 6.51560\n",
      "Epoch [8/25], Step [16500/41412], Loss: 1.9946, Perplexity: 7.34900\n",
      "Epoch [8/25], Step [16600/41412], Loss: 2.0336, Perplexity: 7.64195\n",
      "Epoch [8/25], Step [16700/41412], Loss: 2.2693, Perplexity: 9.67274\n",
      "Epoch [8/25], Step [16800/41412], Loss: 2.7326, Perplexity: 15.3720\n",
      "Epoch [8/25], Step [16900/41412], Loss: 1.9019, Perplexity: 6.69880\n",
      "Epoch [8/25], Step [17000/41412], Loss: 1.6273, Perplexity: 5.09010\n",
      "Epoch [8/25], Step [17100/41412], Loss: 2.4366, Perplexity: 11.4337\n",
      "Epoch [8/25], Step [17200/41412], Loss: 2.1367, Perplexity: 8.47158\n",
      "Epoch [8/25], Step [17300/41412], Loss: 1.8591, Perplexity: 6.41806\n",
      "Epoch [8/25], Step [17400/41412], Loss: 2.2639, Perplexity: 9.62092\n",
      "Epoch [8/25], Step [17500/41412], Loss: 1.6572, Perplexity: 5.24442\n",
      "Epoch [8/25], Step [17600/41412], Loss: 1.9732, Perplexity: 7.19363\n",
      "Epoch [8/25], Step [17700/41412], Loss: 2.0870, Perplexity: 8.06075\n",
      "Epoch [8/25], Step [17800/41412], Loss: 1.9844, Perplexity: 7.27466\n",
      "Epoch [8/25], Step [17900/41412], Loss: 1.8195, Perplexity: 6.16857\n",
      "Epoch [8/25], Step [18000/41412], Loss: 1.6122, Perplexity: 5.01374\n",
      "Epoch [8/25], Step [18100/41412], Loss: 1.6801, Perplexity: 5.36590\n",
      "Epoch [8/25], Step [18200/41412], Loss: 2.0907, Perplexity: 8.09028\n",
      "Epoch [8/25], Step [18300/41412], Loss: 1.9601, Perplexity: 7.09995\n",
      "Epoch [8/25], Step [18400/41412], Loss: 2.1079, Perplexity: 8.23093\n",
      "Epoch [8/25], Step [18500/41412], Loss: 1.9541, Perplexity: 7.05764\n",
      "Epoch [8/25], Step [18600/41412], Loss: 2.3931, Perplexity: 10.9471\n",
      "Epoch [8/25], Step [18700/41412], Loss: 1.8551, Perplexity: 6.39228\n",
      "Epoch [8/25], Step [18800/41412], Loss: 2.2188, Perplexity: 9.19606\n",
      "Epoch [8/25], Step [18900/41412], Loss: 1.7716, Perplexity: 5.88012\n",
      "Epoch [8/25], Step [19000/41412], Loss: 1.6713, Perplexity: 5.31918\n",
      "Epoch [8/25], Step [19100/41412], Loss: 2.0492, Perplexity: 7.76153\n",
      "Epoch [8/25], Step [19200/41412], Loss: 1.8962, Perplexity: 6.66054\n",
      "Epoch [8/25], Step [19300/41412], Loss: 1.6800, Perplexity: 5.36557\n",
      "Epoch [8/25], Step [19400/41412], Loss: 2.1552, Perplexity: 8.62980\n",
      "Epoch [8/25], Step [19500/41412], Loss: 2.0030, Perplexity: 7.41168\n",
      "Epoch [8/25], Step [19600/41412], Loss: 1.7974, Perplexity: 6.03409\n",
      "Epoch [8/25], Step [19700/41412], Loss: 1.9051, Perplexity: 6.72047\n",
      "Epoch [8/25], Step [19800/41412], Loss: 1.7461, Perplexity: 5.73208\n",
      "Epoch [8/25], Step [19900/41412], Loss: 2.1584, Perplexity: 8.65765\n",
      "Epoch [8/25], Step [20000/41412], Loss: 2.0989, Perplexity: 8.15695\n",
      "Epoch [8/25], Step [20100/41412], Loss: 2.3327, Perplexity: 10.3055\n",
      "Epoch [8/25], Step [20200/41412], Loss: 1.5257, Perplexity: 4.59869\n",
      "Epoch [8/25], Step [20300/41412], Loss: 1.9216, Perplexity: 6.83223\n",
      "Epoch [8/25], Step [20400/41412], Loss: 1.6291, Perplexity: 5.09933\n",
      "Epoch [8/25], Step [20500/41412], Loss: 1.7341, Perplexity: 5.66379\n",
      "Epoch [8/25], Step [20600/41412], Loss: 2.0290, Perplexity: 7.60625\n",
      "Epoch [8/25], Step [20700/41412], Loss: 1.3814, Perplexity: 3.98058\n",
      "Epoch [8/25], Step [20800/41412], Loss: 1.5830, Perplexity: 4.86956\n",
      "Epoch [8/25], Step [20900/41412], Loss: 2.0846, Perplexity: 8.04113\n",
      "Epoch [8/25], Step [21000/41412], Loss: 1.7753, Perplexity: 5.90184\n",
      "Epoch [8/25], Step [21100/41412], Loss: 2.2747, Perplexity: 9.72458\n",
      "Epoch [8/25], Step [21200/41412], Loss: 2.6371, Perplexity: 13.9726\n",
      "Epoch [8/25], Step [21300/41412], Loss: 1.8175, Perplexity: 6.15670\n",
      "Epoch [8/25], Step [21400/41412], Loss: 1.7626, Perplexity: 5.82758\n",
      "Epoch [8/25], Step [21500/41412], Loss: 2.2230, Perplexity: 9.23456\n",
      "Epoch [8/25], Step [21600/41412], Loss: 1.7404, Perplexity: 5.69940\n",
      "Epoch [8/25], Step [21700/41412], Loss: 1.8286, Perplexity: 6.22530\n",
      "Epoch [8/25], Step [21800/41412], Loss: 1.9709, Perplexity: 7.17681\n",
      "Epoch [8/25], Step [21900/41412], Loss: 1.9269, Perplexity: 6.86827\n",
      "Epoch [8/25], Step [22000/41412], Loss: 1.9312, Perplexity: 6.89741\n",
      "Epoch [8/25], Step [22100/41412], Loss: 1.6275, Perplexity: 5.09118\n",
      "Epoch [8/25], Step [22200/41412], Loss: 2.1776, Perplexity: 8.82510\n",
      "Epoch [8/25], Step [22300/41412], Loss: 1.9352, Perplexity: 6.92538\n",
      "Epoch [8/25], Step [22400/41412], Loss: 2.3096, Perplexity: 10.0709\n",
      "Epoch [8/25], Step [22500/41412], Loss: 1.8893, Perplexity: 6.61470\n",
      "Epoch [8/25], Step [22600/41412], Loss: 2.1383, Perplexity: 8.48494\n",
      "Epoch [8/25], Step [22700/41412], Loss: 1.7489, Perplexity: 5.74840\n",
      "Epoch [8/25], Step [22800/41412], Loss: 1.9030, Perplexity: 6.70623\n",
      "Epoch [8/25], Step [22900/41412], Loss: 1.9845, Perplexity: 7.27545\n",
      "Epoch [8/25], Step [23000/41412], Loss: 2.3457, Perplexity: 10.4403\n",
      "Epoch [8/25], Step [23100/41412], Loss: 2.5231, Perplexity: 12.4666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Step [23200/41412], Loss: 1.9252, Perplexity: 6.85637\n",
      "Epoch [8/25], Step [23300/41412], Loss: 2.3228, Perplexity: 10.2043\n",
      "Epoch [8/25], Step [23400/41412], Loss: 2.2540, Perplexity: 9.52532\n",
      "Epoch [8/25], Step [23500/41412], Loss: 2.0350, Perplexity: 7.65251\n",
      "Epoch [8/25], Step [23600/41412], Loss: 1.8533, Perplexity: 6.38081\n",
      "Epoch [8/25], Step [23700/41412], Loss: 2.1737, Perplexity: 8.79042\n",
      "Epoch [8/25], Step [23800/41412], Loss: 2.2430, Perplexity: 9.42127\n",
      "Epoch [8/25], Step [23900/41412], Loss: 2.0108, Perplexity: 7.46921\n",
      "Epoch [8/25], Step [24000/41412], Loss: 2.1858, Perplexity: 8.89737\n",
      "Epoch [8/25], Step [24100/41412], Loss: 2.7239, Perplexity: 15.2389\n",
      "Epoch [8/25], Step [24200/41412], Loss: 1.9309, Perplexity: 6.89594\n",
      "Epoch [8/25], Step [24300/41412], Loss: 2.6455, Perplexity: 14.0905\n",
      "Epoch [8/25], Step [24400/41412], Loss: 2.0731, Perplexity: 7.94929\n",
      "Epoch [8/25], Step [24500/41412], Loss: 1.6358, Perplexity: 5.13355\n",
      "Epoch [8/25], Step [24600/41412], Loss: 1.8549, Perplexity: 6.39110\n",
      "Epoch [8/25], Step [24700/41412], Loss: 1.5313, Perplexity: 4.62432\n",
      "Epoch [8/25], Step [24800/41412], Loss: 1.5191, Perplexity: 4.56838\n",
      "Epoch [8/25], Step [24900/41412], Loss: 1.9265, Perplexity: 6.86573\n",
      "Epoch [8/25], Step [25000/41412], Loss: 2.0890, Perplexity: 8.07667\n",
      "Epoch [8/25], Step [25100/41412], Loss: 2.2650, Perplexity: 9.63115\n",
      "Epoch [8/25], Step [25200/41412], Loss: 2.0015, Perplexity: 7.40028\n",
      "Epoch [8/25], Step [25300/41412], Loss: 1.9058, Perplexity: 6.72456\n",
      "Epoch [8/25], Step [25400/41412], Loss: 1.9965, Perplexity: 7.36293\n",
      "Epoch [8/25], Step [25500/41412], Loss: 1.6853, Perplexity: 5.39427\n",
      "Epoch [8/25], Step [25600/41412], Loss: 1.7446, Perplexity: 5.72366\n",
      "Epoch [8/25], Step [25700/41412], Loss: 1.6756, Perplexity: 5.34196\n",
      "Epoch [8/25], Step [25800/41412], Loss: 2.3917, Perplexity: 10.9321\n",
      "Epoch [8/25], Step [25900/41412], Loss: 2.0888, Perplexity: 8.07518\n",
      "Epoch [8/25], Step [26000/41412], Loss: 1.5944, Perplexity: 4.92549\n",
      "Epoch [8/25], Step [26100/41412], Loss: 1.6837, Perplexity: 5.38579\n",
      "Epoch [8/25], Step [26200/41412], Loss: 1.5211, Perplexity: 4.57741\n",
      "Epoch [8/25], Step [26300/41412], Loss: 1.7763, Perplexity: 5.90784\n",
      "Epoch [8/25], Step [26400/41412], Loss: 2.7506, Perplexity: 15.6513\n",
      "Epoch [8/25], Step [26500/41412], Loss: 1.9954, Perplexity: 7.35531\n",
      "Epoch [8/25], Step [26600/41412], Loss: 2.5152, Perplexity: 12.36931\n",
      "Epoch [8/25], Step [26700/41412], Loss: 2.2535, Perplexity: 9.52110\n",
      "Epoch [8/25], Step [26800/41412], Loss: 2.0160, Perplexity: 7.50819\n",
      "Epoch [8/25], Step [26900/41412], Loss: 2.7471, Perplexity: 15.5967\n",
      "Epoch [8/25], Step [27000/41412], Loss: 1.9211, Perplexity: 6.82861\n",
      "Epoch [8/25], Step [27100/41412], Loss: 1.6614, Perplexity: 5.26642\n",
      "Epoch [8/25], Step [27200/41412], Loss: 1.9996, Perplexity: 7.38615\n",
      "Epoch [8/25], Step [27300/41412], Loss: 1.6952, Perplexity: 5.44800\n",
      "Epoch [8/25], Step [27400/41412], Loss: 2.1610, Perplexity: 8.67960\n",
      "Epoch [8/25], Step [27500/41412], Loss: 1.9939, Perplexity: 7.34390\n",
      "Epoch [8/25], Step [27600/41412], Loss: 1.5333, Perplexity: 4.63352\n",
      "Epoch [8/25], Step [27700/41412], Loss: 2.1103, Perplexity: 8.25051\n",
      "Epoch [8/25], Step [27800/41412], Loss: 1.9372, Perplexity: 6.93919\n",
      "Epoch [8/25], Step [27900/41412], Loss: 2.2083, Perplexity: 9.10033\n",
      "Epoch [8/25], Step [28000/41412], Loss: 1.6998, Perplexity: 5.47311\n",
      "Epoch [8/25], Step [28100/41412], Loss: 1.4086, Perplexity: 4.09025\n",
      "Epoch [8/25], Step [28200/41412], Loss: 1.7380, Perplexity: 5.68587\n",
      "Epoch [8/25], Step [28300/41412], Loss: 1.9515, Perplexity: 7.03915\n",
      "Epoch [8/25], Step [28400/41412], Loss: 1.8764, Perplexity: 6.52971\n",
      "Epoch [8/25], Step [28500/41412], Loss: 1.9628, Perplexity: 7.11959\n",
      "Epoch [8/25], Step [28600/41412], Loss: 1.7523, Perplexity: 5.76777\n",
      "Epoch [8/25], Step [28700/41412], Loss: 1.7061, Perplexity: 5.50757\n",
      "Epoch [8/25], Step [28800/41412], Loss: 2.0085, Perplexity: 7.45242\n",
      "Epoch [8/25], Step [28900/41412], Loss: 1.8325, Perplexity: 6.24972\n",
      "Epoch [8/25], Step [29000/41412], Loss: 1.9828, Perplexity: 7.26292\n",
      "Epoch [8/25], Step [29100/41412], Loss: 2.0539, Perplexity: 7.79858\n",
      "Epoch [8/25], Step [29200/41412], Loss: 1.5713, Perplexity: 4.81295\n",
      "Epoch [8/25], Step [29300/41412], Loss: 2.3039, Perplexity: 10.01340\n",
      "Epoch [8/25], Step [29400/41412], Loss: 2.2602, Perplexity: 9.58481\n",
      "Epoch [8/25], Step [29500/41412], Loss: 2.2226, Perplexity: 9.23142\n",
      "Epoch [8/25], Step [29600/41412], Loss: 1.7740, Perplexity: 5.89448\n",
      "Epoch [8/25], Step [29700/41412], Loss: 1.6031, Perplexity: 4.96833\n",
      "Epoch [8/25], Step [29800/41412], Loss: 2.2474, Perplexity: 9.46355\n",
      "Epoch [8/25], Step [29900/41412], Loss: 1.9808, Perplexity: 7.24849\n",
      "Epoch [8/25], Step [30000/41412], Loss: 2.7247, Perplexity: 15.2519\n",
      "Epoch [8/25], Step [30100/41412], Loss: 1.5102, Perplexity: 4.52767\n",
      "Epoch [8/25], Step [30200/41412], Loss: 2.5164, Perplexity: 12.3841\n",
      "Epoch [8/25], Step [30300/41412], Loss: 1.8553, Perplexity: 6.39354\n",
      "Epoch [8/25], Step [30400/41412], Loss: 2.1462, Perplexity: 8.55237\n",
      "Epoch [8/25], Step [30500/41412], Loss: 2.2409, Perplexity: 9.40140\n",
      "Epoch [8/25], Step [30600/41412], Loss: 2.0036, Perplexity: 7.41578\n",
      "Epoch [8/25], Step [30700/41412], Loss: 1.6413, Perplexity: 5.16182\n",
      "Epoch [8/25], Step [30800/41412], Loss: 2.6453, Perplexity: 14.0879\n",
      "Epoch [8/25], Step [30900/41412], Loss: 2.5584, Perplexity: 12.9154\n",
      "Epoch [8/25], Step [31000/41412], Loss: 1.7228, Perplexity: 5.60001\n",
      "Epoch [8/25], Step [31100/41412], Loss: 2.0383, Perplexity: 7.67747\n",
      "Epoch [8/25], Step [31200/41412], Loss: 2.1721, Perplexity: 8.77660\n",
      "Epoch [8/25], Step [31300/41412], Loss: 1.7027, Perplexity: 5.48895\n",
      "Epoch [8/25], Step [31400/41412], Loss: 1.8770, Perplexity: 6.53367\n",
      "Epoch [8/25], Step [31500/41412], Loss: 1.8243, Perplexity: 6.19868\n",
      "Epoch [8/25], Step [31600/41412], Loss: 2.3439, Perplexity: 10.4223\n",
      "Epoch [8/25], Step [31700/41412], Loss: 2.0187, Perplexity: 7.52849\n",
      "Epoch [8/25], Step [31800/41412], Loss: 2.5341, Perplexity: 12.6052\n",
      "Epoch [8/25], Step [31900/41412], Loss: 1.8345, Perplexity: 6.26186\n",
      "Epoch [8/25], Step [32000/41412], Loss: 1.6818, Perplexity: 5.37505\n",
      "Epoch [8/25], Step [32100/41412], Loss: 2.4525, Perplexity: 11.6174\n",
      "Epoch [8/25], Step [32200/41412], Loss: 2.3063, Perplexity: 10.0367\n",
      "Epoch [8/25], Step [32300/41412], Loss: 2.3623, Perplexity: 10.6149\n",
      "Epoch [8/25], Step [32400/41412], Loss: 1.8004, Perplexity: 6.05238\n",
      "Epoch [8/25], Step [32500/41412], Loss: 1.7100, Perplexity: 5.52905\n",
      "Epoch [8/25], Step [32600/41412], Loss: 1.9636, Perplexity: 7.12528\n",
      "Epoch [8/25], Step [32700/41412], Loss: 2.2155, Perplexity: 9.16649\n",
      "Epoch [8/25], Step [32800/41412], Loss: 2.6146, Perplexity: 13.6611\n",
      "Epoch [8/25], Step [32900/41412], Loss: 2.2701, Perplexity: 9.67992\n",
      "Epoch [8/25], Step [33000/41412], Loss: 2.1826, Perplexity: 8.86913\n",
      "Epoch [8/25], Step [33100/41412], Loss: 2.3009, Perplexity: 9.98315\n",
      "Epoch [8/25], Step [33200/41412], Loss: 2.0301, Perplexity: 7.61513\n",
      "Epoch [8/25], Step [33300/41412], Loss: 1.9631, Perplexity: 7.12106\n",
      "Epoch [8/25], Step [33400/41412], Loss: 2.5360, Perplexity: 12.6290\n",
      "Epoch [8/25], Step [33500/41412], Loss: 2.1603, Perplexity: 8.67397\n",
      "Epoch [8/25], Step [33600/41412], Loss: 1.7074, Perplexity: 5.51473\n",
      "Epoch [8/25], Step [33700/41412], Loss: 2.3458, Perplexity: 10.4420\n",
      "Epoch [8/25], Step [33800/41412], Loss: 2.8885, Perplexity: 17.9662\n",
      "Epoch [8/25], Step [33900/41412], Loss: 1.8300, Perplexity: 6.23380\n",
      "Epoch [8/25], Step [34000/41412], Loss: 1.7521, Perplexity: 5.76652\n",
      "Epoch [8/25], Step [34100/41412], Loss: 2.2288, Perplexity: 9.28839\n",
      "Epoch [8/25], Step [34200/41412], Loss: 1.8864, Perplexity: 6.59560\n",
      "Epoch [8/25], Step [34300/41412], Loss: 1.3055, Perplexity: 3.68967\n",
      "Epoch [8/25], Step [34400/41412], Loss: 1.8708, Perplexity: 6.49352\n",
      "Epoch [8/25], Step [34500/41412], Loss: 2.3906, Perplexity: 10.9197\n",
      "Epoch [8/25], Step [34600/41412], Loss: 1.6144, Perplexity: 5.02512\n",
      "Epoch [8/25], Step [34700/41412], Loss: 2.2069, Perplexity: 9.08771\n",
      "Epoch [8/25], Step [34800/41412], Loss: 2.2545, Perplexity: 9.53104\n",
      "Epoch [8/25], Step [34900/41412], Loss: 2.6616, Perplexity: 14.3194\n",
      "Epoch [8/25], Step [35000/41412], Loss: 1.8780, Perplexity: 6.54017\n",
      "Epoch [8/25], Step [35100/41412], Loss: 2.0597, Perplexity: 7.84380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Step [35200/41412], Loss: 1.5268, Perplexity: 4.60333\n",
      "Epoch [8/25], Step [35300/41412], Loss: 1.7683, Perplexity: 5.86063\n",
      "Epoch [8/25], Step [35400/41412], Loss: 2.1269, Perplexity: 8.38908\n",
      "Epoch [8/25], Step [35500/41412], Loss: 1.4751, Perplexity: 4.37169\n",
      "Epoch [8/25], Step [35600/41412], Loss: 2.3634, Perplexity: 10.6269\n",
      "Epoch [8/25], Step [35700/41412], Loss: 1.9150, Perplexity: 6.78691\n",
      "Epoch [8/25], Step [35800/41412], Loss: 1.8402, Perplexity: 6.29763\n",
      "Epoch [8/25], Step [35900/41412], Loss: 1.5568, Perplexity: 4.74347\n",
      "Epoch [8/25], Step [36000/41412], Loss: 1.9159, Perplexity: 6.79298\n",
      "Epoch [8/25], Step [36100/41412], Loss: 2.4389, Perplexity: 11.4606\n",
      "Epoch [8/25], Step [36200/41412], Loss: 1.6422, Perplexity: 5.16672\n",
      "Epoch [8/25], Step [36300/41412], Loss: 1.8887, Perplexity: 6.61085\n",
      "Epoch [8/25], Step [36400/41412], Loss: 1.8714, Perplexity: 6.49741\n",
      "Epoch [8/25], Step [36500/41412], Loss: 1.9434, Perplexity: 6.98288\n",
      "Epoch [8/25], Step [36600/41412], Loss: 1.8791, Perplexity: 6.54738\n",
      "Epoch [8/25], Step [36700/41412], Loss: 2.0741, Perplexity: 7.95721\n",
      "Epoch [8/25], Step [36800/41412], Loss: 1.8968, Perplexity: 6.66477\n",
      "Epoch [8/25], Step [36900/41412], Loss: 2.2631, Perplexity: 9.61295\n",
      "Epoch [8/25], Step [37000/41412], Loss: 1.7504, Perplexity: 5.75723\n",
      "Epoch [8/25], Step [37100/41412], Loss: 2.3636, Perplexity: 10.6296\n",
      "Epoch [8/25], Step [37200/41412], Loss: 1.9265, Perplexity: 6.86560\n",
      "Epoch [8/25], Step [37300/41412], Loss: 2.0612, Perplexity: 7.85550\n",
      "Epoch [8/25], Step [37400/41412], Loss: 2.4173, Perplexity: 11.2159\n",
      "Epoch [8/25], Step [37500/41412], Loss: 2.0388, Perplexity: 7.68153\n",
      "Epoch [8/25], Step [37600/41412], Loss: 1.9284, Perplexity: 6.87833\n",
      "Epoch [8/25], Step [37700/41412], Loss: 2.1507, Perplexity: 8.59106\n",
      "Epoch [8/25], Step [37800/41412], Loss: 1.7276, Perplexity: 5.62743\n",
      "Epoch [8/25], Step [37900/41412], Loss: 1.9634, Perplexity: 7.12365\n",
      "Epoch [8/25], Step [38000/41412], Loss: 1.9217, Perplexity: 6.83253\n",
      "Epoch [8/25], Step [38100/41412], Loss: 2.1583, Perplexity: 8.65609\n",
      "Epoch [8/25], Step [38200/41412], Loss: 1.7367, Perplexity: 5.67875\n",
      "Epoch [8/25], Step [38300/41412], Loss: 2.6092, Perplexity: 13.5881\n",
      "Epoch [8/25], Step [38400/41412], Loss: 2.3279, Perplexity: 10.2567\n",
      "Epoch [8/25], Step [38500/41412], Loss: 1.8289, Perplexity: 6.22715\n",
      "Epoch [8/25], Step [38600/41412], Loss: 1.6913, Perplexity: 5.42641\n",
      "Epoch [8/25], Step [38700/41412], Loss: 2.3010, Perplexity: 9.98389\n",
      "Epoch [8/25], Step [38800/41412], Loss: 2.0909, Perplexity: 8.09205\n",
      "Epoch [8/25], Step [38900/41412], Loss: 1.6722, Perplexity: 5.32409\n",
      "Epoch [8/25], Step [39000/41412], Loss: 2.0785, Perplexity: 7.99224\n",
      "Epoch [8/25], Step [39100/41412], Loss: 2.2410, Perplexity: 9.40285\n",
      "Epoch [8/25], Step [39200/41412], Loss: 1.5519, Perplexity: 4.72030\n",
      "Epoch [8/25], Step [39300/41412], Loss: 1.7736, Perplexity: 5.892267\n",
      "Epoch [8/25], Step [39400/41412], Loss: 1.7769, Perplexity: 5.911322\n",
      "Epoch [8/25], Step [39500/41412], Loss: 2.1911, Perplexity: 8.94478\n",
      "Epoch [8/25], Step [39600/41412], Loss: 1.3137, Perplexity: 3.72002\n",
      "Epoch [8/25], Step [39700/41412], Loss: 2.0789, Perplexity: 7.99530\n",
      "Epoch [8/25], Step [39800/41412], Loss: 1.4998, Perplexity: 4.48098\n",
      "Epoch [8/25], Step [39900/41412], Loss: 1.4173, Perplexity: 4.12607\n",
      "Epoch [8/25], Step [40000/41412], Loss: 1.6452, Perplexity: 5.18212\n",
      "Epoch [8/25], Step [40100/41412], Loss: 2.1142, Perplexity: 8.28349\n",
      "Epoch [8/25], Step [40200/41412], Loss: 2.1285, Perplexity: 8.40259\n",
      "Epoch [8/25], Step [40300/41412], Loss: 2.1563, Perplexity: 8.63950\n",
      "Epoch [8/25], Step [40400/41412], Loss: 1.3807, Perplexity: 3.97787\n",
      "Epoch [8/25], Step [40500/41412], Loss: 2.4192, Perplexity: 11.2369\n",
      "Epoch [8/25], Step [40600/41412], Loss: 2.1454, Perplexity: 8.54546\n",
      "Epoch [8/25], Step [40700/41412], Loss: 2.3110, Perplexity: 10.0849\n",
      "Epoch [8/25], Step [40800/41412], Loss: 2.4605, Perplexity: 11.7102\n",
      "Epoch [8/25], Step [40900/41412], Loss: 1.4521, Perplexity: 4.27207\n",
      "Epoch [8/25], Step [41000/41412], Loss: 1.9499, Perplexity: 7.02805\n",
      "Epoch [8/25], Step [41100/41412], Loss: 2.2037, Perplexity: 9.05872\n",
      "Epoch [8/25], Step [41200/41412], Loss: 1.6892, Perplexity: 5.41519\n",
      "Epoch [8/25], Step [41300/41412], Loss: 2.0601, Perplexity: 7.84689\n",
      "Epoch [8/25], Step [41400/41412], Loss: 2.3029, Perplexity: 10.0028\n",
      "Epoch [9/25], Step [100/41412], Loss: 1.8735, Perplexity: 6.5113363\n",
      "Epoch [9/25], Step [200/41412], Loss: 1.9030, Perplexity: 6.70622\n",
      "Epoch [9/25], Step [300/41412], Loss: 2.1779, Perplexity: 8.82753\n",
      "Epoch [9/25], Step [400/41412], Loss: 1.5492, Perplexity: 4.70776\n",
      "Epoch [9/25], Step [500/41412], Loss: 2.2287, Perplexity: 9.28769\n",
      "Epoch [9/25], Step [600/41412], Loss: 2.0965, Perplexity: 8.13740\n",
      "Epoch [9/25], Step [700/41412], Loss: 2.4969, Perplexity: 12.14535\n",
      "Epoch [9/25], Step [800/41412], Loss: 2.6096, Perplexity: 13.5934\n",
      "Epoch [9/25], Step [900/41412], Loss: 1.9833, Perplexity: 7.26700\n",
      "Epoch [9/25], Step [1000/41412], Loss: 2.2365, Perplexity: 9.3601\n",
      "Epoch [9/25], Step [1100/41412], Loss: 1.8415, Perplexity: 6.30610\n",
      "Epoch [9/25], Step [1200/41412], Loss: 1.8800, Perplexity: 6.55354\n",
      "Epoch [9/25], Step [1300/41412], Loss: 1.8070, Perplexity: 6.09235\n",
      "Epoch [9/25], Step [1400/41412], Loss: 1.7891, Perplexity: 5.98416\n",
      "Epoch [9/25], Step [1500/41412], Loss: 1.8817, Perplexity: 6.56480\n",
      "Epoch [9/25], Step [1600/41412], Loss: 2.2332, Perplexity: 9.32962\n",
      "Epoch [9/25], Step [1700/41412], Loss: 2.3200, Perplexity: 10.1757\n",
      "Epoch [9/25], Step [1800/41412], Loss: 2.0890, Perplexity: 8.07702\n",
      "Epoch [9/25], Step [1900/41412], Loss: 2.2191, Perplexity: 9.19874\n",
      "Epoch [9/25], Step [2000/41412], Loss: 1.7301, Perplexity: 5.64110\n",
      "Epoch [9/25], Step [2100/41412], Loss: 1.9429, Perplexity: 6.97907\n",
      "Epoch [9/25], Step [2200/41412], Loss: 1.5715, Perplexity: 4.81412\n",
      "Epoch [9/25], Step [2300/41412], Loss: 1.8883, Perplexity: 6.60811\n",
      "Epoch [9/25], Step [2400/41412], Loss: 1.6553, Perplexity: 5.23499\n",
      "Epoch [9/25], Step [2500/41412], Loss: 1.7212, Perplexity: 5.59124\n",
      "Epoch [9/25], Step [2600/41412], Loss: 2.0872, Perplexity: 8.06239\n",
      "Epoch [9/25], Step [2700/41412], Loss: 1.9761, Perplexity: 7.21483\n",
      "Epoch [9/25], Step [2800/41412], Loss: 1.8644, Perplexity: 6.45204\n",
      "Epoch [9/25], Step [2900/41412], Loss: 1.7172, Perplexity: 5.56888\n",
      "Epoch [9/25], Step [3000/41412], Loss: 1.9075, Perplexity: 6.73594\n",
      "Epoch [9/25], Step [3100/41412], Loss: 1.5462, Perplexity: 4.69363\n",
      "Epoch [9/25], Step [3200/41412], Loss: 1.9262, Perplexity: 6.86343\n",
      "Epoch [9/25], Step [3300/41412], Loss: 1.9769, Perplexity: 7.22021\n",
      "Epoch [9/25], Step [3400/41412], Loss: 1.7692, Perplexity: 5.86624\n",
      "Epoch [9/25], Step [3500/41412], Loss: 1.8345, Perplexity: 6.26191\n",
      "Epoch [9/25], Step [3600/41412], Loss: 1.7691, Perplexity: 5.86589\n",
      "Epoch [9/25], Step [3700/41412], Loss: 1.6226, Perplexity: 5.06606\n",
      "Epoch [9/25], Step [3800/41412], Loss: 1.6169, Perplexity: 5.03757\n",
      "Epoch [9/25], Step [3900/41412], Loss: 2.0674, Perplexity: 7.90391\n",
      "Epoch [9/25], Step [4000/41412], Loss: 1.6231, Perplexity: 5.06891\n",
      "Epoch [9/25], Step [4100/41412], Loss: 1.9650, Perplexity: 7.134789\n",
      "Epoch [9/25], Step [4200/41412], Loss: 1.5351, Perplexity: 4.64185\n",
      "Epoch [9/25], Step [4300/41412], Loss: 1.9016, Perplexity: 6.69638\n",
      "Epoch [9/25], Step [4400/41412], Loss: 2.1813, Perplexity: 8.85815\n",
      "Epoch [9/25], Step [4500/41412], Loss: 2.1334, Perplexity: 8.44339\n",
      "Epoch [9/25], Step [4600/41412], Loss: 1.6271, Perplexity: 5.08901\n",
      "Epoch [9/25], Step [4700/41412], Loss: 2.0185, Perplexity: 7.52728\n",
      "Epoch [9/25], Step [4800/41412], Loss: 1.9588, Perplexity: 7.09062\n",
      "Epoch [9/25], Step [4900/41412], Loss: 1.4959, Perplexity: 4.46332\n",
      "Epoch [9/25], Step [5000/41412], Loss: 1.7330, Perplexity: 5.65760\n",
      "Epoch [9/25], Step [5100/41412], Loss: 2.1545, Perplexity: 8.62377\n",
      "Epoch [9/25], Step [5200/41412], Loss: 1.8333, Perplexity: 6.25477\n",
      "Epoch [9/25], Step [5300/41412], Loss: 2.1602, Perplexity: 8.67261\n",
      "Epoch [9/25], Step [5400/41412], Loss: 1.9273, Perplexity: 6.87103\n",
      "Epoch [9/25], Step [5500/41412], Loss: 2.0973, Perplexity: 8.14407\n",
      "Epoch [9/25], Step [5600/41412], Loss: 1.9798, Perplexity: 7.24116\n",
      "Epoch [9/25], Step [5700/41412], Loss: 1.4615, Perplexity: 4.31269\n",
      "Epoch [9/25], Step [5800/41412], Loss: 1.7265, Perplexity: 5.62074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Step [5900/41412], Loss: 1.8366, Perplexity: 6.27509\n",
      "Epoch [9/25], Step [6000/41412], Loss: 2.1006, Perplexity: 8.17140\n",
      "Epoch [9/25], Step [6100/41412], Loss: 1.9289, Perplexity: 6.88223\n",
      "Epoch [9/25], Step [6200/41412], Loss: 1.8538, Perplexity: 6.38398\n",
      "Epoch [9/25], Step [6300/41412], Loss: 2.2483, Perplexity: 9.47188\n",
      "Epoch [9/25], Step [6400/41412], Loss: 2.3549, Perplexity: 10.5370\n",
      "Epoch [9/25], Step [6500/41412], Loss: 2.1578, Perplexity: 8.65232\n",
      "Epoch [9/25], Step [6600/41412], Loss: 1.9464, Perplexity: 7.00310\n",
      "Epoch [9/25], Step [6700/41412], Loss: 1.9745, Perplexity: 7.20307\n",
      "Epoch [9/25], Step [6800/41412], Loss: 1.8614, Perplexity: 6.43261\n",
      "Epoch [9/25], Step [6900/41412], Loss: 1.7825, Perplexity: 5.94469\n",
      "Epoch [9/25], Step [7000/41412], Loss: 1.5566, Perplexity: 4.74255\n",
      "Epoch [9/25], Step [7100/41412], Loss: 1.8387, Perplexity: 6.28843\n",
      "Epoch [9/25], Step [7200/41412], Loss: 2.1117, Perplexity: 8.26267\n",
      "Epoch [9/25], Step [7300/41412], Loss: 2.1171, Perplexity: 8.30672\n",
      "Epoch [9/25], Step [7400/41412], Loss: 2.3355, Perplexity: 10.3344\n",
      "Epoch [9/25], Step [7500/41412], Loss: 1.9082, Perplexity: 6.74111\n",
      "Epoch [9/25], Step [7600/41412], Loss: 2.0759, Perplexity: 7.97211\n",
      "Epoch [9/25], Step [7700/41412], Loss: 2.0329, Perplexity: 7.63614\n",
      "Epoch [9/25], Step [7800/41412], Loss: 2.4103, Perplexity: 11.1374\n",
      "Epoch [9/25], Step [7900/41412], Loss: 2.5412, Perplexity: 12.6943\n",
      "Epoch [9/25], Step [8000/41412], Loss: 1.9108, Perplexity: 6.75851\n",
      "Epoch [9/25], Step [8100/41412], Loss: 1.5541, Perplexity: 4.730755\n",
      "Epoch [9/25], Step [8200/41412], Loss: 2.2224, Perplexity: 9.22991\n",
      "Epoch [9/25], Step [8300/41412], Loss: 2.0864, Perplexity: 8.05569\n",
      "Epoch [9/25], Step [8400/41412], Loss: 1.8127, Perplexity: 6.12734\n",
      "Epoch [9/25], Step [8500/41412], Loss: 2.5852, Perplexity: 13.2655\n",
      "Epoch [9/25], Step [8600/41412], Loss: 2.3449, Perplexity: 10.4327\n",
      "Epoch [9/25], Step [8700/41412], Loss: 2.2266, Perplexity: 9.26850\n",
      "Epoch [9/25], Step [8800/41412], Loss: 2.2058, Perplexity: 9.07749\n",
      "Epoch [9/25], Step [8900/41412], Loss: 1.8341, Perplexity: 6.25982\n",
      "Epoch [9/25], Step [9000/41412], Loss: 1.5984, Perplexity: 4.94533\n",
      "Epoch [9/25], Step [9100/41412], Loss: 2.0170, Perplexity: 7.51600\n",
      "Epoch [9/25], Step [9200/41412], Loss: 1.6316, Perplexity: 5.11219\n",
      "Epoch [9/25], Step [9300/41412], Loss: 2.5766, Perplexity: 13.1519\n",
      "Epoch [9/25], Step [9400/41412], Loss: 2.0458, Perplexity: 7.73551\n",
      "Epoch [9/25], Step [9500/41412], Loss: 2.3578, Perplexity: 10.5679\n",
      "Epoch [9/25], Step [9600/41412], Loss: 2.0525, Perplexity: 7.787387\n",
      "Epoch [9/25], Step [9700/41412], Loss: 2.1180, Perplexity: 8.31489\n",
      "Epoch [9/25], Step [9800/41412], Loss: 1.6863, Perplexity: 5.39960\n",
      "Epoch [9/25], Step [9900/41412], Loss: 1.4386, Perplexity: 4.21484\n",
      "Epoch [9/25], Step [10000/41412], Loss: 1.9180, Perplexity: 6.8074\n",
      "Epoch [9/25], Step [10100/41412], Loss: 1.5935, Perplexity: 4.92073\n",
      "Epoch [9/25], Step [10200/41412], Loss: 1.6579, Perplexity: 5.24857\n",
      "Epoch [9/25], Step [10300/41412], Loss: 1.8132, Perplexity: 6.13029\n",
      "Epoch [9/25], Step [10400/41412], Loss: 1.8823, Perplexity: 6.56848\n",
      "Epoch [9/25], Step [10500/41412], Loss: 1.9751, Perplexity: 7.20706\n",
      "Epoch [9/25], Step [10600/41412], Loss: 1.5678, Perplexity: 4.79616\n",
      "Epoch [9/25], Step [10700/41412], Loss: 2.0224, Perplexity: 7.55629\n",
      "Epoch [9/25], Step [10800/41412], Loss: 1.9282, Perplexity: 6.87758\n",
      "Epoch [9/25], Step [10900/41412], Loss: 2.4236, Perplexity: 11.2862\n",
      "Epoch [9/25], Step [11000/41412], Loss: 2.0216, Perplexity: 7.55026\n",
      "Epoch [9/25], Step [11100/41412], Loss: 1.8450, Perplexity: 6.32818\n",
      "Epoch [9/25], Step [11200/41412], Loss: 2.0924, Perplexity: 8.10459\n",
      "Epoch [9/25], Step [11300/41412], Loss: 2.0984, Perplexity: 8.15273\n",
      "Epoch [9/25], Step [11400/41412], Loss: 1.8801, Perplexity: 6.55459\n",
      "Epoch [9/25], Step [11500/41412], Loss: 1.7343, Perplexity: 5.66479\n",
      "Epoch [9/25], Step [11600/41412], Loss: 2.6905, Perplexity: 14.7386\n",
      "Epoch [9/25], Step [11700/41412], Loss: 2.0530, Perplexity: 7.79106\n",
      "Epoch [9/25], Step [11800/41412], Loss: 2.0844, Perplexity: 8.03973\n",
      "Epoch [9/25], Step [11900/41412], Loss: 2.1708, Perplexity: 8.76506\n",
      "Epoch [9/25], Step [12000/41412], Loss: 2.7916, Perplexity: 16.3079\n",
      "Epoch [9/25], Step [12100/41412], Loss: 1.9037, Perplexity: 6.71057\n",
      "Epoch [9/25], Step [12200/41412], Loss: 1.6996, Perplexity: 5.47175\n",
      "Epoch [9/25], Step [12300/41412], Loss: 2.0197, Perplexity: 7.53593\n",
      "Epoch [9/25], Step [12400/41412], Loss: 1.7267, Perplexity: 5.62193\n",
      "Epoch [9/25], Step [12500/41412], Loss: 1.6196, Perplexity: 5.05117\n",
      "Epoch [9/25], Step [12600/41412], Loss: 1.8750, Perplexity: 6.52058\n",
      "Epoch [9/25], Step [12700/41412], Loss: 1.9180, Perplexity: 6.80715\n",
      "Epoch [9/25], Step [12800/41412], Loss: 2.1175, Perplexity: 8.31013\n",
      "Epoch [9/25], Step [12900/41412], Loss: 1.3619, Perplexity: 3.90368\n",
      "Epoch [9/25], Step [13000/41412], Loss: 2.0317, Perplexity: 7.62696\n",
      "Epoch [9/25], Step [13100/41412], Loss: 1.6019, Perplexity: 4.96230\n",
      "Epoch [9/25], Step [13200/41412], Loss: 2.9002, Perplexity: 18.1781\n",
      "Epoch [9/25], Step [13300/41412], Loss: 1.9253, Perplexity: 6.85742\n",
      "Epoch [9/25], Step [13400/41412], Loss: 1.8107, Perplexity: 6.11459\n",
      "Epoch [9/25], Step [13500/41412], Loss: 1.8985, Perplexity: 6.67619\n",
      "Epoch [9/25], Step [13600/41412], Loss: 2.0108, Perplexity: 7.46891\n",
      "Epoch [9/25], Step [13700/41412], Loss: 1.9436, Perplexity: 6.98361\n",
      "Epoch [9/25], Step [13800/41412], Loss: 1.6925, Perplexity: 5.43329\n",
      "Epoch [9/25], Step [13900/41412], Loss: 1.8366, Perplexity: 6.27517\n",
      "Epoch [9/25], Step [14000/41412], Loss: 1.7852, Perplexity: 5.96097\n",
      "Epoch [9/25], Step [14100/41412], Loss: 1.8667, Perplexity: 6.46678\n",
      "Epoch [9/25], Step [14200/41412], Loss: 1.9222, Perplexity: 6.83631\n",
      "Epoch [9/25], Step [14300/41412], Loss: 1.8249, Perplexity: 6.20249\n",
      "Epoch [9/25], Step [14400/41412], Loss: 1.9072, Perplexity: 6.73443\n",
      "Epoch [9/25], Step [14500/41412], Loss: 1.8617, Perplexity: 6.43486\n",
      "Epoch [9/25], Step [14600/41412], Loss: 1.4856, Perplexity: 4.41775\n",
      "Epoch [9/25], Step [14700/41412], Loss: 1.3527, Perplexity: 3.86771\n",
      "Epoch [9/25], Step [14800/41412], Loss: 1.6977, Perplexity: 5.46130\n",
      "Epoch [9/25], Step [14900/41412], Loss: 1.7394, Perplexity: 5.69397\n",
      "Epoch [9/25], Step [15000/41412], Loss: 1.9426, Perplexity: 6.97689\n",
      "Epoch [9/25], Step [15100/41412], Loss: 1.7504, Perplexity: 5.75723\n",
      "Epoch [9/25], Step [15200/41412], Loss: 2.4646, Perplexity: 11.7590\n",
      "Epoch [9/25], Step [15300/41412], Loss: 1.7744, Perplexity: 5.89704\n",
      "Epoch [9/25], Step [15400/41412], Loss: 1.7865, Perplexity: 5.96881\n",
      "Epoch [9/25], Step [15500/41412], Loss: 1.9620, Perplexity: 7.11380\n",
      "Epoch [9/25], Step [15600/41412], Loss: 1.7004, Perplexity: 5.47628\n",
      "Epoch [9/25], Step [15700/41412], Loss: 2.1532, Perplexity: 8.61258\n",
      "Epoch [9/25], Step [15800/41412], Loss: 2.0958, Perplexity: 8.13188\n",
      "Epoch [9/25], Step [15900/41412], Loss: 2.3565, Perplexity: 10.5540\n",
      "Epoch [9/25], Step [16000/41412], Loss: 1.8357, Perplexity: 6.26962\n",
      "Epoch [9/25], Step [16100/41412], Loss: 2.0177, Perplexity: 7.52140\n",
      "Epoch [9/25], Step [16200/41412], Loss: 1.9437, Perplexity: 6.98476\n",
      "Epoch [9/25], Step [16300/41412], Loss: 1.8246, Perplexity: 6.20001\n",
      "Epoch [9/25], Step [16400/41412], Loss: 2.3006, Perplexity: 9.97981\n",
      "Epoch [9/25], Step [16500/41412], Loss: 1.9447, Perplexity: 6.99136\n",
      "Epoch [9/25], Step [16600/41412], Loss: 1.9770, Perplexity: 7.22133\n",
      "Epoch [9/25], Step [16700/41412], Loss: 2.0439, Perplexity: 7.72071\n",
      "Epoch [9/25], Step [16800/41412], Loss: 1.5676, Perplexity: 4.79528\n",
      "Epoch [9/25], Step [16900/41412], Loss: 2.2761, Perplexity: 9.73890\n",
      "Epoch [9/25], Step [17000/41412], Loss: 1.9988, Perplexity: 7.38045\n",
      "Epoch [9/25], Step [17100/41412], Loss: 2.0291, Perplexity: 7.60703\n",
      "Epoch [9/25], Step [17200/41412], Loss: 2.0040, Perplexity: 7.41843\n",
      "Epoch [9/25], Step [17300/41412], Loss: 1.7510, Perplexity: 5.76025\n",
      "Epoch [9/25], Step [17400/41412], Loss: 1.6849, Perplexity: 5.39178\n",
      "Epoch [9/25], Step [17500/41412], Loss: 1.8802, Perplexity: 6.55479\n",
      "Epoch [9/25], Step [17600/41412], Loss: 1.9850, Perplexity: 7.27901\n",
      "Epoch [9/25], Step [17700/41412], Loss: 1.8680, Perplexity: 6.47564\n",
      "Epoch [9/25], Step [17800/41412], Loss: 2.1374, Perplexity: 8.47717\n",
      "Epoch [9/25], Step [17900/41412], Loss: 2.2552, Perplexity: 9.53693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Step [18000/41412], Loss: 1.8173, Perplexity: 6.15511\n",
      "Epoch [9/25], Step [18100/41412], Loss: 2.1121, Perplexity: 8.26528\n",
      "Epoch [9/25], Step [18200/41412], Loss: 2.6308, Perplexity: 13.8855\n",
      "Epoch [9/25], Step [18300/41412], Loss: 1.2677, Perplexity: 3.55278\n",
      "Epoch [9/25], Step [18400/41412], Loss: 1.7863, Perplexity: 5.96732\n",
      "Epoch [9/25], Step [18500/41412], Loss: 2.5035, Perplexity: 12.2251\n",
      "Epoch [9/25], Step [18600/41412], Loss: 1.8842, Perplexity: 6.58126\n",
      "Epoch [9/25], Step [18700/41412], Loss: 2.0282, Perplexity: 7.60049\n",
      "Epoch [9/25], Step [18800/41412], Loss: 2.1682, Perplexity: 8.74237\n",
      "Epoch [9/25], Step [18900/41412], Loss: 1.9694, Perplexity: 7.16667\n",
      "Epoch [9/25], Step [19000/41412], Loss: 1.9417, Perplexity: 6.97062\n",
      "Epoch [9/25], Step [19100/41412], Loss: 1.7248, Perplexity: 5.61123\n",
      "Epoch [9/25], Step [19200/41412], Loss: 1.8134, Perplexity: 6.13139\n",
      "Epoch [9/25], Step [19300/41412], Loss: 1.8240, Perplexity: 6.19682\n",
      "Epoch [9/25], Step [19400/41412], Loss: 1.5803, Perplexity: 4.85668\n",
      "Epoch [9/25], Step [19500/41412], Loss: 1.6538, Perplexity: 5.22692\n",
      "Epoch [9/25], Step [19600/41412], Loss: 1.5097, Perplexity: 4.52553\n",
      "Epoch [9/25], Step [19700/41412], Loss: 2.0817, Perplexity: 8.01807\n",
      "Epoch [9/25], Step [19800/41412], Loss: 1.5549, Perplexity: 4.73461\n",
      "Epoch [9/25], Step [19900/41412], Loss: 2.1213, Perplexity: 8.34164\n",
      "Epoch [9/25], Step [20000/41412], Loss: 2.2093, Perplexity: 9.10933\n",
      "Epoch [9/25], Step [20100/41412], Loss: 1.7511, Perplexity: 5.761026\n",
      "Epoch [9/25], Step [20200/41412], Loss: 1.7930, Perplexity: 6.00767\n",
      "Epoch [9/25], Step [20300/41412], Loss: 2.3380, Perplexity: 10.3604\n",
      "Epoch [9/25], Step [20400/41412], Loss: 1.6850, Perplexity: 5.39260\n",
      "Epoch [9/25], Step [20500/41412], Loss: 2.5107, Perplexity: 12.3137\n",
      "Epoch [9/25], Step [20600/41412], Loss: 2.4369, Perplexity: 11.4374\n",
      "Epoch [9/25], Step [20700/41412], Loss: 1.9832, Perplexity: 7.26570\n",
      "Epoch [9/25], Step [20800/41412], Loss: 4.2186, Perplexity: 67.9400\n",
      "Epoch [9/25], Step [20900/41412], Loss: 3.2065, Perplexity: 24.6925\n",
      "Epoch [9/25], Step [21000/41412], Loss: 2.0769, Perplexity: 7.97981\n",
      "Epoch [9/25], Step [21100/41412], Loss: 2.1106, Perplexity: 8.25292\n",
      "Epoch [9/25], Step [21200/41412], Loss: 1.9052, Perplexity: 6.72067\n",
      "Epoch [9/25], Step [21300/41412], Loss: 2.0909, Perplexity: 8.09213\n",
      "Epoch [9/25], Step [21400/41412], Loss: 1.5071, Perplexity: 4.51363\n",
      "Epoch [9/25], Step [21500/41412], Loss: 2.0969, Perplexity: 8.14112\n",
      "Epoch [9/25], Step [21600/41412], Loss: 2.3627, Perplexity: 10.6201\n",
      "Epoch [9/25], Step [21700/41412], Loss: 2.0096, Perplexity: 7.46000\n",
      "Epoch [9/25], Step [21800/41412], Loss: 2.7070, Perplexity: 14.9837\n",
      "Epoch [9/25], Step [21900/41412], Loss: 1.4509, Perplexity: 4.26684\n",
      "Epoch [9/25], Step [22000/41412], Loss: 2.0017, Perplexity: 7.40148\n",
      "Epoch [9/25], Step [22100/41412], Loss: 2.7783, Perplexity: 16.0911\n",
      "Epoch [9/25], Step [22200/41412], Loss: 1.7054, Perplexity: 5.50340\n",
      "Epoch [9/25], Step [22300/41412], Loss: 1.8496, Perplexity: 6.35725\n",
      "Epoch [9/25], Step [22400/41412], Loss: 2.0625, Perplexity: 7.86568\n",
      "Epoch [9/25], Step [22500/41412], Loss: 1.8916, Perplexity: 6.63014\n",
      "Epoch [9/25], Step [22600/41412], Loss: 1.6975, Perplexity: 5.46052\n",
      "Epoch [9/25], Step [22700/41412], Loss: 2.3745, Perplexity: 10.7455\n",
      "Epoch [9/25], Step [22800/41412], Loss: 2.2046, Perplexity: 9.06708\n",
      "Epoch [9/25], Step [22900/41412], Loss: 2.0321, Perplexity: 7.63002\n",
      "Epoch [9/25], Step [23000/41412], Loss: 1.6813, Perplexity: 5.37274\n",
      "Epoch [9/25], Step [23100/41412], Loss: 1.6794, Perplexity: 5.36236\n",
      "Epoch [9/25], Step [23200/41412], Loss: 2.7387, Perplexity: 15.4672\n",
      "Epoch [9/25], Step [23300/41412], Loss: 1.9705, Perplexity: 7.17413\n",
      "Epoch [9/25], Step [23400/41412], Loss: 1.8369, Perplexity: 6.27736\n",
      "Epoch [9/25], Step [23500/41412], Loss: 2.0933, Perplexity: 8.11164\n",
      "Epoch [9/25], Step [23600/41412], Loss: 2.7017, Perplexity: 14.9054\n",
      "Epoch [9/25], Step [23700/41412], Loss: 2.3846, Perplexity: 10.8551\n",
      "Epoch [9/25], Step [23800/41412], Loss: 2.1020, Perplexity: 8.18214\n",
      "Epoch [9/25], Step [23900/41412], Loss: 1.9387, Perplexity: 6.95009\n",
      "Epoch [9/25], Step [24000/41412], Loss: 2.3906, Perplexity: 10.9206\n",
      "Epoch [9/25], Step [24100/41412], Loss: 1.8360, Perplexity: 6.27111\n",
      "Epoch [9/25], Step [24200/41412], Loss: 1.4914, Perplexity: 4.44340\n",
      "Epoch [9/25], Step [24300/41412], Loss: 1.6618, Perplexity: 5.26893\n",
      "Epoch [9/25], Step [24400/41412], Loss: 2.0625, Perplexity: 7.86553\n",
      "Epoch [9/25], Step [24500/41412], Loss: 2.0564, Perplexity: 7.81755\n",
      "Epoch [9/25], Step [24600/41412], Loss: 2.3017, Perplexity: 9.99139\n",
      "Epoch [9/25], Step [24700/41412], Loss: 1.9234, Perplexity: 6.84436\n",
      "Epoch [9/25], Step [24800/41412], Loss: 2.3243, Perplexity: 10.2200\n",
      "Epoch [9/25], Step [24900/41412], Loss: 2.9089, Perplexity: 18.3363\n",
      "Epoch [9/25], Step [25000/41412], Loss: 1.7304, Perplexity: 5.64277\n",
      "Epoch [9/25], Step [25100/41412], Loss: 1.9923, Perplexity: 7.33279\n",
      "Epoch [9/25], Step [25200/41412], Loss: 1.9287, Perplexity: 6.88068\n",
      "Epoch [9/25], Step [25300/41412], Loss: 2.0054, Perplexity: 7.42910\n",
      "Epoch [9/25], Step [25400/41412], Loss: 1.6101, Perplexity: 5.00331\n",
      "Epoch [9/25], Step [25500/41412], Loss: 1.9218, Perplexity: 6.83354\n",
      "Epoch [9/25], Step [25600/41412], Loss: 1.8215, Perplexity: 6.18104\n",
      "Epoch [9/25], Step [25700/41412], Loss: 2.3391, Perplexity: 10.3715\n",
      "Epoch [9/25], Step [25800/41412], Loss: 2.7517, Perplexity: 15.6697\n",
      "Epoch [9/25], Step [25900/41412], Loss: 1.5493, Perplexity: 4.70846\n",
      "Epoch [9/25], Step [26000/41412], Loss: 1.6121, Perplexity: 5.01317\n",
      "Epoch [9/25], Step [26100/41412], Loss: 1.9987, Perplexity: 7.37951\n",
      "Epoch [9/25], Step [26200/41412], Loss: 2.3383, Perplexity: 10.3637\n",
      "Epoch [9/25], Step [26300/41412], Loss: 2.5101, Perplexity: 12.3059\n",
      "Epoch [9/25], Step [26400/41412], Loss: 1.5531, Perplexity: 4.72598\n",
      "Epoch [9/25], Step [26500/41412], Loss: 1.7966, Perplexity: 6.02936\n",
      "Epoch [9/25], Step [26600/41412], Loss: 3.6834, Perplexity: 39.7802\n",
      "Epoch [9/25], Step [26700/41412], Loss: 1.8511, Perplexity: 6.36665\n",
      "Epoch [9/25], Step [26800/41412], Loss: 1.5641, Perplexity: 4.77859\n",
      "Epoch [9/25], Step [26900/41412], Loss: 2.1344, Perplexity: 8.45195\n",
      "Epoch [9/25], Step [27000/41412], Loss: 1.7638, Perplexity: 5.83431\n",
      "Epoch [9/25], Step [27100/41412], Loss: 2.1567, Perplexity: 8.64266\n",
      "Epoch [9/25], Step [27200/41412], Loss: 2.0299, Perplexity: 7.61319\n",
      "Epoch [9/25], Step [27300/41412], Loss: 2.0510, Perplexity: 7.77557\n",
      "Epoch [9/25], Step [27400/41412], Loss: 1.5815, Perplexity: 4.86257\n",
      "Epoch [9/25], Step [27500/41412], Loss: 2.2020, Perplexity: 9.04302\n",
      "Epoch [9/25], Step [27600/41412], Loss: 2.0135, Perplexity: 7.48933\n",
      "Epoch [9/25], Step [27700/41412], Loss: 1.6632, Perplexity: 5.27635\n",
      "Epoch [9/25], Step [27800/41412], Loss: 2.1614, Perplexity: 8.68309\n",
      "Epoch [9/25], Step [27900/41412], Loss: 1.8767, Perplexity: 6.53169\n",
      "Epoch [9/25], Step [28000/41412], Loss: 1.7347, Perplexity: 5.66707\n",
      "Epoch [9/25], Step [28100/41412], Loss: 1.9298, Perplexity: 6.88843\n",
      "Epoch [9/25], Step [28200/41412], Loss: 2.1614, Perplexity: 8.68341\n",
      "Epoch [9/25], Step [28300/41412], Loss: 1.6945, Perplexity: 5.44426\n",
      "Epoch [9/25], Step [28400/41412], Loss: 1.3408, Perplexity: 3.82200\n",
      "Epoch [9/25], Step [28500/41412], Loss: 2.1458, Perplexity: 8.54920\n",
      "Epoch [9/25], Step [28600/41412], Loss: 2.0847, Perplexity: 8.04244\n",
      "Epoch [9/25], Step [28700/41412], Loss: 2.0189, Perplexity: 7.52983\n",
      "Epoch [9/25], Step [28800/41412], Loss: 1.8292, Perplexity: 6.22914\n",
      "Epoch [9/25], Step [28900/41412], Loss: 1.5416, Perplexity: 4.67197\n",
      "Epoch [9/25], Step [29000/41412], Loss: 2.2428, Perplexity: 9.41960\n",
      "Epoch [9/25], Step [29100/41412], Loss: 1.8681, Perplexity: 6.47638\n",
      "Epoch [9/25], Step [29200/41412], Loss: 2.0916, Perplexity: 8.09754\n",
      "Epoch [9/25], Step [29300/41412], Loss: 2.1682, Perplexity: 8.742496\n",
      "Epoch [9/25], Step [29400/41412], Loss: 2.1022, Perplexity: 8.18456\n",
      "Epoch [9/25], Step [29500/41412], Loss: 1.3516, Perplexity: 3.86359\n",
      "Epoch [9/25], Step [29600/41412], Loss: 2.0683, Perplexity: 7.91128\n",
      "Epoch [9/25], Step [29700/41412], Loss: 2.2867, Perplexity: 9.84221\n",
      "Epoch [9/25], Step [29800/41412], Loss: 1.8344, Perplexity: 6.26178\n",
      "Epoch [9/25], Step [29900/41412], Loss: 1.8728, Perplexity: 6.50652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Step [30000/41412], Loss: 1.8386, Perplexity: 6.28799\n",
      "Epoch [9/25], Step [30100/41412], Loss: 1.6547, Perplexity: 5.23160\n",
      "Epoch [9/25], Step [30200/41412], Loss: 2.0252, Perplexity: 7.57725\n",
      "Epoch [9/25], Step [30300/41412], Loss: 1.9547, Perplexity: 7.06220\n",
      "Epoch [9/25], Step [30400/41412], Loss: 2.3432, Perplexity: 10.4147\n",
      "Epoch [9/25], Step [30500/41412], Loss: 1.8720, Perplexity: 6.50102\n",
      "Epoch [9/25], Step [30600/41412], Loss: 2.2171, Perplexity: 9.18076\n",
      "Epoch [9/25], Step [30700/41412], Loss: 1.6202, Perplexity: 5.05429\n",
      "Epoch [9/25], Step [30800/41412], Loss: 2.1592, Perplexity: 8.66421\n",
      "Epoch [9/25], Step [30900/41412], Loss: 1.6039, Perplexity: 4.97266\n",
      "Epoch [9/25], Step [31000/41412], Loss: 1.9590, Perplexity: 7.09235\n",
      "Epoch [9/25], Step [31100/41412], Loss: 1.9972, Perplexity: 7.36838\n",
      "Epoch [9/25], Step [31200/41412], Loss: 1.7007, Perplexity: 5.47780\n",
      "Epoch [9/25], Step [31300/41412], Loss: 1.8790, Perplexity: 6.54684\n",
      "Epoch [9/25], Step [31400/41412], Loss: 1.4857, Perplexity: 4.41820\n",
      "Epoch [9/25], Step [31500/41412], Loss: 2.1901, Perplexity: 8.93656\n",
      "Epoch [9/25], Step [31600/41412], Loss: 1.9148, Perplexity: 6.78568\n",
      "Epoch [9/25], Step [31700/41412], Loss: 2.0075, Perplexity: 7.44457\n",
      "Epoch [9/25], Step [31800/41412], Loss: 1.9594, Perplexity: 7.09482\n",
      "Epoch [9/25], Step [31900/41412], Loss: 2.5340, Perplexity: 12.6038\n",
      "Epoch [9/25], Step [32000/41412], Loss: 2.0096, Perplexity: 7.46013\n",
      "Epoch [9/25], Step [32100/41412], Loss: 1.7875, Perplexity: 5.97429\n",
      "Epoch [9/25], Step [32200/41412], Loss: 2.0122, Perplexity: 7.47991\n",
      "Epoch [9/25], Step [32300/41412], Loss: 2.2927, Perplexity: 9.90199\n",
      "Epoch [9/25], Step [32400/41412], Loss: 2.0889, Perplexity: 8.07646\n",
      "Epoch [9/25], Step [32500/41412], Loss: 2.1070, Perplexity: 8.22377\n",
      "Epoch [9/25], Step [32600/41412], Loss: 2.4028, Perplexity: 11.0536\n",
      "Epoch [9/25], Step [32700/41412], Loss: 2.3888, Perplexity: 10.9009\n",
      "Epoch [9/25], Step [32800/41412], Loss: 2.1037, Perplexity: 8.19663\n",
      "Epoch [9/25], Step [32900/41412], Loss: 1.9001, Perplexity: 6.68686\n",
      "Epoch [9/25], Step [33000/41412], Loss: 2.1360, Perplexity: 8.46568\n",
      "Epoch [9/25], Step [33100/41412], Loss: 1.7933, Perplexity: 6.00901\n",
      "Epoch [9/25], Step [33200/41412], Loss: 2.2670, Perplexity: 9.65036\n",
      "Epoch [9/25], Step [33300/41412], Loss: 2.2331, Perplexity: 9.32841\n",
      "Epoch [9/25], Step [33400/41412], Loss: 1.6064, Perplexity: 4.98491\n",
      "Epoch [9/25], Step [33500/41412], Loss: 1.8457, Perplexity: 6.33258\n",
      "Epoch [9/25], Step [33600/41412], Loss: 1.7903, Perplexity: 5.99140\n",
      "Epoch [9/25], Step [33700/41412], Loss: 2.2041, Perplexity: 9.06226\n",
      "Epoch [9/25], Step [33800/41412], Loss: 1.8826, Perplexity: 6.57079\n",
      "Epoch [9/25], Step [33900/41412], Loss: 1.6230, Perplexity: 5.06833\n",
      "Epoch [9/25], Step [34000/41412], Loss: 2.1391, Perplexity: 8.49201\n",
      "Epoch [9/25], Step [34100/41412], Loss: 2.7171, Perplexity: 15.1370\n",
      "Epoch [9/25], Step [34200/41412], Loss: 2.1238, Perplexity: 8.36269\n",
      "Epoch [9/25], Step [34300/41412], Loss: 1.5164, Perplexity: 4.55608\n",
      "Epoch [9/25], Step [34400/41412], Loss: 1.8112, Perplexity: 6.11816\n",
      "Epoch [9/25], Step [34500/41412], Loss: 2.5638, Perplexity: 12.9847\n",
      "Epoch [9/25], Step [34600/41412], Loss: 1.9197, Perplexity: 6.81907\n",
      "Epoch [9/25], Step [34700/41412], Loss: 2.1939, Perplexity: 8.97047\n",
      "Epoch [9/25], Step [34800/41412], Loss: 1.6952, Perplexity: 5.44757\n",
      "Epoch [9/25], Step [34900/41412], Loss: 1.6705, Perplexity: 5.31482\n",
      "Epoch [9/25], Step [35000/41412], Loss: 2.0436, Perplexity: 7.71816\n",
      "Epoch [9/25], Step [35100/41412], Loss: 2.3589, Perplexity: 10.5790\n",
      "Epoch [9/25], Step [35200/41412], Loss: 2.0718, Perplexity: 7.93911\n",
      "Epoch [9/25], Step [35300/41412], Loss: 1.8670, Perplexity: 6.46870\n",
      "Epoch [9/25], Step [35400/41412], Loss: 2.0843, Perplexity: 8.03889\n",
      "Epoch [9/25], Step [35500/41412], Loss: 1.9165, Perplexity: 6.79724\n",
      "Epoch [9/25], Step [35600/41412], Loss: 1.6648, Perplexity: 5.28470\n",
      "Epoch [9/25], Step [35700/41412], Loss: 2.5231, Perplexity: 12.4670\n",
      "Epoch [9/25], Step [35800/41412], Loss: 2.1487, Perplexity: 8.57389\n",
      "Epoch [9/25], Step [35900/41412], Loss: 2.0968, Perplexity: 8.14039\n",
      "Epoch [9/25], Step [36000/41412], Loss: 2.1356, Perplexity: 8.46227\n",
      "Epoch [9/25], Step [36100/41412], Loss: 1.7828, Perplexity: 5.94655\n",
      "Epoch [9/25], Step [36200/41412], Loss: 2.0685, Perplexity: 7.91292\n",
      "Epoch [9/25], Step [36300/41412], Loss: 2.2118, Perplexity: 9.13219\n",
      "Epoch [9/25], Step [36400/41412], Loss: 2.8319, Perplexity: 16.9780\n",
      "Epoch [9/25], Step [36500/41412], Loss: 2.7023, Perplexity: 14.9138\n",
      "Epoch [9/25], Step [36600/41412], Loss: 1.8745, Perplexity: 6.51748\n",
      "Epoch [9/25], Step [36700/41412], Loss: 1.6734, Perplexity: 5.33034\n",
      "Epoch [9/25], Step [36800/41412], Loss: 2.2320, Perplexity: 9.31815\n",
      "Epoch [9/25], Step [36900/41412], Loss: 2.9630, Perplexity: 19.3552\n",
      "Epoch [9/25], Step [37000/41412], Loss: 1.8951, Perplexity: 6.65329\n",
      "Epoch [9/25], Step [37100/41412], Loss: 2.2069, Perplexity: 9.08726\n",
      "Epoch [9/25], Step [37200/41412], Loss: 1.8302, Perplexity: 6.23542\n",
      "Epoch [9/25], Step [37300/41412], Loss: 1.6016, Perplexity: 4.96114\n",
      "Epoch [9/25], Step [37400/41412], Loss: 1.8570, Perplexity: 6.40452\n",
      "Epoch [9/25], Step [37500/41412], Loss: 2.3835, Perplexity: 10.8431\n",
      "Epoch [9/25], Step [37600/41412], Loss: 2.0567, Perplexity: 7.819862\n",
      "Epoch [9/25], Step [37700/41412], Loss: 2.0902, Perplexity: 8.08650\n",
      "Epoch [9/25], Step [37800/41412], Loss: 2.1371, Perplexity: 8.47462\n",
      "Epoch [9/25], Step [37900/41412], Loss: 2.0915, Perplexity: 8.09742\n",
      "Epoch [9/25], Step [38000/41412], Loss: 2.4955, Perplexity: 12.1284\n",
      "Epoch [9/25], Step [38100/41412], Loss: 1.9438, Perplexity: 6.98544\n",
      "Epoch [9/25], Step [38200/41412], Loss: 2.6339, Perplexity: 13.9283\n",
      "Epoch [9/25], Step [38300/41412], Loss: 1.6131, Perplexity: 5.01819\n",
      "Epoch [9/25], Step [38400/41412], Loss: 1.4978, Perplexity: 4.47174\n",
      "Epoch [9/25], Step [38500/41412], Loss: 2.3948, Perplexity: 10.9659\n",
      "Epoch [9/25], Step [38600/41412], Loss: 1.9457, Perplexity: 6.99830\n",
      "Epoch [9/25], Step [38700/41412], Loss: 1.8942, Perplexity: 6.64723\n",
      "Epoch [9/25], Step [38800/41412], Loss: 1.6945, Perplexity: 5.44407\n",
      "Epoch [9/25], Step [38900/41412], Loss: 1.8243, Perplexity: 6.19820\n",
      "Epoch [9/25], Step [39000/41412], Loss: 1.7573, Perplexity: 5.79652\n",
      "Epoch [9/25], Step [39100/41412], Loss: 2.2092, Perplexity: 9.10804\n",
      "Epoch [9/25], Step [39200/41412], Loss: 1.8740, Perplexity: 6.51462\n",
      "Epoch [9/25], Step [39300/41412], Loss: 2.7686, Perplexity: 15.9366\n",
      "Epoch [9/25], Step [39400/41412], Loss: 2.3215, Perplexity: 10.1914\n",
      "Epoch [9/25], Step [39500/41412], Loss: 1.6341, Perplexity: 5.12508\n",
      "Epoch [9/25], Step [39600/41412], Loss: 1.7501, Perplexity: 5.75509\n",
      "Epoch [9/25], Step [39700/41412], Loss: 1.8473, Perplexity: 6.34248\n",
      "Epoch [9/25], Step [39800/41412], Loss: 1.7896, Perplexity: 5.98695\n",
      "Epoch [9/25], Step [39900/41412], Loss: 2.0889, Perplexity: 8.07568\n",
      "Epoch [9/25], Step [40000/41412], Loss: 1.4790, Perplexity: 4.38872\n",
      "Epoch [9/25], Step [40100/41412], Loss: 2.3690, Perplexity: 10.6871\n",
      "Epoch [9/25], Step [40200/41412], Loss: 1.9004, Perplexity: 6.68888\n",
      "Epoch [9/25], Step [40300/41412], Loss: 2.0097, Perplexity: 7.46135\n",
      "Epoch [9/25], Step [40400/41412], Loss: 2.1006, Perplexity: 8.17107\n",
      "Epoch [9/25], Step [40500/41412], Loss: 1.5657, Perplexity: 4.78620\n",
      "Epoch [9/25], Step [40600/41412], Loss: 2.0606, Perplexity: 7.85088\n",
      "Epoch [9/25], Step [40700/41412], Loss: 1.8537, Perplexity: 6.38369\n",
      "Epoch [9/25], Step [40800/41412], Loss: 2.3446, Perplexity: 10.4294\n",
      "Epoch [9/25], Step [40900/41412], Loss: 1.5122, Perplexity: 4.53666\n",
      "Epoch [9/25], Step [41000/41412], Loss: 1.7822, Perplexity: 5.94313\n",
      "Epoch [9/25], Step [41100/41412], Loss: 1.5147, Perplexity: 4.54810\n",
      "Epoch [9/25], Step [41200/41412], Loss: 1.7717, Perplexity: 5.88074\n",
      "Epoch [9/25], Step [41300/41412], Loss: 2.1623, Perplexity: 8.69107\n",
      "Epoch [9/25], Step [41400/41412], Loss: 1.7577, Perplexity: 5.79910\n",
      "Epoch [10/25], Step [100/41412], Loss: 1.6601, Perplexity: 5.259644\n",
      "Epoch [10/25], Step [200/41412], Loss: 2.2273, Perplexity: 9.27450\n",
      "Epoch [10/25], Step [300/41412], Loss: 1.9308, Perplexity: 6.89491\n",
      "Epoch [10/25], Step [400/41412], Loss: 1.9864, Perplexity: 7.28931\n",
      "Epoch [10/25], Step [500/41412], Loss: 2.2137, Perplexity: 9.14970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Step [600/41412], Loss: 1.9670, Perplexity: 7.14940\n",
      "Epoch [10/25], Step [700/41412], Loss: 1.9770, Perplexity: 7.22118\n",
      "Epoch [10/25], Step [800/41412], Loss: 1.8443, Perplexity: 6.32397\n",
      "Epoch [10/25], Step [900/41412], Loss: 1.7835, Perplexity: 5.95040\n",
      "Epoch [10/25], Step [1000/41412], Loss: 1.7942, Perplexity: 6.0150\n",
      "Epoch [10/25], Step [1100/41412], Loss: 1.7675, Perplexity: 5.85610\n",
      "Epoch [10/25], Step [1200/41412], Loss: 2.0946, Perplexity: 8.12225\n",
      "Epoch [10/25], Step [1300/41412], Loss: 1.7573, Perplexity: 5.79709\n",
      "Epoch [10/25], Step [1400/41412], Loss: 2.0848, Perplexity: 8.04286\n",
      "Epoch [10/25], Step [1500/41412], Loss: 1.8970, Perplexity: 6.66592\n",
      "Epoch [10/25], Step [1600/41412], Loss: 2.3509, Perplexity: 10.4952\n",
      "Epoch [10/25], Step [1700/41412], Loss: 2.0510, Perplexity: 7.77559\n",
      "Epoch [10/25], Step [1800/41412], Loss: 2.2751, Perplexity: 9.72848\n",
      "Epoch [10/25], Step [1900/41412], Loss: 2.0344, Perplexity: 7.647328\n",
      "Epoch [10/25], Step [2000/41412], Loss: 2.1679, Perplexity: 8.74020\n",
      "Epoch [10/25], Step [2100/41412], Loss: 2.2467, Perplexity: 9.45612\n",
      "Epoch [10/25], Step [2200/41412], Loss: 2.4988, Perplexity: 12.1683\n",
      "Epoch [10/25], Step [2300/41412], Loss: 2.1278, Perplexity: 8.39604\n",
      "Epoch [10/25], Step [2400/41412], Loss: 2.1908, Perplexity: 8.94248\n",
      "Epoch [10/25], Step [2500/41412], Loss: 2.0461, Perplexity: 7.73785\n",
      "Epoch [10/25], Step [2600/41412], Loss: 2.1555, Perplexity: 8.63240\n",
      "Epoch [10/25], Step [2700/41412], Loss: 2.2200, Perplexity: 9.20769\n",
      "Epoch [10/25], Step [2800/41412], Loss: 1.9145, Perplexity: 6.78354\n",
      "Epoch [10/25], Step [2900/41412], Loss: 1.8414, Perplexity: 6.30561\n",
      "Epoch [10/25], Step [3000/41412], Loss: 1.6097, Perplexity: 5.00133\n",
      "Epoch [10/25], Step [3100/41412], Loss: 1.2953, Perplexity: 3.65207\n",
      "Epoch [10/25], Step [3200/41412], Loss: 2.0915, Perplexity: 8.09682\n",
      "Epoch [10/25], Step [3300/41412], Loss: 2.0270, Perplexity: 7.59128\n",
      "Epoch [10/25], Step [3400/41412], Loss: 1.6349, Perplexity: 5.12911\n",
      "Epoch [10/25], Step [3500/41412], Loss: 1.7666, Perplexity: 5.85106\n",
      "Epoch [10/25], Step [3600/41412], Loss: 2.1025, Perplexity: 8.18651\n",
      "Epoch [10/25], Step [3700/41412], Loss: 2.4926, Perplexity: 12.0931\n",
      "Epoch [10/25], Step [3800/41412], Loss: 1.7583, Perplexity: 5.80277\n",
      "Epoch [10/25], Step [3900/41412], Loss: 1.6754, Perplexity: 5.34109\n",
      "Epoch [10/25], Step [4000/41412], Loss: 1.5778, Perplexity: 4.84456\n",
      "Epoch [10/25], Step [4100/41412], Loss: 2.4098, Perplexity: 11.1318\n",
      "Epoch [10/25], Step [4200/41412], Loss: 1.8728, Perplexity: 6.50637\n",
      "Epoch [10/25], Step [4300/41412], Loss: 1.5335, Perplexity: 4.63430\n",
      "Epoch [10/25], Step [4400/41412], Loss: 1.9359, Perplexity: 6.92996\n",
      "Epoch [10/25], Step [4500/41412], Loss: 2.3075, Perplexity: 10.0495\n",
      "Epoch [10/25], Step [4600/41412], Loss: 1.9293, Perplexity: 6.88480\n",
      "Epoch [10/25], Step [4700/41412], Loss: 2.0665, Perplexity: 7.89742\n",
      "Epoch [10/25], Step [4800/41412], Loss: 2.1743, Perplexity: 8.79634\n",
      "Epoch [10/25], Step [4900/41412], Loss: 1.8419, Perplexity: 6.30852\n",
      "Epoch [10/25], Step [5000/41412], Loss: 1.7890, Perplexity: 5.98367\n",
      "Epoch [10/25], Step [5100/41412], Loss: 1.6606, Perplexity: 5.26249\n",
      "Epoch [10/25], Step [5200/41412], Loss: 1.9100, Perplexity: 6.75321\n",
      "Epoch [10/25], Step [5300/41412], Loss: 1.8505, Perplexity: 6.36290\n",
      "Epoch [10/25], Step [5400/41412], Loss: 1.5505, Perplexity: 4.71387\n",
      "Epoch [10/25], Step [5500/41412], Loss: 1.6747, Perplexity: 5.33722\n",
      "Epoch [10/25], Step [5600/41412], Loss: 2.1441, Perplexity: 8.53466\n",
      "Epoch [10/25], Step [5700/41412], Loss: 2.4534, Perplexity: 11.6276\n",
      "Epoch [10/25], Step [5800/41412], Loss: 2.2652, Perplexity: 9.63260\n",
      "Epoch [10/25], Step [5900/41412], Loss: 2.2692, Perplexity: 9.67150\n",
      "Epoch [10/25], Step [6000/41412], Loss: 2.1659, Perplexity: 8.72202\n",
      "Epoch [10/25], Step [6100/41412], Loss: 1.8750, Perplexity: 6.52083\n",
      "Epoch [10/25], Step [6200/41412], Loss: 2.0082, Perplexity: 7.45015\n",
      "Epoch [10/25], Step [6300/41412], Loss: 1.4928, Perplexity: 4.44989\n",
      "Epoch [10/25], Step [6400/41412], Loss: 3.3516, Perplexity: 28.5477\n",
      "Epoch [10/25], Step [6500/41412], Loss: 1.9146, Perplexity: 6.78430\n",
      "Epoch [10/25], Step [6600/41412], Loss: 2.2221, Perplexity: 9.22651\n",
      "Epoch [10/25], Step [6700/41412], Loss: 2.0026, Perplexity: 7.40804\n",
      "Epoch [10/25], Step [6800/41412], Loss: 1.4365, Perplexity: 4.20597\n",
      "Epoch [10/25], Step [6900/41412], Loss: 1.7401, Perplexity: 5.69760\n",
      "Epoch [10/25], Step [7000/41412], Loss: 1.4554, Perplexity: 4.28609\n",
      "Epoch [10/25], Step [7100/41412], Loss: 2.4852, Perplexity: 12.0038\n",
      "Epoch [10/25], Step [7200/41412], Loss: 1.8040, Perplexity: 6.07379\n",
      "Epoch [10/25], Step [7300/41412], Loss: 2.3060, Perplexity: 10.0347\n",
      "Epoch [10/25], Step [7400/41412], Loss: 1.7485, Perplexity: 5.74613\n",
      "Epoch [10/25], Step [7500/41412], Loss: 1.9657, Perplexity: 7.14018\n",
      "Epoch [10/25], Step [7600/41412], Loss: 1.8941, Perplexity: 6.64664\n",
      "Epoch [10/25], Step [7700/41412], Loss: 1.5270, Perplexity: 4.60441\n",
      "Epoch [10/25], Step [7800/41412], Loss: 2.1795, Perplexity: 8.84235\n",
      "Epoch [10/25], Step [7900/41412], Loss: 1.8965, Perplexity: 6.66258\n",
      "Epoch [10/25], Step [8000/41412], Loss: 3.0156, Perplexity: 20.4010\n",
      "Epoch [10/25], Step [8100/41412], Loss: 2.2917, Perplexity: 9.89163\n",
      "Epoch [10/25], Step [8200/41412], Loss: 1.8885, Perplexity: 6.609769\n",
      "Epoch [10/25], Step [8300/41412], Loss: 2.1384, Perplexity: 8.48583\n",
      "Epoch [10/25], Step [8400/41412], Loss: 1.6318, Perplexity: 5.11332\n",
      "Epoch [10/25], Step [8500/41412], Loss: 1.9749, Perplexity: 7.205704\n",
      "Epoch [10/25], Step [8600/41412], Loss: 2.1558, Perplexity: 8.63495\n",
      "Epoch [10/25], Step [8700/41412], Loss: 2.7397, Perplexity: 15.4831\n",
      "Epoch [10/25], Step [8800/41412], Loss: 2.2378, Perplexity: 9.37273\n",
      "Epoch [10/25], Step [8900/41412], Loss: 1.8947, Perplexity: 6.65092\n",
      "Epoch [10/25], Step [9000/41412], Loss: 1.5122, Perplexity: 4.53664\n",
      "Epoch [10/25], Step [9100/41412], Loss: 2.1089, Perplexity: 8.23946\n",
      "Epoch [10/25], Step [9200/41412], Loss: 1.5840, Perplexity: 4.87441\n",
      "Epoch [10/25], Step [9300/41412], Loss: 2.1784, Perplexity: 8.83194\n",
      "Epoch [10/25], Step [9400/41412], Loss: 1.9942, Perplexity: 7.34641\n",
      "Epoch [10/25], Step [9500/41412], Loss: 1.6555, Perplexity: 5.23573\n",
      "Epoch [10/25], Step [9600/41412], Loss: 1.7273, Perplexity: 5.62526\n",
      "Epoch [10/25], Step [9700/41412], Loss: 1.9678, Perplexity: 7.15468\n",
      "Epoch [10/25], Step [9800/41412], Loss: 1.7017, Perplexity: 5.48319\n",
      "Epoch [10/25], Step [9900/41412], Loss: 1.9465, Perplexity: 7.00448\n",
      "Epoch [10/25], Step [10000/41412], Loss: 2.5683, Perplexity: 13.0442\n",
      "Epoch [10/25], Step [10100/41412], Loss: 1.9080, Perplexity: 6.73950\n",
      "Epoch [10/25], Step [10200/41412], Loss: 2.5015, Perplexity: 12.2004\n",
      "Epoch [10/25], Step [10300/41412], Loss: 1.6885, Perplexity: 5.41149\n",
      "Epoch [10/25], Step [10400/41412], Loss: 2.2846, Perplexity: 9.82182\n",
      "Epoch [10/25], Step [10500/41412], Loss: 2.4416, Perplexity: 11.4916\n",
      "Epoch [10/25], Step [10600/41412], Loss: 1.8463, Perplexity: 6.33636\n",
      "Epoch [10/25], Step [10700/41412], Loss: 1.5670, Perplexity: 4.79230\n",
      "Epoch [10/25], Step [10800/41412], Loss: 1.8540, Perplexity: 6.38522\n",
      "Epoch [10/25], Step [10900/41412], Loss: 1.3801, Perplexity: 3.97514\n",
      "Epoch [10/25], Step [11000/41412], Loss: 1.4741, Perplexity: 4.36717\n",
      "Epoch [10/25], Step [11100/41412], Loss: 2.2133, Perplexity: 9.14615\n",
      "Epoch [10/25], Step [11200/41412], Loss: 1.9922, Perplexity: 7.33131\n",
      "Epoch [10/25], Step [11300/41412], Loss: 1.9722, Perplexity: 7.18617\n",
      "Epoch [10/25], Step [11400/41412], Loss: 2.1952, Perplexity: 8.98147\n",
      "Epoch [10/25], Step [11500/41412], Loss: 1.9369, Perplexity: 6.93704\n",
      "Epoch [10/25], Step [11600/41412], Loss: 1.9825, Perplexity: 7.26121\n",
      "Epoch [10/25], Step [11700/41412], Loss: 2.4431, Perplexity: 11.5087\n",
      "Epoch [10/25], Step [11800/41412], Loss: 2.0304, Perplexity: 7.61701\n",
      "Epoch [10/25], Step [11900/41412], Loss: 2.0752, Perplexity: 7.96603\n",
      "Epoch [10/25], Step [12000/41412], Loss: 1.6933, Perplexity: 5.43733\n",
      "Epoch [10/25], Step [12100/41412], Loss: 3.0977, Perplexity: 22.1475\n",
      "Epoch [10/25], Step [12200/41412], Loss: 1.7950, Perplexity: 6.01956\n",
      "Epoch [10/25], Step [12300/41412], Loss: 2.3766, Perplexity: 10.7685\n",
      "Epoch [10/25], Step [12400/41412], Loss: 1.6472, Perplexity: 5.19225\n",
      "Epoch [10/25], Step [12500/41412], Loss: 2.1723, Perplexity: 8.77863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Step [12600/41412], Loss: 1.7938, Perplexity: 6.01251\n",
      "Epoch [10/25], Step [12700/41412], Loss: 1.8992, Perplexity: 6.68035\n",
      "Epoch [10/25], Step [12800/41412], Loss: 1.8574, Perplexity: 6.40722\n",
      "Epoch [10/25], Step [12900/41412], Loss: 1.7708, Perplexity: 5.87543\n",
      "Epoch [10/25], Step [13000/41412], Loss: 2.0266, Perplexity: 7.58791\n",
      "Epoch [10/25], Step [13100/41412], Loss: 2.2101, Perplexity: 9.11641\n",
      "Epoch [10/25], Step [13200/41412], Loss: 1.3301, Perplexity: 3.78146\n",
      "Epoch [10/25], Step [13300/41412], Loss: 1.6987, Perplexity: 5.46709\n",
      "Epoch [10/25], Step [13400/41412], Loss: 1.6853, Perplexity: 5.39428\n",
      "Epoch [10/25], Step [13500/41412], Loss: 1.6456, Perplexity: 5.18397\n",
      "Epoch [10/25], Step [13600/41412], Loss: 1.6825, Perplexity: 5.37923\n",
      "Epoch [10/25], Step [13700/41412], Loss: 2.8993, Perplexity: 18.1606\n",
      "Epoch [10/25], Step [13800/41412], Loss: 2.1816, Perplexity: 8.86054\n",
      "Epoch [10/25], Step [13900/41412], Loss: 1.9450, Perplexity: 6.99378\n",
      "Epoch [10/25], Step [14000/41412], Loss: 2.0175, Perplexity: 7.51952\n",
      "Epoch [10/25], Step [14100/41412], Loss: 3.0507, Perplexity: 21.1297\n",
      "Epoch [10/25], Step [14200/41412], Loss: 1.9293, Perplexity: 6.88466\n",
      "Epoch [10/25], Step [14300/41412], Loss: 1.7462, Perplexity: 5.73262\n",
      "Epoch [10/25], Step [14400/41412], Loss: 1.3584, Perplexity: 3.89016\n",
      "Epoch [10/25], Step [14500/41412], Loss: 1.7507, Perplexity: 5.75882\n",
      "Epoch [10/25], Step [14600/41412], Loss: 1.7550, Perplexity: 5.78366\n",
      "Epoch [10/25], Step [14700/41412], Loss: 1.5253, Perplexity: 4.59669\n",
      "Epoch [10/25], Step [14800/41412], Loss: 2.3491, Perplexity: 10.4757\n",
      "Epoch [10/25], Step [14900/41412], Loss: 1.9644, Perplexity: 7.13035\n",
      "Epoch [10/25], Step [15000/41412], Loss: 2.0667, Perplexity: 7.89862\n",
      "Epoch [10/25], Step [15100/41412], Loss: 2.3709, Perplexity: 10.7073\n",
      "Epoch [10/25], Step [15200/41412], Loss: 2.4303, Perplexity: 11.3618\n",
      "Epoch [10/25], Step [15300/41412], Loss: 2.1224, Perplexity: 8.35143\n",
      "Epoch [10/25], Step [15400/41412], Loss: 2.0734, Perplexity: 7.95219\n",
      "Epoch [10/25], Step [15500/41412], Loss: 1.5932, Perplexity: 4.91970\n",
      "Epoch [10/25], Step [15600/41412], Loss: 2.1007, Perplexity: 8.17215\n",
      "Epoch [10/25], Step [15700/41412], Loss: 2.2109, Perplexity: 9.12424\n",
      "Epoch [10/25], Step [15800/41412], Loss: 1.9894, Perplexity: 7.31140\n",
      "Epoch [10/25], Step [15900/41412], Loss: 1.2649, Perplexity: 3.54284\n",
      "Epoch [10/25], Step [16000/41412], Loss: 2.1199, Perplexity: 8.33011\n",
      "Epoch [10/25], Step [16100/41412], Loss: 1.6979, Perplexity: 5.46259\n",
      "Epoch [10/25], Step [16200/41412], Loss: 2.1224, Perplexity: 8.35124\n",
      "Epoch [10/25], Step [16300/41412], Loss: 2.1180, Perplexity: 8.31480\n",
      "Epoch [10/25], Step [16400/41412], Loss: 1.7028, Perplexity: 5.48949\n",
      "Epoch [10/25], Step [16500/41412], Loss: 2.1648, Perplexity: 8.71326\n",
      "Epoch [10/25], Step [16600/41412], Loss: 1.7638, Perplexity: 5.83474\n",
      "Epoch [10/25], Step [16700/41412], Loss: 1.7775, Perplexity: 5.91504\n",
      "Epoch [10/25], Step [16800/41412], Loss: 1.8745, Perplexity: 6.51762\n",
      "Epoch [10/25], Step [16900/41412], Loss: 2.0092, Perplexity: 7.45756\n",
      "Epoch [10/25], Step [17000/41412], Loss: 1.9590, Perplexity: 7.09213\n",
      "Epoch [10/25], Step [17100/41412], Loss: 1.8028, Perplexity: 6.06679\n",
      "Epoch [10/25], Step [17200/41412], Loss: 2.1410, Perplexity: 8.50827\n",
      "Epoch [10/25], Step [17300/41412], Loss: 2.0672, Perplexity: 7.90235\n",
      "Epoch [10/25], Step [17400/41412], Loss: 1.9302, Perplexity: 6.89118\n",
      "Epoch [10/25], Step [17500/41412], Loss: 1.9829, Perplexity: 7.26393\n",
      "Epoch [10/25], Step [17600/41412], Loss: 2.0647, Perplexity: 7.88324\n",
      "Epoch [10/25], Step [17700/41412], Loss: 2.1299, Perplexity: 8.41371\n",
      "Epoch [10/25], Step [17800/41412], Loss: 1.6438, Perplexity: 5.17461\n",
      "Epoch [10/25], Step [17900/41412], Loss: 2.1242, Perplexity: 8.36661\n",
      "Epoch [10/25], Step [18000/41412], Loss: 1.7955, Perplexity: 6.02254\n",
      "Epoch [10/25], Step [18100/41412], Loss: 1.5801, Perplexity: 4.85538\n",
      "Epoch [10/25], Step [18200/41412], Loss: 1.9904, Perplexity: 7.31840\n",
      "Epoch [10/25], Step [18300/41412], Loss: 1.8306, Perplexity: 6.23767\n",
      "Epoch [10/25], Step [18400/41412], Loss: 1.6513, Perplexity: 5.21367\n",
      "Epoch [10/25], Step [18500/41412], Loss: 1.9150, Perplexity: 6.78672\n",
      "Epoch [10/25], Step [18600/41412], Loss: 1.7738, Perplexity: 5.89306\n",
      "Epoch [10/25], Step [18700/41412], Loss: 2.3155, Perplexity: 10.1302\n",
      "Epoch [10/25], Step [18800/41412], Loss: 2.1445, Perplexity: 8.53747\n",
      "Epoch [10/25], Step [18900/41412], Loss: 2.3625, Perplexity: 10.6174\n",
      "Epoch [10/25], Step [19000/41412], Loss: 1.7506, Perplexity: 5.75834\n",
      "Epoch [10/25], Step [19100/41412], Loss: 1.8234, Perplexity: 6.19291\n",
      "Epoch [10/25], Step [19200/41412], Loss: 1.9670, Perplexity: 7.14897\n",
      "Epoch [10/25], Step [19300/41412], Loss: 2.1519, Perplexity: 8.60095\n",
      "Epoch [10/25], Step [19400/41412], Loss: 2.1361, Perplexity: 8.46682\n",
      "Epoch [10/25], Step [19500/41412], Loss: 2.2107, Perplexity: 9.12209\n",
      "Epoch [10/25], Step [19600/41412], Loss: 1.6409, Perplexity: 5.15978\n",
      "Epoch [10/25], Step [19700/41412], Loss: 2.9686, Perplexity: 19.4643\n",
      "Epoch [10/25], Step [19800/41412], Loss: 1.8061, Perplexity: 6.08653\n",
      "Epoch [10/25], Step [19900/41412], Loss: 2.3624, Perplexity: 10.6163\n",
      "Epoch [10/25], Step [20000/41412], Loss: 1.5688, Perplexity: 4.80078\n",
      "Epoch [10/25], Step [20100/41412], Loss: 1.7001, Perplexity: 5.47446\n",
      "Epoch [10/25], Step [20200/41412], Loss: 2.5125, Perplexity: 12.3357\n",
      "Epoch [10/25], Step [20300/41412], Loss: 1.8709, Perplexity: 6.49459\n",
      "Epoch [10/25], Step [20400/41412], Loss: 2.4011, Perplexity: 11.0353\n",
      "Epoch [10/25], Step [20500/41412], Loss: 2.0728, Perplexity: 7.94711\n",
      "Epoch [10/25], Step [20600/41412], Loss: 2.5153, Perplexity: 12.3707\n",
      "Epoch [10/25], Step [20700/41412], Loss: 1.4933, Perplexity: 4.45166\n",
      "Epoch [10/25], Step [20800/41412], Loss: 2.4280, Perplexity: 11.3357\n",
      "Epoch [10/25], Step [20900/41412], Loss: 1.6398, Perplexity: 5.15399\n",
      "Epoch [10/25], Step [21000/41412], Loss: 1.7494, Perplexity: 5.75104\n",
      "Epoch [10/25], Step [21100/41412], Loss: 2.0751, Perplexity: 7.96545\n",
      "Epoch [10/25], Step [21200/41412], Loss: 1.7947, Perplexity: 6.01758\n",
      "Epoch [10/25], Step [21300/41412], Loss: 2.3999, Perplexity: 11.0222\n",
      "Epoch [10/25], Step [21400/41412], Loss: 1.9409, Perplexity: 6.96515\n",
      "Epoch [10/25], Step [21500/41412], Loss: 1.9389, Perplexity: 6.95108\n",
      "Epoch [10/25], Step [21600/41412], Loss: 1.9424, Perplexity: 6.97577\n",
      "Epoch [10/25], Step [21700/41412], Loss: 2.1415, Perplexity: 8.51244\n",
      "Epoch [10/25], Step [21800/41412], Loss: 2.3289, Perplexity: 10.2661\n",
      "Epoch [10/25], Step [21900/41412], Loss: 2.3670, Perplexity: 10.6652\n",
      "Epoch [10/25], Step [22000/41412], Loss: 2.2625, Perplexity: 9.60740\n",
      "Epoch [10/25], Step [22100/41412], Loss: 1.6157, Perplexity: 5.03137\n",
      "Epoch [10/25], Step [22200/41412], Loss: 1.7021, Perplexity: 5.48529\n",
      "Epoch [10/25], Step [22300/41412], Loss: 2.4528, Perplexity: 11.6206\n",
      "Epoch [10/25], Step [22400/41412], Loss: 1.9442, Perplexity: 6.98785\n",
      "Epoch [10/25], Step [22500/41412], Loss: 1.6591, Perplexity: 5.25468\n",
      "Epoch [10/25], Step [22600/41412], Loss: 1.9808, Perplexity: 7.24878\n",
      "Epoch [10/25], Step [22700/41412], Loss: 1.8431, Perplexity: 6.31633\n",
      "Epoch [10/25], Step [22800/41412], Loss: 1.8363, Perplexity: 6.27326\n",
      "Epoch [10/25], Step [22900/41412], Loss: 1.8764, Perplexity: 6.52975\n",
      "Epoch [10/25], Step [23000/41412], Loss: 1.6519, Perplexity: 5.21678\n",
      "Epoch [10/25], Step [23100/41412], Loss: 2.0670, Perplexity: 7.90149\n",
      "Epoch [10/25], Step [23200/41412], Loss: 1.4050, Perplexity: 4.07532\n",
      "Epoch [10/25], Step [23300/41412], Loss: 2.2072, Perplexity: 9.08999\n",
      "Epoch [10/25], Step [23400/41412], Loss: 1.9825, Perplexity: 7.26083\n",
      "Epoch [10/25], Step [23500/41412], Loss: 2.0275, Perplexity: 7.59549\n",
      "Epoch [10/25], Step [23600/41412], Loss: 2.0011, Perplexity: 7.39711\n",
      "Epoch [10/25], Step [23700/41412], Loss: 2.2409, Perplexity: 9.40192\n",
      "Epoch [10/25], Step [23800/41412], Loss: 1.9189, Perplexity: 6.81338\n",
      "Epoch [10/25], Step [23900/41412], Loss: 2.1531, Perplexity: 8.61187\n",
      "Epoch [10/25], Step [24000/41412], Loss: 2.4071, Perplexity: 11.1019\n",
      "Epoch [10/25], Step [24100/41412], Loss: 2.2688, Perplexity: 9.66790\n",
      "Epoch [10/25], Step [24200/41412], Loss: 1.7978, Perplexity: 6.03649\n",
      "Epoch [10/25], Step [24300/41412], Loss: 2.0400, Perplexity: 7.69037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Step [24400/41412], Loss: 1.3255, Perplexity: 3.76428\n",
      "Epoch [10/25], Step [24500/41412], Loss: 2.3992, Perplexity: 11.0145\n",
      "Epoch [10/25], Step [24600/41412], Loss: 1.9068, Perplexity: 6.73178\n",
      "Epoch [10/25], Step [24700/41412], Loss: 1.8210, Perplexity: 6.17780\n",
      "Epoch [10/25], Step [24800/41412], Loss: 2.1071, Perplexity: 8.22479\n",
      "Epoch [10/25], Step [24900/41412], Loss: 2.1996, Perplexity: 9.02189\n",
      "Epoch [10/25], Step [25000/41412], Loss: 1.7319, Perplexity: 5.65129\n",
      "Epoch [10/25], Step [25100/41412], Loss: 2.1333, Perplexity: 8.44302\n",
      "Epoch [10/25], Step [25200/41412], Loss: 2.2520, Perplexity: 9.50657\n",
      "Epoch [10/25], Step [25300/41412], Loss: 1.9006, Perplexity: 6.68971\n",
      "Epoch [10/25], Step [25400/41412], Loss: 1.9699, Perplexity: 7.17024\n",
      "Epoch [10/25], Step [25500/41412], Loss: 1.2702, Perplexity: 3.56158\n",
      "Epoch [10/25], Step [25600/41412], Loss: 1.7339, Perplexity: 5.66291\n",
      "Epoch [10/25], Step [25700/41412], Loss: 2.3507, Perplexity: 10.4925\n",
      "Epoch [10/25], Step [25800/41412], Loss: 1.9433, Perplexity: 6.98188\n",
      "Epoch [10/25], Step [25900/41412], Loss: 2.1162, Perplexity: 8.29915\n",
      "Epoch [10/25], Step [26000/41412], Loss: 1.8052, Perplexity: 6.08144\n",
      "Epoch [10/25], Step [26100/41412], Loss: 2.1052, Perplexity: 8.20879\n",
      "Epoch [10/25], Step [26200/41412], Loss: 1.7342, Perplexity: 5.66443\n",
      "Epoch [10/25], Step [26300/41412], Loss: 2.1746, Perplexity: 8.79871\n",
      "Epoch [10/25], Step [26400/41412], Loss: 2.1786, Perplexity: 8.83371\n",
      "Epoch [10/25], Step [26500/41412], Loss: 1.8331, Perplexity: 6.25324\n",
      "Epoch [10/25], Step [26600/41412], Loss: 1.6323, Perplexity: 5.11577\n",
      "Epoch [10/25], Step [26700/41412], Loss: 2.7249, Perplexity: 15.2554\n",
      "Epoch [10/25], Step [26800/41412], Loss: 2.3525, Perplexity: 10.5120\n",
      "Epoch [10/25], Step [26900/41412], Loss: 1.8053, Perplexity: 6.081759\n",
      "Epoch [10/25], Step [27000/41412], Loss: 1.3433, Perplexity: 3.83175\n",
      "Epoch [10/25], Step [27100/41412], Loss: 1.7665, Perplexity: 5.85069\n",
      "Epoch [10/25], Step [27200/41412], Loss: 1.8929, Perplexity: 6.63863\n",
      "Epoch [10/25], Step [27300/41412], Loss: 2.4549, Perplexity: 11.6458\n",
      "Epoch [10/25], Step [27400/41412], Loss: 2.1070, Perplexity: 8.22351\n",
      "Epoch [10/25], Step [27500/41412], Loss: 1.9885, Perplexity: 7.30457\n",
      "Epoch [10/25], Step [27600/41412], Loss: 2.3471, Perplexity: 10.4555\n",
      "Epoch [10/25], Step [27700/41412], Loss: 1.7288, Perplexity: 5.63424\n",
      "Epoch [10/25], Step [27800/41412], Loss: 2.0710, Perplexity: 7.93255\n",
      "Epoch [10/25], Step [27900/41412], Loss: 1.7719, Perplexity: 5.88211\n",
      "Epoch [10/25], Step [28000/41412], Loss: 2.1365, Perplexity: 8.46979\n",
      "Epoch [10/25], Step [28100/41412], Loss: 2.0231, Perplexity: 7.56196\n",
      "Epoch [10/25], Step [28200/41412], Loss: 1.5099, Perplexity: 4.52633\n",
      "Epoch [10/25], Step [28300/41412], Loss: 1.8653, Perplexity: 6.45781\n",
      "Epoch [10/25], Step [28400/41412], Loss: 1.7851, Perplexity: 5.96040\n",
      "Epoch [10/25], Step [28500/41412], Loss: 1.7660, Perplexity: 5.84740\n",
      "Epoch [10/25], Step [28600/41412], Loss: 1.9557, Perplexity: 7.06899\n",
      "Epoch [10/25], Step [28700/41412], Loss: 2.0525, Perplexity: 7.78706\n",
      "Epoch [10/25], Step [28800/41412], Loss: 1.4546, Perplexity: 4.28279\n",
      "Epoch [10/25], Step [28900/41412], Loss: 2.1260, Perplexity: 8.38144\n",
      "Epoch [10/25], Step [29000/41412], Loss: 2.1079, Perplexity: 8.23069\n",
      "Epoch [10/25], Step [29100/41412], Loss: 2.8866, Perplexity: 17.9323\n",
      "Epoch [10/25], Step [29200/41412], Loss: 1.9987, Perplexity: 7.37973\n",
      "Epoch [10/25], Step [29300/41412], Loss: 1.6585, Perplexity: 5.25162\n",
      "Epoch [10/25], Step [29400/41412], Loss: 1.8436, Perplexity: 6.31953\n",
      "Epoch [10/25], Step [29500/41412], Loss: 2.3123, Perplexity: 10.0974\n",
      "Epoch [10/25], Step [29600/41412], Loss: 1.8266, Perplexity: 6.21242\n",
      "Epoch [10/25], Step [29700/41412], Loss: 1.9007, Perplexity: 6.69074\n",
      "Epoch [10/25], Step [29800/41412], Loss: 1.7864, Perplexity: 5.96785\n",
      "Epoch [10/25], Step [29900/41412], Loss: 1.9192, Perplexity: 6.81589\n",
      "Epoch [10/25], Step [30000/41412], Loss: 1.8077, Perplexity: 6.09649\n",
      "Epoch [10/25], Step [30100/41412], Loss: 2.2967, Perplexity: 9.94132\n",
      "Epoch [10/25], Step [30200/41412], Loss: 1.8699, Perplexity: 6.48748\n",
      "Epoch [10/25], Step [30300/41412], Loss: 1.9010, Perplexity: 6.69258\n",
      "Epoch [10/25], Step [30400/41412], Loss: 1.7412, Perplexity: 5.70433\n",
      "Epoch [10/25], Step [30500/41412], Loss: 2.2693, Perplexity: 9.67224\n",
      "Epoch [10/25], Step [30600/41412], Loss: 1.6954, Perplexity: 5.44917\n",
      "Epoch [10/25], Step [30700/41412], Loss: 1.8982, Perplexity: 6.67394\n",
      "Epoch [10/25], Step [30800/41412], Loss: 1.6199, Perplexity: 5.05289\n",
      "Epoch [10/25], Step [30900/41412], Loss: 2.2824, Perplexity: 9.80014\n",
      "Epoch [10/25], Step [31000/41412], Loss: 1.6188, Perplexity: 5.04693\n",
      "Epoch [10/25], Step [31100/41412], Loss: 1.4150, Perplexity: 4.11633\n",
      "Epoch [10/25], Step [31200/41412], Loss: 1.5414, Perplexity: 4.67125\n",
      "Epoch [10/25], Step [31300/41412], Loss: 1.9876, Perplexity: 7.29776\n",
      "Epoch [10/25], Step [31400/41412], Loss: 1.9342, Perplexity: 6.91841\n",
      "Epoch [10/25], Step [31500/41412], Loss: 1.8630, Perplexity: 6.44313\n",
      "Epoch [10/25], Step [31600/41412], Loss: 1.5177, Perplexity: 4.56198\n",
      "Epoch [10/25], Step [31700/41412], Loss: 2.1676, Perplexity: 8.73723\n",
      "Epoch [10/25], Step [31800/41412], Loss: 2.0043, Perplexity: 7.42112\n",
      "Epoch [10/25], Step [31900/41412], Loss: 1.8678, Perplexity: 6.47405\n",
      "Epoch [10/25], Step [32000/41412], Loss: 1.9232, Perplexity: 6.84279\n",
      "Epoch [10/25], Step [32100/41412], Loss: 2.0166, Perplexity: 7.51281\n",
      "Epoch [10/25], Step [32200/41412], Loss: 2.0470, Perplexity: 7.74474\n",
      "Epoch [10/25], Step [32300/41412], Loss: 2.2196, Perplexity: 9.20393\n",
      "Epoch [10/25], Step [32400/41412], Loss: 2.0765, Perplexity: 7.97624\n",
      "Epoch [10/25], Step [32500/41412], Loss: 1.8523, Perplexity: 6.37473\n",
      "Epoch [10/25], Step [32600/41412], Loss: 2.0797, Perplexity: 8.00228\n",
      "Epoch [10/25], Step [32700/41412], Loss: 1.8361, Perplexity: 6.27184\n",
      "Epoch [10/25], Step [32800/41412], Loss: 2.3581, Perplexity: 10.5708\n",
      "Epoch [10/25], Step [32900/41412], Loss: 1.8932, Perplexity: 6.64084\n",
      "Epoch [10/25], Step [33000/41412], Loss: 3.0884, Perplexity: 21.9419\n",
      "Epoch [10/25], Step [33100/41412], Loss: 2.2197, Perplexity: 9.20473\n",
      "Epoch [10/25], Step [33200/41412], Loss: 1.8177, Perplexity: 6.15742\n",
      "Epoch [10/25], Step [33300/41412], Loss: 1.8042, Perplexity: 6.07502\n",
      "Epoch [10/25], Step [33400/41412], Loss: 2.0476, Perplexity: 7.74902\n",
      "Epoch [10/25], Step [33500/41412], Loss: 2.2269, Perplexity: 9.27103\n",
      "Epoch [10/25], Step [33600/41412], Loss: 1.8616, Perplexity: 6.43438\n",
      "Epoch [10/25], Step [33700/41412], Loss: 2.3902, Perplexity: 10.9161\n",
      "Epoch [10/25], Step [33800/41412], Loss: 2.0250, Perplexity: 7.57627\n",
      "Epoch [10/25], Step [33900/41412], Loss: 1.7916, Perplexity: 5.99915\n",
      "Epoch [10/25], Step [34000/41412], Loss: 1.7537, Perplexity: 5.77615\n",
      "Epoch [10/25], Step [34100/41412], Loss: 2.2205, Perplexity: 9.21150\n",
      "Epoch [10/25], Step [34200/41412], Loss: 2.2441, Perplexity: 9.43199\n",
      "Epoch [10/25], Step [34300/41412], Loss: 1.9977, Perplexity: 7.37222\n",
      "Epoch [10/25], Step [34400/41412], Loss: 1.9338, Perplexity: 6.91552\n",
      "Epoch [10/25], Step [34500/41412], Loss: 1.9408, Perplexity: 6.96455\n",
      "Epoch [10/25], Step [34600/41412], Loss: 2.0299, Perplexity: 7.61372\n",
      "Epoch [10/25], Step [34700/41412], Loss: 1.3502, Perplexity: 3.85811\n",
      "Epoch [10/25], Step [34800/41412], Loss: 2.0975, Perplexity: 8.14568\n",
      "Epoch [10/25], Step [34900/41412], Loss: 2.3884, Perplexity: 10.8956\n",
      "Epoch [10/25], Step [35000/41412], Loss: 2.0207, Perplexity: 7.54337\n",
      "Epoch [10/25], Step [35100/41412], Loss: 1.9411, Perplexity: 6.96660\n",
      "Epoch [10/25], Step [35200/41412], Loss: 2.3880, Perplexity: 10.8919\n",
      "Epoch [10/25], Step [35300/41412], Loss: 1.7410, Perplexity: 5.70334\n",
      "Epoch [10/25], Step [35400/41412], Loss: 2.0893, Perplexity: 8.07919\n",
      "Epoch [10/25], Step [35500/41412], Loss: 2.6137, Perplexity: 13.6501\n",
      "Epoch [10/25], Step [35600/41412], Loss: 1.6588, Perplexity: 5.25296\n",
      "Epoch [10/25], Step [35700/41412], Loss: 2.1066, Perplexity: 8.22035\n",
      "Epoch [10/25], Step [35800/41412], Loss: 2.0036, Perplexity: 7.41547\n",
      "Epoch [10/25], Step [35900/41412], Loss: 2.3602, Perplexity: 10.5930\n",
      "Epoch [10/25], Step [36000/41412], Loss: 2.2267, Perplexity: 9.26973\n",
      "Epoch [10/25], Step [36100/41412], Loss: 2.1573, Perplexity: 8.64794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Step [36200/41412], Loss: 1.8718, Perplexity: 6.50000\n",
      "Epoch [10/25], Step [36300/41412], Loss: 1.9673, Perplexity: 7.15169\n",
      "Epoch [10/25], Step [36400/41412], Loss: 1.7470, Perplexity: 5.73764\n",
      "Epoch [10/25], Step [36500/41412], Loss: 1.6984, Perplexity: 5.46525\n",
      "Epoch [10/25], Step [36600/41412], Loss: 1.8761, Perplexity: 6.52817\n",
      "Epoch [10/25], Step [36700/41412], Loss: 2.2140, Perplexity: 9.15221\n",
      "Epoch [10/25], Step [36800/41412], Loss: 1.9597, Perplexity: 7.09700\n",
      "Epoch [10/25], Step [36900/41412], Loss: 1.9669, Perplexity: 7.14888\n",
      "Epoch [10/25], Step [37000/41412], Loss: 2.1881, Perplexity: 8.91824\n",
      "Epoch [10/25], Step [37100/41412], Loss: 1.9396, Perplexity: 6.95605\n",
      "Epoch [10/25], Step [37200/41412], Loss: 1.9378, Perplexity: 6.94320\n",
      "Epoch [10/25], Step [37300/41412], Loss: 1.6943, Perplexity: 5.44268\n",
      "Epoch [10/25], Step [37400/41412], Loss: 1.8510, Perplexity: 6.36608\n",
      "Epoch [10/25], Step [37500/41412], Loss: 2.0712, Perplexity: 7.93446\n",
      "Epoch [10/25], Step [37600/41412], Loss: 1.9570, Perplexity: 7.07771\n",
      "Epoch [10/25], Step [37700/41412], Loss: 1.5726, Perplexity: 4.81900\n",
      "Epoch [10/25], Step [37800/41412], Loss: 1.4712, Perplexity: 4.35469\n",
      "Epoch [10/25], Step [37900/41412], Loss: 2.4478, Perplexity: 11.5625\n",
      "Epoch [10/25], Step [38000/41412], Loss: 2.3806, Perplexity: 10.8109\n",
      "Epoch [10/25], Step [38100/41412], Loss: 2.0603, Perplexity: 7.84805\n",
      "Epoch [10/25], Step [38200/41412], Loss: 1.6798, Perplexity: 5.36448\n",
      "Epoch [10/25], Step [38300/41412], Loss: 1.9991, Perplexity: 7.38225\n",
      "Epoch [10/25], Step [38400/41412], Loss: 1.6099, Perplexity: 5.00251\n",
      "Epoch [10/25], Step [38500/41412], Loss: 2.7477, Perplexity: 15.6072\n",
      "Epoch [10/25], Step [38600/41412], Loss: 2.9776, Perplexity: 19.6407\n",
      "Epoch [10/25], Step [38700/41412], Loss: 1.6304, Perplexity: 5.10604\n",
      "Epoch [10/25], Step [38800/41412], Loss: 2.1408, Perplexity: 8.50667\n",
      "Epoch [10/25], Step [38900/41412], Loss: 1.4876, Perplexity: 4.42666\n",
      "Epoch [10/25], Step [39000/41412], Loss: 1.8718, Perplexity: 6.49985\n",
      "Epoch [10/25], Step [39100/41412], Loss: 2.3759, Perplexity: 10.7603\n",
      "Epoch [10/25], Step [39200/41412], Loss: 1.7956, Perplexity: 6.02325\n",
      "Epoch [10/25], Step [39300/41412], Loss: 1.5894, Perplexity: 4.90087\n",
      "Epoch [10/25], Step [39400/41412], Loss: 2.3609, Perplexity: 10.6002\n",
      "Epoch [10/25], Step [39500/41412], Loss: 2.1133, Perplexity: 8.27534\n",
      "Epoch [10/25], Step [39600/41412], Loss: 2.7065, Perplexity: 14.9760\n",
      "Epoch [10/25], Step [39700/41412], Loss: 1.9505, Perplexity: 7.03232\n",
      "Epoch [10/25], Step [39800/41412], Loss: 2.5297, Perplexity: 12.5498\n",
      "Epoch [10/25], Step [39900/41412], Loss: 1.8515, Perplexity: 6.36957\n",
      "Epoch [10/25], Step [40000/41412], Loss: 2.2622, Perplexity: 9.60466\n",
      "Epoch [10/25], Step [40100/41412], Loss: 2.1487, Perplexity: 8.57330\n",
      "Epoch [10/25], Step [40200/41412], Loss: 1.9236, Perplexity: 6.84548\n",
      "Epoch [10/25], Step [40300/41412], Loss: 2.2716, Perplexity: 9.69511\n",
      "Epoch [10/25], Step [40400/41412], Loss: 1.6947, Perplexity: 5.44524\n",
      "Epoch [10/25], Step [40500/41412], Loss: 1.8760, Perplexity: 6.52711\n",
      "Epoch [10/25], Step [40600/41412], Loss: 2.0197, Perplexity: 7.53570\n",
      "Epoch [10/25], Step [40700/41412], Loss: 1.7694, Perplexity: 5.86712\n",
      "Epoch [10/25], Step [40800/41412], Loss: 1.6931, Perplexity: 5.43643\n",
      "Epoch [10/25], Step [40900/41412], Loss: 2.4417, Perplexity: 11.4928\n",
      "Epoch [10/25], Step [41000/41412], Loss: 1.6654, Perplexity: 5.28775\n",
      "Epoch [10/25], Step [41100/41412], Loss: 2.2478, Perplexity: 9.46683\n",
      "Epoch [10/25], Step [41200/41412], Loss: 2.0178, Perplexity: 7.52195\n",
      "Epoch [10/25], Step [41300/41412], Loss: 1.5021, Perplexity: 4.49121\n",
      "Epoch [10/25], Step [41400/41412], Loss: 2.4257, Perplexity: 11.3103\n",
      "Epoch [11/25], Step [100/41412], Loss: 2.0595, Perplexity: 7.8418830\n",
      "Epoch [11/25], Step [200/41412], Loss: 1.8828, Perplexity: 6.57210\n",
      "Epoch [11/25], Step [300/41412], Loss: 1.7806, Perplexity: 5.93331\n",
      "Epoch [11/25], Step [400/41412], Loss: 1.7448, Perplexity: 5.72483\n",
      "Epoch [11/25], Step [500/41412], Loss: 2.2038, Perplexity: 9.05907\n",
      "Epoch [11/25], Step [600/41412], Loss: 2.5258, Perplexity: 12.5012\n",
      "Epoch [11/25], Step [700/41412], Loss: 1.9741, Perplexity: 7.20042\n",
      "Epoch [11/25], Step [800/41412], Loss: 1.3077, Perplexity: 3.69784\n",
      "Epoch [11/25], Step [900/41412], Loss: 2.0840, Perplexity: 8.03650\n",
      "Epoch [11/25], Step [1000/41412], Loss: 1.9118, Perplexity: 6.7654\n",
      "Epoch [11/25], Step [1100/41412], Loss: 1.8209, Perplexity: 6.17729\n",
      "Epoch [11/25], Step [1200/41412], Loss: 2.0906, Perplexity: 8.08976\n",
      "Epoch [11/25], Step [1300/41412], Loss: 1.8040, Perplexity: 6.07425\n",
      "Epoch [11/25], Step [1400/41412], Loss: 1.9347, Perplexity: 6.92190\n",
      "Epoch [11/25], Step [1500/41412], Loss: 2.0842, Perplexity: 8.03852\n",
      "Epoch [11/25], Step [1600/41412], Loss: 2.1600, Perplexity: 8.67151\n",
      "Epoch [11/25], Step [1700/41412], Loss: 1.8604, Perplexity: 6.42615\n",
      "Epoch [11/25], Step [1800/41412], Loss: 1.9328, Perplexity: 6.90873\n",
      "Epoch [11/25], Step [1900/41412], Loss: 1.8684, Perplexity: 6.47783\n",
      "Epoch [11/25], Step [2000/41412], Loss: 1.9340, Perplexity: 6.91734\n",
      "Epoch [11/25], Step [2100/41412], Loss: 2.3406, Perplexity: 10.3872\n",
      "Epoch [11/25], Step [2200/41412], Loss: 1.4181, Perplexity: 4.12957\n",
      "Epoch [11/25], Step [2300/41412], Loss: 2.9539, Perplexity: 19.1814\n",
      "Epoch [11/25], Step [2400/41412], Loss: 2.2485, Perplexity: 9.47366\n",
      "Epoch [11/25], Step [2500/41412], Loss: 2.0752, Perplexity: 7.96633\n",
      "Epoch [11/25], Step [2600/41412], Loss: 1.8216, Perplexity: 6.18184\n",
      "Epoch [11/25], Step [2700/41412], Loss: 2.3471, Perplexity: 10.4555\n",
      "Epoch [11/25], Step [2800/41412], Loss: 1.7648, Perplexity: 5.84045\n",
      "Epoch [11/25], Step [2900/41412], Loss: 2.0208, Perplexity: 7.54460\n",
      "Epoch [11/25], Step [3000/41412], Loss: 2.2578, Perplexity: 9.56174\n",
      "Epoch [11/25], Step [3100/41412], Loss: 2.3341, Perplexity: 10.3197\n",
      "Epoch [11/25], Step [3200/41412], Loss: 2.1822, Perplexity: 8.86558\n",
      "Epoch [11/25], Step [3300/41412], Loss: 1.3711, Perplexity: 3.93992\n",
      "Epoch [11/25], Step [3400/41412], Loss: 1.6950, Perplexity: 5.44694\n",
      "Epoch [11/25], Step [3500/41412], Loss: 2.1799, Perplexity: 8.84552\n",
      "Epoch [11/25], Step [3600/41412], Loss: 1.8009, Perplexity: 6.05523\n",
      "Epoch [11/25], Step [3700/41412], Loss: 1.7019, Perplexity: 5.48430\n",
      "Epoch [11/25], Step [3800/41412], Loss: 1.5971, Perplexity: 4.93893\n",
      "Epoch [11/25], Step [3900/41412], Loss: 2.2106, Perplexity: 9.12110\n",
      "Epoch [11/25], Step [4000/41412], Loss: 1.7862, Perplexity: 5.96664\n",
      "Epoch [11/25], Step [4100/41412], Loss: 2.2362, Perplexity: 9.357761\n",
      "Epoch [11/25], Step [4200/41412], Loss: 1.8530, Perplexity: 6.37923\n",
      "Epoch [11/25], Step [4300/41412], Loss: 1.7164, Perplexity: 5.56474\n",
      "Epoch [11/25], Step [4400/41412], Loss: 1.9621, Perplexity: 7.11401\n",
      "Epoch [11/25], Step [4500/41412], Loss: 1.7489, Perplexity: 5.74834\n",
      "Epoch [11/25], Step [4600/41412], Loss: 1.8264, Perplexity: 6.21167\n",
      "Epoch [11/25], Step [4700/41412], Loss: 1.5264, Perplexity: 4.60145\n",
      "Epoch [11/25], Step [4800/41412], Loss: 2.3668, Perplexity: 10.6631\n",
      "Epoch [11/25], Step [4900/41412], Loss: 2.4270, Perplexity: 11.3246\n",
      "Epoch [11/25], Step [5000/41412], Loss: 2.0942, Perplexity: 8.11923\n",
      "Epoch [11/25], Step [5100/41412], Loss: 2.1887, Perplexity: 8.92400\n",
      "Epoch [11/25], Step [5200/41412], Loss: 2.4880, Perplexity: 12.0369\n",
      "Epoch [11/25], Step [5300/41412], Loss: 2.2927, Perplexity: 9.90163\n",
      "Epoch [11/25], Step [5400/41412], Loss: 2.4130, Perplexity: 11.1679\n",
      "Epoch [11/25], Step [5500/41412], Loss: 1.8463, Perplexity: 6.33653\n",
      "Epoch [11/25], Step [5600/41412], Loss: 2.2730, Perplexity: 9.70843\n",
      "Epoch [11/25], Step [5700/41412], Loss: 2.3172, Perplexity: 10.1470\n",
      "Epoch [11/25], Step [5800/41412], Loss: 2.0462, Perplexity: 7.73838\n",
      "Epoch [11/25], Step [5900/41412], Loss: 1.5145, Perplexity: 4.54731\n",
      "Epoch [11/25], Step [6000/41412], Loss: 2.0910, Perplexity: 8.09343\n",
      "Epoch [11/25], Step [6100/41412], Loss: 1.8154, Perplexity: 6.14335\n",
      "Epoch [11/25], Step [6200/41412], Loss: 1.8094, Perplexity: 6.10715\n",
      "Epoch [11/25], Step [6300/41412], Loss: 3.3736, Perplexity: 29.1838\n",
      "Epoch [11/25], Step [6400/41412], Loss: 1.8675, Perplexity: 6.47239\n",
      "Epoch [11/25], Step [6500/41412], Loss: 1.6269, Perplexity: 5.08823\n",
      "Epoch [11/25], Step [6600/41412], Loss: 2.3395, Perplexity: 10.3763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Step [6700/41412], Loss: 2.1347, Perplexity: 8.45416\n",
      "Epoch [11/25], Step [6800/41412], Loss: 1.5167, Perplexity: 4.55742\n",
      "Epoch [11/25], Step [6900/41412], Loss: 2.1700, Perplexity: 8.75836\n",
      "Epoch [11/25], Step [7000/41412], Loss: 1.8018, Perplexity: 6.06031\n",
      "Epoch [11/25], Step [7100/41412], Loss: 1.9919, Perplexity: 7.32956\n",
      "Epoch [11/25], Step [7200/41412], Loss: 1.3145, Perplexity: 3.72301\n",
      "Epoch [11/25], Step [7300/41412], Loss: 1.5699, Perplexity: 4.80642\n",
      "Epoch [11/25], Step [7307/41412], Loss: 2.0314, Perplexity: 7.6245"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# temporary\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "## running the training locally\n",
    "#old_time = time.time()\n",
    "#response = requests.request(\"GET\", \n",
    "#                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "#                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "\n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        ## running the training locally\n",
    "        #if time.time() - old_time > 60:\n",
    "        #    old_time = time.time()\n",
    "        #    requests.request(\"POST\", \n",
    "        #                     \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "        #                     headers={'Authorization': \"STAR \" + response.text})\n",
    "\n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "\n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "\n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "\n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "\n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.contiguous().view(-1, vocab_size), captions.contiguous().view(-1))\n",
    "\n",
    "        # Backward pass.\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "\n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "\n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "\n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
